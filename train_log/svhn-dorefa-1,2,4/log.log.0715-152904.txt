[32m[0715 14:02:42 @logger.py:92][0m Argv: /usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py -f /root/.local/share/jupyter/runtime/kernel-49d3f7f6-7d8c-4bc8-ae1e-7863be7d26fe.json
[32m[0715 14:02:42 @parallel.py:340][0m [MultiProcessRunnerZMQ] Will fork a dataflow more than one times. This assumes the datapoints are i.i.d.
[32m[0715 14:02:42 @input_source.py:221][0m Setting up the queue 'QueueInput/input_queue' for CPU prefetching ...
[32m[0715 14:02:43 @trainers.py:48][0m Building graph for a single training tower ...
[32m[0715 14:02:43 @<ipython-input-17-200335a6510d>:113][0m Binarizing weight conv1/W
[32m[0715 14:02:43 @<ipython-input-17-200335a6510d>:113][0m Binarizing weight conv2/W
[32m[0715 14:02:43 @<ipython-input-17-200335a6510d>:113][0m Binarizing weight conv3/W
[32m[0715 14:02:43 @<ipython-input-17-200335a6510d>:113][0m Binarizing weight conv4/W
[32m[0715 14:02:43 @<ipython-input-17-200335a6510d>:113][0m Binarizing weight conv5/W
[32m[0715 14:02:43 @<ipython-input-17-200335a6510d>:113][0m Binarizing weight conv6/W
[32m[0715 14:02:43 @regularize.py:97][0m regularize_cost() found 1 variables to regularize.
[32m[0715 14:02:43 @regularize.py:21][0m The following tensors will be regularized: fc1/W:0
[32m[0715 14:02:44 @model_utils.py:67][0m [36mList of Trainable Variables: 
[0mname       shape               #elements
---------  ----------------  -----------
conv0/W    [5, 5, 3, 48]            3600
conv0/b    [48]                       48
conv1/W    [3, 3, 48, 64]          27648
bn1/gamma  [64]                       64
bn1/beta   [64]                       64
conv2/W    [3, 3, 64, 64]          36864
bn2/gamma  [64]                       64
bn2/beta   [64]                       64
conv3/W    [3, 3, 64, 128]         73728
bn3/gamma  [128]                     128
bn3/beta   [128]                     128
conv4/W    [3, 3, 128, 128]       147456
bn4/gamma  [128]                     128
bn4/beta   [128]                     128
conv5/W    [3, 3, 128, 128]       147456
bn5/gamma  [128]                     128
bn5/beta   [128]                     128
conv6/W    [5, 5, 128, 512]      1638400
bn6/gamma  [512]                     512
bn6/beta   [512]                     512
fc1/W      [512, 10]                5120
fc1/b      [10]                       10[36m
Number of trainable variables: 22
Number of parameters (elements): 2082378
Storage space needed for all trainable variables: 7.94MB[0m
[32m[0715 14:02:44 @base.py:207][0m Setup callbacks graph ...
[32m[0715 14:02:44 @argtools.py:138][0m [5m[31mWRN[0m "import prctl" failed! Install python-prctl so that processes can be cleaned with guarantee.
[32m[0715 14:02:45 @inference_runner.py:148][0m [InferenceRunner] Building tower 'InferenceTower' on device /gpu:0 ...
[32m[0715 14:02:45 @<ipython-input-17-200335a6510d>:113][0m Binarizing weight conv1/W
[32m[0715 14:02:45 @<ipython-input-17-200335a6510d>:113][0m Binarizing weight conv2/W
[32m[0715 14:02:45 @<ipython-input-17-200335a6510d>:113][0m Binarizing weight conv3/W
[32m[0715 14:02:46 @<ipython-input-17-200335a6510d>:113][0m Binarizing weight conv4/W
[32m[0715 14:02:46 @<ipython-input-17-200335a6510d>:113][0m Binarizing weight conv5/W
[32m[0715 14:02:46 @<ipython-input-17-200335a6510d>:113][0m Binarizing weight conv6/W
[32m[0715 14:02:46 @summary.py:47][0m [MovingAverageSummary] 5 operations in collection 'MOVING_SUMMARY_OPS' will be run with session hooks.
[32m[0715 14:02:46 @summary.py:94][0m Summarizing collection 'summaries' of size 22.
[32m[0715 14:02:46 @graph.py:99][0m Applying collection UPDATE_OPS of 12 ops.
[32m[0715 14:02:46 @base.py:228][0m Creating the session ...
[32m[0715 14:02:48 @base.py:234][0m Initializing the session ...
[32m[0715 14:02:48 @base.py:241][0m Graph Finalized.
[32m[0715 14:02:48 @concurrency.py:37][0m Starting EnqueueThread: enqueue dataflow to TF queue "QueueInput/input_queue" ...
[32m[0715 14:02:49 @inference_runner.py:95][0m [InferenceRunner] Will eval 204 iterations
[32m[0715 14:02:49 @monitor.py:361][0m [5m[31mWRN[0m History epoch=2 from JSON is not the predecessor of the current starting_epoch=1
[32m[0715 14:02:49 @monitor.py:362][0m [5m[31mWRN[0m If you want to resume old training, either use `AutoResumeTrainConfig` or correctly set the new starting_epoch yourself to avoid inconsistency. 
[32m[0715 14:02:49 @monitor.py:369][0m [5m[31mWRN[0m Now, we will train with starting_epoch=1 and backup old json to train_log/svhn-dorefa-1,2,4/stats.json.0715-140249
[32m[0715 14:02:49 @base.py:273][0m Start Epoch 1 ...
[32m[0715 14:08:00 @base.py:283][0m Epoch 1 (global_step 4721) finished, time:5 minutes 10 seconds.
[32m[0715 14:08:00 @saver.py:82][0m Model saved to train_log/svhn-dorefa-1,2,4/model-4721.
[32m[0715 14:08:13 @monitor.py:476][0m QueueInput/queue_size: 19
[32m[0715 14:08:13 @monitor.py:476][0m accuracy: 0.95088
[32m[0715 14:08:13 @monitor.py:476][0m cost: 0.1655
[32m[0715 14:08:13 @monitor.py:476][0m cross_entropy_loss: 0.1655
[32m[0715 14:08:13 @monitor.py:476][0m param-summary/conv0/W-rms: 0.17576
[32m[0715 14:08:13 @monitor.py:476][0m param-summary/conv1/W-rms: 0.078577
[32m[0715 14:08:13 @monitor.py:476][0m param-summary/conv2/W-rms: 0.071168
[32m[0715 14:08:13 @monitor.py:476][0m param-summary/conv3/W-rms: 0.074478
[32m[0715 14:08:13 @monitor.py:476][0m param-summary/conv4/W-rms: 0.062045
[32m[0715 14:08:13 @monitor.py:476][0m param-summary/conv5/W-rms: 0.065983
[32m[0715 14:08:13 @monitor.py:476][0m param-summary/conv6/W-rms: 0.052521
[32m[0715 14:08:13 @monitor.py:476][0m param-summary/fc1/W-rms: 0.10409
[32m[0715 14:08:13 @monitor.py:476][0m regularize_cost: 2.7634e-06
[32m[0715 14:08:13 @monitor.py:476][0m train_error: 0.049122
[32m[0715 14:08:13 @monitor.py:476][0m val_accuracy: 0.92184
[32m[0715 14:08:13 @monitor.py:476][0m val_cross_entropy_loss: 0.2737
[32m[0715 14:08:13 @group.py:44][0m Callbacks took 13.576 sec in total. InferenceRunner: 12.8 seconds
[32m[0715 14:08:13 @base.py:273][0m Start Epoch 2 ...
[32m[0715 14:13:04 @base.py:283][0m Epoch 2 (global_step 9442) finished, time:4 minutes 50 seconds.
[32m[0715 14:13:04 @saver.py:82][0m Model saved to train_log/svhn-dorefa-1,2,4/model-9442.
[32m[0715 14:13:16 @monitor.py:476][0m QueueInput/queue_size: 0.55469
[32m[0715 14:13:16 @monitor.py:476][0m accuracy: 0.9615
[32m[0715 14:13:16 @monitor.py:476][0m cost: 0.1334
[32m[0715 14:13:16 @monitor.py:476][0m cross_entropy_loss: 0.13339
[32m[0715 14:13:16 @monitor.py:476][0m param-summary/conv0/W-rms: 0.19275
[32m[0715 14:13:16 @monitor.py:476][0m param-summary/conv1/W-rms: 0.093796
[32m[0715 14:13:16 @monitor.py:476][0m param-summary/conv2/W-rms: 0.092398
[32m[0715 14:13:16 @monitor.py:476][0m param-summary/conv3/W-rms: 0.097813
[32m[0715 14:13:16 @monitor.py:476][0m param-summary/conv4/W-rms: 0.087621
[32m[0715 14:13:16 @monitor.py:476][0m param-summary/conv5/W-rms: 0.091966
[32m[0715 14:13:16 @monitor.py:476][0m param-summary/conv6/W-rms: 0.078654
[32m[0715 14:13:16 @monitor.py:476][0m param-summary/fc1/W-rms: 0.12801
[32m[0715 14:13:16 @monitor.py:476][0m regularize_cost: 4.1913e-06
[32m[0715 14:13:16 @monitor.py:476][0m train_error: 0.038498
[32m[0715 14:13:16 @monitor.py:476][0m val_accuracy: 0.93879
[32m[0715 14:13:16 @monitor.py:476][0m val_cross_entropy_loss: 0.21328
[32m[0715 14:13:16 @group.py:44][0m Callbacks took 12.502 sec in total. InferenceRunner: 12.1 seconds
[32m[0715 14:13:16 @base.py:273][0m Start Epoch 3 ...
[32m[0715 14:18:09 @base.py:283][0m Epoch 3 (global_step 14163) finished, time:4 minutes 52 seconds.
[32m[0715 14:18:09 @saver.py:82][0m Model saved to train_log/svhn-dorefa-1,2,4/model-14163.
[32m[0715 14:18:21 @monitor.py:476][0m QueueInput/queue_size: 3.2588e-30
[32m[0715 14:18:21 @monitor.py:476][0m accuracy: 0.97266
[32m[0715 14:18:21 @monitor.py:476][0m cost: 0.097908
[32m[0715 14:18:21 @monitor.py:476][0m cross_entropy_loss: 0.097902
[32m[0715 14:18:21 @monitor.py:476][0m param-summary/conv0/W-rms: 0.21286
[32m[0715 14:18:21 @monitor.py:476][0m param-summary/conv1/W-rms: 0.11218
[32m[0715 14:18:21 @monitor.py:476][0m param-summary/conv2/W-rms: 0.1134
[32m[0715 14:18:21 @monitor.py:476][0m param-summary/conv3/W-rms: 0.12164
[32m[0715 14:18:21 @monitor.py:476][0m param-summary/conv4/W-rms: 0.11177
[32m[0715 14:18:21 @monitor.py:476][0m param-summary/conv5/W-rms: 0.11602
[32m[0715 14:18:21 @monitor.py:476][0m param-summary/conv6/W-rms: 0.10088
[32m[0715 14:18:21 @monitor.py:476][0m param-summary/fc1/W-rms: 0.14532
[32m[0715 14:18:21 @monitor.py:476][0m regularize_cost: 5.3996e-06
[32m[0715 14:18:21 @monitor.py:476][0m train_error: 0.027341
[32m[0715 14:18:21 @monitor.py:476][0m val_accuracy: 0.95144
[32m[0715 14:18:21 @monitor.py:476][0m val_cross_entropy_loss: 0.18067
[32m[0715 14:18:21 @group.py:44][0m Callbacks took 12.481 sec in total. InferenceRunner: 12.2 seconds
[32m[0715 14:18:21 @base.py:273][0m Start Epoch 4 ...
[32m[0715 14:23:14 @base.py:283][0m Epoch 4 (global_step 18884) finished, time:4 minutes 52 seconds.
[32m[0715 14:23:14 @saver.py:82][0m Model saved to train_log/svhn-dorefa-1,2,4/model-18884.
[32m[0715 14:23:26 @monitor.py:476][0m QueueInput/queue_size: 3.4925e-10
[32m[0715 14:23:26 @monitor.py:476][0m accuracy: 0.97083
[32m[0715 14:23:26 @monitor.py:476][0m cost: 0.10469
[32m[0715 14:23:26 @monitor.py:476][0m cross_entropy_loss: 0.10469
[32m[0715 14:23:26 @monitor.py:476][0m param-summary/conv0/W-rms: 0.23129
[32m[0715 14:23:26 @monitor.py:476][0m param-summary/conv1/W-rms: 0.1311
[32m[0715 14:23:26 @monitor.py:476][0m param-summary/conv2/W-rms: 0.13496
[32m[0715 14:23:26 @monitor.py:476][0m param-summary/conv3/W-rms: 0.1417
[32m[0715 14:23:26 @monitor.py:476][0m param-summary/conv4/W-rms: 0.13243
[32m[0715 14:23:26 @monitor.py:476][0m param-summary/conv5/W-rms: 0.13764
[32m[0715 14:23:26 @monitor.py:476][0m param-summary/conv6/W-rms: 0.11945
[32m[0715 14:23:26 @monitor.py:476][0m param-summary/fc1/W-rms: 0.15858
[32m[0715 14:23:26 @monitor.py:476][0m regularize_cost: 6.4354e-06
[32m[0715 14:23:26 @monitor.py:476][0m train_error: 0.029169
[32m[0715 14:23:26 @monitor.py:476][0m val_accuracy: 0.95287
[32m[0715 14:23:26 @monitor.py:476][0m val_cross_entropy_loss: 0.17245
[32m[0715 14:23:26 @group.py:44][0m Callbacks took 12.327 sec in total. InferenceRunner: 12 seconds
[32m[0715 14:23:26 @base.py:273][0m Start Epoch 5 ...
[32m[0715 14:28:22 @base.py:283][0m Epoch 5 (global_step 23605) finished, time:4 minutes 55 seconds.
[32m[0715 14:28:22 @saver.py:82][0m Model saved to train_log/svhn-dorefa-1,2,4/model-23605.
[32m[0715 14:28:33 @monitor.py:476][0m QueueInput/queue_size: 1.3531e-26
[32m[0715 14:28:33 @monitor.py:476][0m accuracy: 0.97286
[32m[0715 14:28:33 @monitor.py:476][0m cost: 0.09501
[32m[0715 14:28:33 @monitor.py:476][0m cross_entropy_loss: 0.095002
[32m[0715 14:28:33 @monitor.py:476][0m param-summary/conv0/W-rms: 0.24888
[32m[0715 14:28:33 @monitor.py:476][0m param-summary/conv1/W-rms: 0.14511
[32m[0715 14:28:33 @monitor.py:476][0m param-summary/conv2/W-rms: 0.15052
[32m[0715 14:28:33 @monitor.py:476][0m param-summary/conv3/W-rms: 0.16046
[32m[0715 14:28:33 @monitor.py:476][0m param-summary/conv4/W-rms: 0.1509
[32m[0715 14:28:33 @monitor.py:476][0m param-summary/conv5/W-rms: 0.15718
[32m[0715 14:28:33 @monitor.py:476][0m param-summary/conv6/W-rms: 0.13557
[32m[0715 14:28:33 @monitor.py:476][0m param-summary/fc1/W-rms: 0.17182
[32m[0715 14:28:33 @monitor.py:476][0m regularize_cost: 7.5527e-06
[32m[0715 14:28:33 @monitor.py:476][0m train_error: 0.027136
[32m[0715 14:28:33 @monitor.py:476][0m val_accuracy: 0.95412
[32m[0715 14:28:33 @monitor.py:476][0m val_cross_entropy_loss: 0.16857
[32m[0715 14:28:33 @group.py:44][0m Callbacks took 11.778 sec in total. InferenceRunner: 11.5 seconds
[32m[0715 14:28:33 @base.py:273][0m Start Epoch 6 ...
[32m[0715 14:33:33 @base.py:283][0m Epoch 6 (global_step 28326) finished, time:5 minutes.
[32m[0715 14:33:34 @saver.py:82][0m Model saved to train_log/svhn-dorefa-1,2,4/model-28326.
[32m[0715 14:33:46 @monitor.py:476][0m QueueInput/queue_size: 7.1395e-17
[32m[0715 14:33:46 @monitor.py:476][0m accuracy: 0.97992
[32m[0715 14:33:46 @monitor.py:476][0m cost: 0.078589
[32m[0715 14:33:46 @monitor.py:476][0m cross_entropy_loss: 0.07858
[32m[0715 14:33:46 @monitor.py:476][0m param-summary/conv0/W-rms: 0.25885
[32m[0715 14:33:46 @monitor.py:476][0m param-summary/conv1/W-rms: 0.15598
[32m[0715 14:33:46 @monitor.py:476][0m param-summary/conv2/W-rms: 0.16919
[32m[0715 14:33:46 @monitor.py:476][0m param-summary/conv3/W-rms: 0.17897
[32m[0715 14:33:46 @monitor.py:476][0m param-summary/conv4/W-rms: 0.16855
[32m[0715 14:33:46 @monitor.py:476][0m param-summary/conv5/W-rms: 0.17577
[32m[0715 14:33:46 @monitor.py:476][0m param-summary/conv6/W-rms: 0.15025
[32m[0715 14:33:46 @monitor.py:476][0m param-summary/fc1/W-rms: 0.18472
[32m[0715 14:33:46 @monitor.py:476][0m regularize_cost: 8.7312e-06
[32m[0715 14:33:46 @monitor.py:476][0m train_error: 0.020084
[32m[0715 14:33:46 @monitor.py:476][0m val_accuracy: 0.96041
[32m[0715 14:33:46 @monitor.py:476][0m val_cross_entropy_loss: 0.1527
[32m[0715 14:33:46 @group.py:44][0m Callbacks took 12.675 sec in total. InferenceRunner: 12.4 seconds
[32m[0715 14:33:46 @base.py:273][0m Start Epoch 7 ...
[32m[0715 14:38:40 @base.py:283][0m Epoch 7 (global_step 33047) finished, time:4 minutes 53 seconds.
[32m[0715 14:38:40 @saver.py:82][0m Model saved to train_log/svhn-dorefa-1,2,4/model-33047.
[32m[0715 14:38:52 @monitor.py:476][0m QueueInput/queue_size: 1.0333
[32m[0715 14:38:52 @monitor.py:476][0m accuracy: 0.97614
[32m[0715 14:38:52 @monitor.py:476][0m cost: 0.082807
[32m[0715 14:38:52 @monitor.py:476][0m cross_entropy_loss: 0.082797
[32m[0715 14:38:52 @monitor.py:476][0m param-summary/conv0/W-rms: 0.25992
[32m[0715 14:38:52 @monitor.py:476][0m param-summary/conv1/W-rms: 0.17084
[32m[0715 14:38:52 @monitor.py:476][0m param-summary/conv2/W-rms: 0.18559
[32m[0715 14:38:52 @monitor.py:476][0m param-summary/conv3/W-rms: 0.19525
[32m[0715 14:38:52 @monitor.py:476][0m param-summary/conv4/W-rms: 0.18425
[32m[0715 14:38:52 @monitor.py:476][0m param-summary/conv5/W-rms: 0.19197
[32m[0715 14:38:52 @monitor.py:476][0m param-summary/conv6/W-rms: 0.16357
[32m[0715 14:38:52 @monitor.py:476][0m param-summary/fc1/W-rms: 0.1973
[32m[0715 14:38:52 @monitor.py:476][0m regularize_cost: 9.9643e-06
[32m[0715 14:38:52 @monitor.py:476][0m train_error: 0.023864
[32m[0715 14:38:52 @monitor.py:476][0m val_accuracy: 0.96126
[32m[0715 14:38:52 @monitor.py:476][0m val_cross_entropy_loss: 0.14981
[32m[0715 14:38:52 @group.py:44][0m Callbacks took 12.320 sec in total. InferenceRunner: 12 seconds
[32m[0715 14:38:52 @base.py:273][0m Start Epoch 8 ...
[32m[0715 14:43:43 @base.py:283][0m Epoch 8 (global_step 37768) finished, time:4 minutes 51 seconds.
[32m[0715 14:43:44 @saver.py:82][0m Model saved to train_log/svhn-dorefa-1,2,4/model-37768.
[32m[0715 14:43:56 @monitor.py:476][0m QueueInput/queue_size: 3.0734e-08
[32m[0715 14:43:56 @monitor.py:476][0m accuracy: 0.97682
[32m[0715 14:43:56 @monitor.py:476][0m cost: 0.076374
[32m[0715 14:43:56 @monitor.py:476][0m cross_entropy_loss: 0.076363
[32m[0715 14:43:56 @monitor.py:476][0m param-summary/conv0/W-rms: 0.26822
[32m[0715 14:43:56 @monitor.py:476][0m param-summary/conv1/W-rms: 0.18218
[32m[0715 14:43:56 @monitor.py:476][0m param-summary/conv2/W-rms: 0.19986
[32m[0715 14:43:56 @monitor.py:476][0m param-summary/conv3/W-rms: 0.21233
[32m[0715 14:43:56 @monitor.py:476][0m param-summary/conv4/W-rms: 0.19969
[32m[0715 14:43:56 @monitor.py:476][0m param-summary/conv5/W-rms: 0.2076
[32m[0715 14:43:56 @monitor.py:476][0m param-summary/conv6/W-rms: 0.17607
[32m[0715 14:43:56 @monitor.py:476][0m param-summary/fc1/W-rms: 0.20764
[32m[0715 14:43:56 @monitor.py:476][0m regularize_cost: 1.1025e-05
[32m[0715 14:43:56 @monitor.py:476][0m train_error: 0.023177
[32m[0715 14:43:56 @monitor.py:476][0m val_accuracy: 0.96292
[32m[0715 14:43:56 @monitor.py:476][0m val_cross_entropy_loss: 0.14542
[32m[0715 14:43:56 @group.py:44][0m Callbacks took 12.467 sec in total. InferenceRunner: 12.1 seconds
[32m[0715 14:43:56 @base.py:273][0m Start Epoch 9 ...
[32m[0715 14:48:49 @base.py:283][0m Epoch 9 (global_step 42489) finished, time:4 minutes 53 seconds.
[32m[0715 14:48:49 @saver.py:82][0m Model saved to train_log/svhn-dorefa-1,2,4/model-42489.
[32m[0715 14:49:01 @monitor.py:476][0m QueueInput/queue_size: 1.1921e-07
[32m[0715 14:49:01 @monitor.py:476][0m accuracy: 0.98016
[32m[0715 14:49:01 @monitor.py:476][0m cost: 0.06972
[32m[0715 14:49:01 @monitor.py:476][0m cross_entropy_loss: 0.069708
[32m[0715 14:49:01 @monitor.py:476][0m param-summary/conv0/W-rms: 0.27201
[32m[0715 14:49:01 @monitor.py:476][0m param-summary/conv1/W-rms: 0.19127
[32m[0715 14:49:01 @monitor.py:476][0m param-summary/conv2/W-rms: 0.21264
[32m[0715 14:49:01 @monitor.py:476][0m param-summary/conv3/W-rms: 0.22677
[32m[0715 14:49:01 @monitor.py:476][0m param-summary/conv4/W-rms: 0.2136
[32m[0715 14:49:01 @monitor.py:476][0m param-summary/conv5/W-rms: 0.22198
[32m[0715 14:49:01 @monitor.py:476][0m param-summary/conv6/W-rms: 0.18778
[32m[0715 14:49:01 @monitor.py:476][0m param-summary/fc1/W-rms: 0.21807
[32m[0715 14:49:01 @monitor.py:476][0m regularize_cost: 1.2162e-05
[32m[0715 14:49:01 @monitor.py:476][0m train_error: 0.01984
[32m[0715 14:49:01 @monitor.py:476][0m val_accuracy: 0.96205
[32m[0715 14:49:01 @monitor.py:476][0m val_cross_entropy_loss: 0.14428
[32m[0715 14:49:01 @group.py:44][0m Callbacks took 12.264 sec in total. InferenceRunner: 12 seconds
[32m[0715 14:49:01 @base.py:273][0m Start Epoch 10 ...
[32m[0715 14:54:00 @base.py:283][0m Epoch 10 (global_step 47210) finished, time:4 minutes 58 seconds.
[32m[0715 14:54:00 @saver.py:82][0m Model saved to train_log/svhn-dorefa-1,2,4/model-47210.
[32m[0715 14:54:12 @monitor.py:476][0m QueueInput/queue_size: 0.78424
[32m[0715 14:54:12 @monitor.py:476][0m accuracy: 0.97947
[32m[0715 14:54:12 @monitor.py:476][0m cost: 0.083818
[32m[0715 14:54:12 @monitor.py:476][0m cross_entropy_loss: 0.083805
[32m[0715 14:54:12 @monitor.py:476][0m param-summary/conv0/W-rms: 0.27628
[32m[0715 14:54:12 @monitor.py:476][0m param-summary/conv1/W-rms: 0.20369
[32m[0715 14:54:12 @monitor.py:476][0m param-summary/conv2/W-rms: 0.22813
[32m[0715 14:54:12 @monitor.py:476][0m param-summary/conv3/W-rms: 0.24078
[32m[0715 14:54:12 @monitor.py:476][0m param-summary/conv4/W-rms: 0.22698
[32m[0715 14:54:12 @monitor.py:476][0m param-summary/conv5/W-rms: 0.23608
[32m[0715 14:54:12 @monitor.py:476][0m param-summary/conv6/W-rms: 0.19868
[32m[0715 14:54:12 @monitor.py:476][0m param-summary/fc1/W-rms: 0.22823
[32m[0715 14:54:12 @monitor.py:476][0m regularize_cost: 1.334e-05
[32m[0715 14:54:12 @monitor.py:476][0m train_error: 0.020529
[32m[0715 14:54:12 @monitor.py:476][0m val_accuracy: 0.96253
[32m[0715 14:54:12 @monitor.py:476][0m val_cross_entropy_loss: 0.14382
[32m[0715 14:54:12 @group.py:44][0m Callbacks took 11.880 sec in total. InferenceRunner: 11.5 seconds
[32m[0715 14:54:12 @base.py:287][0m Training has finished!
[32m[0715 14:54:13 @input_source.py:177][0m [EnqueueThread] Thread EnqueueThread: enqueue dataflow to TF queue "QueueInput/input_queue" Exited.
