[32m[0721 14:27:29 @logger.py:92][0m Argv: /usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py -f /root/.local/share/jupyter/runtime/kernel-d79aa494-03b5-4efe-9dd8-f98e81da4317.json
[32m[0721 14:27:30 @parallel.py:340][0m [MultiProcessRunnerZMQ] Will fork a dataflow more than one times. This assumes the datapoints are i.i.d.
[32m[0721 14:27:30 @input_source.py:221][0m Setting up the queue 'QueueInput/input_queue' for CPU prefetching ...
[32m[0721 14:27:30 @trainers.py:48][0m Building graph for a single training tower ...
[32m[0721 14:27:30 @<ipython-input-10-189c3a653236>:114][0m Binarizing weight conv0/W
[32m[0721 14:27:30 @<ipython-input-10-189c3a653236>:114][0m Binarizing weight conv1/W
[32m[0721 14:27:30 @<ipython-input-10-189c3a653236>:114][0m Binarizing weight conv2/W
[32m[0721 14:27:30 @<ipython-input-10-189c3a653236>:114][0m Binarizing weight conv3/W
[32m[0721 14:27:30 @<ipython-input-10-189c3a653236>:114][0m Binarizing weight conv4/W
[32m[0721 14:27:30 @<ipython-input-10-189c3a653236>:114][0m Binarizing weight conv5/W
[32m[0721 14:27:30 @<ipython-input-10-189c3a653236>:114][0m Binarizing weight conv6/W
[32m[0721 14:27:30 @<ipython-input-10-189c3a653236>:114][0m Binarizing weight fc1/W
[32m[0721 14:27:30 @regularize.py:97][0m regularize_cost() found 1 variables to regularize.
[32m[0721 14:27:30 @regularize.py:21][0m The following tensors will be regularized: fc1/W:0
[32m[0721 14:27:31 @model_utils.py:67][0m [36mList of Trainable Variables: 
[0mname       shape               #elements
---------  ----------------  -----------
conv0/W    [5, 5, 1, 48]            1200
conv0/b    [48]                       48
conv1/W    [3, 3, 48, 64]          27648
bn1/gamma  [64]                       64
bn1/beta   [64]                       64
conv2/W    [3, 3, 64, 64]          36864
bn2/gamma  [64]                       64
bn2/beta   [64]                       64
conv3/W    [3, 3, 64, 128]         73728
bn3/gamma  [128]                     128
bn3/beta   [128]                     128
conv4/W    [3, 3, 128, 128]       147456
bn4/gamma  [128]                     128
bn4/beta   [128]                     128
conv5/W    [3, 3, 128, 128]       147456
bn5/gamma  [128]                     128
bn5/beta   [128]                     128
conv6/W    [5, 5, 128, 512]      1638400
bn6/gamma  [512]                     512
bn6/beta   [512]                     512
fc1/W      [512, 10]                5120
fc1/b      [10]                       10[36m
Number of trainable variables: 22
Number of parameters (elements): 2079978
Storage space needed for all trainable variables: 7.93MB[0m
[32m[0721 14:27:31 @base.py:207][0m Setup callbacks graph ...
[32m[0721 14:27:31 @argtools.py:138][0m [5m[31mWRN[0m "import prctl" failed! Install python-prctl so that processes can be cleaned with guarantee.
[32m[0721 14:27:32 @inference_runner.py:148][0m [InferenceRunner] Building tower 'InferenceTower' on device /gpu:0 ...
[32m[0721 14:27:32 @<ipython-input-10-189c3a653236>:114][0m Binarizing weight conv0/W
[32m[0721 14:27:32 @<ipython-input-10-189c3a653236>:114][0m Binarizing weight conv1/W
[32m[0721 14:27:32 @<ipython-input-10-189c3a653236>:114][0m Binarizing weight conv2/W
[32m[0721 14:27:33 @<ipython-input-10-189c3a653236>:114][0m Binarizing weight conv3/W
[32m[0721 14:27:33 @<ipython-input-10-189c3a653236>:114][0m Binarizing weight conv4/W
[32m[0721 14:27:33 @<ipython-input-10-189c3a653236>:114][0m Binarizing weight conv5/W
[32m[0721 14:27:33 @<ipython-input-10-189c3a653236>:114][0m Binarizing weight conv6/W
[32m[0721 14:27:33 @<ipython-input-10-189c3a653236>:114][0m Binarizing weight fc1/W
[32m[0721 14:27:33 @summary.py:47][0m [MovingAverageSummary] 5 operations in collection 'MOVING_SUMMARY_OPS' will be run with session hooks.
[32m[0721 14:27:33 @summary.py:94][0m Summarizing collection 'summaries' of size 22.
[32m[0721 14:27:33 @graph.py:99][0m Applying collection UPDATE_OPS of 12 ops.
[32m[0721 14:27:34 @base.py:228][0m Creating the session ...
[32m[0721 14:27:34 @base.py:234][0m Initializing the session ...
[32m[0721 14:27:34 @base.py:241][0m Graph Finalized.
[32m[0721 14:27:34 @concurrency.py:37][0m Starting EnqueueThread: enqueue dataflow to TF queue "QueueInput/input_queue" ...
[32m[0721 14:27:34 @inference_runner.py:95][0m [InferenceRunner] Will eval 79 iterations
[32m[0721 14:27:35 @base.py:273][0m Start Epoch 1 ...
[32m[0721 14:27:48 @base.py:283][0m Epoch 1 (global_step 468) finished, time:13.5 seconds.
[32m[0721 14:27:48 @saver.py:82][0m Model saved to train_log/mnist-dorefa-1,6,4/model-468.
[32m[0721 14:27:49 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[0721 14:27:49 @monitor.py:476][0m accuracy: 0.97244
[32m[0721 14:27:49 @monitor.py:476][0m cost: 0.095734
[32m[0721 14:27:49 @monitor.py:476][0m cross_entropy_loss: 0.095733
[32m[0721 14:27:49 @monitor.py:476][0m param-summary/conv0/W-rms: 0.27835
[32m[0721 14:27:49 @monitor.py:476][0m param-summary/conv1/W-rms: 0.069286
[32m[0721 14:27:49 @monitor.py:476][0m param-summary/conv2/W-rms: 0.060372
[32m[0721 14:27:49 @monitor.py:476][0m param-summary/conv3/W-rms: 0.060277
[32m[0721 14:27:49 @monitor.py:476][0m param-summary/conv4/W-rms: 0.044125
[32m[0721 14:27:49 @monitor.py:476][0m param-summary/conv5/W-rms: 0.044664
[32m[0721 14:27:49 @monitor.py:476][0m param-summary/conv6/W-rms: 0.028959
[32m[0721 14:27:49 @monitor.py:476][0m param-summary/fc1/W-rms: 0.080845
[32m[0721 14:27:49 @monitor.py:476][0m regularize_cost: 1.6619e-06
[32m[0721 14:27:49 @monitor.py:476][0m train_error: 0.027562
[32m[0721 14:27:49 @monitor.py:476][0m val_accuracy: 0.97399
[32m[0721 14:27:49 @monitor.py:476][0m val_cross_entropy_loss: 0.077801
[32m[0721 14:27:49 @base.py:273][0m Start Epoch 2 ...
[32m[0721 14:28:02 @base.py:283][0m Epoch 2 (global_step 936) finished, time:12.6 seconds.
[32m[0721 14:28:02 @saver.py:82][0m Model saved to train_log/mnist-dorefa-1,6,4/model-936.
[32m[0721 14:28:03 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[0721 14:28:03 @monitor.py:476][0m accuracy: 0.97271
[32m[0721 14:28:03 @monitor.py:476][0m cost: 0.091057
[32m[0721 14:28:03 @monitor.py:476][0m cross_entropy_loss: 0.091055
[32m[0721 14:28:03 @monitor.py:476][0m param-summary/conv0/W-rms: 0.28025
[32m[0721 14:28:03 @monitor.py:476][0m param-summary/conv1/W-rms: 0.070435
[32m[0721 14:28:03 @monitor.py:476][0m param-summary/conv2/W-rms: 0.061746
[32m[0721 14:28:03 @monitor.py:476][0m param-summary/conv3/W-rms: 0.061786
[32m[0721 14:28:03 @monitor.py:476][0m param-summary/conv4/W-rms: 0.04621
[32m[0721 14:28:03 @monitor.py:476][0m param-summary/conv5/W-rms: 0.047202
[32m[0721 14:28:03 @monitor.py:476][0m param-summary/conv6/W-rms: 0.031997
[32m[0721 14:28:03 @monitor.py:476][0m param-summary/fc1/W-rms: 0.088248
[32m[0721 14:28:03 @monitor.py:476][0m regularize_cost: 1.985e-06
[32m[0721 14:28:03 @monitor.py:476][0m train_error: 0.027292
[32m[0721 14:28:03 @monitor.py:476][0m val_accuracy: 0.94136
[32m[0721 14:28:03 @monitor.py:476][0m val_cross_entropy_loss: 0.1763
[32m[0721 14:28:03 @base.py:273][0m Start Epoch 3 ...
[32m[0721 14:28:16 @base.py:283][0m Epoch 3 (global_step 1404) finished, time:13 seconds.
[32m[0721 14:28:16 @saver.py:82][0m Model saved to train_log/mnist-dorefa-1,6,4/model-1404.
[32m[0721 14:28:17 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[0721 14:28:17 @monitor.py:476][0m accuracy: 0.97856
[32m[0721 14:28:17 @monitor.py:476][0m cost: 0.06709
[32m[0721 14:28:17 @monitor.py:476][0m cross_entropy_loss: 0.067087
[32m[0721 14:28:17 @monitor.py:476][0m param-summary/conv0/W-rms: 0.28282
[32m[0721 14:28:17 @monitor.py:476][0m param-summary/conv1/W-rms: 0.071562
[32m[0721 14:28:17 @monitor.py:476][0m param-summary/conv2/W-rms: 0.062847
[32m[0721 14:28:17 @monitor.py:476][0m param-summary/conv3/W-rms: 0.063123
[32m[0721 14:28:17 @monitor.py:476][0m param-summary/conv4/W-rms: 0.047833
[32m[0721 14:28:17 @monitor.py:476][0m param-summary/conv5/W-rms: 0.049431
[32m[0721 14:28:17 @monitor.py:476][0m param-summary/conv6/W-rms: 0.034627
[32m[0721 14:28:17 @monitor.py:476][0m param-summary/fc1/W-rms: 0.093465
[32m[0721 14:28:17 @monitor.py:476][0m regularize_cost: 2.2297e-06
[32m[0721 14:28:17 @monitor.py:476][0m train_error: 0.021442
[32m[0721 14:28:17 @monitor.py:476][0m val_accuracy: 0.98299
[32m[0721 14:28:17 @monitor.py:476][0m val_cross_entropy_loss: 0.051197
[32m[0721 14:28:17 @base.py:273][0m Start Epoch 4 ...
[32m[0721 14:28:30 @base.py:283][0m Epoch 4 (global_step 1872) finished, time:12.8 seconds.
[32m[0721 14:28:30 @saver.py:82][0m Model saved to train_log/mnist-dorefa-1,6,4/model-1872.
[32m[0721 14:28:31 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[0721 14:28:31 @monitor.py:476][0m accuracy: 0.98303
[32m[0721 14:28:31 @monitor.py:476][0m cost: 0.053196
[32m[0721 14:28:31 @monitor.py:476][0m cross_entropy_loss: 0.053194
[32m[0721 14:28:31 @monitor.py:476][0m param-summary/conv0/W-rms: 0.29089
[32m[0721 14:28:31 @monitor.py:476][0m param-summary/conv1/W-rms: 0.073843
[32m[0721 14:28:31 @monitor.py:476][0m param-summary/conv2/W-rms: 0.064226
[32m[0721 14:28:31 @monitor.py:476][0m param-summary/conv3/W-rms: 0.064549
[32m[0721 14:28:31 @monitor.py:476][0m param-summary/conv4/W-rms: 0.049744
[32m[0721 14:28:31 @monitor.py:476][0m param-summary/conv5/W-rms: 0.051881
[32m[0721 14:28:31 @monitor.py:476][0m param-summary/conv6/W-rms: 0.037452
[32m[0721 14:28:31 @monitor.py:476][0m param-summary/fc1/W-rms: 0.098073
[32m[0721 14:28:31 @monitor.py:476][0m regularize_cost: 2.4524e-06
[32m[0721 14:28:31 @monitor.py:476][0m train_error: 0.016971
[32m[0721 14:28:31 @monitor.py:476][0m val_accuracy: 0.98052
[32m[0721 14:28:31 @monitor.py:476][0m val_cross_entropy_loss: 0.05998
[32m[0721 14:28:31 @base.py:273][0m Start Epoch 5 ...
[32m[0721 14:28:44 @base.py:283][0m Epoch 5 (global_step 2340) finished, time:12.8 seconds.
[32m[0721 14:28:44 @saver.py:82][0m Model saved to train_log/mnist-dorefa-1,6,4/model-2340.
[32m[0721 14:28:45 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[0721 14:28:45 @monitor.py:476][0m accuracy: 0.98862
[32m[0721 14:28:45 @monitor.py:476][0m cost: 0.036563
[32m[0721 14:28:45 @monitor.py:476][0m cross_entropy_loss: 0.03656
[32m[0721 14:28:45 @monitor.py:476][0m param-summary/conv0/W-rms: 0.2959
[32m[0721 14:28:45 @monitor.py:476][0m param-summary/conv1/W-rms: 0.075275
[32m[0721 14:28:45 @monitor.py:476][0m param-summary/conv2/W-rms: 0.065217
[32m[0721 14:28:45 @monitor.py:476][0m param-summary/conv3/W-rms: 0.065803
[32m[0721 14:28:45 @monitor.py:476][0m param-summary/conv4/W-rms: 0.051206
[32m[0721 14:28:45 @monitor.py:476][0m param-summary/conv5/W-rms: 0.05381
[32m[0721 14:28:45 @monitor.py:476][0m param-summary/conv6/W-rms: 0.039743
[32m[0721 14:28:45 @monitor.py:476][0m param-summary/fc1/W-rms: 0.10285
[32m[0721 14:28:45 @monitor.py:476][0m regularize_cost: 2.6968e-06
[32m[0721 14:28:45 @monitor.py:476][0m train_error: 0.011383
[32m[0721 14:28:45 @monitor.py:476][0m val_accuracy: 0.90447
[32m[0721 14:28:45 @monitor.py:476][0m val_cross_entropy_loss: 0.28556
[32m[0721 14:28:45 @base.py:273][0m Start Epoch 6 ...
[32m[0721 14:28:57 @base.py:283][0m Epoch 6 (global_step 2808) finished, time:12.4 seconds.
[32m[0721 14:28:57 @saver.py:82][0m Model saved to train_log/mnist-dorefa-1,6,4/model-2808.
[32m[0721 14:28:58 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[0721 14:28:58 @monitor.py:476][0m accuracy: 0.98734
[32m[0721 14:28:58 @monitor.py:476][0m cost: 0.038916
[32m[0721 14:28:58 @monitor.py:476][0m cross_entropy_loss: 0.038913
[32m[0721 14:28:58 @monitor.py:476][0m param-summary/conv0/W-rms: 0.30527
[32m[0721 14:28:58 @monitor.py:476][0m param-summary/conv1/W-rms: 0.077044
[32m[0721 14:28:58 @monitor.py:476][0m param-summary/conv2/W-rms: 0.066625
[32m[0721 14:28:58 @monitor.py:476][0m param-summary/conv3/W-rms: 0.067405
[32m[0721 14:28:58 @monitor.py:476][0m param-summary/conv4/W-rms: 0.053042
[32m[0721 14:28:58 @monitor.py:476][0m param-summary/conv5/W-rms: 0.056129
[32m[0721 14:28:58 @monitor.py:476][0m param-summary/conv6/W-rms: 0.04239
[32m[0721 14:28:58 @monitor.py:476][0m param-summary/fc1/W-rms: 0.10682
[32m[0721 14:28:58 @monitor.py:476][0m regularize_cost: 2.9107e-06
[32m[0721 14:28:58 @monitor.py:476][0m train_error: 0.012663
[32m[0721 14:28:58 @monitor.py:476][0m val_accuracy: 0.98428
[32m[0721 14:28:58 @monitor.py:476][0m val_cross_entropy_loss: 0.047919
[32m[0721 14:28:58 @base.py:273][0m Start Epoch 7 ...
[32m[0721 14:29:11 @base.py:283][0m Epoch 7 (global_step 3276) finished, time:12.6 seconds.
[32m[0721 14:29:11 @saver.py:82][0m Model saved to train_log/mnist-dorefa-1,6,4/model-3276.
[32m[0721 14:29:12 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[0721 14:29:12 @monitor.py:476][0m accuracy: 0.9929
[32m[0721 14:29:12 @monitor.py:476][0m cost: 0.025852
[32m[0721 14:29:12 @monitor.py:476][0m cross_entropy_loss: 0.025849
[32m[0721 14:29:12 @monitor.py:476][0m param-summary/conv0/W-rms: 0.31542
[32m[0721 14:29:12 @monitor.py:476][0m param-summary/conv1/W-rms: 0.078307
[32m[0721 14:29:12 @monitor.py:476][0m param-summary/conv2/W-rms: 0.067935
[32m[0721 14:29:12 @monitor.py:476][0m param-summary/conv3/W-rms: 0.069023
[32m[0721 14:29:12 @monitor.py:476][0m param-summary/conv4/W-rms: 0.054812
[32m[0721 14:29:12 @monitor.py:476][0m param-summary/conv5/W-rms: 0.058341
[32m[0721 14:29:12 @monitor.py:476][0m param-summary/conv6/W-rms: 0.044809
[32m[0721 14:29:12 @monitor.py:476][0m param-summary/fc1/W-rms: 0.11156
[32m[0721 14:29:12 @monitor.py:476][0m regularize_cost: 3.1747e-06
[32m[0721 14:29:12 @monitor.py:476][0m train_error: 0.0071037
[32m[0721 14:29:12 @monitor.py:476][0m val_accuracy: 0.98853
[32m[0721 14:29:12 @monitor.py:476][0m val_cross_entropy_loss: 0.034783
[32m[0721 14:29:12 @base.py:273][0m Start Epoch 8 ...
[32m[0721 14:29:25 @base.py:283][0m Epoch 8 (global_step 3744) finished, time:12.6 seconds.
[32m[0721 14:29:25 @saver.py:82][0m Model saved to train_log/mnist-dorefa-1,6,4/model-3744.
[32m[0721 14:29:26 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[0721 14:29:26 @monitor.py:476][0m accuracy: 0.99283
[32m[0721 14:29:26 @monitor.py:476][0m cost: 0.02408
[32m[0721 14:29:26 @monitor.py:476][0m cross_entropy_loss: 0.024076
[32m[0721 14:29:26 @monitor.py:476][0m param-summary/conv0/W-rms: 0.32338
[32m[0721 14:29:26 @monitor.py:476][0m param-summary/conv1/W-rms: 0.07961
[32m[0721 14:29:26 @monitor.py:476][0m param-summary/conv2/W-rms: 0.06906
[32m[0721 14:29:26 @monitor.py:476][0m param-summary/conv3/W-rms: 0.070368
[32m[0721 14:29:26 @monitor.py:476][0m param-summary/conv4/W-rms: 0.056675
[32m[0721 14:29:26 @monitor.py:476][0m param-summary/conv5/W-rms: 0.060462
[32m[0721 14:29:26 @monitor.py:476][0m param-summary/conv6/W-rms: 0.0472
[32m[0721 14:29:26 @monitor.py:476][0m param-summary/fc1/W-rms: 0.1162
[32m[0721 14:29:26 @monitor.py:476][0m regularize_cost: 3.4419e-06
[32m[0721 14:29:26 @monitor.py:476][0m train_error: 0.0071716
[32m[0721 14:29:26 @monitor.py:476][0m val_accuracy: 0.98259
[32m[0721 14:29:26 @monitor.py:476][0m val_cross_entropy_loss: 0.0552
[32m[0721 14:29:26 @base.py:273][0m Start Epoch 9 ...
[32m[0721 14:29:39 @base.py:283][0m Epoch 9 (global_step 4212) finished, time:12.8 seconds.
[32m[0721 14:29:39 @saver.py:82][0m Model saved to train_log/mnist-dorefa-1,6,4/model-4212.
[32m[0721 14:29:40 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[0721 14:29:40 @monitor.py:476][0m accuracy: 0.9904
[32m[0721 14:29:40 @monitor.py:476][0m cost: 0.031676
[32m[0721 14:29:40 @monitor.py:476][0m cross_entropy_loss: 0.031672
[32m[0721 14:29:40 @monitor.py:476][0m param-summary/conv0/W-rms: 0.33695
[32m[0721 14:29:40 @monitor.py:476][0m param-summary/conv1/W-rms: 0.082301
[32m[0721 14:29:40 @monitor.py:476][0m param-summary/conv2/W-rms: 0.071083
[32m[0721 14:29:40 @monitor.py:476][0m param-summary/conv3/W-rms: 0.072106
[32m[0721 14:29:40 @monitor.py:476][0m param-summary/conv4/W-rms: 0.058553
[32m[0721 14:29:40 @monitor.py:476][0m param-summary/conv5/W-rms: 0.062759
[32m[0721 14:29:40 @monitor.py:476][0m param-summary/conv6/W-rms: 0.049791
[32m[0721 14:29:40 @monitor.py:476][0m param-summary/fc1/W-rms: 0.12078
[32m[0721 14:29:40 @monitor.py:476][0m regularize_cost: 3.7239e-06
[32m[0721 14:29:40 @monitor.py:476][0m train_error: 0.0096049
[32m[0721 14:29:40 @monitor.py:476][0m val_accuracy: 0.91742
[32m[0721 14:29:40 @monitor.py:476][0m val_cross_entropy_loss: 0.26254
[32m[0721 14:29:40 @base.py:273][0m Start Epoch 10 ...
[32m[0721 14:29:52 @base.py:283][0m Epoch 10 (global_step 4680) finished, time:12.6 seconds.
[32m[0721 14:29:52 @saver.py:82][0m Model saved to train_log/mnist-dorefa-1,6,4/model-4680.
[32m[0721 14:29:53 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[0721 14:29:53 @monitor.py:476][0m accuracy: 0.99092
[32m[0721 14:29:53 @monitor.py:476][0m cost: 0.02543
[32m[0721 14:29:53 @monitor.py:476][0m cross_entropy_loss: 0.025426
[32m[0721 14:29:53 @monitor.py:476][0m param-summary/conv0/W-rms: 0.35046
[32m[0721 14:29:53 @monitor.py:476][0m param-summary/conv1/W-rms: 0.084003
[32m[0721 14:29:53 @monitor.py:476][0m param-summary/conv2/W-rms: 0.07327
[32m[0721 14:29:53 @monitor.py:476][0m param-summary/conv3/W-rms: 0.074397
[32m[0721 14:29:53 @monitor.py:476][0m param-summary/conv4/W-rms: 0.060876
[32m[0721 14:29:53 @monitor.py:476][0m param-summary/conv5/W-rms: 0.065161
[32m[0721 14:29:53 @monitor.py:476][0m param-summary/conv6/W-rms: 0.052617
[32m[0721 14:29:53 @monitor.py:476][0m param-summary/fc1/W-rms: 0.12475
[32m[0721 14:29:53 @monitor.py:476][0m regularize_cost: 3.9689e-06
[32m[0721 14:29:53 @monitor.py:476][0m train_error: 0.0090765
[32m[0721 14:29:53 @monitor.py:476][0m val_accuracy: 0.98932
[32m[0721 14:29:53 @monitor.py:476][0m val_cross_entropy_loss: 0.033551
[32m[0721 14:29:53 @base.py:287][0m Training has finished!
[32m[0721 14:29:54 @input_source.py:177][0m [EnqueueThread] Thread EnqueueThread: enqueue dataflow to TF queue "QueueInput/input_queue" Exited.
