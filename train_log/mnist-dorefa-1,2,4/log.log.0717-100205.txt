[32m[0717 09:57:58 @logger.py:92][0m Argv: /usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py -f /root/.local/share/jupyter/runtime/kernel-234ea4b0-0d2e-4527-92f7-e4e8b495e88d.json
[32m[0717 09:57:59 @parallel.py:340][0m [MultiProcessRunnerZMQ] Will fork a dataflow more than one times. This assumes the datapoints are i.i.d.
[32m[0717 09:57:59 @input_source.py:221][0m Setting up the queue 'QueueInput/input_queue' for CPU prefetching ...
[32m[0717 09:57:59 @trainers.py:48][0m Building graph for a single training tower ...
[32m[0717 09:57:59 @<ipython-input-6-9360198f0fe6>:113][0m Binarizing weight conv0/W
[32m[0717 09:57:59 @<ipython-input-6-9360198f0fe6>:113][0m Binarizing weight conv1/W
[32m[0717 09:57:59 @<ipython-input-6-9360198f0fe6>:113][0m Binarizing weight conv2/W
[32m[0717 09:57:59 @<ipython-input-6-9360198f0fe6>:113][0m Binarizing weight conv3/W
[32m[0717 09:57:59 @<ipython-input-6-9360198f0fe6>:113][0m Binarizing weight conv4/W
[32m[0717 09:57:59 @<ipython-input-6-9360198f0fe6>:113][0m Binarizing weight conv5/W
[32m[0717 09:57:59 @<ipython-input-6-9360198f0fe6>:113][0m Binarizing weight conv6/W
[32m[0717 09:57:59 @<ipython-input-6-9360198f0fe6>:113][0m Binarizing weight fc1/W
[32m[0717 09:57:59 @regularize.py:97][0m regularize_cost() found 1 variables to regularize.
[32m[0717 09:57:59 @regularize.py:21][0m The following tensors will be regularized: fc1/W:0
[32m[0717 09:58:00 @model_utils.py:67][0m [36mList of Trainable Variables: 
[0mname       shape               #elements
---------  ----------------  -----------
conv0/W    [5, 5, 1, 48]            1200
conv0/b    [48]                       48
conv1/W    [3, 3, 48, 64]          27648
bn1/gamma  [64]                       64
bn1/beta   [64]                       64
conv2/W    [3, 3, 64, 64]          36864
bn2/gamma  [64]                       64
bn2/beta   [64]                       64
conv3/W    [3, 3, 64, 128]         73728
bn3/gamma  [128]                     128
bn3/beta   [128]                     128
conv4/W    [3, 3, 128, 128]       147456
bn4/gamma  [128]                     128
bn4/beta   [128]                     128
conv5/W    [3, 3, 128, 128]       147456
bn5/gamma  [128]                     128
bn5/beta   [128]                     128
conv6/W    [5, 5, 128, 512]      1638400
bn6/gamma  [512]                     512
bn6/beta   [512]                     512
fc1/W      [512, 10]                5120
fc1/b      [10]                       10[36m
Number of trainable variables: 22
Number of parameters (elements): 2079978
Storage space needed for all trainable variables: 7.93MB[0m
[32m[0717 09:58:00 @base.py:207][0m Setup callbacks graph ...
[32m[0717 09:58:00 @argtools.py:138][0m [5m[31mWRN[0m "import prctl" failed! Install python-prctl so that processes can be cleaned with guarantee.
[32m[0717 09:58:01 @inference_runner.py:148][0m [InferenceRunner] Building tower 'InferenceTower' on device /gpu:0 ...
[32m[0717 09:58:01 @<ipython-input-6-9360198f0fe6>:113][0m Binarizing weight conv0/W
[32m[0717 09:58:01 @<ipython-input-6-9360198f0fe6>:113][0m Binarizing weight conv1/W
[32m[0717 09:58:01 @<ipython-input-6-9360198f0fe6>:113][0m Binarizing weight conv2/W
[32m[0717 09:58:02 @<ipython-input-6-9360198f0fe6>:113][0m Binarizing weight conv3/W
[32m[0717 09:58:02 @<ipython-input-6-9360198f0fe6>:113][0m Binarizing weight conv4/W
[32m[0717 09:58:02 @<ipython-input-6-9360198f0fe6>:113][0m Binarizing weight conv5/W
[32m[0717 09:58:02 @<ipython-input-6-9360198f0fe6>:113][0m Binarizing weight conv6/W
[32m[0717 09:58:02 @<ipython-input-6-9360198f0fe6>:113][0m Binarizing weight fc1/W
[32m[0717 09:58:02 @summary.py:47][0m [MovingAverageSummary] 5 operations in collection 'MOVING_SUMMARY_OPS' will be run with session hooks.
[32m[0717 09:58:02 @summary.py:94][0m Summarizing collection 'summaries' of size 22.
[32m[0717 09:58:02 @graph.py:99][0m Applying collection UPDATE_OPS of 12 ops.
[32m[0717 09:58:03 @base.py:228][0m Creating the session ...
[32m[0717 09:58:03 @base.py:234][0m Initializing the session ...
[32m[0717 09:58:03 @base.py:241][0m Graph Finalized.
[32m[0717 09:58:03 @concurrency.py:37][0m Starting EnqueueThread: enqueue dataflow to TF queue "QueueInput/input_queue" ...
[32m[0717 09:58:03 @inference_runner.py:95][0m [InferenceRunner] Will eval 79 iterations
[32m[0717 09:58:03 @monitor.py:361][0m [5m[31mWRN[0m History epoch=10 from JSON is not the predecessor of the current starting_epoch=1
[32m[0717 09:58:03 @monitor.py:362][0m [5m[31mWRN[0m If you want to resume old training, either use `AutoResumeTrainConfig` or correctly set the new starting_epoch yourself to avoid inconsistency. 
[32m[0717 09:58:03 @monitor.py:369][0m [5m[31mWRN[0m Now, we will train with starting_epoch=1 and backup old json to train_log/mnist-dorefa-1,2,4/stats.json.0717-095803
[32m[0717 09:58:03 @base.py:273][0m Start Epoch 1 ...
[32m[0717 09:58:16 @base.py:283][0m Epoch 1 (global_step 468) finished, time:12.4 seconds.
[32m[0717 09:58:16 @saver.py:82][0m Model saved to train_log/mnist-dorefa-1,2,4/model-468.
[32m[0717 09:58:17 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[0717 09:58:17 @monitor.py:476][0m accuracy: 0.10904
[32m[0717 09:58:17 @monitor.py:476][0m cost: 2.3029
[32m[0717 09:58:17 @monitor.py:476][0m cross_entropy_loss: 2.3029
[32m[0717 09:58:17 @monitor.py:476][0m param-summary/conv0/W-rms: 0.2828
[32m[0717 09:58:17 @monitor.py:476][0m param-summary/conv1/W-rms: 0.068469
[32m[0717 09:58:17 @monitor.py:476][0m param-summary/conv2/W-rms: 0.058827
[32m[0717 09:58:17 @monitor.py:476][0m param-summary/conv3/W-rms: 0.058713
[32m[0717 09:58:17 @monitor.py:476][0m param-summary/conv4/W-rms: 0.041774
[32m[0717 09:58:17 @monitor.py:476][0m param-summary/conv5/W-rms: 0.041655
[32m[0717 09:58:17 @monitor.py:476][0m param-summary/conv6/W-rms: 0.024999
[32m[0717 09:58:17 @monitor.py:476][0m param-summary/fc1/W-rms: 0.062483
[32m[0717 09:58:17 @monitor.py:476][0m regularize_cost: 1.0062e-06
[32m[0717 09:58:17 @monitor.py:476][0m train_error: 0.89096
[32m[0717 09:58:17 @monitor.py:476][0m val_accuracy: 0.11294
[32m[0717 09:58:17 @monitor.py:476][0m val_cross_entropy_loss: 2.3012
[32m[0717 09:58:17 @base.py:273][0m Start Epoch 2 ...
[32m[0717 09:58:28 @base.py:283][0m Epoch 2 (global_step 936) finished, time:11.2 seconds.
[32m[0717 09:58:28 @saver.py:82][0m Model saved to train_log/mnist-dorefa-1,2,4/model-936.
[32m[0717 09:58:29 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[0717 09:58:29 @monitor.py:476][0m accuracy: 0.11879
[32m[0717 09:58:29 @monitor.py:476][0m cost: 2.3004
[32m[0717 09:58:29 @monitor.py:476][0m cross_entropy_loss: 2.3004
[32m[0717 09:58:29 @monitor.py:476][0m param-summary/conv0/W-rms: 0.28382
[32m[0717 09:58:29 @monitor.py:476][0m param-summary/conv1/W-rms: 0.068469
[32m[0717 09:58:29 @monitor.py:476][0m param-summary/conv2/W-rms: 0.058827
[32m[0717 09:58:29 @monitor.py:476][0m param-summary/conv3/W-rms: 0.058713
[32m[0717 09:58:29 @monitor.py:476][0m param-summary/conv4/W-rms: 0.041774
[32m[0717 09:58:29 @monitor.py:476][0m param-summary/conv5/W-rms: 0.041655
[32m[0717 09:58:29 @monitor.py:476][0m param-summary/conv6/W-rms: 0.024999
[32m[0717 09:58:29 @monitor.py:476][0m param-summary/fc1/W-rms: 0.062507
[32m[0717 09:58:29 @monitor.py:476][0m regularize_cost: 9.9828e-07
[32m[0717 09:58:29 @monitor.py:476][0m train_error: 0.88121
[32m[0717 09:58:29 @monitor.py:476][0m val_accuracy: 0.11363
[32m[0717 09:58:29 @monitor.py:476][0m val_cross_entropy_loss: 2.3009
[32m[0717 09:58:29 @base.py:273][0m Start Epoch 3 ...
[32m[0717 09:58:41 @base.py:283][0m Epoch 3 (global_step 1404) finished, time:11.5 seconds.
[32m[0717 09:58:41 @saver.py:82][0m Model saved to train_log/mnist-dorefa-1,2,4/model-1404.
[32m[0717 09:58:42 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[0717 09:58:42 @monitor.py:476][0m accuracy: 0.11125
[32m[0717 09:58:42 @monitor.py:476][0m cost: 2.3015
[32m[0717 09:58:42 @monitor.py:476][0m cross_entropy_loss: 2.3015
[32m[0717 09:58:42 @monitor.py:476][0m param-summary/conv0/W-rms: 0.28479
[32m[0717 09:58:42 @monitor.py:476][0m param-summary/conv1/W-rms: 0.068469
[32m[0717 09:58:42 @monitor.py:476][0m param-summary/conv2/W-rms: 0.058827
[32m[0717 09:58:42 @monitor.py:476][0m param-summary/conv3/W-rms: 0.058713
[32m[0717 09:58:42 @monitor.py:476][0m param-summary/conv4/W-rms: 0.041774
[32m[0717 09:58:42 @monitor.py:476][0m param-summary/conv5/W-rms: 0.041655
[32m[0717 09:58:42 @monitor.py:476][0m param-summary/conv6/W-rms: 0.024999
[32m[0717 09:58:42 @monitor.py:476][0m param-summary/fc1/W-rms: 0.062287
[32m[0717 09:58:42 @monitor.py:476][0m regularize_cost: 9.9361e-07
[32m[0717 09:58:42 @monitor.py:476][0m train_error: 0.88875
[32m[0717 09:58:42 @monitor.py:476][0m val_accuracy: 0.11501
[32m[0717 09:58:42 @monitor.py:476][0m val_cross_entropy_loss: 2.3009
[32m[0717 09:58:42 @base.py:273][0m Start Epoch 4 ...
[32m[0717 09:58:53 @base.py:283][0m Epoch 4 (global_step 1872) finished, time:11.6 seconds.
[32m[0717 09:58:54 @saver.py:82][0m Model saved to train_log/mnist-dorefa-1,2,4/model-1872.
[32m[0717 09:58:54 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[0717 09:58:54 @monitor.py:476][0m accuracy: 0.11057
[32m[0717 09:58:54 @monitor.py:476][0m cost: 2.3017
[32m[0717 09:58:54 @monitor.py:476][0m cross_entropy_loss: 2.3017
[32m[0717 09:58:54 @monitor.py:476][0m param-summary/conv0/W-rms: 0.28533
[32m[0717 09:58:54 @monitor.py:476][0m param-summary/conv1/W-rms: 0.068469
[32m[0717 09:58:54 @monitor.py:476][0m param-summary/conv2/W-rms: 0.058827
[32m[0717 09:58:55 @monitor.py:476][0m param-summary/conv3/W-rms: 0.058713
[32m[0717 09:58:55 @monitor.py:476][0m param-summary/conv4/W-rms: 0.041774
[32m[0717 09:58:55 @monitor.py:476][0m param-summary/conv5/W-rms: 0.041655
[32m[0717 09:58:55 @monitor.py:476][0m param-summary/conv6/W-rms: 0.024999
[32m[0717 09:58:55 @monitor.py:476][0m param-summary/fc1/W-rms: 0.062021
[32m[0717 09:58:55 @monitor.py:476][0m regularize_cost: 9.8532e-07
[32m[0717 09:58:55 @monitor.py:476][0m train_error: 0.88943
[32m[0717 09:58:55 @monitor.py:476][0m val_accuracy: 0.11432
[32m[0717 09:58:55 @monitor.py:476][0m val_cross_entropy_loss: 2.3009
[32m[0717 09:58:55 @base.py:273][0m Start Epoch 5 ...
[32m[0717 09:59:06 @base.py:283][0m Epoch 5 (global_step 2340) finished, time:11.9 seconds.
[32m[0717 09:59:07 @saver.py:82][0m Model saved to train_log/mnist-dorefa-1,2,4/model-2340.
[32m[0717 09:59:08 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[0717 09:59:08 @monitor.py:476][0m accuracy: 0.11278
[32m[0717 09:59:08 @monitor.py:476][0m cost: 2.3019
[32m[0717 09:59:08 @monitor.py:476][0m cross_entropy_loss: 2.3019
[32m[0717 09:59:08 @monitor.py:476][0m param-summary/conv0/W-rms: 0.2856
[32m[0717 09:59:08 @monitor.py:476][0m param-summary/conv1/W-rms: 0.068469
[32m[0717 09:59:08 @monitor.py:476][0m param-summary/conv2/W-rms: 0.058827
[32m[0717 09:59:08 @monitor.py:476][0m param-summary/conv3/W-rms: 0.058713
[32m[0717 09:59:08 @monitor.py:476][0m param-summary/conv4/W-rms: 0.041774
[32m[0717 09:59:08 @monitor.py:476][0m param-summary/conv5/W-rms: 0.041655
[32m[0717 09:59:08 @monitor.py:476][0m param-summary/conv6/W-rms: 0.024999
[32m[0717 09:59:08 @monitor.py:476][0m param-summary/fc1/W-rms: 0.061857
[32m[0717 09:59:08 @monitor.py:476][0m regularize_cost: 9.8047e-07
[32m[0717 09:59:08 @monitor.py:476][0m train_error: 0.88722
[32m[0717 09:59:08 @monitor.py:476][0m val_accuracy: 0.11224
[32m[0717 09:59:08 @monitor.py:476][0m val_cross_entropy_loss: 2.3012
[32m[0717 09:59:08 @base.py:273][0m Start Epoch 6 ...
[32m[0717 09:59:19 @base.py:283][0m Epoch 6 (global_step 2808) finished, time:11.7 seconds.
[32m[0717 09:59:19 @saver.py:82][0m Model saved to train_log/mnist-dorefa-1,2,4/model-2808.
[32m[0717 09:59:20 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[0717 09:59:20 @monitor.py:476][0m accuracy: 0.11565
[32m[0717 09:59:20 @monitor.py:476][0m cost: 2.3009
[32m[0717 09:59:20 @monitor.py:476][0m cross_entropy_loss: 2.3009
[32m[0717 09:59:20 @monitor.py:476][0m param-summary/conv0/W-rms: 0.28583
[32m[0717 09:59:20 @monitor.py:476][0m param-summary/conv1/W-rms: 0.068469
[32m[0717 09:59:20 @monitor.py:476][0m param-summary/conv2/W-rms: 0.058827
[32m[0717 09:59:20 @monitor.py:476][0m param-summary/conv3/W-rms: 0.058713
[32m[0717 09:59:20 @monitor.py:476][0m param-summary/conv4/W-rms: 0.041774
[32m[0717 09:59:20 @monitor.py:476][0m param-summary/conv5/W-rms: 0.041655
[32m[0717 09:59:20 @monitor.py:476][0m param-summary/conv6/W-rms: 0.024999
[32m[0717 09:59:20 @monitor.py:476][0m param-summary/fc1/W-rms: 0.061675
[32m[0717 09:59:20 @monitor.py:476][0m regularize_cost: 9.7204e-07
[32m[0717 09:59:20 @monitor.py:476][0m train_error: 0.88435
[32m[0717 09:59:20 @monitor.py:476][0m val_accuracy: 0.11224
[32m[0717 09:59:20 @monitor.py:476][0m val_cross_entropy_loss: 2.3012
[32m[0717 09:59:20 @base.py:273][0m Start Epoch 7 ...
[32m[0717 09:59:32 @base.py:283][0m Epoch 7 (global_step 3276) finished, time:11.7 seconds.
[32m[0717 09:59:32 @saver.py:82][0m Model saved to train_log/mnist-dorefa-1,2,4/model-3276.
[32m[0717 09:59:33 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[0717 09:59:33 @monitor.py:476][0m accuracy: 0.11234
[32m[0717 09:59:33 @monitor.py:476][0m cost: 2.3007
[32m[0717 09:59:33 @monitor.py:476][0m cross_entropy_loss: 2.3007
[32m[0717 09:59:33 @monitor.py:476][0m param-summary/conv0/W-rms: 0.28615
[32m[0717 09:59:33 @monitor.py:476][0m param-summary/conv1/W-rms: 0.068469
[32m[0717 09:59:33 @monitor.py:476][0m param-summary/conv2/W-rms: 0.058827
[32m[0717 09:59:33 @monitor.py:476][0m param-summary/conv3/W-rms: 0.058713
[32m[0717 09:59:33 @monitor.py:476][0m param-summary/conv4/W-rms: 0.041774
[32m[0717 09:59:33 @monitor.py:476][0m param-summary/conv5/W-rms: 0.041655
[32m[0717 09:59:33 @monitor.py:476][0m param-summary/conv6/W-rms: 0.024999
[32m[0717 09:59:33 @monitor.py:476][0m param-summary/fc1/W-rms: 0.061905
[32m[0717 09:59:33 @monitor.py:476][0m regularize_cost: 9.8074e-07
[32m[0717 09:59:33 @monitor.py:476][0m train_error: 0.88766
[32m[0717 09:59:33 @monitor.py:476][0m val_accuracy: 0.11363
[32m[0717 09:59:33 @monitor.py:476][0m val_cross_entropy_loss: 2.3011
[32m[0717 09:59:33 @base.py:273][0m Start Epoch 8 ...
[32m[0717 09:59:45 @base.py:283][0m Epoch 8 (global_step 3744) finished, time:11.7 seconds.
[32m[0717 09:59:45 @saver.py:82][0m Model saved to train_log/mnist-dorefa-1,2,4/model-3744.
[32m[0717 09:59:46 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[0717 09:59:46 @monitor.py:476][0m accuracy: 0.1107
[32m[0717 09:59:46 @monitor.py:476][0m cost: 2.3021
[32m[0717 09:59:46 @monitor.py:476][0m cross_entropy_loss: 2.3021
[32m[0717 09:59:46 @monitor.py:476][0m param-summary/conv0/W-rms: 0.28624
[32m[0717 09:59:46 @monitor.py:476][0m param-summary/conv1/W-rms: 0.068469
[32m[0717 09:59:46 @monitor.py:476][0m param-summary/conv2/W-rms: 0.058827
[32m[0717 09:59:46 @monitor.py:476][0m param-summary/conv3/W-rms: 0.058713
[32m[0717 09:59:46 @monitor.py:476][0m param-summary/conv4/W-rms: 0.041774
[32m[0717 09:59:46 @monitor.py:476][0m param-summary/conv5/W-rms: 0.041655
[32m[0717 09:59:46 @monitor.py:476][0m param-summary/conv6/W-rms: 0.024999
[32m[0717 09:59:46 @monitor.py:476][0m param-summary/fc1/W-rms: 0.061327
[32m[0717 09:59:46 @monitor.py:476][0m regularize_cost: 9.6347e-07
[32m[0717 09:59:46 @monitor.py:476][0m train_error: 0.8893
[32m[0717 09:59:46 @monitor.py:476][0m val_accuracy: 0.11294
[32m[0717 09:59:46 @monitor.py:476][0m val_cross_entropy_loss: 2.3012
[32m[0717 09:59:46 @base.py:273][0m Start Epoch 9 ...
[32m[0717 09:59:58 @base.py:283][0m Epoch 9 (global_step 4212) finished, time:11.8 seconds.
[32m[0717 09:59:58 @saver.py:82][0m Model saved to train_log/mnist-dorefa-1,2,4/model-4212.
[32m[0717 09:59:59 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[0717 09:59:59 @monitor.py:476][0m accuracy: 0.11301
[32m[0717 09:59:59 @monitor.py:476][0m cost: 2.3013
[32m[0717 09:59:59 @monitor.py:476][0m cross_entropy_loss: 2.3013
[32m[0717 09:59:59 @monitor.py:476][0m param-summary/conv0/W-rms: 0.28648
[32m[0717 09:59:59 @monitor.py:476][0m param-summary/conv1/W-rms: 0.068469
[32m[0717 09:59:59 @monitor.py:476][0m param-summary/conv2/W-rms: 0.058827
[32m[0717 09:59:59 @monitor.py:476][0m param-summary/conv3/W-rms: 0.058713
[32m[0717 09:59:59 @monitor.py:476][0m param-summary/conv4/W-rms: 0.041774
[32m[0717 09:59:59 @monitor.py:476][0m param-summary/conv5/W-rms: 0.041655
[32m[0717 09:59:59 @monitor.py:476][0m param-summary/conv6/W-rms: 0.024999
[32m[0717 09:59:59 @monitor.py:476][0m param-summary/fc1/W-rms: 0.061004
[32m[0717 09:59:59 @monitor.py:476][0m regularize_cost: 9.5268e-07
[32m[0717 09:59:59 @monitor.py:476][0m train_error: 0.88699
[32m[0717 09:59:59 @monitor.py:476][0m val_accuracy: 0.11432
[32m[0717 09:59:59 @monitor.py:476][0m val_cross_entropy_loss: 2.3009
[32m[0717 09:59:59 @base.py:273][0m Start Epoch 10 ...
[32m[0717 10:00:10 @base.py:283][0m Epoch 10 (global_step 4680) finished, time:11.8 seconds.
[32m[0717 10:00:11 @saver.py:82][0m Model saved to train_log/mnist-dorefa-1,2,4/model-4680.
[32m[0717 10:00:11 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[0717 10:00:11 @monitor.py:476][0m accuracy: 0.11641
[32m[0717 10:00:11 @monitor.py:476][0m cost: 2.3013
[32m[0717 10:00:11 @monitor.py:476][0m cross_entropy_loss: 2.3013
[32m[0717 10:00:11 @monitor.py:476][0m param-summary/conv0/W-rms: 0.28695
[32m[0717 10:00:11 @monitor.py:476][0m param-summary/conv1/W-rms: 0.068469
[32m[0717 10:00:11 @monitor.py:476][0m param-summary/conv2/W-rms: 0.058827
[32m[0717 10:00:11 @monitor.py:476][0m param-summary/conv3/W-rms: 0.058713
[32m[0717 10:00:11 @monitor.py:476][0m param-summary/conv4/W-rms: 0.041774
[32m[0717 10:00:11 @monitor.py:476][0m param-summary/conv5/W-rms: 0.041655
[32m[0717 10:00:11 @monitor.py:476][0m param-summary/conv6/W-rms: 0.024999
[32m[0717 10:00:11 @monitor.py:476][0m param-summary/fc1/W-rms: 0.060791
[32m[0717 10:00:11 @monitor.py:476][0m regularize_cost: 9.4621e-07
[32m[0717 10:00:11 @monitor.py:476][0m train_error: 0.88359
[32m[0717 10:00:11 @monitor.py:476][0m val_accuracy: 0.11363
[32m[0717 10:00:11 @monitor.py:476][0m val_cross_entropy_loss: 2.3013
[32m[0717 10:00:11 @base.py:273][0m Start Epoch 11 ...
[32m[0717 10:00:24 @base.py:283][0m Epoch 11 (global_step 5148) finished, time:12.1 seconds.
[32m[0717 10:00:24 @saver.py:82][0m Model saved to train_log/mnist-dorefa-1,2,4/model-5148.
[32m[0717 10:00:25 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[0717 10:00:25 @monitor.py:476][0m accuracy: 0.11608
[32m[0717 10:00:25 @monitor.py:476][0m cost: 2.3005
[32m[0717 10:00:25 @monitor.py:476][0m cross_entropy_loss: 2.3005
[32m[0717 10:00:25 @monitor.py:476][0m param-summary/conv0/W-rms: 0.28688
[32m[0717 10:00:25 @monitor.py:476][0m param-summary/conv1/W-rms: 0.068469
[32m[0717 10:00:25 @monitor.py:476][0m param-summary/conv2/W-rms: 0.058827
[32m[0717 10:00:25 @monitor.py:476][0m param-summary/conv3/W-rms: 0.058713
[32m[0717 10:00:25 @monitor.py:476][0m param-summary/conv4/W-rms: 0.041774
[32m[0717 10:00:25 @monitor.py:476][0m param-summary/conv5/W-rms: 0.041655
[32m[0717 10:00:25 @monitor.py:476][0m param-summary/conv6/W-rms: 0.024999
[32m[0717 10:00:25 @monitor.py:476][0m param-summary/fc1/W-rms: 0.060623
[32m[0717 10:00:25 @monitor.py:476][0m regularize_cost: 9.4109e-07
[32m[0717 10:00:25 @monitor.py:476][0m train_error: 0.88392
[32m[0717 10:00:25 @monitor.py:476][0m val_accuracy: 0.11294
[32m[0717 10:00:25 @monitor.py:476][0m val_cross_entropy_loss: 2.3011
[32m[0717 10:00:25 @base.py:273][0m Start Epoch 12 ...
[32m[0717 10:00:37 @base.py:283][0m Epoch 12 (global_step 5616) finished, time:11.9 seconds.
[32m[0717 10:00:37 @saver.py:82][0m Model saved to train_log/mnist-dorefa-1,2,4/model-5616.
[32m[0717 10:00:38 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[0717 10:00:38 @monitor.py:476][0m accuracy: 0.11708
[32m[0717 10:00:38 @monitor.py:476][0m cost: 2.3002
[32m[0717 10:00:38 @monitor.py:476][0m cross_entropy_loss: 2.3002
[32m[0717 10:00:38 @monitor.py:476][0m param-summary/conv0/W-rms: 0.28706
[32m[0717 10:00:38 @monitor.py:476][0m param-summary/conv1/W-rms: 0.068469
[32m[0717 10:00:38 @monitor.py:476][0m param-summary/conv2/W-rms: 0.058827
[32m[0717 10:00:38 @monitor.py:476][0m param-summary/conv3/W-rms: 0.058713
[32m[0717 10:00:38 @monitor.py:476][0m param-summary/conv4/W-rms: 0.041774
[32m[0717 10:00:38 @monitor.py:476][0m param-summary/conv5/W-rms: 0.041655
[32m[0717 10:00:38 @monitor.py:476][0m param-summary/conv6/W-rms: 0.024999
[32m[0717 10:00:38 @monitor.py:476][0m param-summary/fc1/W-rms: 0.060348
[32m[0717 10:00:38 @monitor.py:476][0m regularize_cost: 9.3194e-07
[32m[0717 10:00:38 @monitor.py:476][0m train_error: 0.88292
[32m[0717 10:00:38 @monitor.py:476][0m val_accuracy: 0.11294
[32m[0717 10:00:38 @monitor.py:476][0m val_cross_entropy_loss: 2.3012
[32m[0717 10:00:38 @base.py:273][0m Start Epoch 13 ...
[32m[0717 10:00:50 @base.py:283][0m Epoch 13 (global_step 6084) finished, time:12 seconds.
[32m[0717 10:00:50 @saver.py:82][0m Model saved to train_log/mnist-dorefa-1,2,4/model-6084.
[32m[0717 10:00:51 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[0717 10:00:51 @monitor.py:476][0m accuracy: 0.1124
[32m[0717 10:00:51 @monitor.py:476][0m cost: 2.3011
[32m[0717 10:00:51 @monitor.py:476][0m cross_entropy_loss: 2.3011
[32m[0717 10:00:51 @monitor.py:476][0m param-summary/conv0/W-rms: 0.28705
[32m[0717 10:00:51 @monitor.py:476][0m param-summary/conv1/W-rms: 0.068469
[32m[0717 10:00:51 @monitor.py:476][0m param-summary/conv2/W-rms: 0.058827
[32m[0717 10:00:51 @monitor.py:476][0m param-summary/conv3/W-rms: 0.058713
[32m[0717 10:00:51 @monitor.py:476][0m param-summary/conv4/W-rms: 0.041774
[32m[0717 10:00:51 @monitor.py:476][0m param-summary/conv5/W-rms: 0.041655
[32m[0717 10:00:51 @monitor.py:476][0m param-summary/conv6/W-rms: 0.024999
[32m[0717 10:00:51 @monitor.py:476][0m param-summary/fc1/W-rms: 0.060069
[32m[0717 10:00:51 @monitor.py:476][0m regularize_cost: 9.2419e-07
[32m[0717 10:00:51 @monitor.py:476][0m train_error: 0.8876
[32m[0717 10:00:51 @monitor.py:476][0m val_accuracy: 0.11294
[32m[0717 10:00:51 @monitor.py:476][0m val_cross_entropy_loss: 2.301
[32m[0717 10:00:51 @base.py:273][0m Start Epoch 14 ...
[32m[0717 10:01:02 @base.py:283][0m Epoch 14 (global_step 6552) finished, time:11.7 seconds.
[32m[0717 10:01:02 @saver.py:82][0m Model saved to train_log/mnist-dorefa-1,2,4/model-6552.
[32m[0717 10:01:03 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[0717 10:01:03 @monitor.py:476][0m accuracy: 0.111
[32m[0717 10:01:03 @monitor.py:476][0m cost: 2.3011
[32m[0717 10:01:03 @monitor.py:476][0m cross_entropy_loss: 2.301
[32m[0717 10:01:03 @monitor.py:476][0m param-summary/conv0/W-rms: 0.28705
[32m[0717 10:01:03 @monitor.py:476][0m param-summary/conv1/W-rms: 0.068469
[32m[0717 10:01:03 @monitor.py:476][0m param-summary/conv2/W-rms: 0.058827
[32m[0717 10:01:03 @monitor.py:476][0m param-summary/conv3/W-rms: 0.058713
[32m[0717 10:01:03 @monitor.py:476][0m param-summary/conv4/W-rms: 0.041774
[32m[0717 10:01:03 @monitor.py:476][0m param-summary/conv5/W-rms: 0.041655
[32m[0717 10:01:03 @monitor.py:476][0m param-summary/conv6/W-rms: 0.024999
[32m[0717 10:01:03 @monitor.py:476][0m param-summary/fc1/W-rms: 0.05981
[32m[0717 10:01:03 @monitor.py:476][0m regularize_cost: 9.161e-07
[32m[0717 10:01:03 @monitor.py:476][0m train_error: 0.889
[32m[0717 10:01:03 @monitor.py:476][0m val_accuracy: 0.11224
[32m[0717 10:01:03 @monitor.py:476][0m val_cross_entropy_loss: 2.3012
[32m[0717 10:01:03 @base.py:273][0m Start Epoch 15 ...
[32m[0717 10:01:15 @base.py:283][0m Epoch 15 (global_step 7020) finished, time:12.1 seconds.
[32m[0717 10:01:16 @saver.py:82][0m Model saved to train_log/mnist-dorefa-1,2,4/model-7020.
[32m[0717 10:01:17 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[0717 10:01:17 @monitor.py:476][0m accuracy: 0.11185
[32m[0717 10:01:17 @monitor.py:476][0m cost: 2.3015
[32m[0717 10:01:17 @monitor.py:476][0m cross_entropy_loss: 2.3015
[32m[0717 10:01:17 @monitor.py:476][0m param-summary/conv0/W-rms: 0.28709
[32m[0717 10:01:17 @monitor.py:476][0m param-summary/conv1/W-rms: 0.068469
[32m[0717 10:01:17 @monitor.py:476][0m param-summary/conv2/W-rms: 0.058827
[32m[0717 10:01:17 @monitor.py:476][0m param-summary/conv3/W-rms: 0.058713
[32m[0717 10:01:17 @monitor.py:476][0m param-summary/conv4/W-rms: 0.041774
[32m[0717 10:01:17 @monitor.py:476][0m param-summary/conv5/W-rms: 0.041655
[32m[0717 10:01:17 @monitor.py:476][0m param-summary/conv6/W-rms: 0.024999
[32m[0717 10:01:17 @monitor.py:476][0m param-summary/fc1/W-rms: 0.059537
[32m[0717 10:01:17 @monitor.py:476][0m regularize_cost: 9.0772e-07
[32m[0717 10:01:17 @monitor.py:476][0m train_error: 0.88815
[32m[0717 10:01:17 @monitor.py:476][0m val_accuracy: 0.11294
[32m[0717 10:01:17 @monitor.py:476][0m val_cross_entropy_loss: 2.3012
[32m[0717 10:01:17 @base.py:273][0m Start Epoch 16 ...
[32m[0717 10:01:29 @base.py:283][0m Epoch 16 (global_step 7488) finished, time:12.2 seconds.
[32m[0717 10:01:29 @saver.py:82][0m Model saved to train_log/mnist-dorefa-1,2,4/model-7488.
[32m[0717 10:01:30 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[0717 10:01:30 @monitor.py:476][0m accuracy: 0.11114
[32m[0717 10:01:30 @monitor.py:476][0m cost: 2.3007
[32m[0717 10:01:30 @monitor.py:476][0m cross_entropy_loss: 2.3007
[32m[0717 10:01:30 @monitor.py:476][0m param-summary/conv0/W-rms: 0.28688
[32m[0717 10:01:30 @monitor.py:476][0m param-summary/conv1/W-rms: 0.068469
[32m[0717 10:01:30 @monitor.py:476][0m param-summary/conv2/W-rms: 0.058827
[32m[0717 10:01:30 @monitor.py:476][0m param-summary/conv3/W-rms: 0.058713
[32m[0717 10:01:30 @monitor.py:476][0m param-summary/conv4/W-rms: 0.041774
[32m[0717 10:01:30 @monitor.py:476][0m param-summary/conv5/W-rms: 0.041655
[32m[0717 10:01:30 @monitor.py:476][0m param-summary/conv6/W-rms: 0.024999
[32m[0717 10:01:30 @monitor.py:476][0m param-summary/fc1/W-rms: 0.0593
[32m[0717 10:01:30 @monitor.py:476][0m regularize_cost: 9.0039e-07
[32m[0717 10:01:30 @monitor.py:476][0m train_error: 0.88886
[32m[0717 10:01:30 @monitor.py:476][0m val_accuracy: 0.11294
[32m[0717 10:01:30 @monitor.py:476][0m val_cross_entropy_loss: 2.3009
[32m[0717 10:01:30 @base.py:273][0m Start Epoch 17 ...
[32m[0717 10:01:42 @input_source.py:177][0m [EnqueueThread] Thread EnqueueThread: enqueue dataflow to TF queue "QueueInput/input_queue" Exited.
