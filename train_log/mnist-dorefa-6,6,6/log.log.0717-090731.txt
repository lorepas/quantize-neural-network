[32m[0717 08:47:00 @logger.py:92][0m Argv: /usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py -f /root/.local/share/jupyter/runtime/kernel-deb98920-21fb-4f50-b049-99bfb143a407.json
[32m[0717 08:47:00 @parallel.py:340][0m [MultiProcessRunnerZMQ] Will fork a dataflow more than one times. This assumes the datapoints are i.i.d.
[32m[0717 08:47:00 @input_source.py:221][0m Setting up the queue 'QueueInput/input_queue' for CPU prefetching ...
[32m[0717 08:47:00 @trainers.py:48][0m Building graph for a single training tower ...
[32m[0717 08:47:00 @<ipython-input-11-a4f74d92390c>:113][0m Binarizing weight conv0/W
[32m[0717 08:47:00 @<ipython-input-11-a4f74d92390c>:113][0m Binarizing weight conv1/W
[32m[0717 08:47:00 @<ipython-input-11-a4f74d92390c>:113][0m Binarizing weight conv2/W
[32m[0717 08:47:00 @<ipython-input-11-a4f74d92390c>:113][0m Binarizing weight conv3/W
[32m[0717 08:47:00 @<ipython-input-11-a4f74d92390c>:113][0m Binarizing weight conv4/W
[32m[0717 08:47:00 @<ipython-input-11-a4f74d92390c>:113][0m Binarizing weight conv5/W
[32m[0717 08:47:00 @<ipython-input-11-a4f74d92390c>:113][0m Binarizing weight conv6/W
[32m[0717 08:47:00 @<ipython-input-11-a4f74d92390c>:113][0m Binarizing weight fc1/W
[32m[0717 08:47:01 @regularize.py:97][0m regularize_cost() found 1 variables to regularize.
[32m[0717 08:47:01 @regularize.py:21][0m The following tensors will be regularized: fc1/W:0
[32m[0717 08:47:01 @model_utils.py:67][0m [36mList of Trainable Variables: 
[0mname       shape               #elements
---------  ----------------  -----------
conv0/W    [5, 5, 1, 48]            1200
conv0/b    [48]                       48
conv1/W    [3, 3, 48, 64]          27648
bn1/gamma  [64]                       64
bn1/beta   [64]                       64
conv2/W    [3, 3, 64, 64]          36864
bn2/gamma  [64]                       64
bn2/beta   [64]                       64
conv3/W    [3, 3, 64, 128]         73728
bn3/gamma  [128]                     128
bn3/beta   [128]                     128
conv4/W    [3, 3, 128, 128]       147456
bn4/gamma  [128]                     128
bn4/beta   [128]                     128
conv5/W    [3, 3, 128, 128]       147456
bn5/gamma  [128]                     128
bn5/beta   [128]                     128
conv6/W    [5, 5, 128, 512]      1638400
bn6/gamma  [512]                     512
bn6/beta   [512]                     512
fc1/W      [512, 10]                5120
fc1/b      [10]                       10[36m
Number of trainable variables: 22
Number of parameters (elements): 2079978
Storage space needed for all trainable variables: 7.93MB[0m
[32m[0717 08:47:01 @base.py:207][0m Setup callbacks graph ...
[32m[0717 08:47:02 @argtools.py:138][0m [5m[31mWRN[0m "import prctl" failed! Install python-prctl so that processes can be cleaned with guarantee.
[32m[0717 08:47:02 @inference_runner.py:148][0m [InferenceRunner] Building tower 'InferenceTower' on device /gpu:0 ...
[32m[0717 08:47:02 @<ipython-input-11-a4f74d92390c>:113][0m Binarizing weight conv0/W
[32m[0717 08:47:02 @<ipython-input-11-a4f74d92390c>:113][0m Binarizing weight conv1/W
[32m[0717 08:47:03 @<ipython-input-11-a4f74d92390c>:113][0m Binarizing weight conv2/W
[32m[0717 08:47:03 @<ipython-input-11-a4f74d92390c>:113][0m Binarizing weight conv3/W
[32m[0717 08:47:03 @<ipython-input-11-a4f74d92390c>:113][0m Binarizing weight conv4/W
[32m[0717 08:47:03 @<ipython-input-11-a4f74d92390c>:113][0m Binarizing weight conv5/W
[32m[0717 08:47:03 @<ipython-input-11-a4f74d92390c>:113][0m Binarizing weight conv6/W
[32m[0717 08:47:04 @<ipython-input-11-a4f74d92390c>:113][0m Binarizing weight fc1/W
[32m[0717 08:47:04 @summary.py:47][0m [MovingAverageSummary] 5 operations in collection 'MOVING_SUMMARY_OPS' will be run with session hooks.
[32m[0717 08:47:04 @summary.py:94][0m Summarizing collection 'summaries' of size 22.
[32m[0717 08:47:04 @graph.py:99][0m Applying collection UPDATE_OPS of 12 ops.
[32m[0717 08:47:04 @base.py:228][0m Creating the session ...
[32m[0717 08:47:05 @base.py:234][0m Initializing the session ...
[32m[0717 08:47:05 @base.py:241][0m Graph Finalized.
[32m[0717 08:47:05 @concurrency.py:37][0m Starting EnqueueThread: enqueue dataflow to TF queue "QueueInput/input_queue" ...
[32m[0717 08:47:05 @inference_runner.py:95][0m [InferenceRunner] Will eval 79 iterations
[32m[0717 08:47:05 @monitor.py:361][0m [5m[31mWRN[0m History epoch=100 from JSON is not the predecessor of the current starting_epoch=1
[32m[0717 08:47:05 @monitor.py:362][0m [5m[31mWRN[0m If you want to resume old training, either use `AutoResumeTrainConfig` or correctly set the new starting_epoch yourself to avoid inconsistency. 
[32m[0717 08:47:05 @monitor.py:369][0m [5m[31mWRN[0m Now, we will train with starting_epoch=1 and backup old json to train_log/mnist-dorefa-6,6,6/stats.json.0717-084705
[32m[0717 08:47:05 @base.py:273][0m Start Epoch 1 ...
[32m[0717 08:47:19 @base.py:283][0m Epoch 1 (global_step 468) finished, time:14.3 seconds.
[32m[0717 08:47:20 @saver.py:82][0m Model saved to train_log/mnist-dorefa-6,6,6/model-468.
[32m[0717 08:47:21 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[0717 08:47:21 @monitor.py:476][0m accuracy: 0.96112
[32m[0717 08:47:21 @monitor.py:476][0m cost: 0.12978
[32m[0717 08:47:21 @monitor.py:476][0m cross_entropy_loss: 0.12977
[32m[0717 08:47:21 @monitor.py:476][0m param-summary/conv0/W-rms: 0.29313
[32m[0717 08:47:21 @monitor.py:476][0m param-summary/conv1/W-rms: 0.068201
[32m[0717 08:47:21 @monitor.py:476][0m param-summary/conv2/W-rms: 0.059231
[32m[0717 08:47:21 @monitor.py:476][0m param-summary/conv3/W-rms: 0.05978
[32m[0717 08:47:21 @monitor.py:476][0m param-summary/conv4/W-rms: 0.042977
[32m[0717 08:47:21 @monitor.py:476][0m param-summary/conv5/W-rms: 0.043184
[32m[0717 08:47:21 @monitor.py:476][0m param-summary/conv6/W-rms: 0.027578
[32m[0717 08:47:21 @monitor.py:476][0m param-summary/fc1/W-rms: 0.057377
[32m[0717 08:47:21 @monitor.py:476][0m regularize_cost: 8.4523e-07
[32m[0717 08:47:21 @monitor.py:476][0m train_error: 0.038884
[32m[0717 08:47:21 @monitor.py:476][0m val_accuracy: 0.97716
[32m[0717 08:47:21 @monitor.py:476][0m val_cross_entropy_loss: 0.076027
[32m[0717 08:47:21 @base.py:273][0m Start Epoch 2 ...
[32m[0717 08:47:34 @base.py:283][0m Epoch 2 (global_step 936) finished, time:13 seconds.
[32m[0717 08:47:34 @saver.py:82][0m Model saved to train_log/mnist-dorefa-6,6,6/model-936.
[32m[0717 08:47:35 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[0717 08:47:35 @monitor.py:476][0m accuracy: 0.98
[32m[0717 08:47:35 @monitor.py:476][0m cost: 0.055304
[32m[0717 08:47:35 @monitor.py:476][0m cross_entropy_loss: 0.055303
[32m[0717 08:47:35 @monitor.py:476][0m param-summary/conv0/W-rms: 0.29354
[32m[0717 08:47:35 @monitor.py:476][0m param-summary/conv1/W-rms: 0.06893
[32m[0717 08:47:35 @monitor.py:476][0m param-summary/conv2/W-rms: 0.059483
[32m[0717 08:47:35 @monitor.py:476][0m param-summary/conv3/W-rms: 0.060091
[32m[0717 08:47:35 @monitor.py:476][0m param-summary/conv4/W-rms: 0.043447
[32m[0717 08:47:35 @monitor.py:476][0m param-summary/conv5/W-rms: 0.043826
[32m[0717 08:47:35 @monitor.py:476][0m param-summary/conv6/W-rms: 0.028597
[32m[0717 08:47:35 @monitor.py:476][0m param-summary/fc1/W-rms: 0.056737
[32m[0717 08:47:35 @monitor.py:476][0m regularize_cost: 8.2306e-07
[32m[0717 08:47:35 @monitor.py:476][0m train_error: 0.020005
[32m[0717 08:47:35 @monitor.py:476][0m val_accuracy: 0.98477
[32m[0717 08:47:35 @monitor.py:476][0m val_cross_entropy_loss: 0.044523
[32m[0717 08:47:35 @base.py:273][0m Start Epoch 3 ...
[32m[0717 08:47:48 @base.py:283][0m Epoch 3 (global_step 1404) finished, time:13.2 seconds.
[32m[0717 08:47:48 @saver.py:82][0m Model saved to train_log/mnist-dorefa-6,6,6/model-1404.
[32m[0717 08:47:49 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[0717 08:47:49 @monitor.py:476][0m accuracy: 0.98624
[32m[0717 08:47:49 @monitor.py:476][0m cost: 0.044306
[32m[0717 08:47:49 @monitor.py:476][0m cross_entropy_loss: 0.044306
[32m[0717 08:47:49 @monitor.py:476][0m param-summary/conv0/W-rms: 0.29399
[32m[0717 08:47:49 @monitor.py:476][0m param-summary/conv1/W-rms: 0.069453
[32m[0717 08:47:49 @monitor.py:476][0m param-summary/conv2/W-rms: 0.059717
[32m[0717 08:47:49 @monitor.py:476][0m param-summary/conv3/W-rms: 0.060368
[32m[0717 08:47:49 @monitor.py:476][0m param-summary/conv4/W-rms: 0.043864
[32m[0717 08:47:49 @monitor.py:476][0m param-summary/conv5/W-rms: 0.044393
[32m[0717 08:47:49 @monitor.py:476][0m param-summary/conv6/W-rms: 0.02944
[32m[0717 08:47:49 @monitor.py:476][0m param-summary/fc1/W-rms: 0.05685
[32m[0717 08:47:49 @monitor.py:476][0m regularize_cost: 8.2792e-07
[32m[0717 08:47:49 @monitor.py:476][0m train_error: 0.013761
[32m[0717 08:47:49 @monitor.py:476][0m val_accuracy: 0.98527
[32m[0717 08:47:49 @monitor.py:476][0m val_cross_entropy_loss: 0.04196
[32m[0717 08:47:49 @base.py:273][0m Start Epoch 4 ...
[32m[0717 08:48:02 @base.py:283][0m Epoch 4 (global_step 1872) finished, time:13.1 seconds.
[32m[0717 08:48:03 @saver.py:82][0m Model saved to train_log/mnist-dorefa-6,6,6/model-1872.
[32m[0717 08:48:03 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[0717 08:48:03 @monitor.py:476][0m accuracy: 0.98753
[32m[0717 08:48:03 @monitor.py:476][0m cost: 0.0382
[32m[0717 08:48:03 @monitor.py:476][0m cross_entropy_loss: 0.038199
[32m[0717 08:48:03 @monitor.py:476][0m param-summary/conv0/W-rms: 0.29423
[32m[0717 08:48:03 @monitor.py:476][0m param-summary/conv1/W-rms: 0.069977
[32m[0717 08:48:03 @monitor.py:476][0m param-summary/conv2/W-rms: 0.060005
[32m[0717 08:48:03 @monitor.py:476][0m param-summary/conv3/W-rms: 0.060731
[32m[0717 08:48:03 @monitor.py:476][0m param-summary/conv4/W-rms: 0.044363
[32m[0717 08:48:03 @monitor.py:476][0m param-summary/conv5/W-rms: 0.045079
[32m[0717 08:48:03 @monitor.py:476][0m param-summary/conv6/W-rms: 0.030378
[32m[0717 08:48:03 @monitor.py:476][0m param-summary/fc1/W-rms: 0.057284
[32m[0717 08:48:03 @monitor.py:476][0m regularize_cost: 8.3964e-07
[32m[0717 08:48:03 @monitor.py:476][0m train_error: 0.012473
[32m[0717 08:48:03 @monitor.py:476][0m val_accuracy: 0.98714
[32m[0717 08:48:03 @monitor.py:476][0m val_cross_entropy_loss: 0.040308
[32m[0717 08:48:03 @base.py:273][0m Start Epoch 5 ...
[32m[0717 08:48:16 @base.py:283][0m Epoch 5 (global_step 2340) finished, time:12.9 seconds.
[32m[0717 08:48:16 @saver.py:82][0m Model saved to train_log/mnist-dorefa-6,6,6/model-2340.
[32m[0717 08:48:17 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[0717 08:48:17 @monitor.py:476][0m accuracy: 0.98914
[32m[0717 08:48:17 @monitor.py:476][0m cost: 0.032143
[32m[0717 08:48:17 @monitor.py:476][0m cross_entropy_loss: 0.032142
[32m[0717 08:48:17 @monitor.py:476][0m param-summary/conv0/W-rms: 0.29466
[32m[0717 08:48:17 @monitor.py:476][0m param-summary/conv1/W-rms: 0.070383
[32m[0717 08:48:17 @monitor.py:476][0m param-summary/conv2/W-rms: 0.060329
[32m[0717 08:48:17 @monitor.py:476][0m param-summary/conv3/W-rms: 0.061131
[32m[0717 08:48:17 @monitor.py:476][0m param-summary/conv4/W-rms: 0.044887
[32m[0717 08:48:17 @monitor.py:476][0m param-summary/conv5/W-rms: 0.04579
[32m[0717 08:48:17 @monitor.py:476][0m param-summary/conv6/W-rms: 0.031327
[32m[0717 08:48:17 @monitor.py:476][0m param-summary/fc1/W-rms: 0.05812
[32m[0717 08:48:17 @monitor.py:476][0m regularize_cost: 8.629e-07
[32m[0717 08:48:17 @monitor.py:476][0m train_error: 0.010865
[32m[0717 08:48:17 @monitor.py:476][0m val_accuracy: 0.99021
[32m[0717 08:48:17 @monitor.py:476][0m val_cross_entropy_loss: 0.029935
[32m[0717 08:48:17 @base.py:273][0m Start Epoch 6 ...
[32m[0717 08:48:30 @base.py:283][0m Epoch 6 (global_step 2808) finished, time:12.8 seconds.
[32m[0717 08:48:30 @saver.py:82][0m Model saved to train_log/mnist-dorefa-6,6,6/model-2808.
[32m[0717 08:48:31 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[0717 08:48:31 @monitor.py:476][0m accuracy: 0.99183
[32m[0717 08:48:31 @monitor.py:476][0m cost: 0.026961
[32m[0717 08:48:31 @monitor.py:476][0m cross_entropy_loss: 0.02696
[32m[0717 08:48:31 @monitor.py:476][0m param-summary/conv0/W-rms: 0.29493
[32m[0717 08:48:31 @monitor.py:476][0m param-summary/conv1/W-rms: 0.070787
[32m[0717 08:48:31 @monitor.py:476][0m param-summary/conv2/W-rms: 0.060696
[32m[0717 08:48:31 @monitor.py:476][0m param-summary/conv3/W-rms: 0.061584
[32m[0717 08:48:31 @monitor.py:476][0m param-summary/conv4/W-rms: 0.045483
[32m[0717 08:48:31 @monitor.py:476][0m param-summary/conv5/W-rms: 0.046601
[32m[0717 08:48:31 @monitor.py:476][0m param-summary/conv6/W-rms: 0.032368
[32m[0717 08:48:31 @monitor.py:476][0m param-summary/fc1/W-rms: 0.059425
[32m[0717 08:48:31 @monitor.py:476][0m regularize_cost: 9.0188e-07
[32m[0717 08:48:31 @monitor.py:476][0m train_error: 0.0081721
[32m[0717 08:48:31 @monitor.py:476][0m val_accuracy: 0.99011
[32m[0717 08:48:31 @monitor.py:476][0m val_cross_entropy_loss: 0.027916
[32m[0717 08:48:31 @base.py:273][0m Start Epoch 7 ...
[32m[0717 08:48:44 @base.py:283][0m Epoch 7 (global_step 3276) finished, time:13 seconds.
[32m[0717 08:48:45 @saver.py:82][0m Model saved to train_log/mnist-dorefa-6,6,6/model-3276.
[32m[0717 08:48:46 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[0717 08:48:46 @monitor.py:476][0m accuracy: 0.98915
[32m[0717 08:48:46 @monitor.py:476][0m cost: 0.0323
[32m[0717 08:48:46 @monitor.py:476][0m cross_entropy_loss: 0.032299
[32m[0717 08:48:46 @monitor.py:476][0m param-summary/conv0/W-rms: 0.29524
[32m[0717 08:48:46 @monitor.py:476][0m param-summary/conv1/W-rms: 0.071219
[32m[0717 08:48:46 @monitor.py:476][0m param-summary/conv2/W-rms: 0.061151
[32m[0717 08:48:46 @monitor.py:476][0m param-summary/conv3/W-rms: 0.062166
[32m[0717 08:48:46 @monitor.py:476][0m param-summary/conv4/W-rms: 0.046246
[32m[0717 08:48:46 @monitor.py:476][0m param-summary/conv5/W-rms: 0.047606
[32m[0717 08:48:46 @monitor.py:476][0m param-summary/conv6/W-rms: 0.033602
[32m[0717 08:48:46 @monitor.py:476][0m param-summary/fc1/W-rms: 0.060828
[32m[0717 08:48:46 @monitor.py:476][0m regularize_cost: 9.4613e-07
[32m[0717 08:48:46 @monitor.py:476][0m train_error: 0.010848
[32m[0717 08:48:46 @monitor.py:476][0m val_accuracy: 0.99169
[32m[0717 08:48:46 @monitor.py:476][0m val_cross_entropy_loss: 0.025492
[32m[0717 08:48:46 @base.py:273][0m Start Epoch 8 ...
[32m[0717 08:48:59 @base.py:283][0m Epoch 8 (global_step 3744) finished, time:13.2 seconds.
[32m[0717 08:48:59 @saver.py:82][0m Model saved to train_log/mnist-dorefa-6,6,6/model-3744.
[32m[0717 08:49:00 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[0717 08:49:00 @monitor.py:476][0m accuracy: 0.99281
[32m[0717 08:49:00 @monitor.py:476][0m cost: 0.022553
[32m[0717 08:49:00 @monitor.py:476][0m cross_entropy_loss: 0.022552
[32m[0717 08:49:00 @monitor.py:476][0m param-summary/conv0/W-rms: 0.29545
[32m[0717 08:49:00 @monitor.py:476][0m param-summary/conv1/W-rms: 0.072005
[32m[0717 08:49:00 @monitor.py:476][0m param-summary/conv2/W-rms: 0.061696
[32m[0717 08:49:00 @monitor.py:476][0m param-summary/conv3/W-rms: 0.062818
[32m[0717 08:49:00 @monitor.py:476][0m param-summary/conv4/W-rms: 0.047102
[32m[0717 08:49:00 @monitor.py:476][0m param-summary/conv5/W-rms: 0.048717
[32m[0717 08:49:00 @monitor.py:476][0m param-summary/conv6/W-rms: 0.034985
[32m[0717 08:49:00 @monitor.py:476][0m param-summary/fc1/W-rms: 0.062608
[32m[0717 08:49:00 @monitor.py:476][0m regularize_cost: 1.001e-06
[32m[0717 08:49:00 @monitor.py:476][0m train_error: 0.007191
[32m[0717 08:49:00 @monitor.py:476][0m val_accuracy: 0.99189
[32m[0717 08:49:00 @monitor.py:476][0m val_cross_entropy_loss: 0.028088
[32m[0717 08:49:00 @base.py:273][0m Start Epoch 9 ...
[32m[0717 08:49:13 @base.py:283][0m Epoch 9 (global_step 4212) finished, time:13.2 seconds.
[32m[0717 08:49:13 @saver.py:82][0m Model saved to train_log/mnist-dorefa-6,6,6/model-4212.
[32m[0717 08:49:14 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[0717 08:49:14 @monitor.py:476][0m accuracy: 0.99334
[32m[0717 08:49:14 @monitor.py:476][0m cost: 0.021489
[32m[0717 08:49:14 @monitor.py:476][0m cross_entropy_loss: 0.021488
[32m[0717 08:49:14 @monitor.py:476][0m param-summary/conv0/W-rms: 0.29567
[32m[0717 08:49:14 @monitor.py:476][0m param-summary/conv1/W-rms: 0.072897
[32m[0717 08:49:14 @monitor.py:476][0m param-summary/conv2/W-rms: 0.062313
[32m[0717 08:49:14 @monitor.py:476][0m param-summary/conv3/W-rms: 0.063572
[32m[0717 08:49:14 @monitor.py:476][0m param-summary/conv4/W-rms: 0.048049
[32m[0717 08:49:14 @monitor.py:476][0m param-summary/conv5/W-rms: 0.049934
[32m[0717 08:49:14 @monitor.py:476][0m param-summary/conv6/W-rms: 0.036441
[32m[0717 08:49:14 @monitor.py:476][0m param-summary/fc1/W-rms: 0.064259
[32m[0717 08:49:14 @monitor.py:476][0m regularize_cost: 1.0537e-06
[32m[0717 08:49:14 @monitor.py:476][0m train_error: 0.0066639
[32m[0717 08:49:14 @monitor.py:476][0m val_accuracy: 0.9913
[32m[0717 08:49:14 @monitor.py:476][0m val_cross_entropy_loss: 0.025832
[32m[0717 08:49:14 @base.py:273][0m Start Epoch 10 ...
[32m[0717 08:49:27 @base.py:283][0m Epoch 10 (global_step 4680) finished, time:12.7 seconds.
[32m[0717 08:49:27 @saver.py:82][0m Model saved to train_log/mnist-dorefa-6,6,6/model-4680.
[32m[0717 08:49:28 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[0717 08:49:28 @monitor.py:476][0m accuracy: 0.99233
[32m[0717 08:49:28 @monitor.py:476][0m cost: 0.027124
[32m[0717 08:49:28 @monitor.py:476][0m cross_entropy_loss: 0.027123
[32m[0717 08:49:28 @monitor.py:476][0m param-summary/conv0/W-rms: 0.29629
[32m[0717 08:49:28 @monitor.py:476][0m param-summary/conv1/W-rms: 0.073763
[32m[0717 08:49:28 @monitor.py:476][0m param-summary/conv2/W-rms: 0.063122
[32m[0717 08:49:28 @monitor.py:476][0m param-summary/conv3/W-rms: 0.064511
[32m[0717 08:49:28 @monitor.py:476][0m param-summary/conv4/W-rms: 0.049161
[32m[0717 08:49:28 @monitor.py:476][0m param-summary/conv5/W-rms: 0.051289
[32m[0717 08:49:28 @monitor.py:476][0m param-summary/conv6/W-rms: 0.038063
[32m[0717 08:49:28 @monitor.py:476][0m param-summary/fc1/W-rms: 0.066002
[32m[0717 08:49:28 @monitor.py:476][0m regularize_cost: 1.1129e-06
[32m[0717 08:49:28 @monitor.py:476][0m train_error: 0.007668
[32m[0717 08:49:28 @monitor.py:476][0m val_accuracy: 0.9907
[32m[0717 08:49:28 @monitor.py:476][0m val_cross_entropy_loss: 0.028652
[32m[0717 08:49:28 @base.py:273][0m Start Epoch 11 ...
[32m[0717 08:49:41 @base.py:283][0m Epoch 11 (global_step 5148) finished, time:12.9 seconds.
[32m[0717 08:49:41 @saver.py:82][0m Model saved to train_log/mnist-dorefa-6,6,6/model-5148.
[32m[0717 08:49:42 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[0717 08:49:42 @monitor.py:476][0m accuracy: 0.99375
[32m[0717 08:49:42 @monitor.py:476][0m cost: 0.019766
[32m[0717 08:49:42 @monitor.py:476][0m cross_entropy_loss: 0.019765
[32m[0717 08:49:42 @monitor.py:476][0m param-summary/conv0/W-rms: 0.29669
[32m[0717 08:49:42 @monitor.py:476][0m param-summary/conv1/W-rms: 0.074327
[32m[0717 08:49:42 @monitor.py:476][0m param-summary/conv2/W-rms: 0.063939
[32m[0717 08:49:42 @monitor.py:476][0m param-summary/conv3/W-rms: 0.065493
[32m[0717 08:49:42 @monitor.py:476][0m param-summary/conv4/W-rms: 0.050263
[32m[0717 08:49:42 @monitor.py:476][0m param-summary/conv5/W-rms: 0.052703
[32m[0717 08:49:42 @monitor.py:476][0m param-summary/conv6/W-rms: 0.039717
[32m[0717 08:49:42 @monitor.py:476][0m param-summary/fc1/W-rms: 0.068089
[32m[0717 08:49:42 @monitor.py:476][0m regularize_cost: 1.1837e-06
[32m[0717 08:49:42 @monitor.py:476][0m train_error: 0.0062459
[32m[0717 08:49:42 @monitor.py:476][0m val_accuracy: 0.99199
[32m[0717 08:49:42 @monitor.py:476][0m val_cross_entropy_loss: 0.02849
[32m[0717 08:49:42 @base.py:273][0m Start Epoch 12 ...
[32m[0717 08:49:55 @base.py:283][0m Epoch 12 (global_step 5616) finished, time:13.2 seconds.
[32m[0717 08:49:55 @saver.py:82][0m Model saved to train_log/mnist-dorefa-6,6,6/model-5616.
[32m[0717 08:49:56 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[0717 08:49:56 @monitor.py:476][0m accuracy: 0.98948
[32m[0717 08:49:56 @monitor.py:476][0m cost: 0.0302
[32m[0717 08:49:56 @monitor.py:476][0m cross_entropy_loss: 0.030198
[32m[0717 08:49:56 @monitor.py:476][0m param-summary/conv0/W-rms: 0.29716
[32m[0717 08:49:56 @monitor.py:476][0m param-summary/conv1/W-rms: 0.075002
[32m[0717 08:49:56 @monitor.py:476][0m param-summary/conv2/W-rms: 0.064726
[32m[0717 08:49:56 @monitor.py:476][0m param-summary/conv3/W-rms: 0.066535
[32m[0717 08:49:56 @monitor.py:476][0m param-summary/conv4/W-rms: 0.051509
[32m[0717 08:49:56 @monitor.py:476][0m param-summary/conv5/W-rms: 0.054171
[32m[0717 08:49:56 @monitor.py:476][0m param-summary/conv6/W-rms: 0.041432
[32m[0717 08:49:56 @monitor.py:476][0m param-summary/fc1/W-rms: 0.070425
[32m[0717 08:49:56 @monitor.py:476][0m regularize_cost: 1.2676e-06
[32m[0717 08:49:56 @monitor.py:476][0m train_error: 0.010517
[32m[0717 08:49:56 @monitor.py:476][0m val_accuracy: 0.98912
[32m[0717 08:49:56 @monitor.py:476][0m val_cross_entropy_loss: 0.037446
[32m[0717 08:49:56 @base.py:273][0m Start Epoch 13 ...
[32m[0717 08:50:10 @base.py:283][0m Epoch 13 (global_step 6084) finished, time:13.4 seconds.
[32m[0717 08:50:10 @saver.py:82][0m Model saved to train_log/mnist-dorefa-6,6,6/model-6084.
[32m[0717 08:50:11 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[0717 08:50:11 @monitor.py:476][0m accuracy: 0.99193
[32m[0717 08:50:11 @monitor.py:476][0m cost: 0.025086
[32m[0717 08:50:11 @monitor.py:476][0m cross_entropy_loss: 0.025085
[32m[0717 08:50:11 @monitor.py:476][0m param-summary/conv0/W-rms: 0.29794
[32m[0717 08:50:11 @monitor.py:476][0m param-summary/conv1/W-rms: 0.075839
[32m[0717 08:50:11 @monitor.py:476][0m param-summary/conv2/W-rms: 0.065864
[32m[0717 08:50:11 @monitor.py:476][0m param-summary/conv3/W-rms: 0.067838
[32m[0717 08:50:11 @monitor.py:476][0m param-summary/conv4/W-rms: 0.053008
[32m[0717 08:50:11 @monitor.py:476][0m param-summary/conv5/W-rms: 0.05595
[32m[0717 08:50:11 @monitor.py:476][0m param-summary/conv6/W-rms: 0.043405
[32m[0717 08:50:11 @monitor.py:476][0m param-summary/fc1/W-rms: 0.073329
[32m[0717 08:50:11 @monitor.py:476][0m regularize_cost: 1.3716e-06
[32m[0717 08:50:11 @monitor.py:476][0m train_error: 0.0080659
[32m[0717 08:50:11 @monitor.py:476][0m val_accuracy: 0.99278
[32m[0717 08:50:11 @monitor.py:476][0m val_cross_entropy_loss: 0.023125
[32m[0717 08:50:11 @base.py:273][0m Start Epoch 14 ...
[32m[0717 08:50:24 @base.py:283][0m Epoch 14 (global_step 6552) finished, time:12.9 seconds.
[32m[0717 08:50:24 @saver.py:82][0m Model saved to train_log/mnist-dorefa-6,6,6/model-6552.
[32m[0717 08:50:25 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[0717 08:50:25 @monitor.py:476][0m accuracy: 0.9928
[32m[0717 08:50:25 @monitor.py:476][0m cost: 0.022001
[32m[0717 08:50:25 @monitor.py:476][0m cross_entropy_loss: 0.021999
[32m[0717 08:50:25 @monitor.py:476][0m param-summary/conv0/W-rms: 0.29918
[32m[0717 08:50:25 @monitor.py:476][0m param-summary/conv1/W-rms: 0.076681
[32m[0717 08:50:25 @monitor.py:476][0m param-summary/conv2/W-rms: 0.067046
[32m[0717 08:50:25 @monitor.py:476][0m param-summary/conv3/W-rms: 0.069223
[32m[0717 08:50:25 @monitor.py:476][0m param-summary/conv4/W-rms: 0.054572
[32m[0717 08:50:25 @monitor.py:476][0m param-summary/conv5/W-rms: 0.057848
[32m[0717 08:50:25 @monitor.py:476][0m param-summary/conv6/W-rms: 0.0455
[32m[0717 08:50:25 @monitor.py:476][0m param-summary/fc1/W-rms: 0.075523
[32m[0717 08:50:25 @monitor.py:476][0m regularize_cost: 1.4545e-06
[32m[0717 08:50:25 @monitor.py:476][0m train_error: 0.0072038
[32m[0717 08:50:25 @monitor.py:476][0m val_accuracy: 0.97468
[32m[0717 08:50:25 @monitor.py:476][0m val_cross_entropy_loss: 0.081301
[32m[0717 08:50:25 @base.py:273][0m Start Epoch 15 ...
[32m[0717 08:50:38 @base.py:283][0m Epoch 15 (global_step 7020) finished, time:13 seconds.
[32m[0717 08:50:38 @saver.py:82][0m Model saved to train_log/mnist-dorefa-6,6,6/model-7020.
[32m[0717 08:50:39 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[0717 08:50:39 @monitor.py:476][0m accuracy: 0.99332
[32m[0717 08:50:39 @monitor.py:476][0m cost: 0.021814
[32m[0717 08:50:39 @monitor.py:476][0m cross_entropy_loss: 0.021812
[32m[0717 08:50:39 @monitor.py:476][0m param-summary/conv0/W-rms: 0.30076
[32m[0717 08:50:39 @monitor.py:476][0m param-summary/conv1/W-rms: 0.077501
[32m[0717 08:50:39 @monitor.py:476][0m param-summary/conv2/W-rms: 0.06824
[32m[0717 08:50:39 @monitor.py:476][0m param-summary/conv3/W-rms: 0.070581
[32m[0717 08:50:39 @monitor.py:476][0m param-summary/conv4/W-rms: 0.056075
[32m[0717 08:50:39 @monitor.py:476][0m param-summary/conv5/W-rms: 0.059579
[32m[0717 08:50:39 @monitor.py:476][0m param-summary/conv6/W-rms: 0.047395
[32m[0717 08:50:39 @monitor.py:476][0m param-summary/fc1/W-rms: 0.078012
[32m[0717 08:50:39 @monitor.py:476][0m regularize_cost: 1.5535e-06
[32m[0717 08:50:39 @monitor.py:476][0m train_error: 0.0066763
[32m[0717 08:50:39 @monitor.py:476][0m val_accuracy: 0.98991
[32m[0717 08:50:39 @monitor.py:476][0m val_cross_entropy_loss: 0.03139
[32m[0717 08:50:39 @base.py:273][0m Start Epoch 16 ...
[32m[0717 08:50:52 @base.py:283][0m Epoch 16 (global_step 7488) finished, time:12.9 seconds.
[32m[0717 08:50:52 @saver.py:82][0m Model saved to train_log/mnist-dorefa-6,6,6/model-7488.
[32m[0717 08:50:53 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[0717 08:50:53 @monitor.py:476][0m accuracy: 0.99555
[32m[0717 08:50:53 @monitor.py:476][0m cost: 0.012496
[32m[0717 08:50:53 @monitor.py:476][0m cross_entropy_loss: 0.012494
[32m[0717 08:50:53 @monitor.py:476][0m param-summary/conv0/W-rms: 0.30215
[32m[0717 08:50:53 @monitor.py:476][0m param-summary/conv1/W-rms: 0.078323
[32m[0717 08:50:53 @monitor.py:476][0m param-summary/conv2/W-rms: 0.069423
[32m[0717 08:50:53 @monitor.py:476][0m param-summary/conv3/W-rms: 0.07198
[32m[0717 08:50:53 @monitor.py:476][0m param-summary/conv4/W-rms: 0.057693
[32m[0717 08:50:53 @monitor.py:476][0m param-summary/conv5/W-rms: 0.061301
[32m[0717 08:50:53 @monitor.py:476][0m param-summary/conv6/W-rms: 0.049248
[32m[0717 08:50:53 @monitor.py:476][0m param-summary/fc1/W-rms: 0.080696
[32m[0717 08:50:53 @monitor.py:476][0m regularize_cost: 1.6626e-06
[32m[0717 08:50:53 @monitor.py:476][0m train_error: 0.0044462
[32m[0717 08:50:53 @monitor.py:476][0m val_accuracy: 0.98813
[32m[0717 08:50:53 @monitor.py:476][0m val_cross_entropy_loss: 0.039669
[32m[0717 08:50:53 @base.py:273][0m Start Epoch 17 ...
[32m[0717 08:51:06 @base.py:283][0m Epoch 17 (global_step 7956) finished, time:13.2 seconds.
[32m[0717 08:51:06 @saver.py:82][0m Model saved to train_log/mnist-dorefa-6,6,6/model-7956.
[32m[0717 08:51:07 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[0717 08:51:07 @monitor.py:476][0m accuracy: 0.99385
[32m[0717 08:51:07 @monitor.py:476][0m cost: 0.019506
[32m[0717 08:51:07 @monitor.py:476][0m cross_entropy_loss: 0.019504
[32m[0717 08:51:07 @monitor.py:476][0m param-summary/conv0/W-rms: 0.30366
[32m[0717 08:51:07 @monitor.py:476][0m param-summary/conv1/W-rms: 0.079288
[32m[0717 08:51:07 @monitor.py:476][0m param-summary/conv2/W-rms: 0.070976
[32m[0717 08:51:07 @monitor.py:476][0m param-summary/conv3/W-rms: 0.073637
[32m[0717 08:51:07 @monitor.py:476][0m param-summary/conv4/W-rms: 0.059521
[32m[0717 08:51:07 @monitor.py:476][0m param-summary/conv5/W-rms: 0.063321
[32m[0717 08:51:07 @monitor.py:476][0m param-summary/conv6/W-rms: 0.051323
[32m[0717 08:51:07 @monitor.py:476][0m param-summary/fc1/W-rms: 0.083258
[32m[0717 08:51:07 @monitor.py:476][0m regularize_cost: 1.7704e-06
[32m[0717 08:51:07 @monitor.py:476][0m train_error: 0.0061515
[32m[0717 08:51:07 @monitor.py:476][0m val_accuracy: 0.99298
[32m[0717 08:51:07 @monitor.py:476][0m val_cross_entropy_loss: 0.022567
[32m[0717 08:51:07 @base.py:273][0m Start Epoch 18 ...
[32m[0717 08:51:20 @base.py:283][0m Epoch 18 (global_step 8424) finished, time:12.9 seconds.
[32m[0717 08:51:20 @saver.py:82][0m Model saved to train_log/mnist-dorefa-6,6,6/model-8424.
[32m[0717 08:51:21 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[0717 08:51:21 @monitor.py:476][0m accuracy: 0.99635
[32m[0717 08:51:21 @monitor.py:476][0m cost: 0.014035
[32m[0717 08:51:21 @monitor.py:476][0m cross_entropy_loss: 0.014033
[32m[0717 08:51:21 @monitor.py:476][0m param-summary/conv0/W-rms: 0.30527
[32m[0717 08:51:21 @monitor.py:476][0m param-summary/conv1/W-rms: 0.080161
[32m[0717 08:51:21 @monitor.py:476][0m param-summary/conv2/W-rms: 0.072512
[32m[0717 08:51:21 @monitor.py:476][0m param-summary/conv3/W-rms: 0.07531
[32m[0717 08:51:21 @monitor.py:476][0m param-summary/conv4/W-rms: 0.061344
[32m[0717 08:51:21 @monitor.py:476][0m param-summary/conv5/W-rms: 0.065284
[32m[0717 08:51:21 @monitor.py:476][0m param-summary/conv6/W-rms: 0.053321
[32m[0717 08:51:21 @monitor.py:476][0m param-summary/fc1/W-rms: 0.085822
[32m[0717 08:51:21 @monitor.py:476][0m regularize_cost: 1.8822e-06
[32m[0717 08:51:21 @monitor.py:476][0m train_error: 0.0036515
[32m[0717 08:51:21 @monitor.py:476][0m val_accuracy: 0.99268
[32m[0717 08:51:21 @monitor.py:476][0m val_cross_entropy_loss: 0.026395
[32m[0717 08:51:21 @base.py:273][0m Start Epoch 19 ...
[32m[0717 08:51:34 @base.py:283][0m Epoch 19 (global_step 8892) finished, time:12.9 seconds.
[32m[0717 08:51:34 @saver.py:82][0m Model saved to train_log/mnist-dorefa-6,6,6/model-8892.
[32m[0717 08:51:35 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[0717 08:51:35 @monitor.py:476][0m accuracy: 0.9938
[32m[0717 08:51:35 @monitor.py:476][0m cost: 0.017633
[32m[0717 08:51:35 @monitor.py:476][0m cross_entropy_loss: 0.017631
[32m[0717 08:51:35 @monitor.py:476][0m param-summary/conv0/W-rms: 0.30731
[32m[0717 08:51:35 @monitor.py:476][0m param-summary/conv1/W-rms: 0.081063
[32m[0717 08:51:35 @monitor.py:476][0m param-summary/conv2/W-rms: 0.074269
[32m[0717 08:51:35 @monitor.py:476][0m param-summary/conv3/W-rms: 0.077246
[32m[0717 08:51:35 @monitor.py:476][0m param-summary/conv4/W-rms: 0.063401
[32m[0717 08:51:35 @monitor.py:476][0m param-summary/conv5/W-rms: 0.067451
[32m[0717 08:51:35 @monitor.py:476][0m param-summary/conv6/W-rms: 0.055538
[32m[0717 08:51:35 @monitor.py:476][0m param-summary/fc1/W-rms: 0.088683
[32m[0717 08:51:35 @monitor.py:476][0m regularize_cost: 2.0079e-06
[32m[0717 08:51:35 @monitor.py:476][0m train_error: 0.0062037
[32m[0717 08:51:35 @monitor.py:476][0m val_accuracy: 0.9908
[32m[0717 08:51:35 @monitor.py:476][0m val_cross_entropy_loss: 0.028057
[32m[0717 08:51:35 @base.py:273][0m Start Epoch 20 ...
[32m[0717 08:51:48 @base.py:283][0m Epoch 20 (global_step 9360) finished, time:13 seconds.
[32m[0717 08:51:48 @saver.py:82][0m Model saved to train_log/mnist-dorefa-6,6,6/model-9360.
[32m[0717 08:51:49 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[0717 08:51:49 @monitor.py:476][0m accuracy: 0.99614
[32m[0717 08:51:49 @monitor.py:476][0m cost: 0.012676
[32m[0717 08:51:49 @monitor.py:476][0m cross_entropy_loss: 0.012674
[32m[0717 08:51:49 @monitor.py:476][0m param-summary/conv0/W-rms: 0.30891
[32m[0717 08:51:49 @monitor.py:476][0m param-summary/conv1/W-rms: 0.082244
[32m[0717 08:51:49 @monitor.py:476][0m param-summary/conv2/W-rms: 0.075986
[32m[0717 08:51:49 @monitor.py:476][0m param-summary/conv3/W-rms: 0.079042
[32m[0717 08:51:49 @monitor.py:476][0m param-summary/conv4/W-rms: 0.065331
[32m[0717 08:51:49 @monitor.py:476][0m param-summary/conv5/W-rms: 0.069523
[32m[0717 08:51:49 @monitor.py:476][0m param-summary/conv6/W-rms: 0.057582
[32m[0717 08:51:49 @monitor.py:476][0m param-summary/fc1/W-rms: 0.091713
[32m[0717 08:51:49 @monitor.py:476][0m regularize_cost: 2.1502e-06
[32m[0717 08:51:49 @monitor.py:476][0m train_error: 0.003862
[32m[0717 08:51:49 @monitor.py:476][0m val_accuracy: 0.98457
[32m[0717 08:51:49 @monitor.py:476][0m val_cross_entropy_loss: 0.050525
[32m[0717 08:51:49 @base.py:273][0m Start Epoch 21 ...
[32m[0717 08:52:03 @base.py:283][0m Epoch 21 (global_step 9828) finished, time:13.2 seconds.
[32m[0717 08:52:03 @saver.py:82][0m Model saved to train_log/mnist-dorefa-6,6,6/model-9828.
[32m[0717 08:52:04 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[0717 08:52:04 @monitor.py:476][0m accuracy: 0.99679
[32m[0717 08:52:04 @monitor.py:476][0m cost: 0.0099127
[32m[0717 08:52:04 @monitor.py:476][0m cross_entropy_loss: 0.0099104
[32m[0717 08:52:04 @monitor.py:476][0m param-summary/conv0/W-rms: 0.31082
[32m[0717 08:52:04 @monitor.py:476][0m param-summary/conv1/W-rms: 0.083115
[32m[0717 08:52:04 @monitor.py:476][0m param-summary/conv2/W-rms: 0.0777
[32m[0717 08:52:04 @monitor.py:476][0m param-summary/conv3/W-rms: 0.080893
[32m[0717 08:52:04 @monitor.py:476][0m param-summary/conv4/W-rms: 0.067376
[32m[0717 08:52:04 @monitor.py:476][0m param-summary/conv5/W-rms: 0.071652
[32m[0717 08:52:04 @monitor.py:476][0m param-summary/conv6/W-rms: 0.059709
[32m[0717 08:52:04 @monitor.py:476][0m param-summary/fc1/W-rms: 0.09461
[32m[0717 08:52:04 @monitor.py:476][0m regularize_cost: 2.2842e-06
[32m[0717 08:52:04 @monitor.py:476][0m train_error: 0.0032091
[32m[0717 08:52:04 @monitor.py:476][0m val_accuracy: 0.98853
[32m[0717 08:52:04 @monitor.py:476][0m val_cross_entropy_loss: 0.038335
[32m[0717 08:52:04 @base.py:273][0m Start Epoch 22 ...
[32m[0717 08:52:17 @base.py:283][0m Epoch 22 (global_step 10296) finished, time:13.1 seconds.
[32m[0717 08:52:17 @saver.py:82][0m Model saved to train_log/mnist-dorefa-6,6,6/model-10296.
[32m[0717 08:52:18 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[0717 08:52:18 @monitor.py:476][0m accuracy: 0.99677
[32m[0717 08:52:18 @monitor.py:476][0m cost: 0.010574
[32m[0717 08:52:18 @monitor.py:476][0m cross_entropy_loss: 0.010572
[32m[0717 08:52:18 @monitor.py:476][0m param-summary/conv0/W-rms: 0.31202
[32m[0717 08:52:18 @monitor.py:476][0m param-summary/conv1/W-rms: 0.083856
[32m[0717 08:52:18 @monitor.py:476][0m param-summary/conv2/W-rms: 0.078995
[32m[0717 08:52:18 @monitor.py:476][0m param-summary/conv3/W-rms: 0.08243
[32m[0717 08:52:18 @monitor.py:476][0m param-summary/conv4/W-rms: 0.069111
[32m[0717 08:52:18 @monitor.py:476][0m param-summary/conv5/W-rms: 0.073477
[32m[0717 08:52:18 @monitor.py:476][0m param-summary/conv6/W-rms: 0.061465
[32m[0717 08:52:18 @monitor.py:476][0m param-summary/fc1/W-rms: 0.097146
[32m[0717 08:52:18 @monitor.py:476][0m regularize_cost: 2.4135e-06
[32m[0717 08:52:18 @monitor.py:476][0m train_error: 0.0032255
[32m[0717 08:52:18 @monitor.py:476][0m val_accuracy: 0.99179
[32m[0717 08:52:18 @monitor.py:476][0m val_cross_entropy_loss: 0.025323
[32m[0717 08:52:18 @base.py:273][0m Start Epoch 23 ...
[32m[0717 08:52:31 @base.py:283][0m Epoch 23 (global_step 10764) finished, time:13.1 seconds.
[32m[0717 08:52:31 @saver.py:82][0m Model saved to train_log/mnist-dorefa-6,6,6/model-10764.
[32m[0717 08:52:32 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[0717 08:52:32 @monitor.py:476][0m accuracy: 0.99546
[32m[0717 08:52:32 @monitor.py:476][0m cost: 0.011402
[32m[0717 08:52:32 @monitor.py:476][0m cross_entropy_loss: 0.0114
[32m[0717 08:52:32 @monitor.py:476][0m param-summary/conv0/W-rms: 0.31393
[32m[0717 08:52:32 @monitor.py:476][0m param-summary/conv1/W-rms: 0.084892
[32m[0717 08:52:32 @monitor.py:476][0m param-summary/conv2/W-rms: 0.081188
[32m[0717 08:52:32 @monitor.py:476][0m param-summary/conv3/W-rms: 0.084639
[32m[0717 08:52:32 @monitor.py:476][0m param-summary/conv4/W-rms: 0.071532
[32m[0717 08:52:32 @monitor.py:476][0m param-summary/conv5/W-rms: 0.075845
[32m[0717 08:52:32 @monitor.py:476][0m param-summary/conv6/W-rms: 0.063584
[32m[0717 08:52:32 @monitor.py:476][0m param-summary/fc1/W-rms: 0.099892
[32m[0717 08:52:32 @monitor.py:476][0m regularize_cost: 2.5478e-06
[32m[0717 08:52:32 @monitor.py:476][0m train_error: 0.0045383
[32m[0717 08:52:32 @monitor.py:476][0m val_accuracy: 0.99061
[32m[0717 08:52:32 @monitor.py:476][0m val_cross_entropy_loss: 0.033742
[32m[0717 08:52:32 @base.py:273][0m Start Epoch 24 ...
[32m[0717 08:52:45 @base.py:283][0m Epoch 24 (global_step 11232) finished, time:12.9 seconds.
[32m[0717 08:52:45 @saver.py:82][0m Model saved to train_log/mnist-dorefa-6,6,6/model-11232.
[32m[0717 08:52:46 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[0717 08:52:46 @monitor.py:476][0m accuracy: 0.99778
[32m[0717 08:52:46 @monitor.py:476][0m cost: 0.00882
[32m[0717 08:52:46 @monitor.py:476][0m cross_entropy_loss: 0.0088173
[32m[0717 08:52:46 @monitor.py:476][0m param-summary/conv0/W-rms: 0.31539
[32m[0717 08:52:46 @monitor.py:476][0m param-summary/conv1/W-rms: 0.085785
[32m[0717 08:52:46 @monitor.py:476][0m param-summary/conv2/W-rms: 0.082727
[32m[0717 08:52:46 @monitor.py:476][0m param-summary/conv3/W-rms: 0.086093
[32m[0717 08:52:46 @monitor.py:476][0m param-summary/conv4/W-rms: 0.073206
[32m[0717 08:52:46 @monitor.py:476][0m param-summary/conv5/W-rms: 0.077624
[32m[0717 08:52:46 @monitor.py:476][0m param-summary/conv6/W-rms: 0.065276
[32m[0717 08:52:46 @monitor.py:476][0m param-summary/fc1/W-rms: 0.10259
[32m[0717 08:52:46 @monitor.py:476][0m regularize_cost: 2.6897e-06
[32m[0717 08:52:46 @monitor.py:476][0m train_error: 0.0022152
[32m[0717 08:52:46 @monitor.py:476][0m val_accuracy: 0.99298
[32m[0717 08:52:46 @monitor.py:476][0m val_cross_entropy_loss: 0.024358
[32m[0717 08:52:46 @base.py:273][0m Start Epoch 25 ...
[32m[0717 08:52:59 @base.py:283][0m Epoch 25 (global_step 11700) finished, time:13 seconds.
[32m[0717 08:52:59 @saver.py:82][0m Model saved to train_log/mnist-dorefa-6,6,6/model-11700.
[32m[0717 08:53:00 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[0717 08:53:00 @monitor.py:476][0m accuracy: 0.9965
[32m[0717 08:53:00 @monitor.py:476][0m cost: 0.010049
[32m[0717 08:53:00 @monitor.py:476][0m cross_entropy_loss: 0.010047
[32m[0717 08:53:00 @monitor.py:476][0m param-summary/conv0/W-rms: 0.31776
[32m[0717 08:53:00 @monitor.py:476][0m param-summary/conv1/W-rms: 0.086756
[32m[0717 08:53:00 @monitor.py:476][0m param-summary/conv2/W-rms: 0.084681
[32m[0717 08:53:00 @monitor.py:476][0m param-summary/conv3/W-rms: 0.088225
[32m[0717 08:53:00 @monitor.py:476][0m param-summary/conv4/W-rms: 0.075529
[32m[0717 08:53:00 @monitor.py:476][0m param-summary/conv5/W-rms: 0.079942
[32m[0717 08:53:00 @monitor.py:476][0m param-summary/conv6/W-rms: 0.067448
[32m[0717 08:53:00 @monitor.py:476][0m param-summary/fc1/W-rms: 0.10513
[32m[0717 08:53:00 @monitor.py:476][0m regularize_cost: 2.8249e-06
[32m[0717 08:53:00 @monitor.py:476][0m train_error: 0.0034978
[32m[0717 08:53:00 @monitor.py:476][0m val_accuracy: 0.99258
[32m[0717 08:53:00 @monitor.py:476][0m val_cross_entropy_loss: 0.02432
[32m[0717 08:53:00 @base.py:273][0m Start Epoch 26 ...
[32m[0717 08:53:13 @base.py:283][0m Epoch 26 (global_step 12168) finished, time:12.9 seconds.
[32m[0717 08:53:14 @saver.py:82][0m Model saved to train_log/mnist-dorefa-6,6,6/model-12168.
[32m[0717 08:53:15 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[0717 08:53:15 @monitor.py:476][0m accuracy: 0.99812
[32m[0717 08:53:15 @monitor.py:476][0m cost: 0.0048174
[32m[0717 08:53:15 @monitor.py:476][0m cross_entropy_loss: 0.0048144
[32m[0717 08:53:15 @monitor.py:476][0m param-summary/conv0/W-rms: 0.3191
[32m[0717 08:53:15 @monitor.py:476][0m param-summary/conv1/W-rms: 0.087407
[32m[0717 08:53:15 @monitor.py:476][0m param-summary/conv2/W-rms: 0.08639
[32m[0717 08:53:15 @monitor.py:476][0m param-summary/conv3/W-rms: 0.0899
[32m[0717 08:53:15 @monitor.py:476][0m param-summary/conv4/W-rms: 0.077347
[32m[0717 08:53:15 @monitor.py:476][0m param-summary/conv5/W-rms: 0.081755
[32m[0717 08:53:15 @monitor.py:476][0m param-summary/conv6/W-rms: 0.069112
[32m[0717 08:53:15 @monitor.py:476][0m param-summary/fc1/W-rms: 0.10761
[32m[0717 08:53:15 @monitor.py:476][0m regularize_cost: 2.959e-06
[32m[0717 08:53:15 @monitor.py:476][0m train_error: 0.0018767
[32m[0717 08:53:15 @monitor.py:476][0m val_accuracy: 0.99476
[32m[0717 08:53:15 @monitor.py:476][0m val_cross_entropy_loss: 0.02185
[32m[0717 08:53:15 @base.py:273][0m Start Epoch 27 ...
[32m[0717 08:53:28 @base.py:283][0m Epoch 27 (global_step 12636) finished, time:13.1 seconds.
[32m[0717 08:53:28 @saver.py:82][0m Model saved to train_log/mnist-dorefa-6,6,6/model-12636.
[32m[0717 08:53:29 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[0717 08:53:29 @monitor.py:476][0m accuracy: 0.99782
[32m[0717 08:53:29 @monitor.py:476][0m cost: 0.0070033
[32m[0717 08:53:29 @monitor.py:476][0m cross_entropy_loss: 0.0070003
[32m[0717 08:53:29 @monitor.py:476][0m param-summary/conv0/W-rms: 0.32087
[32m[0717 08:53:29 @monitor.py:476][0m param-summary/conv1/W-rms: 0.088479
[32m[0717 08:53:29 @monitor.py:476][0m param-summary/conv2/W-rms: 0.088326
[32m[0717 08:53:29 @monitor.py:476][0m param-summary/conv3/W-rms: 0.091793
[32m[0717 08:53:29 @monitor.py:476][0m param-summary/conv4/W-rms: 0.079202
[32m[0717 08:53:29 @monitor.py:476][0m param-summary/conv5/W-rms: 0.08358
[32m[0717 08:53:29 @monitor.py:476][0m param-summary/conv6/W-rms: 0.070721
[32m[0717 08:53:29 @monitor.py:476][0m param-summary/fc1/W-rms: 0.10966
[32m[0717 08:53:29 @monitor.py:476][0m regularize_cost: 3.0732e-06
[32m[0717 08:53:29 @monitor.py:476][0m train_error: 0.0021754
[32m[0717 08:53:29 @monitor.py:476][0m val_accuracy: 0.99258
[32m[0717 08:53:29 @monitor.py:476][0m val_cross_entropy_loss: 0.024825
[32m[0717 08:53:29 @base.py:273][0m Start Epoch 28 ...
[32m[0717 08:53:42 @base.py:283][0m Epoch 28 (global_step 13104) finished, time:12.9 seconds.
[32m[0717 08:53:42 @saver.py:82][0m Model saved to train_log/mnist-dorefa-6,6,6/model-13104.
[32m[0717 08:53:43 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[0717 08:53:43 @monitor.py:476][0m accuracy: 0.99693
[32m[0717 08:53:43 @monitor.py:476][0m cost: 0.01026
[32m[0717 08:53:43 @monitor.py:476][0m cross_entropy_loss: 0.010257
[32m[0717 08:53:43 @monitor.py:476][0m param-summary/conv0/W-rms: 0.32268
[32m[0717 08:53:43 @monitor.py:476][0m param-summary/conv1/W-rms: 0.089619
[32m[0717 08:53:43 @monitor.py:476][0m param-summary/conv2/W-rms: 0.090318
[32m[0717 08:53:43 @monitor.py:476][0m param-summary/conv3/W-rms: 0.09383
[32m[0717 08:53:43 @monitor.py:476][0m param-summary/conv4/W-rms: 0.0813
[32m[0717 08:53:43 @monitor.py:476][0m param-summary/conv5/W-rms: 0.085493
[32m[0717 08:53:43 @monitor.py:476][0m param-summary/conv6/W-rms: 0.072349
[32m[0717 08:53:43 @monitor.py:476][0m param-summary/fc1/W-rms: 0.11223
[32m[0717 08:53:43 @monitor.py:476][0m regularize_cost: 3.2205e-06
[32m[0717 08:53:43 @monitor.py:476][0m train_error: 0.0030696
[32m[0717 08:53:43 @monitor.py:476][0m val_accuracy: 0.99308
[32m[0717 08:53:43 @monitor.py:476][0m val_cross_entropy_loss: 0.025204
[32m[0717 08:53:43 @base.py:273][0m Start Epoch 29 ...
[32m[0717 08:53:56 @base.py:283][0m Epoch 29 (global_step 13572) finished, time:13.2 seconds.
[32m[0717 08:53:56 @saver.py:82][0m Model saved to train_log/mnist-dorefa-6,6,6/model-13572.
[32m[0717 08:53:57 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[0717 08:53:57 @monitor.py:476][0m accuracy: 0.99503
[32m[0717 08:53:57 @monitor.py:476][0m cost: 0.013304
[32m[0717 08:53:57 @monitor.py:476][0m cross_entropy_loss: 0.013301
[32m[0717 08:53:57 @monitor.py:476][0m param-summary/conv0/W-rms: 0.32453
[32m[0717 08:53:57 @monitor.py:476][0m param-summary/conv1/W-rms: 0.09045
[32m[0717 08:53:57 @monitor.py:476][0m param-summary/conv2/W-rms: 0.092199
[32m[0717 08:53:57 @monitor.py:476][0m param-summary/conv3/W-rms: 0.095688
[32m[0717 08:53:57 @monitor.py:476][0m param-summary/conv4/W-rms: 0.08326
[32m[0717 08:53:57 @monitor.py:476][0m param-summary/conv5/W-rms: 0.08745
[32m[0717 08:53:57 @monitor.py:476][0m param-summary/conv6/W-rms: 0.074055
[32m[0717 08:53:57 @monitor.py:476][0m param-summary/fc1/W-rms: 0.1147
[32m[0717 08:53:57 @monitor.py:476][0m regularize_cost: 3.3612e-06
[32m[0717 08:53:57 @monitor.py:476][0m train_error: 0.0049731
[32m[0717 08:53:57 @monitor.py:476][0m val_accuracy: 0.9915
[32m[0717 08:53:57 @monitor.py:476][0m val_cross_entropy_loss: 0.036863
[32m[0717 08:53:57 @base.py:273][0m Start Epoch 30 ...
[32m[0717 08:54:10 @base.py:283][0m Epoch 30 (global_step 14040) finished, time:12.9 seconds.
[32m[0717 08:54:10 @saver.py:82][0m Model saved to train_log/mnist-dorefa-6,6,6/model-14040.
[32m[0717 08:54:11 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[0717 08:54:11 @monitor.py:476][0m accuracy: 0.9966
[32m[0717 08:54:11 @monitor.py:476][0m cost: 0.0077441
[32m[0717 08:54:11 @monitor.py:476][0m cross_entropy_loss: 0.0077406
[32m[0717 08:54:11 @monitor.py:476][0m param-summary/conv0/W-rms: 0.32638
[32m[0717 08:54:11 @monitor.py:476][0m param-summary/conv1/W-rms: 0.091469
[32m[0717 08:54:11 @monitor.py:476][0m param-summary/conv2/W-rms: 0.093882
[32m[0717 08:54:11 @monitor.py:476][0m param-summary/conv3/W-rms: 0.097309
[32m[0717 08:54:11 @monitor.py:476][0m param-summary/conv4/W-rms: 0.084901
[32m[0717 08:54:11 @monitor.py:476][0m param-summary/conv5/W-rms: 0.089049
[32m[0717 08:54:11 @monitor.py:476][0m param-summary/conv6/W-rms: 0.075492
[32m[0717 08:54:11 @monitor.py:476][0m param-summary/fc1/W-rms: 0.11713
[32m[0717 08:54:11 @monitor.py:476][0m regularize_cost: 3.5076e-06
[32m[0717 08:54:11 @monitor.py:476][0m train_error: 0.0034027
[32m[0717 08:54:11 @monitor.py:476][0m val_accuracy: 0.99308
[32m[0717 08:54:11 @monitor.py:476][0m val_cross_entropy_loss: 0.023573
[32m[0717 08:54:11 @base.py:287][0m Training has finished!
[32m[0717 08:54:11 @input_source.py:177][0m [EnqueueThread] Thread EnqueueThread: enqueue dataflow to TF queue "QueueInput/input_queue" Exited.
