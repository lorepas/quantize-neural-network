[32m[0717 09:07:31 @logger.py:92][0m Argv: /usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py -f /root/.local/share/jupyter/runtime/kernel-deb98920-21fb-4f50-b049-99bfb143a407.json
[32m[0717 09:07:31 @parallel.py:340][0m [MultiProcessRunnerZMQ] Will fork a dataflow more than one times. This assumes the datapoints are i.i.d.
[32m[0717 09:07:31 @input_source.py:221][0m Setting up the queue 'QueueInput/input_queue' for CPU prefetching ...
[32m[0717 09:07:31 @trainers.py:48][0m Building graph for a single training tower ...
[32m[0717 09:07:31 @<ipython-input-19-7e1b074e8e82>:113][0m Binarizing weight conv0/W
[32m[0717 09:07:31 @<ipython-input-19-7e1b074e8e82>:113][0m Binarizing weight conv1/W
[32m[0717 09:07:31 @<ipython-input-19-7e1b074e8e82>:113][0m Binarizing weight conv2/W
[32m[0717 09:07:31 @<ipython-input-19-7e1b074e8e82>:113][0m Binarizing weight conv3/W
[32m[0717 09:07:31 @<ipython-input-19-7e1b074e8e82>:113][0m Binarizing weight conv4/W
[32m[0717 09:07:31 @<ipython-input-19-7e1b074e8e82>:113][0m Binarizing weight conv5/W
[32m[0717 09:07:31 @<ipython-input-19-7e1b074e8e82>:113][0m Binarizing weight conv6/W
[32m[0717 09:07:31 @<ipython-input-19-7e1b074e8e82>:113][0m Binarizing weight fc1/W
[32m[0717 09:07:31 @regularize.py:97][0m regularize_cost() found 1 variables to regularize.
[32m[0717 09:07:31 @regularize.py:21][0m The following tensors will be regularized: fc1/W:0
[32m[0717 09:07:33 @model_utils.py:67][0m [36mList of Trainable Variables: 
[0mname       shape               #elements
---------  ----------------  -----------
conv0/W    [5, 5, 1, 48]            1200
conv0/b    [48]                       48
conv1/W    [3, 3, 48, 64]          27648
bn1/gamma  [64]                       64
bn1/beta   [64]                       64
conv2/W    [3, 3, 64, 64]          36864
bn2/gamma  [64]                       64
bn2/beta   [64]                       64
conv3/W    [3, 3, 64, 128]         73728
bn3/gamma  [128]                     128
bn3/beta   [128]                     128
conv4/W    [3, 3, 128, 128]       147456
bn4/gamma  [128]                     128
bn4/beta   [128]                     128
conv5/W    [3, 3, 128, 128]       147456
bn5/gamma  [128]                     128
bn5/beta   [128]                     128
conv6/W    [5, 5, 128, 512]      1638400
bn6/gamma  [512]                     512
bn6/beta   [512]                     512
fc1/W      [512, 10]                5120
fc1/b      [10]                       10[36m
Number of trainable variables: 22
Number of parameters (elements): 2079978
Storage space needed for all trainable variables: 7.93MB[0m
[32m[0717 09:07:33 @base.py:207][0m Setup callbacks graph ...
[32m[0717 09:07:33 @argtools.py:138][0m [5m[31mWRN[0m "import prctl" failed! Install python-prctl so that processes can be cleaned with guarantee.
[32m[0717 09:07:33 @inference_runner.py:148][0m [InferenceRunner] Building tower 'InferenceTower' on device /gpu:0 ...
[32m[0717 09:07:33 @<ipython-input-19-7e1b074e8e82>:113][0m Binarizing weight conv0/W
[32m[0717 09:07:34 @<ipython-input-19-7e1b074e8e82>:113][0m Binarizing weight conv1/W
[32m[0717 09:07:34 @<ipython-input-19-7e1b074e8e82>:113][0m Binarizing weight conv2/W
[32m[0717 09:07:34 @<ipython-input-19-7e1b074e8e82>:113][0m Binarizing weight conv3/W
[32m[0717 09:07:34 @<ipython-input-19-7e1b074e8e82>:113][0m Binarizing weight conv4/W
[32m[0717 09:07:35 @<ipython-input-19-7e1b074e8e82>:113][0m Binarizing weight conv5/W
[32m[0717 09:07:35 @<ipython-input-19-7e1b074e8e82>:113][0m Binarizing weight conv6/W
[32m[0717 09:07:35 @<ipython-input-19-7e1b074e8e82>:113][0m Binarizing weight fc1/W
[32m[0717 09:07:35 @summary.py:47][0m [MovingAverageSummary] 5 operations in collection 'MOVING_SUMMARY_OPS' will be run with session hooks.
[32m[0717 09:07:35 @summary.py:94][0m Summarizing collection 'summaries' of size 22.
[32m[0717 09:07:35 @graph.py:99][0m Applying collection UPDATE_OPS of 12 ops.
[32m[0717 09:07:35 @base.py:228][0m Creating the session ...
[32m[0717 09:07:37 @base.py:234][0m Initializing the session ...
[32m[0717 09:07:37 @base.py:241][0m Graph Finalized.
[32m[0717 09:07:37 @concurrency.py:37][0m Starting EnqueueThread: enqueue dataflow to TF queue "QueueInput/input_queue" ...
[32m[0717 09:07:38 @inference_runner.py:95][0m [InferenceRunner] Will eval 79 iterations
[32m[0717 09:07:38 @monitor.py:361][0m [5m[31mWRN[0m History epoch=30 from JSON is not the predecessor of the current starting_epoch=1
[32m[0717 09:07:38 @monitor.py:362][0m [5m[31mWRN[0m If you want to resume old training, either use `AutoResumeTrainConfig` or correctly set the new starting_epoch yourself to avoid inconsistency. 
[32m[0717 09:07:38 @monitor.py:369][0m [5m[31mWRN[0m Now, we will train with starting_epoch=1 and backup old json to train_log/mnist-dorefa-6,6,6/stats.json.0717-090738
[32m[0717 09:07:38 @base.py:273][0m Start Epoch 1 ...
[32m[0717 09:07:59 @base.py:283][0m Epoch 1 (global_step 468) finished, time:21.4 seconds.
[32m[0717 09:08:00 @saver.py:82][0m Model saved to train_log/mnist-dorefa-6,6,6/model-468.
[32m[0717 09:08:04 @monitor.py:476][0m QueueInput/queue_size: 38.386
[32m[0717 09:08:04 @monitor.py:476][0m accuracy: 0.10302
[32m[0717 09:08:04 @monitor.py:476][0m cost: 2.3662
[32m[0717 09:08:04 @monitor.py:476][0m cross_entropy_loss: 2.3662
[32m[0717 09:08:04 @monitor.py:476][0m param-summary/conv0/W-rms: 0.28318
[32m[0717 09:08:04 @monitor.py:476][0m param-summary/conv1/W-rms: 0.068291
[32m[0717 09:08:04 @monitor.py:476][0m param-summary/conv2/W-rms: 0.05882
[32m[0717 09:08:04 @monitor.py:476][0m param-summary/conv3/W-rms: 0.059181
[32m[0717 09:08:04 @monitor.py:476][0m param-summary/conv4/W-rms: 0.042198
[32m[0717 09:08:04 @monitor.py:476][0m param-summary/conv5/W-rms: 0.042208
[32m[0717 09:08:04 @monitor.py:476][0m param-summary/conv6/W-rms: 0.026487
[32m[0717 09:08:04 @monitor.py:476][0m param-summary/fc1/W-rms: 0.058533
[32m[0717 09:08:04 @monitor.py:476][0m regularize_cost: 8.7842e-07
[32m[0717 09:08:04 @monitor.py:476][0m train_error: 0.89698
[32m[0717 09:08:04 @monitor.py:476][0m val_accuracy: 0.29598
[32m[0717 09:08:04 @monitor.py:476][0m val_cross_entropy_loss: 2.1747
[32m[0717 09:08:04 @group.py:44][0m Callbacks took 4.250 sec in total. InferenceRunner: 3.62 seconds
[32m[0717 09:08:04 @base.py:273][0m Start Epoch 2 ...
[32m[0717 09:08:20 @base.py:283][0m Epoch 2 (global_step 936) finished, time:16.5 seconds.
[32m[0717 09:08:20 @saver.py:82][0m Model saved to train_log/mnist-dorefa-6,6,6/model-936.
[32m[0717 09:08:23 @monitor.py:476][0m QueueInput/queue_size: 32.166
[32m[0717 09:08:23 @monitor.py:476][0m accuracy: 0.106
[32m[0717 09:08:23 @monitor.py:476][0m cost: 2.3404
[32m[0717 09:08:23 @monitor.py:476][0m cross_entropy_loss: 2.3404
[32m[0717 09:08:23 @monitor.py:476][0m param-summary/conv0/W-rms: 0.28329
[32m[0717 09:08:23 @monitor.py:476][0m param-summary/conv1/W-rms: 0.068603
[32m[0717 09:08:23 @monitor.py:476][0m param-summary/conv2/W-rms: 0.058888
[32m[0717 09:08:23 @monitor.py:476][0m param-summary/conv3/W-rms: 0.05923
[32m[0717 09:08:23 @monitor.py:476][0m param-summary/conv4/W-rms: 0.04227
[32m[0717 09:08:23 @monitor.py:476][0m param-summary/conv5/W-rms: 0.042357
[32m[0717 09:08:23 @monitor.py:476][0m param-summary/conv6/W-rms: 0.027143
[32m[0717 09:08:24 @monitor.py:476][0m param-summary/fc1/W-rms: 0.05792
[32m[0717 09:08:24 @monitor.py:476][0m regularize_cost: 8.5912e-07
[32m[0717 09:08:24 @monitor.py:476][0m train_error: 0.894
[32m[0717 09:08:24 @monitor.py:476][0m val_accuracy: 0.48358
[32m[0717 09:08:24 @monitor.py:476][0m val_cross_entropy_loss: 1.8305
[32m[0717 09:08:24 @group.py:44][0m Callbacks took 3.347 sec in total. InferenceRunner: 3.06 seconds
[32m[0717 09:08:24 @base.py:273][0m Start Epoch 3 ...
[32m[0717 09:08:41 @base.py:283][0m Epoch 3 (global_step 1404) finished, time:17.2 seconds.
[32m[0717 09:08:41 @saver.py:82][0m Model saved to train_log/mnist-dorefa-6,6,6/model-1404.
[32m[0717 09:08:44 @monitor.py:476][0m QueueInput/queue_size: 4.9269e-07
[32m[0717 09:08:44 @monitor.py:476][0m accuracy: 0.4508
[32m[0717 09:08:44 @monitor.py:476][0m cost: 1.5247
[32m[0717 09:08:44 @monitor.py:476][0m cross_entropy_loss: 1.5247
[32m[0717 09:08:44 @monitor.py:476][0m param-summary/conv0/W-rms: 0.28598
[32m[0717 09:08:44 @monitor.py:476][0m param-summary/conv1/W-rms: 0.073819
[32m[0717 09:08:44 @monitor.py:476][0m param-summary/conv2/W-rms: 0.061452
[32m[0717 09:08:44 @monitor.py:476][0m param-summary/conv3/W-rms: 0.061393
[32m[0717 09:08:44 @monitor.py:476][0m param-summary/conv4/W-rms: 0.044486
[32m[0717 09:08:44 @monitor.py:476][0m param-summary/conv5/W-rms: 0.04483
[32m[0717 09:08:44 @monitor.py:476][0m param-summary/conv6/W-rms: 0.029871
[32m[0717 09:08:44 @monitor.py:476][0m param-summary/fc1/W-rms: 0.05807
[32m[0717 09:08:44 @monitor.py:476][0m regularize_cost: 8.6169e-07
[32m[0717 09:08:44 @monitor.py:476][0m train_error: 0.5492
[32m[0717 09:08:44 @monitor.py:476][0m val_accuracy: 0.87085
[32m[0717 09:08:44 @monitor.py:476][0m val_cross_entropy_loss: 0.40344
[32m[0717 09:08:44 @group.py:44][0m Callbacks took 2.955 sec in total. InferenceRunner: 2.66 seconds
[32m[0717 09:08:44 @base.py:273][0m Start Epoch 4 ...
[32m[0717 09:09:03 @base.py:283][0m Epoch 4 (global_step 1872) finished, time:18.8 seconds.
[32m[0717 09:09:03 @saver.py:82][0m Model saved to train_log/mnist-dorefa-6,6,6/model-1872.
[32m[0717 09:09:06 @monitor.py:476][0m QueueInput/queue_size: 9.5368e-07
[32m[0717 09:09:06 @monitor.py:476][0m accuracy: 0.50632
[32m[0717 09:09:06 @monitor.py:476][0m cost: 1.332
[32m[0717 09:09:06 @monitor.py:476][0m cross_entropy_loss: 1.332
[32m[0717 09:09:06 @monitor.py:476][0m param-summary/conv0/W-rms: 0.28681
[32m[0717 09:09:06 @monitor.py:476][0m param-summary/conv1/W-rms: 0.076697
[32m[0717 09:09:06 @monitor.py:476][0m param-summary/conv2/W-rms: 0.063101
[32m[0717 09:09:06 @monitor.py:476][0m param-summary/conv3/W-rms: 0.062751
[32m[0717 09:09:06 @monitor.py:476][0m param-summary/conv4/W-rms: 0.045671
[32m[0717 09:09:06 @monitor.py:476][0m param-summary/conv5/W-rms: 0.046271
[32m[0717 09:09:06 @monitor.py:476][0m param-summary/conv6/W-rms: 0.031954
[32m[0717 09:09:06 @monitor.py:476][0m param-summary/fc1/W-rms: 0.059114
[32m[0717 09:09:06 @monitor.py:476][0m regularize_cost: 8.9334e-07
[32m[0717 09:09:06 @monitor.py:476][0m train_error: 0.49368
[32m[0717 09:09:06 @monitor.py:476][0m val_accuracy: 0.93325
[32m[0717 09:09:06 @monitor.py:476][0m val_cross_entropy_loss: 0.22862
[32m[0717 09:09:06 @group.py:44][0m Callbacks took 3.321 sec in total. InferenceRunner: 3.01 seconds
[32m[0717 09:09:06 @base.py:273][0m Start Epoch 5 ...
[32m[0717 09:09:26 @base.py:283][0m Epoch 5 (global_step 2340) finished, time:19.7 seconds.
[32m[0717 09:09:26 @saver.py:82][0m Model saved to train_log/mnist-dorefa-6,6,6/model-2340.
[32m[0717 09:09:29 @monitor.py:476][0m QueueInput/queue_size: 1.8626e-09
[32m[0717 09:09:29 @monitor.py:476][0m accuracy: 0.53487
[32m[0717 09:09:29 @monitor.py:476][0m cost: 1.2609
[32m[0717 09:09:29 @monitor.py:476][0m cross_entropy_loss: 1.2609
[32m[0717 09:09:29 @monitor.py:476][0m param-summary/conv0/W-rms: 0.28752
[32m[0717 09:09:29 @monitor.py:476][0m param-summary/conv1/W-rms: 0.079232
[32m[0717 09:09:29 @monitor.py:476][0m param-summary/conv2/W-rms: 0.064099
[32m[0717 09:09:29 @monitor.py:476][0m param-summary/conv3/W-rms: 0.063454
[32m[0717 09:09:29 @monitor.py:476][0m param-summary/conv4/W-rms: 0.046439
[32m[0717 09:09:29 @monitor.py:476][0m param-summary/conv5/W-rms: 0.047386
[32m[0717 09:09:29 @monitor.py:476][0m param-summary/conv6/W-rms: 0.033507
[32m[0717 09:09:29 @monitor.py:476][0m param-summary/fc1/W-rms: 0.06001
[32m[0717 09:09:29 @monitor.py:476][0m regularize_cost: 9.2139e-07
[32m[0717 09:09:29 @monitor.py:476][0m train_error: 0.46513
[32m[0717 09:09:29 @monitor.py:476][0m val_accuracy: 0.92356
[32m[0717 09:09:29 @monitor.py:476][0m val_cross_entropy_loss: 0.24845
[32m[0717 09:09:29 @group.py:44][0m Callbacks took 3.389 sec in total. InferenceRunner: 3.08 seconds
[32m[0717 09:09:29 @base.py:273][0m Start Epoch 6 ...
[32m[0717 09:09:48 @base.py:283][0m Epoch 6 (global_step 2808) finished, time:19.4 seconds.
[32m[0717 09:09:49 @saver.py:82][0m Model saved to train_log/mnist-dorefa-6,6,6/model-2808.
[32m[0717 09:09:52 @monitor.py:476][0m QueueInput/queue_size: 7.58e-09
[32m[0717 09:09:52 @monitor.py:476][0m accuracy: 0.52453
[32m[0717 09:09:52 @monitor.py:476][0m cost: 1.2653
[32m[0717 09:09:52 @monitor.py:476][0m cross_entropy_loss: 1.2653
[32m[0717 09:09:52 @monitor.py:476][0m param-summary/conv0/W-rms: 0.28814
[32m[0717 09:09:52 @monitor.py:476][0m param-summary/conv1/W-rms: 0.08235
[32m[0717 09:09:52 @monitor.py:476][0m param-summary/conv2/W-rms: 0.065049
[32m[0717 09:09:52 @monitor.py:476][0m param-summary/conv3/W-rms: 0.064122
[32m[0717 09:09:52 @monitor.py:476][0m param-summary/conv4/W-rms: 0.047175
[32m[0717 09:09:52 @monitor.py:476][0m param-summary/conv5/W-rms: 0.04845
[32m[0717 09:09:52 @monitor.py:476][0m param-summary/conv6/W-rms: 0.034966
[32m[0717 09:09:52 @monitor.py:476][0m param-summary/fc1/W-rms: 0.06084
[32m[0717 09:09:52 @monitor.py:476][0m regularize_cost: 9.4657e-07
[32m[0717 09:09:52 @monitor.py:476][0m train_error: 0.47547
[32m[0717 09:09:52 @monitor.py:476][0m val_accuracy: 0.94126
[32m[0717 09:09:52 @monitor.py:476][0m val_cross_entropy_loss: 0.19842
[32m[0717 09:09:52 @group.py:44][0m Callbacks took 3.368 sec in total. InferenceRunner: 3.06 seconds
[32m[0717 09:09:52 @base.py:273][0m Start Epoch 7 ...
[32m[0717 09:10:10 @base.py:283][0m Epoch 7 (global_step 3276) finished, time:18.7 seconds.
[32m[0717 09:10:11 @saver.py:82][0m Model saved to train_log/mnist-dorefa-6,6,6/model-3276.
[32m[0717 09:10:14 @monitor.py:476][0m QueueInput/queue_size: 5.6847e-14
[32m[0717 09:10:14 @monitor.py:476][0m accuracy: 0.52506
[32m[0717 09:10:14 @monitor.py:476][0m cost: 1.2811
[32m[0717 09:10:14 @monitor.py:476][0m cross_entropy_loss: 1.2811
[32m[0717 09:10:14 @monitor.py:476][0m param-summary/conv0/W-rms: 0.28998
[32m[0717 09:10:14 @monitor.py:476][0m param-summary/conv1/W-rms: 0.086321
[32m[0717 09:10:14 @monitor.py:476][0m param-summary/conv2/W-rms: 0.066688
[32m[0717 09:10:14 @monitor.py:476][0m param-summary/conv3/W-rms: 0.065524
[32m[0717 09:10:14 @monitor.py:476][0m param-summary/conv4/W-rms: 0.048541
[32m[0717 09:10:14 @monitor.py:476][0m param-summary/conv5/W-rms: 0.050014
[32m[0717 09:10:14 @monitor.py:476][0m param-summary/conv6/W-rms: 0.036891
[32m[0717 09:10:14 @monitor.py:476][0m param-summary/fc1/W-rms: 0.061626
[32m[0717 09:10:14 @monitor.py:476][0m regularize_cost: 9.73e-07
[32m[0717 09:10:14 @monitor.py:476][0m train_error: 0.47494
[32m[0717 09:10:14 @monitor.py:476][0m val_accuracy: 0.9643
[32m[0717 09:10:14 @monitor.py:476][0m val_cross_entropy_loss: 0.11606
[32m[0717 09:10:14 @group.py:44][0m Callbacks took 3.124 sec in total. InferenceRunner: 2.86 seconds
[32m[0717 09:10:14 @base.py:273][0m Start Epoch 8 ...
[32m[0717 09:10:32 @base.py:283][0m Epoch 8 (global_step 3744) finished, time:18.6 seconds.
[32m[0717 09:10:32 @saver.py:82][0m Model saved to train_log/mnist-dorefa-6,6,6/model-3744.
[32m[0717 09:10:35 @monitor.py:476][0m QueueInput/queue_size: 0.0004884
[32m[0717 09:10:35 @monitor.py:476][0m accuracy: 0.53326
[32m[0717 09:10:35 @monitor.py:476][0m cost: 1.2286
[32m[0717 09:10:35 @monitor.py:476][0m cross_entropy_loss: 1.2286
[32m[0717 09:10:35 @monitor.py:476][0m param-summary/conv0/W-rms: 0.29119
[32m[0717 09:10:35 @monitor.py:476][0m param-summary/conv1/W-rms: 0.089788
[32m[0717 09:10:35 @monitor.py:476][0m param-summary/conv2/W-rms: 0.068976
[32m[0717 09:10:35 @monitor.py:476][0m param-summary/conv3/W-rms: 0.068598
[32m[0717 09:10:35 @monitor.py:476][0m param-summary/conv4/W-rms: 0.051104
[32m[0717 09:10:35 @monitor.py:476][0m param-summary/conv5/W-rms: 0.05241
[32m[0717 09:10:35 @monitor.py:476][0m param-summary/conv6/W-rms: 0.039093
[32m[0717 09:10:35 @monitor.py:476][0m param-summary/fc1/W-rms: 0.06185
[32m[0717 09:10:35 @monitor.py:476][0m regularize_cost: 9.7904e-07
[32m[0717 09:10:35 @monitor.py:476][0m train_error: 0.46674
[32m[0717 09:10:35 @monitor.py:476][0m val_accuracy: 0.96954
[32m[0717 09:10:35 @monitor.py:476][0m val_cross_entropy_loss: 0.095689
[32m[0717 09:10:35 @group.py:44][0m Callbacks took 3.009 sec in total. InferenceRunner: 2.76 seconds
[32m[0717 09:10:35 @base.py:273][0m Start Epoch 9 ...
[32m[0717 09:10:55 @base.py:283][0m Epoch 9 (global_step 4212) finished, time:19.4 seconds.
[32m[0717 09:10:55 @saver.py:82][0m Model saved to train_log/mnist-dorefa-6,6,6/model-4212.
[32m[0717 09:10:58 @monitor.py:476][0m QueueInput/queue_size: 0.0015116
[32m[0717 09:10:58 @monitor.py:476][0m accuracy: 0.53378
[32m[0717 09:10:58 @monitor.py:476][0m cost: 1.2203
[32m[0717 09:10:58 @monitor.py:476][0m cross_entropy_loss: 1.2203
[32m[0717 09:10:58 @monitor.py:476][0m param-summary/conv0/W-rms: 0.29008
[32m[0717 09:10:58 @monitor.py:476][0m param-summary/conv1/W-rms: 0.089019
[32m[0717 09:10:58 @monitor.py:476][0m param-summary/conv2/W-rms: 0.069659
[32m[0717 09:10:58 @monitor.py:476][0m param-summary/conv3/W-rms: 0.069306
[32m[0717 09:10:58 @monitor.py:476][0m param-summary/conv4/W-rms: 0.052015
[32m[0717 09:10:58 @monitor.py:476][0m param-summary/conv5/W-rms: 0.053573
[32m[0717 09:10:58 @monitor.py:476][0m param-summary/conv6/W-rms: 0.040773
[32m[0717 09:10:58 @monitor.py:476][0m param-summary/fc1/W-rms: 0.062462
[32m[0717 09:10:58 @monitor.py:476][0m regularize_cost: 9.9796e-07
[32m[0717 09:10:58 @monitor.py:476][0m train_error: 0.46622
[32m[0717 09:10:58 @monitor.py:476][0m val_accuracy: 0.97449
[32m[0717 09:10:58 @monitor.py:476][0m val_cross_entropy_loss: 0.07866
[32m[0717 09:10:58 @group.py:44][0m Callbacks took 3.199 sec in total. InferenceRunner: 2.92 seconds
[32m[0717 09:10:58 @base.py:273][0m Start Epoch 10 ...
[32m[0717 09:11:17 @base.py:283][0m Epoch 10 (global_step 4680) finished, time:19.3 seconds.
[32m[0717 09:11:17 @saver.py:82][0m Model saved to train_log/mnist-dorefa-6,6,6/model-4680.
[32m[0717 09:11:20 @monitor.py:476][0m QueueInput/queue_size: 1.22e-07
[32m[0717 09:11:20 @monitor.py:476][0m accuracy: 0.54012
[32m[0717 09:11:20 @monitor.py:476][0m cost: 1.1976
[32m[0717 09:11:20 @monitor.py:476][0m cross_entropy_loss: 1.1976
[32m[0717 09:11:20 @monitor.py:476][0m param-summary/conv0/W-rms: 0.29111
[32m[0717 09:11:20 @monitor.py:476][0m param-summary/conv1/W-rms: 0.090024
[32m[0717 09:11:20 @monitor.py:476][0m param-summary/conv2/W-rms: 0.070967
[32m[0717 09:11:20 @monitor.py:476][0m param-summary/conv3/W-rms: 0.070281
[32m[0717 09:11:20 @monitor.py:476][0m param-summary/conv4/W-rms: 0.05316
[32m[0717 09:11:20 @monitor.py:476][0m param-summary/conv5/W-rms: 0.054943
[32m[0717 09:11:20 @monitor.py:476][0m param-summary/conv6/W-rms: 0.042447
[32m[0717 09:11:20 @monitor.py:476][0m param-summary/fc1/W-rms: 0.063325
[32m[0717 09:11:20 @monitor.py:476][0m regularize_cost: 1.0256e-06
[32m[0717 09:11:20 @monitor.py:476][0m train_error: 0.45988
[32m[0717 09:11:20 @monitor.py:476][0m val_accuracy: 0.97379
[32m[0717 09:11:20 @monitor.py:476][0m val_cross_entropy_loss: 0.0845
[32m[0717 09:11:20 @group.py:44][0m Callbacks took 3.280 sec in total. InferenceRunner: 3 seconds
[32m[0717 09:11:20 @base.py:287][0m Training has finished!
[32m[0717 09:11:21 @input_source.py:177][0m [EnqueueThread] Thread EnqueueThread: enqueue dataflow to TF queue "QueueInput/input_queue" Exited.
