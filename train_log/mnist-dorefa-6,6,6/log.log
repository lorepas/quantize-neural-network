[32m[0717 09:13:52 @logger.py:92][0m Argv: /usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py -f /root/.local/share/jupyter/runtime/kernel-deb98920-21fb-4f50-b049-99bfb143a407.json
[32m[0717 09:13:53 @parallel.py:340][0m [MultiProcessRunnerZMQ] Will fork a dataflow more than one times. This assumes the datapoints are i.i.d.
[32m[0717 09:13:53 @input_source.py:221][0m Setting up the queue 'QueueInput/input_queue' for CPU prefetching ...
[32m[0717 09:13:53 @trainers.py:48][0m Building graph for a single training tower ...
[32m[0717 09:13:53 @<ipython-input-20-64ea70a806e1>:113][0m Binarizing weight conv0/W
[32m[0717 09:13:53 @<ipython-input-20-64ea70a806e1>:113][0m Binarizing weight conv1/W
[32m[0717 09:13:53 @<ipython-input-20-64ea70a806e1>:113][0m Binarizing weight conv2/W
[32m[0717 09:13:53 @<ipython-input-20-64ea70a806e1>:113][0m Binarizing weight conv3/W
[32m[0717 09:13:53 @<ipython-input-20-64ea70a806e1>:113][0m Binarizing weight conv4/W
[32m[0717 09:13:53 @<ipython-input-20-64ea70a806e1>:113][0m Binarizing weight conv5/W
[32m[0717 09:13:53 @<ipython-input-20-64ea70a806e1>:113][0m Binarizing weight conv6/W
[32m[0717 09:13:53 @<ipython-input-20-64ea70a806e1>:113][0m Binarizing weight fc1/W
[32m[0717 09:13:53 @regularize.py:97][0m regularize_cost() found 1 variables to regularize.
[32m[0717 09:13:53 @regularize.py:21][0m The following tensors will be regularized: fc1/W:0
[32m[0717 09:13:54 @model_utils.py:67][0m [36mList of Trainable Variables: 
[0mname       shape               #elements
---------  ----------------  -----------
conv0/W    [5, 5, 1, 48]            1200
conv0/b    [48]                       48
conv1/W    [3, 3, 48, 64]          27648
bn1/gamma  [64]                       64
bn1/beta   [64]                       64
conv2/W    [3, 3, 64, 64]          36864
bn2/gamma  [64]                       64
bn2/beta   [64]                       64
conv3/W    [3, 3, 64, 128]         73728
bn3/gamma  [128]                     128
bn3/beta   [128]                     128
conv4/W    [3, 3, 128, 128]       147456
bn4/gamma  [128]                     128
bn4/beta   [128]                     128
conv5/W    [3, 3, 128, 128]       147456
bn5/gamma  [128]                     128
bn5/beta   [128]                     128
conv6/W    [5, 5, 128, 512]      1638400
bn6/gamma  [512]                     512
bn6/beta   [512]                     512
fc1/W      [512, 10]                5120
fc1/b      [10]                       10[36m
Number of trainable variables: 22
Number of parameters (elements): 2079978
Storage space needed for all trainable variables: 7.93MB[0m
[32m[0717 09:13:54 @base.py:207][0m Setup callbacks graph ...
[32m[0717 09:13:54 @argtools.py:138][0m [5m[31mWRN[0m "import prctl" failed! Install python-prctl so that processes can be cleaned with guarantee.
[32m[0717 09:13:55 @inference_runner.py:148][0m [InferenceRunner] Building tower 'InferenceTower' on device /gpu:0 ...
[32m[0717 09:13:55 @<ipython-input-20-64ea70a806e1>:113][0m Binarizing weight conv0/W
[32m[0717 09:13:55 @<ipython-input-20-64ea70a806e1>:113][0m Binarizing weight conv1/W
[32m[0717 09:13:56 @<ipython-input-20-64ea70a806e1>:113][0m Binarizing weight conv2/W
[32m[0717 09:13:56 @<ipython-input-20-64ea70a806e1>:113][0m Binarizing weight conv3/W
[32m[0717 09:13:56 @<ipython-input-20-64ea70a806e1>:113][0m Binarizing weight conv4/W
[32m[0717 09:13:56 @<ipython-input-20-64ea70a806e1>:113][0m Binarizing weight conv5/W
[32m[0717 09:13:57 @<ipython-input-20-64ea70a806e1>:113][0m Binarizing weight conv6/W
[32m[0717 09:13:57 @<ipython-input-20-64ea70a806e1>:113][0m Binarizing weight fc1/W
[32m[0717 09:13:57 @summary.py:47][0m [MovingAverageSummary] 5 operations in collection 'MOVING_SUMMARY_OPS' will be run with session hooks.
[32m[0717 09:13:57 @summary.py:94][0m Summarizing collection 'summaries' of size 22.
[32m[0717 09:13:57 @graph.py:99][0m Applying collection UPDATE_OPS of 12 ops.
[32m[0717 09:13:57 @base.py:228][0m Creating the session ...
[32m[0717 09:13:58 @base.py:234][0m Initializing the session ...
[32m[0717 09:13:58 @base.py:241][0m Graph Finalized.
[32m[0717 09:13:58 @concurrency.py:37][0m Starting EnqueueThread: enqueue dataflow to TF queue "QueueInput/input_queue" ...
[32m[0717 09:13:58 @inference_runner.py:95][0m [InferenceRunner] Will eval 79 iterations
[32m[0717 09:13:58 @monitor.py:361][0m [5m[31mWRN[0m History epoch=10 from JSON is not the predecessor of the current starting_epoch=1
[32m[0717 09:13:58 @monitor.py:362][0m [5m[31mWRN[0m If you want to resume old training, either use `AutoResumeTrainConfig` or correctly set the new starting_epoch yourself to avoid inconsistency. 
[32m[0717 09:13:58 @monitor.py:369][0m [5m[31mWRN[0m Now, we will train with starting_epoch=1 and backup old json to train_log/mnist-dorefa-6,6,6/stats.json.0717-091358
[32m[0717 09:13:58 @base.py:273][0m Start Epoch 1 ...
[32m[0717 09:14:13 @base.py:283][0m Epoch 1 (global_step 468) finished, time:14.4 seconds.
[32m[0717 09:14:13 @saver.py:82][0m Model saved to train_log/mnist-dorefa-6,6,6/model-468.
[32m[0717 09:14:14 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[0717 09:14:14 @monitor.py:476][0m accuracy: 0.96493
[32m[0717 09:14:14 @monitor.py:476][0m cost: 0.10435
[32m[0717 09:14:14 @monitor.py:476][0m cross_entropy_loss: 0.10435
[32m[0717 09:14:14 @monitor.py:476][0m param-summary/conv0/W-rms: 0.2855
[32m[0717 09:14:14 @monitor.py:476][0m param-summary/conv1/W-rms: 0.067979
[32m[0717 09:14:14 @monitor.py:476][0m param-summary/conv2/W-rms: 0.059744
[32m[0717 09:14:14 @monitor.py:476][0m param-summary/conv3/W-rms: 0.059539
[32m[0717 09:14:14 @monitor.py:476][0m param-summary/conv4/W-rms: 0.042983
[32m[0717 09:14:14 @monitor.py:476][0m param-summary/conv5/W-rms: 0.043162
[32m[0717 09:14:14 @monitor.py:476][0m param-summary/conv6/W-rms: 0.027592
[32m[0717 09:14:14 @monitor.py:476][0m param-summary/fc1/W-rms: 0.057285
[32m[0717 09:14:14 @monitor.py:476][0m regularize_cost: 8.4149e-07
[32m[0717 09:14:14 @monitor.py:476][0m train_error: 0.035066
[32m[0717 09:14:14 @monitor.py:476][0m val_accuracy: 0.97953
[32m[0717 09:14:14 @monitor.py:476][0m val_cross_entropy_loss: 0.069036
[32m[0717 09:14:14 @base.py:273][0m Start Epoch 2 ...
[32m[0717 09:14:27 @base.py:283][0m Epoch 2 (global_step 936) finished, time:13.2 seconds.
[32m[0717 09:14:27 @saver.py:82][0m Model saved to train_log/mnist-dorefa-6,6,6/model-936.
[32m[0717 09:14:28 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[0717 09:14:28 @monitor.py:476][0m accuracy: 0.97634
[32m[0717 09:14:28 @monitor.py:476][0m cost: 0.074439
[32m[0717 09:14:28 @monitor.py:476][0m cross_entropy_loss: 0.074438
[32m[0717 09:14:28 @monitor.py:476][0m param-summary/conv0/W-rms: 0.28595
[32m[0717 09:14:28 @monitor.py:476][0m param-summary/conv1/W-rms: 0.068308
[32m[0717 09:14:28 @monitor.py:476][0m param-summary/conv2/W-rms: 0.060022
[32m[0717 09:14:28 @monitor.py:476][0m param-summary/conv3/W-rms: 0.059868
[32m[0717 09:14:28 @monitor.py:476][0m param-summary/conv4/W-rms: 0.043444
[32m[0717 09:14:28 @monitor.py:476][0m param-summary/conv5/W-rms: 0.043803
[32m[0717 09:14:28 @monitor.py:476][0m param-summary/conv6/W-rms: 0.028663
[32m[0717 09:14:28 @monitor.py:476][0m param-summary/fc1/W-rms: 0.056382
[32m[0717 09:14:28 @monitor.py:476][0m regularize_cost: 8.1475e-07
[32m[0717 09:14:28 @monitor.py:476][0m train_error: 0.02366
[32m[0717 09:14:28 @monitor.py:476][0m val_accuracy: 0.98259
[32m[0717 09:14:28 @monitor.py:476][0m val_cross_entropy_loss: 0.054493
[32m[0717 09:14:28 @base.py:273][0m Start Epoch 3 ...
[32m[0717 09:14:42 @base.py:283][0m Epoch 3 (global_step 1404) finished, time:13.2 seconds.
[32m[0717 09:14:42 @saver.py:82][0m Model saved to train_log/mnist-dorefa-6,6,6/model-1404.
[32m[0717 09:14:43 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[0717 09:14:43 @monitor.py:476][0m accuracy: 0.98456
[32m[0717 09:14:43 @monitor.py:476][0m cost: 0.05296
[32m[0717 09:14:43 @monitor.py:476][0m cross_entropy_loss: 0.052959
[32m[0717 09:14:43 @monitor.py:476][0m param-summary/conv0/W-rms: 0.28653
[32m[0717 09:14:43 @monitor.py:476][0m param-summary/conv1/W-rms: 0.068892
[32m[0717 09:14:43 @monitor.py:476][0m param-summary/conv2/W-rms: 0.060289
[32m[0717 09:14:43 @monitor.py:476][0m param-summary/conv3/W-rms: 0.060174
[32m[0717 09:14:43 @monitor.py:476][0m param-summary/conv4/W-rms: 0.043874
[32m[0717 09:14:43 @monitor.py:476][0m param-summary/conv5/W-rms: 0.044392
[32m[0717 09:14:43 @monitor.py:476][0m param-summary/conv6/W-rms: 0.029587
[32m[0717 09:14:43 @monitor.py:476][0m param-summary/fc1/W-rms: 0.056781
[32m[0717 09:14:43 @monitor.py:476][0m regularize_cost: 8.2471e-07
[32m[0717 09:14:43 @monitor.py:476][0m train_error: 0.01544
[32m[0717 09:14:43 @monitor.py:476][0m val_accuracy: 0.98833
[32m[0717 09:14:43 @monitor.py:476][0m val_cross_entropy_loss: 0.036704
[32m[0717 09:14:43 @base.py:273][0m Start Epoch 4 ...
[32m[0717 09:14:56 @base.py:283][0m Epoch 4 (global_step 1872) finished, time:13.1 seconds.
[32m[0717 09:14:56 @saver.py:82][0m Model saved to train_log/mnist-dorefa-6,6,6/model-1872.
[32m[0717 09:14:57 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[0717 09:14:57 @monitor.py:476][0m accuracy: 0.98683
[32m[0717 09:14:57 @monitor.py:476][0m cost: 0.035322
[32m[0717 09:14:57 @monitor.py:476][0m cross_entropy_loss: 0.035321
[32m[0717 09:14:57 @monitor.py:476][0m param-summary/conv0/W-rms: 0.28715
[32m[0717 09:14:57 @monitor.py:476][0m param-summary/conv1/W-rms: 0.069444
[32m[0717 09:14:57 @monitor.py:476][0m param-summary/conv2/W-rms: 0.060572
[32m[0717 09:14:57 @monitor.py:476][0m param-summary/conv3/W-rms: 0.060521
[32m[0717 09:14:57 @monitor.py:476][0m param-summary/conv4/W-rms: 0.04435
[32m[0717 09:14:57 @monitor.py:476][0m param-summary/conv5/W-rms: 0.045024
[32m[0717 09:14:57 @monitor.py:476][0m param-summary/conv6/W-rms: 0.030502
[32m[0717 09:14:57 @monitor.py:476][0m param-summary/fc1/W-rms: 0.05771
[32m[0717 09:14:57 @monitor.py:476][0m regularize_cost: 8.5069e-07
[32m[0717 09:14:57 @monitor.py:476][0m train_error: 0.013172
[32m[0717 09:14:57 @monitor.py:476][0m val_accuracy: 0.98853
[32m[0717 09:14:57 @monitor.py:476][0m val_cross_entropy_loss: 0.033862
[32m[0717 09:14:57 @base.py:273][0m Start Epoch 5 ...
[32m[0717 09:15:10 @base.py:283][0m Epoch 5 (global_step 2340) finished, time:13 seconds.
[32m[0717 09:15:10 @saver.py:82][0m Model saved to train_log/mnist-dorefa-6,6,6/model-2340.
[32m[0717 09:15:11 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[0717 09:15:11 @monitor.py:476][0m accuracy: 0.98633
[32m[0717 09:15:11 @monitor.py:476][0m cost: 0.041962
[32m[0717 09:15:11 @monitor.py:476][0m cross_entropy_loss: 0.041961
[32m[0717 09:15:11 @monitor.py:476][0m param-summary/conv0/W-rms: 0.28757
[32m[0717 09:15:11 @monitor.py:476][0m param-summary/conv1/W-rms: 0.070526
[32m[0717 09:15:11 @monitor.py:476][0m param-summary/conv2/W-rms: 0.060967
[32m[0717 09:15:11 @monitor.py:476][0m param-summary/conv3/W-rms: 0.060985
[32m[0717 09:15:11 @monitor.py:476][0m param-summary/conv4/W-rms: 0.044979
[32m[0717 09:15:11 @monitor.py:476][0m param-summary/conv5/W-rms: 0.045855
[32m[0717 09:15:11 @monitor.py:476][0m param-summary/conv6/W-rms: 0.031643
[32m[0717 09:15:11 @monitor.py:476][0m param-summary/fc1/W-rms: 0.058758
[32m[0717 09:15:11 @monitor.py:476][0m regularize_cost: 8.8265e-07
[32m[0717 09:15:11 @monitor.py:476][0m train_error: 0.013672
[32m[0717 09:15:11 @monitor.py:476][0m val_accuracy: 0.98863
[32m[0717 09:15:11 @monitor.py:476][0m val_cross_entropy_loss: 0.03427
[32m[0717 09:15:11 @base.py:273][0m Start Epoch 6 ...
[32m[0717 09:15:24 @base.py:283][0m Epoch 6 (global_step 2808) finished, time:12.8 seconds.
[32m[0717 09:15:24 @saver.py:82][0m Model saved to train_log/mnist-dorefa-6,6,6/model-2808.
[32m[0717 09:15:25 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[0717 09:15:25 @monitor.py:476][0m accuracy: 0.98561
[32m[0717 09:15:25 @monitor.py:476][0m cost: 0.0407
[32m[0717 09:15:25 @monitor.py:476][0m cross_entropy_loss: 0.040699
[32m[0717 09:15:25 @monitor.py:476][0m param-summary/conv0/W-rms: 0.28816
[32m[0717 09:15:25 @monitor.py:476][0m param-summary/conv1/W-rms: 0.071645
[32m[0717 09:15:25 @monitor.py:476][0m param-summary/conv2/W-rms: 0.061367
[32m[0717 09:15:25 @monitor.py:476][0m param-summary/conv3/W-rms: 0.06147
[32m[0717 09:15:25 @monitor.py:476][0m param-summary/conv4/W-rms: 0.045596
[32m[0717 09:15:25 @monitor.py:476][0m param-summary/conv5/W-rms: 0.046677
[32m[0717 09:15:25 @monitor.py:476][0m param-summary/conv6/W-rms: 0.032748
[32m[0717 09:15:25 @monitor.py:476][0m param-summary/fc1/W-rms: 0.06014
[32m[0717 09:15:25 @monitor.py:476][0m regularize_cost: 9.2464e-07
[32m[0717 09:15:25 @monitor.py:476][0m train_error: 0.01439
[32m[0717 09:15:25 @monitor.py:476][0m val_accuracy: 0.98863
[32m[0717 09:15:25 @monitor.py:476][0m val_cross_entropy_loss: 0.03259
[32m[0717 09:15:25 @base.py:273][0m Start Epoch 7 ...
[32m[0717 09:15:38 @base.py:283][0m Epoch 7 (global_step 3276) finished, time:13.1 seconds.
[32m[0717 09:15:38 @saver.py:82][0m Model saved to train_log/mnist-dorefa-6,6,6/model-3276.
[32m[0717 09:15:39 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[0717 09:15:39 @monitor.py:476][0m accuracy: 0.99037
[32m[0717 09:15:39 @monitor.py:476][0m cost: 0.032041
[32m[0717 09:15:39 @monitor.py:476][0m cross_entropy_loss: 0.03204
[32m[0717 09:15:39 @monitor.py:476][0m param-summary/conv0/W-rms: 0.28893
[32m[0717 09:15:39 @monitor.py:476][0m param-summary/conv1/W-rms: 0.07271
[32m[0717 09:15:39 @monitor.py:476][0m param-summary/conv2/W-rms: 0.061888
[32m[0717 09:15:39 @monitor.py:476][0m param-summary/conv3/W-rms: 0.062126
[32m[0717 09:15:39 @monitor.py:476][0m param-summary/conv4/W-rms: 0.046393
[32m[0717 09:15:39 @monitor.py:476][0m param-summary/conv5/W-rms: 0.04775
[32m[0717 09:15:39 @monitor.py:476][0m param-summary/conv6/W-rms: 0.034113
[32m[0717 09:15:39 @monitor.py:476][0m param-summary/fc1/W-rms: 0.06158
[32m[0717 09:15:39 @monitor.py:476][0m regularize_cost: 9.6861e-07
[32m[0717 09:15:39 @monitor.py:476][0m train_error: 0.0096253
[32m[0717 09:15:39 @monitor.py:476][0m val_accuracy: 0.99041
[32m[0717 09:15:39 @monitor.py:476][0m val_cross_entropy_loss: 0.028934
[32m[0717 09:15:39 @base.py:273][0m Start Epoch 8 ...
[32m[0717 09:15:52 @base.py:283][0m Epoch 8 (global_step 3744) finished, time:13.2 seconds.
[32m[0717 09:15:52 @saver.py:82][0m Model saved to train_log/mnist-dorefa-6,6,6/model-3744.
[32m[0717 09:15:53 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[0717 09:15:53 @monitor.py:476][0m accuracy: 0.99189
[32m[0717 09:15:53 @monitor.py:476][0m cost: 0.024643
[32m[0717 09:15:53 @monitor.py:476][0m cross_entropy_loss: 0.024642
[32m[0717 09:15:53 @monitor.py:476][0m param-summary/conv0/W-rms: 0.28949
[32m[0717 09:15:53 @monitor.py:476][0m param-summary/conv1/W-rms: 0.073473
[32m[0717 09:15:53 @monitor.py:476][0m param-summary/conv2/W-rms: 0.062437
[32m[0717 09:15:53 @monitor.py:476][0m param-summary/conv3/W-rms: 0.062813
[32m[0717 09:15:53 @monitor.py:476][0m param-summary/conv4/W-rms: 0.047226
[32m[0717 09:15:53 @monitor.py:476][0m param-summary/conv5/W-rms: 0.048853
[32m[0717 09:15:53 @monitor.py:476][0m param-summary/conv6/W-rms: 0.035483
[32m[0717 09:15:53 @monitor.py:476][0m param-summary/fc1/W-rms: 0.063406
[32m[0717 09:15:53 @monitor.py:476][0m regularize_cost: 1.0261e-06
[32m[0717 09:15:53 @monitor.py:476][0m train_error: 0.0081088
[32m[0717 09:15:53 @monitor.py:476][0m val_accuracy: 0.9907
[32m[0717 09:15:53 @monitor.py:476][0m val_cross_entropy_loss: 0.029073
[32m[0717 09:15:53 @base.py:273][0m Start Epoch 9 ...
[32m[0717 09:16:07 @base.py:283][0m Epoch 9 (global_step 4212) finished, time:13.3 seconds.
[32m[0717 09:16:07 @saver.py:82][0m Model saved to train_log/mnist-dorefa-6,6,6/model-4212.
[32m[0717 09:16:08 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[0717 09:16:08 @monitor.py:476][0m accuracy: 0.99272
[32m[0717 09:16:08 @monitor.py:476][0m cost: 0.021471
[32m[0717 09:16:08 @monitor.py:476][0m cross_entropy_loss: 0.02147
[32m[0717 09:16:08 @monitor.py:476][0m param-summary/conv0/W-rms: 0.29026
[32m[0717 09:16:08 @monitor.py:476][0m param-summary/conv1/W-rms: 0.074085
[32m[0717 09:16:08 @monitor.py:476][0m param-summary/conv2/W-rms: 0.06314
[32m[0717 09:16:08 @monitor.py:476][0m param-summary/conv3/W-rms: 0.063641
[32m[0717 09:16:08 @monitor.py:476][0m param-summary/conv4/W-rms: 0.048217
[32m[0717 09:16:08 @monitor.py:476][0m param-summary/conv5/W-rms: 0.050128
[32m[0717 09:16:08 @monitor.py:476][0m param-summary/conv6/W-rms: 0.03703
[32m[0717 09:16:08 @monitor.py:476][0m param-summary/fc1/W-rms: 0.065395
[32m[0717 09:16:08 @monitor.py:476][0m regularize_cost: 1.0909e-06
[32m[0717 09:16:08 @monitor.py:476][0m train_error: 0.0072774
[32m[0717 09:16:08 @monitor.py:476][0m val_accuracy: 0.98981
[32m[0717 09:16:08 @monitor.py:476][0m val_cross_entropy_loss: 0.035255
[32m[0717 09:16:08 @base.py:273][0m Start Epoch 10 ...
[32m[0717 09:16:21 @base.py:283][0m Epoch 10 (global_step 4680) finished, time:12.8 seconds.
[32m[0717 09:16:21 @saver.py:82][0m Model saved to train_log/mnist-dorefa-6,6,6/model-4680.
[32m[0717 09:16:22 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[0717 09:16:22 @monitor.py:476][0m accuracy: 0.99035
[32m[0717 09:16:22 @monitor.py:476][0m cost: 0.029972
[32m[0717 09:16:22 @monitor.py:476][0m cross_entropy_loss: 0.029971
[32m[0717 09:16:22 @monitor.py:476][0m param-summary/conv0/W-rms: 0.29098
[32m[0717 09:16:22 @monitor.py:476][0m param-summary/conv1/W-rms: 0.074906
[32m[0717 09:16:22 @monitor.py:476][0m param-summary/conv2/W-rms: 0.063842
[32m[0717 09:16:22 @monitor.py:476][0m param-summary/conv3/W-rms: 0.06453
[32m[0717 09:16:22 @monitor.py:476][0m param-summary/conv4/W-rms: 0.04929
[32m[0717 09:16:22 @monitor.py:476][0m param-summary/conv5/W-rms: 0.051471
[32m[0717 09:16:22 @monitor.py:476][0m param-summary/conv6/W-rms: 0.038591
[32m[0717 09:16:22 @monitor.py:476][0m param-summary/fc1/W-rms: 0.067537
[32m[0717 09:16:22 @monitor.py:476][0m regularize_cost: 1.1663e-06
[32m[0717 09:16:22 @monitor.py:476][0m train_error: 0.0096529
[32m[0717 09:16:22 @monitor.py:476][0m val_accuracy: 0.98912
[32m[0717 09:16:22 @monitor.py:476][0m val_cross_entropy_loss: 0.035005
[32m[0717 09:16:22 @base.py:287][0m Training has finished!
[32m[0717 09:16:22 @input_source.py:177][0m [EnqueueThread] Thread EnqueueThread: enqueue dataflow to TF queue "QueueInput/input_queue" Exited.
