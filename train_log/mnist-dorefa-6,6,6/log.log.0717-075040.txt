[32m[0717 07:45:49 @logger.py:92][0m Argv: /usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py -f /root/.local/share/jupyter/runtime/kernel-deb98920-21fb-4f50-b049-99bfb143a407.json
[32m[0717 07:45:49 @parallel.py:340][0m [MultiProcessRunnerZMQ] Will fork a dataflow more than one times. This assumes the datapoints are i.i.d.
[32m[0717 07:45:49 @input_source.py:221][0m Setting up the queue 'QueueInput/input_queue' for CPU prefetching ...
[32m[0717 07:45:49 @trainers.py:48][0m Building graph for a single training tower ...
[32m[0717 07:45:49 @<ipython-input-6-18a26361feb5>:113][0m Binarizing weight conv0/W
[32m[0717 07:45:49 @<ipython-input-6-18a26361feb5>:113][0m Binarizing weight conv1/W
[32m[0717 07:45:49 @<ipython-input-6-18a26361feb5>:113][0m Binarizing weight conv2/W
[32m[0717 07:45:49 @<ipython-input-6-18a26361feb5>:113][0m Binarizing weight conv3/W
[32m[0717 07:45:49 @<ipython-input-6-18a26361feb5>:113][0m Binarizing weight conv4/W
[32m[0717 07:45:50 @<ipython-input-6-18a26361feb5>:113][0m Binarizing weight conv5/W
[32m[0717 07:45:50 @<ipython-input-6-18a26361feb5>:113][0m Binarizing weight conv6/W
[32m[0717 07:45:50 @<ipython-input-6-18a26361feb5>:113][0m Binarizing weight fc1/W
[32m[0717 07:45:50 @regularize.py:97][0m regularize_cost() found 1 variables to regularize.
[32m[0717 07:45:50 @regularize.py:21][0m The following tensors will be regularized: fc1/W:0
[32m[0717 07:45:51 @model_utils.py:67][0m [36mList of Trainable Variables: 
[0mname       shape               #elements
---------  ----------------  -----------
conv0/W    [5, 5, 1, 48]            1200
conv0/b    [48]                       48
conv1/W    [3, 3, 48, 64]          27648
bn1/gamma  [64]                       64
bn1/beta   [64]                       64
conv2/W    [3, 3, 64, 64]          36864
bn2/gamma  [64]                       64
bn2/beta   [64]                       64
conv3/W    [3, 3, 64, 128]         73728
bn3/gamma  [128]                     128
bn3/beta   [128]                     128
conv4/W    [3, 3, 128, 128]       147456
bn4/gamma  [128]                     128
bn4/beta   [128]                     128
conv5/W    [3, 3, 128, 128]       147456
bn5/gamma  [128]                     128
bn5/beta   [128]                     128
conv6/W    [5, 5, 128, 512]      1638400
bn6/gamma  [512]                     512
bn6/beta   [512]                     512
fc1/W      [512, 10]                5120
fc1/b      [10]                       10[36m
Number of trainable variables: 22
Number of parameters (elements): 2079978
Storage space needed for all trainable variables: 7.93MB[0m
[32m[0717 07:45:51 @base.py:207][0m Setup callbacks graph ...
[32m[0717 07:45:51 @argtools.py:138][0m [5m[31mWRN[0m "import prctl" failed! Install python-prctl so that processes can be cleaned with guarantee.
[32m[0717 07:45:51 @inference_runner.py:148][0m [InferenceRunner] Building tower 'InferenceTower' on device /gpu:0 ...
[32m[0717 07:45:51 @<ipython-input-6-18a26361feb5>:113][0m Binarizing weight conv0/W
[32m[0717 07:45:51 @<ipython-input-6-18a26361feb5>:113][0m Binarizing weight conv1/W
[32m[0717 07:45:52 @<ipython-input-6-18a26361feb5>:113][0m Binarizing weight conv2/W
[32m[0717 07:45:52 @<ipython-input-6-18a26361feb5>:113][0m Binarizing weight conv3/W
[32m[0717 07:45:52 @<ipython-input-6-18a26361feb5>:113][0m Binarizing weight conv4/W
[32m[0717 07:45:52 @<ipython-input-6-18a26361feb5>:113][0m Binarizing weight conv5/W
[32m[0717 07:45:52 @<ipython-input-6-18a26361feb5>:113][0m Binarizing weight conv6/W
[32m[0717 07:45:53 @<ipython-input-6-18a26361feb5>:113][0m Binarizing weight fc1/W
[32m[0717 07:45:53 @summary.py:47][0m [MovingAverageSummary] 5 operations in collection 'MOVING_SUMMARY_OPS' will be run with session hooks.
[32m[0717 07:45:53 @summary.py:94][0m Summarizing collection 'summaries' of size 22.
[32m[0717 07:45:53 @graph.py:99][0m Applying collection UPDATE_OPS of 12 ops.
[32m[0717 07:45:53 @base.py:228][0m Creating the session ...
[32m[0717 07:45:54 @base.py:234][0m Initializing the session ...
[32m[0717 07:45:54 @base.py:241][0m Graph Finalized.
[32m[0717 07:45:54 @concurrency.py:37][0m Starting EnqueueThread: enqueue dataflow to TF queue "QueueInput/input_queue" ...
[32m[0717 07:45:55 @inference_runner.py:95][0m [InferenceRunner] Will eval 79 iterations
[32m[0717 07:45:55 @base.py:273][0m Start Epoch 1 ...
[32m[0717 07:46:50 @base.py:283][0m Epoch 1 (global_step 468) finished, time:54.4 seconds.
[32m[0717 07:46:50 @saver.py:82][0m Model saved to train_log/mnist-dorefa-6,6,6/model-468.
[32m[0717 07:46:54 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[0717 07:46:54 @monitor.py:476][0m accuracy: 0.10038
[32m[0717 07:46:54 @monitor.py:476][0m cost: 2.3812
[32m[0717 07:46:54 @monitor.py:476][0m cross_entropy_loss: 2.3812
[32m[0717 07:46:54 @monitor.py:476][0m param-summary/conv0/W-rms: 0.27576
[32m[0717 07:46:54 @monitor.py:476][0m param-summary/conv1/W-rms: 0.068653
[32m[0717 07:46:54 @monitor.py:476][0m param-summary/conv2/W-rms: 0.059419
[32m[0717 07:46:54 @monitor.py:476][0m param-summary/conv3/W-rms: 0.059259
[32m[0717 07:46:54 @monitor.py:476][0m param-summary/conv4/W-rms: 0.04218
[32m[0717 07:46:54 @monitor.py:476][0m param-summary/conv5/W-rms: 0.042216
[32m[0717 07:46:54 @monitor.py:476][0m param-summary/conv6/W-rms: 0.026445
[32m[0717 07:46:54 @monitor.py:476][0m param-summary/fc1/W-rms: 0.057791
[32m[0717 07:46:54 @monitor.py:476][0m regularize_cost: 8.5625e-07
[32m[0717 07:46:54 @monitor.py:476][0m train_error: 0.89962
[32m[0717 07:46:54 @monitor.py:476][0m val_accuracy: 0.26553
[32m[0717 07:46:54 @monitor.py:476][0m val_cross_entropy_loss: 2.1381
[32m[0717 07:46:54 @group.py:44][0m Callbacks took 4.479 sec in total. InferenceRunner: 3.84 seconds
[32m[0717 07:46:54 @base.py:273][0m Start Epoch 2 ...
[32m[0717 07:47:10 @base.py:283][0m Epoch 2 (global_step 936) finished, time:15.9 seconds.
[32m[0717 07:47:10 @saver.py:82][0m Model saved to train_log/mnist-dorefa-6,6,6/model-936.
[32m[0717 07:47:13 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[0717 07:47:13 @monitor.py:476][0m accuracy: 0.096345
[32m[0717 07:47:13 @monitor.py:476][0m cost: 2.3529
[32m[0717 07:47:13 @monitor.py:476][0m cross_entropy_loss: 2.3529
[32m[0717 07:47:13 @monitor.py:476][0m param-summary/conv0/W-rms: 0.27578
[32m[0717 07:47:13 @monitor.py:476][0m param-summary/conv1/W-rms: 0.069518
[32m[0717 07:47:13 @monitor.py:476][0m param-summary/conv2/W-rms: 0.059617
[32m[0717 07:47:13 @monitor.py:476][0m param-summary/conv3/W-rms: 0.059421
[32m[0717 07:47:13 @monitor.py:476][0m param-summary/conv4/W-rms: 0.042332
[32m[0717 07:47:13 @monitor.py:476][0m param-summary/conv5/W-rms: 0.04244
[32m[0717 07:47:13 @monitor.py:476][0m param-summary/conv6/W-rms: 0.027104
[32m[0717 07:47:13 @monitor.py:476][0m param-summary/fc1/W-rms: 0.056972
[32m[0717 07:47:13 @monitor.py:476][0m regularize_cost: 8.3157e-07
[32m[0717 07:47:13 @monitor.py:476][0m train_error: 0.90365
[32m[0717 07:47:13 @monitor.py:476][0m val_accuracy: 0.098596
[32m[0717 07:47:13 @monitor.py:476][0m val_cross_entropy_loss: 2.342
[32m[0717 07:47:13 @group.py:44][0m Callbacks took 3.252 sec in total. InferenceRunner: 2.98 seconds
[32m[0717 07:47:13 @base.py:273][0m Start Epoch 3 ...
[32m[0717 07:47:30 @base.py:283][0m Epoch 3 (global_step 1404) finished, time:16.2 seconds.
[32m[0717 07:47:30 @saver.py:82][0m Model saved to train_log/mnist-dorefa-6,6,6/model-1404.
[32m[0717 07:47:33 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[0717 07:47:33 @monitor.py:476][0m accuracy: 0.10289
[32m[0717 07:47:33 @monitor.py:476][0m cost: 2.3433
[32m[0717 07:47:33 @monitor.py:476][0m cross_entropy_loss: 2.3433
[32m[0717 07:47:33 @monitor.py:476][0m param-summary/conv0/W-rms: 0.27589
[32m[0717 07:47:33 @monitor.py:476][0m param-summary/conv1/W-rms: 0.070424
[32m[0717 07:47:33 @monitor.py:476][0m param-summary/conv2/W-rms: 0.059845
[32m[0717 07:47:33 @monitor.py:476][0m param-summary/conv3/W-rms: 0.059552
[32m[0717 07:47:33 @monitor.py:476][0m param-summary/conv4/W-rms: 0.042446
[32m[0717 07:47:33 @monitor.py:476][0m param-summary/conv5/W-rms: 0.04262
[32m[0717 07:47:33 @monitor.py:476][0m param-summary/conv6/W-rms: 0.027639
[32m[0717 07:47:33 @monitor.py:476][0m param-summary/fc1/W-rms: 0.056494
[32m[0717 07:47:33 @monitor.py:476][0m regularize_cost: 8.1756e-07
[32m[0717 07:47:33 @monitor.py:476][0m train_error: 0.89711
[32m[0717 07:47:33 @monitor.py:476][0m val_accuracy: 0.094047
[32m[0717 07:47:33 @monitor.py:476][0m val_cross_entropy_loss: 2.3258
[32m[0717 07:47:33 @group.py:44][0m Callbacks took 2.922 sec in total. InferenceRunner: 2.66 seconds
[32m[0717 07:47:33 @base.py:273][0m Start Epoch 4 ...
[32m[0717 07:47:49 @base.py:283][0m Epoch 4 (global_step 1872) finished, time:16.3 seconds.
[32m[0717 07:47:49 @saver.py:82][0m Model saved to train_log/mnist-dorefa-6,6,6/model-1872.
[32m[0717 07:47:52 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[0717 07:47:52 @monitor.py:476][0m accuracy: 0.10028
[32m[0717 07:47:52 @monitor.py:476][0m cost: 2.3352
[32m[0717 07:47:52 @monitor.py:476][0m cross_entropy_loss: 2.3352
[32m[0717 07:47:52 @monitor.py:476][0m param-summary/conv0/W-rms: 0.27572
[32m[0717 07:47:52 @monitor.py:476][0m param-summary/conv1/W-rms: 0.071178
[32m[0717 07:47:52 @monitor.py:476][0m param-summary/conv2/W-rms: 0.060139
[32m[0717 07:47:52 @monitor.py:476][0m param-summary/conv3/W-rms: 0.059691
[32m[0717 07:47:52 @monitor.py:476][0m param-summary/conv4/W-rms: 0.042525
[32m[0717 07:47:52 @monitor.py:476][0m param-summary/conv5/W-rms: 0.042761
[32m[0717 07:47:52 @monitor.py:476][0m param-summary/conv6/W-rms: 0.028242
[32m[0717 07:47:52 @monitor.py:476][0m param-summary/fc1/W-rms: 0.0561
[32m[0717 07:47:52 @monitor.py:476][0m regularize_cost: 8.0587e-07
[32m[0717 07:47:52 @monitor.py:476][0m train_error: 0.89972
[32m[0717 07:47:52 @monitor.py:476][0m val_accuracy: 0.052907
[32m[0717 07:47:52 @monitor.py:476][0m val_cross_entropy_loss: 2.3507
[32m[0717 07:47:52 @group.py:44][0m Callbacks took 3.207 sec in total. InferenceRunner: 2.95 seconds
[32m[0717 07:47:52 @base.py:273][0m Start Epoch 5 ...
[32m[0717 07:48:09 @base.py:283][0m Epoch 5 (global_step 2340) finished, time:16.3 seconds.
[32m[0717 07:48:09 @saver.py:82][0m Model saved to train_log/mnist-dorefa-6,6,6/model-2340.
[32m[0717 07:48:12 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[0717 07:48:12 @monitor.py:476][0m accuracy: 0.10726
[32m[0717 07:48:12 @monitor.py:476][0m cost: 2.326
[32m[0717 07:48:12 @monitor.py:476][0m cross_entropy_loss: 2.326
[32m[0717 07:48:12 @monitor.py:476][0m param-summary/conv0/W-rms: 0.27549
[32m[0717 07:48:12 @monitor.py:476][0m param-summary/conv1/W-rms: 0.071599
[32m[0717 07:48:12 @monitor.py:476][0m param-summary/conv2/W-rms: 0.060231
[32m[0717 07:48:12 @monitor.py:476][0m param-summary/conv3/W-rms: 0.059765
[32m[0717 07:48:12 @monitor.py:476][0m param-summary/conv4/W-rms: 0.04259
[32m[0717 07:48:12 @monitor.py:476][0m param-summary/conv5/W-rms: 0.04284
[32m[0717 07:48:12 @monitor.py:476][0m param-summary/conv6/W-rms: 0.028584
[32m[0717 07:48:12 @monitor.py:476][0m param-summary/fc1/W-rms: 0.055977
[32m[0717 07:48:12 @monitor.py:476][0m regularize_cost: 8.0227e-07
[32m[0717 07:48:12 @monitor.py:476][0m train_error: 0.89274
[32m[0717 07:48:12 @monitor.py:476][0m val_accuracy: 0.11432
[32m[0717 07:48:12 @monitor.py:476][0m val_cross_entropy_loss: 2.3158
[32m[0717 07:48:12 @group.py:44][0m Callbacks took 3.058 sec in total. InferenceRunner: 2.83 seconds
[32m[0717 07:48:12 @base.py:273][0m Start Epoch 6 ...
[32m[0717 07:48:27 @base.py:283][0m Epoch 6 (global_step 2808) finished, time:15.4 seconds.
[32m[0717 07:48:27 @saver.py:82][0m Model saved to train_log/mnist-dorefa-6,6,6/model-2808.
[32m[0717 07:48:30 @monitor.py:476][0m QueueInput/queue_size: 0.00012156
[32m[0717 07:48:30 @monitor.py:476][0m accuracy: 0.1094
[32m[0717 07:48:30 @monitor.py:476][0m cost: 2.3226
[32m[0717 07:48:30 @monitor.py:476][0m cross_entropy_loss: 2.3226
[32m[0717 07:48:30 @monitor.py:476][0m param-summary/conv0/W-rms: 0.27596
[32m[0717 07:48:30 @monitor.py:476][0m param-summary/conv1/W-rms: 0.071644
[32m[0717 07:48:30 @monitor.py:476][0m param-summary/conv2/W-rms: 0.060385
[32m[0717 07:48:30 @monitor.py:476][0m param-summary/conv3/W-rms: 0.059931
[32m[0717 07:48:30 @monitor.py:476][0m param-summary/conv4/W-rms: 0.042738
[32m[0717 07:48:30 @monitor.py:476][0m param-summary/conv5/W-rms: 0.043038
[32m[0717 07:48:30 @monitor.py:476][0m param-summary/conv6/W-rms: 0.029082
[32m[0717 07:48:30 @monitor.py:476][0m param-summary/fc1/W-rms: 0.055915
[32m[0717 07:48:30 @monitor.py:476][0m regularize_cost: 8.0056e-07
[32m[0717 07:48:30 @monitor.py:476][0m train_error: 0.8906
[32m[0717 07:48:30 @monitor.py:476][0m val_accuracy: 0.27413
[32m[0717 07:48:30 @monitor.py:476][0m val_cross_entropy_loss: 2.1005
[32m[0717 07:48:30 @group.py:44][0m Callbacks took 3.106 sec in total. InferenceRunner: 2.84 seconds
[32m[0717 07:48:30 @base.py:273][0m Start Epoch 7 ...
[32m[0717 07:48:49 @base.py:283][0m Epoch 7 (global_step 3276) finished, time:18.5 seconds.
[32m[0717 07:48:49 @saver.py:82][0m Model saved to train_log/mnist-dorefa-6,6,6/model-3276.
[32m[0717 07:48:52 @monitor.py:476][0m QueueInput/queue_size: 0.0019531
[32m[0717 07:48:52 @monitor.py:476][0m accuracy: 0.1121
[32m[0717 07:48:52 @monitor.py:476][0m cost: 2.3135
[32m[0717 07:48:52 @monitor.py:476][0m cross_entropy_loss: 2.3135
[32m[0717 07:48:52 @monitor.py:476][0m param-summary/conv0/W-rms: 0.27685
[32m[0717 07:48:52 @monitor.py:476][0m param-summary/conv1/W-rms: 0.074422
[32m[0717 07:48:52 @monitor.py:476][0m param-summary/conv2/W-rms: 0.06159
[32m[0717 07:48:52 @monitor.py:476][0m param-summary/conv3/W-rms: 0.061325
[32m[0717 07:48:52 @monitor.py:476][0m param-summary/conv4/W-rms: 0.04422
[32m[0717 07:48:52 @monitor.py:476][0m param-summary/conv5/W-rms: 0.044619
[32m[0717 07:48:52 @monitor.py:476][0m param-summary/conv6/W-rms: 0.031696
[32m[0717 07:48:52 @monitor.py:476][0m param-summary/fc1/W-rms: 0.054954
[32m[0717 07:48:52 @monitor.py:476][0m regularize_cost: 7.7352e-07
[32m[0717 07:48:52 @monitor.py:476][0m train_error: 0.8879
[32m[0717 07:48:52 @monitor.py:476][0m val_accuracy: 0.23002
[32m[0717 07:48:52 @monitor.py:476][0m val_cross_entropy_loss: 2.0571
[32m[0717 07:48:52 @group.py:44][0m Callbacks took 3.369 sec in total. InferenceRunner: 3.09 seconds
[32m[0717 07:48:52 @base.py:273][0m Start Epoch 8 ...
[32m[0717 07:49:11 @base.py:283][0m Epoch 8 (global_step 3744) finished, time:18.8 seconds.
[32m[0717 07:49:11 @saver.py:82][0m Model saved to train_log/mnist-dorefa-6,6,6/model-3744.
[32m[0717 07:49:14 @monitor.py:476][0m QueueInput/queue_size: 1.3553e-20
[32m[0717 07:49:14 @monitor.py:476][0m accuracy: 0.4765
[32m[0717 07:49:14 @monitor.py:476][0m cost: 1.4218
[32m[0717 07:49:14 @monitor.py:476][0m cross_entropy_loss: 1.4218
[32m[0717 07:49:14 @monitor.py:476][0m param-summary/conv0/W-rms: 0.28199
[32m[0717 07:49:14 @monitor.py:476][0m param-summary/conv1/W-rms: 0.083083
[32m[0717 07:49:14 @monitor.py:476][0m param-summary/conv2/W-rms: 0.068982
[32m[0717 07:49:14 @monitor.py:476][0m param-summary/conv3/W-rms: 0.068801
[32m[0717 07:49:14 @monitor.py:476][0m param-summary/conv4/W-rms: 0.050726
[32m[0717 07:49:14 @monitor.py:476][0m param-summary/conv5/W-rms: 0.051375
[32m[0717 07:49:14 @monitor.py:476][0m param-summary/conv6/W-rms: 0.037077
[32m[0717 07:49:14 @monitor.py:476][0m param-summary/fc1/W-rms: 0.056063
[32m[0717 07:49:14 @monitor.py:476][0m regularize_cost: 8.0166e-07
[32m[0717 07:49:14 @monitor.py:476][0m train_error: 0.5235
[32m[0717 07:49:14 @monitor.py:476][0m val_accuracy: 0.67435
[32m[0717 07:49:14 @monitor.py:476][0m val_cross_entropy_loss: 1.0531
[32m[0717 07:49:14 @group.py:44][0m Callbacks took 3.014 sec in total. InferenceRunner: 2.79 seconds
[32m[0717 07:49:14 @base.py:273][0m Start Epoch 9 ...
[32m[0717 07:49:32 @base.py:283][0m Epoch 9 (global_step 4212) finished, time:17.9 seconds.
[32m[0717 07:49:32 @saver.py:82][0m Model saved to train_log/mnist-dorefa-6,6,6/model-4212.
[32m[0717 07:49:35 @monitor.py:476][0m QueueInput/queue_size: 0.64326
[32m[0717 07:49:35 @monitor.py:476][0m accuracy: 0.4904
[32m[0717 07:49:35 @monitor.py:476][0m cost: 1.3571
[32m[0717 07:49:35 @monitor.py:476][0m cross_entropy_loss: 1.3571
[32m[0717 07:49:35 @monitor.py:476][0m param-summary/conv0/W-rms: 0.28378
[32m[0717 07:49:35 @monitor.py:476][0m param-summary/conv1/W-rms: 0.08617
[32m[0717 07:49:35 @monitor.py:476][0m param-summary/conv2/W-rms: 0.07116
[32m[0717 07:49:35 @monitor.py:476][0m param-summary/conv3/W-rms: 0.07103
[32m[0717 07:49:35 @monitor.py:476][0m param-summary/conv4/W-rms: 0.053035
[32m[0717 07:49:35 @monitor.py:476][0m param-summary/conv5/W-rms: 0.054089
[32m[0717 07:49:35 @monitor.py:476][0m param-summary/conv6/W-rms: 0.039694
[32m[0717 07:49:35 @monitor.py:476][0m param-summary/fc1/W-rms: 0.05812
[32m[0717 07:49:35 @monitor.py:476][0m regularize_cost: 8.6194e-07
[32m[0717 07:49:35 @monitor.py:476][0m train_error: 0.5096
[32m[0717 07:49:35 @monitor.py:476][0m val_accuracy: 0.9107
[32m[0717 07:49:35 @monitor.py:476][0m val_cross_entropy_loss: 0.28416
[32m[0717 07:49:35 @group.py:44][0m Callbacks took 3.110 sec in total. InferenceRunner: 2.83 seconds
[32m[0717 07:49:35 @base.py:273][0m Start Epoch 10 ...
[32m[0717 07:49:53 @base.py:283][0m Epoch 10 (global_step 4680) finished, time:18.4 seconds.
[32m[0717 07:49:53 @saver.py:82][0m Model saved to train_log/mnist-dorefa-6,6,6/model-4680.
[32m[0717 07:49:57 @monitor.py:476][0m QueueInput/queue_size: 0.015625
[32m[0717 07:49:57 @monitor.py:476][0m accuracy: 0.51914
[32m[0717 07:49:57 @monitor.py:476][0m cost: 1.2835
[32m[0717 07:49:57 @monitor.py:476][0m cross_entropy_loss: 1.2835
[32m[0717 07:49:57 @monitor.py:476][0m param-summary/conv0/W-rms: 0.28406
[32m[0717 07:49:57 @monitor.py:476][0m param-summary/conv1/W-rms: 0.087176
[32m[0717 07:49:57 @monitor.py:476][0m param-summary/conv2/W-rms: 0.072252
[32m[0717 07:49:57 @monitor.py:476][0m param-summary/conv3/W-rms: 0.072304
[32m[0717 07:49:57 @monitor.py:476][0m param-summary/conv4/W-rms: 0.054272
[32m[0717 07:49:57 @monitor.py:476][0m param-summary/conv5/W-rms: 0.055796
[32m[0717 07:49:57 @monitor.py:476][0m param-summary/conv6/W-rms: 0.041741
[32m[0717 07:49:57 @monitor.py:476][0m param-summary/fc1/W-rms: 0.060222
[32m[0717 07:49:57 @monitor.py:476][0m regularize_cost: 9.2607e-07
[32m[0717 07:49:57 @monitor.py:476][0m train_error: 0.48086
[32m[0717 07:49:57 @monitor.py:476][0m val_accuracy: 0.87985
[32m[0717 07:49:57 @monitor.py:476][0m val_cross_entropy_loss: 0.43762
[32m[0717 07:49:57 @group.py:44][0m Callbacks took 3.305 sec in total. InferenceRunner: 3.06 seconds
[32m[0717 07:49:57 @base.py:287][0m Training has finished!
[32m[0717 07:49:57 @input_source.py:177][0m [EnqueueThread] Thread EnqueueThread: enqueue dataflow to TF queue "QueueInput/input_queue" Exited.
