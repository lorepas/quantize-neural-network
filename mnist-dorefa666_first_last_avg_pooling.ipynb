{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"mnist-dorefa666_first&last_avg_pooling.ipynb","provenance":[],"authorship_tag":"ABX9TyNnYcIHvMyGAgZDXFJcLj3D"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"5qzKFEQKqXDt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626506792149,"user_tz":-120,"elapsed":18844,"user":{"displayName":"Lorenzo Pasco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgShaitSLZm3zyLVjMQT7ZzTrEV3kQEXha_A9lkVw=s64","userId":"01314717049817932576"}},"outputId":"c1746f21-e505-4afc-9100-4ec5844f4b8b"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eDXKVoHj26H8","executionInfo":{"status":"ok","timestamp":1626506797612,"user_tz":-120,"elapsed":3599,"user":{"displayName":"Lorenzo Pasco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgShaitSLZm3zyLVjMQT7ZzTrEV3kQEXha_A9lkVw=s64","userId":"01314717049817932576"}},"outputId":"657f95c8-7cc8-43a7-e18d-d8149b7574e1"},"source":["!pip install tensorpack\n","\n","%cd gdrive/MyDrive/SEAI_Project"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting tensorpack\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f9/8c/63e5f5a4a04dea36b75850f9daa885ccbfad64bec1fae0ee4ca9f31b3eaa/tensorpack-0.11-py2.py3-none-any.whl (296kB)\n","\r\u001b[K     |█                               | 10kB 23.6MB/s eta 0:00:01\r\u001b[K     |██▏                             | 20kB 18.0MB/s eta 0:00:01\r\u001b[K     |███▎                            | 30kB 15.0MB/s eta 0:00:01\r\u001b[K     |████▍                           | 40kB 14.0MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 51kB 7.4MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 61kB 7.8MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 71kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 81kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████                      | 92kB 8.8MB/s eta 0:00:01\r\u001b[K     |███████████                     | 102kB 7.3MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 112kB 7.3MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 122kB 7.3MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 133kB 7.3MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 143kB 7.3MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 153kB 7.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 163kB 7.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 174kB 7.3MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 184kB 7.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 194kB 7.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 204kB 7.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 215kB 7.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 225kB 7.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 235kB 7.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 245kB 7.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 256kB 7.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 266kB 7.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 276kB 7.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 286kB 7.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 296kB 7.3MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tensorpack) (1.15.0)\n","Requirement already satisfied: psutil>=5 in /usr/local/lib/python3.7/dist-packages (from tensorpack) (5.4.8)\n","Requirement already satisfied: numpy>=1.14 in /usr/local/lib/python3.7/dist-packages (from tensorpack) (1.19.5)\n","Requirement already satisfied: msgpack>=0.5.2 in /usr/local/lib/python3.7/dist-packages (from tensorpack) (1.0.2)\n","Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.7/dist-packages (from tensorpack) (1.1.0)\n","Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.7/dist-packages (from tensorpack) (4.41.1)\n","Collecting msgpack-numpy>=0.4.4.2\n","  Downloading https://files.pythonhosted.org/packages/19/05/05b8d7c69c6abb36a34325cc3150089bdafc359f0a81fb998d93c5d5c737/msgpack_numpy-0.4.7.1-py2.py3-none-any.whl\n","Requirement already satisfied: pyzmq>=16 in /usr/local/lib/python3.7/dist-packages (from tensorpack) (22.1.0)\n","Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.7/dist-packages (from tensorpack) (0.8.9)\n","Installing collected packages: msgpack-numpy, tensorpack\n","Successfully installed msgpack-numpy-0.4.7.1 tensorpack-0.11\n","/content/gdrive/MyDrive/SEAI_Project\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"47qPSLMU19HM","executionInfo":{"status":"ok","timestamp":1626513381475,"user_tz":-120,"elapsed":152572,"user":{"displayName":"Lorenzo Pasco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgShaitSLZm3zyLVjMQT7ZzTrEV3kQEXha_A9lkVw=s64","userId":"01314717049817932576"}},"outputId":"4f3cded7-7ff3-4d2c-ab67-b5049dd11fbd"},"source":["#!/usr/bin/env python\n","# -*- coding: utf-8 -*-\n","# File: svhn-digit-dorefa.py\n","# Author: Yuxin Wu\n","\n","import argparse\n","import os\n","import tensorflow as tf\n","\n","from tensorpack import *\n","from tensorpack.dataflow import dataset\n","from tensorpack.tfutils.summary import add_moving_summary, add_param_summary\n","from tensorpack.tfutils.varreplace import remap_variables\n","\n","\"\"\"\n","This is a tensorpack script for the SVHN results in paper:\n","DoReFa-Net: Training Low Bitwidth Convolutional Neural Networks with Low Bitwidth Gradients\n","http://arxiv.org/abs/1606.06160\n","The original experiements are performed on a proprietary framework.\n","This is our attempt to reproduce it on tensorpack.\n","Accuracy:\n","    With (W,A,G)=(1,1,4), can reach 3.1~3.2% error after 150 epochs.\n","    With (W,A,G)=(1,2,4), error is 3.0~3.1%.\n","    With (W,A,G)=(32,32,32), error is about 2.3%.\n","Speed:\n","    With quantization, 60 batch/s on 1 1080Ti. (4721 batch / epoch)\n","To Run:\n","    ./svhn-digit-dorefa.py --dorefa 1,2,4\n","\"\"\"\n","tf.compat.v1.reset_default_graph()\n","\n","BITW = 6\n","BITA = 6\n","BITG = 6\n","\n","\"\"\"\n","imported from dorefa file\n","\"\"\"\n","def get_dorefa(bitW, bitA, bitG):\n","    \"\"\"\n","    Return the three quantization functions fw, fa, fg, for weights, activations and gradients respectively\n","    \"\"\"\n","    def quantize(x, k):\n","        n = float(2 ** k - 1)\n","\n","        @tf.custom_gradient\n","        def _quantize(x):\n","            return tf.round(x * n) / n, lambda dy: dy\n","\n","        return _quantize(x)\n","\n","    def fw(x):\n","        if bitW == 32:\n","            return x\n","\n","        if bitW == 1:   # BWN\n","            E = tf.stop_gradient(tf.reduce_mean(tf.abs(x)))\n","\n","            @tf.custom_gradient\n","            def _sign(x):\n","                return tf.where(tf.equal(x, 0), tf.ones_like(x), tf.sign(x / E)) * E, lambda dy: dy\n","\n","            return _sign(x)\n","\n","        x = tf.tanh(x)\n","        x = x / tf.reduce_max(tf.abs(x)) * 0.5 + 0.5\n","        return 2 * quantize(x, bitW) - 1\n","\n","    def fa(x):\n","        if bitA == 32:\n","            return x\n","        return quantize(x, bitA)\n","\n","    def fg(x):\n","        if bitG == 32:\n","            return x\n","\n","        @tf.custom_gradient\n","        def _identity(input):\n","            def grad_fg(x):\n","                rank = x.get_shape().ndims\n","                assert rank is not None\n","                maxx = tf.reduce_max(tf.abs(x), list(range(1, rank)), keepdims=True)\n","                x = x / maxx\n","                n = float(2**bitG - 1)\n","                x = x * 0.5 + 0.5 + tf.random.uniform(\n","                    tf.shape(x), minval=-0.5 / n, maxval=0.5 / n)\n","                x = tf.clip_by_value(x, 0.0, 1.0)\n","                x = quantize(x, bitG) - 0.5\n","                return x * maxx * 2\n","\n","            return input, grad_fg\n","\n","        return _identity(x)\n","    return fw, fa, fg\n","\n","\n","class Model(ModelDesc):\n","    def inputs(self):\n","        return [tf.TensorSpec([None, 40, 40], tf.float32, 'input'),\n","                tf.TensorSpec([None], tf.int32, 'label')]\n","\n","    def build_graph(self, image, label):\n","        fw, fa, fg = get_dorefa(BITW, BITA, BITG)\n","\n","        # monkey-patch tf.get_variable to apply fw\n","        def binarize_weight(v):\n","            name = v.op.name\n","            # don't binarize first and last layer\n","            if not name.endswith('W'):\n","                return v\n","            else:\n","                logger.info(\"Binarizing weight {}\".format(v.op.name))\n","                return fw(v)\n","\n","        def nonlin(x):\n","            if BITA == 32:\n","                return tf.nn.relu(x)\n","            return tf.clip_by_value(x, 0.0, 1.0)\n","\n","        def activate(x):\n","            return fa(nonlin(x))\n","\n","        image = tf.expand_dims(image, 3)\n","        image = image / 256.0\n","\n","        with remap_variables(binarize_weight), \\\n","                argscope(BatchNorm, momentum=0.9, epsilon=1e-4), \\\n","                argscope(Conv2D, use_bias=False):\n","            logits = (LinearWrap(image)\n","                      .Conv2D('conv0', 48, 5, padding='VALID', use_bias=True)\n","                      .AvgPooling('pool0', 2, padding='SAME')\n","                      .apply(activate)\n","                      # 18\n","                      .Conv2D('conv1', 64, 3, padding='SAME')\n","                      .apply(fg)\n","                      .BatchNorm('bn1').apply(activate)\n","#AVGPooling\n","                      .Conv2D('conv2', 64, 3, padding='SAME')\n","                      .apply(fg)\n","                      .BatchNorm('bn2')\n","                      .AvgPooling('pool1', 2, padding='SAME')\n","                      .apply(activate)\n","                      # 9\n","                      .Conv2D('conv3', 128, 3, padding='VALID')\n","                      .apply(fg)\n","                      .BatchNorm('bn3').apply(activate)\n","                      # 7\n","\n","                      .Conv2D('conv4', 128, 3, padding='SAME')\n","                      .apply(fg)\n","                      .BatchNorm('bn4').apply(activate)\n","\n","                      .Conv2D('conv5', 128, 3, padding='VALID')\n","                      .apply(fg)\n","                      .BatchNorm('bn5').apply(activate)\n","                      # 5\n","                      .Dropout(rate=0.5 if self.training else 0.0)\n","                      .Conv2D('conv6', 512, 5, padding='VALID')\n","                      .apply(fg).BatchNorm('bn6')\n","                      .apply(nonlin)\n","                      .FullyConnected('fc1', 10)())\n","        tf.nn.softmax(logits, name='output')\n","\n","        correct = tf.cast(tf.nn.in_top_k(predictions=logits, targets=label, k=1), tf.float32, name='correct')\n","        accuracy = tf.reduce_mean(correct, name='accuracy')\n","        train_error = tf.reduce_mean(1 - correct, name='train_error')\n","        summary.add_moving_summary(train_error, accuracy)\n","        \n","        cost = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=label)\n","        cost = tf.reduce_mean(cost, name='cross_entropy_loss')\n","        # weight decay on all W of fc layers\n","        wd_cost = regularize_cost('fc.*/W', l2_regularizer(1e-7))\n","        add_param_summary(('.*/W', ['histogram', 'rms']))\n","        total_cost = tf.add_n([cost, wd_cost], name='cost')\n","        add_moving_summary(cost, wd_cost, total_cost)\n","        return total_cost\n","\n","    def optimizer(self):\n","        lr = tf.compat.v1.train.exponential_decay(\n","            learning_rate=1e-3,\n","            global_step=get_global_step_var(),\n","            decay_steps=4721 * 100,\n","            decay_rate=0.5, staircase=True, name='learning_rate')\n","        tf.summary.scalar('lr', lr)\n","\n","        return tf.compat.v1.train.AdamOptimizer(lr, epsilon=1e-5)\n","\n","\n","def get_config():\n","    logger.set_logger_dir(os.path.join('train_log', 'mnist-dorefa-{}'.format(args)))\n","\n","    # prepare dataset\n","    data_train = dataset.Mnist('train', shuffle=True)\n","    data_test = dataset.Mnist('test', shuffle=True)\n","\n","    augmentors = [imgaug.Resize((40, 40))]\n","    data_train = AugmentImageComponent(data_train, augmentors)\n","    data_train = BatchData(data_train, 128)\n","    data_train = MultiProcessRunnerZMQ(data_train, 5)\n","\n","    augmentors = [imgaug.Resize((40, 40))]\n","    data_test = AugmentImageComponent(data_test, augmentors)\n","    data_test = BatchData(data_test, 128, remainder=True)\n","\n","    return TrainConfig(\n","        data=QueueInput(data_train),\n","        callbacks=[\n","            ModelSaver(),\n","            InferenceRunner(    # run inference(for validation) after every epoch\n","                data_test,   # the DataFlow instance used for validation\n","                ScalarStats(    # produce `val_accuracy` and `val_cross_entropy_loss`\n","                    ['cross_entropy_loss', 'accuracy'], prefix='val'))\n","        ],\n","        model=Model(),\n","        max_epoch=10,\n","    )\n","\n","args = \"6,6,6\"\n","BITW, BITA, BITG = map(int, args.split(','))\n","config = get_config()\n","launch_train_with_config(config, SimpleTrainer())\n","\n","'''\n","if __name__ == '__main__':\n","    parser = argparse.ArgumentParser()\n","    parser.add_argument('--dorefa',\n","                        help='number of bits for W,A,G, separated by comma. Defaults to \\'1,2,4\\'',\n","                        default='1,2,4')\n","    args = parser.parse_args()\n","\n","    BITW, BITA, BITG = map(int, args.dorefa.split(','))\n","    config = get_config()\n","    launch_train_with_config(config, SimpleTrainer())\n","'''"],"execution_count":20,"outputs":[{"output_type":"stream","text":["\u001b[32m[0717 09:13:49 @logger.py:128]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m Log directory train_log/mnist-dorefa-6,6,6 exists! Use 'd' to delete it. \n","\u001b[32m[0717 09:13:49 @logger.py:131]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m If you're resuming from a previous run, you can choose to keep it.\n","Press any other key to exit. \n","Select Action: k (keep) / d (delete) / q (quit):k\n","\u001b[32m[0717 09:13:52 @logger.py:85]\u001b[0m Existing log file 'train_log/mnist-dorefa-6,6,6/log.log' backuped to 'train_log/mnist-dorefa-6,6,6/log.log.0717-091352'\n","\u001b[32m[0717 09:13:52 @logger.py:92]\u001b[0m Argv: /usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py -f /root/.local/share/jupyter/runtime/kernel-deb98920-21fb-4f50-b049-99bfb143a407.json\n","\u001b[32m[0717 09:13:53 @parallel.py:340]\u001b[0m [MultiProcessRunnerZMQ] Will fork a dataflow more than one times. This assumes the datapoints are i.i.d.\n","\u001b[32m[0717 09:13:53 @input_source.py:221]\u001b[0m Setting up the queue 'QueueInput/input_queue' for CPU prefetching ...\n","\u001b[32m[0717 09:13:53 @trainers.py:48]\u001b[0m Building graph for a single training tower ...\n","\u001b[32m[0717 09:13:53 @<ipython-input-20-64ea70a806e1>:113]\u001b[0m Binarizing weight conv0/W\n","\u001b[32m[0717 09:13:53 @<ipython-input-20-64ea70a806e1>:113]\u001b[0m Binarizing weight conv1/W\n","\u001b[32m[0717 09:13:53 @<ipython-input-20-64ea70a806e1>:113]\u001b[0m Binarizing weight conv2/W\n","\u001b[32m[0717 09:13:53 @<ipython-input-20-64ea70a806e1>:113]\u001b[0m Binarizing weight conv3/W\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1692: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n","  warnings.warn('`layer.apply` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0717 09:13:53 @<ipython-input-20-64ea70a806e1>:113]\u001b[0m Binarizing weight conv4/W\n","\u001b[32m[0717 09:13:53 @<ipython-input-20-64ea70a806e1>:113]\u001b[0m Binarizing weight conv5/W\n","\u001b[32m[0717 09:13:53 @<ipython-input-20-64ea70a806e1>:113]\u001b[0m Binarizing weight conv6/W\n","\u001b[32m[0717 09:13:53 @<ipython-input-20-64ea70a806e1>:113]\u001b[0m Binarizing weight fc1/W\n","\u001b[32m[0717 09:13:53 @regularize.py:97]\u001b[0m regularize_cost() found 1 variables to regularize.\n","\u001b[32m[0717 09:13:53 @regularize.py:21]\u001b[0m The following tensors will be regularized: fc1/W:0\n","\u001b[32m[0717 09:13:54 @model_utils.py:67]\u001b[0m \u001b[36mList of Trainable Variables: \n","\u001b[0mname       shape               #elements\n","---------  ----------------  -----------\n","conv0/W    [5, 5, 1, 48]            1200\n","conv0/b    [48]                       48\n","conv1/W    [3, 3, 48, 64]          27648\n","bn1/gamma  [64]                       64\n","bn1/beta   [64]                       64\n","conv2/W    [3, 3, 64, 64]          36864\n","bn2/gamma  [64]                       64\n","bn2/beta   [64]                       64\n","conv3/W    [3, 3, 64, 128]         73728\n","bn3/gamma  [128]                     128\n","bn3/beta   [128]                     128\n","conv4/W    [3, 3, 128, 128]       147456\n","bn4/gamma  [128]                     128\n","bn4/beta   [128]                     128\n","conv5/W    [3, 3, 128, 128]       147456\n","bn5/gamma  [128]                     128\n","bn5/beta   [128]                     128\n","conv6/W    [5, 5, 128, 512]      1638400\n","bn6/gamma  [512]                     512\n","bn6/beta   [512]                     512\n","fc1/W      [512, 10]                5120\n","fc1/b      [10]                       10\u001b[36m\n","Number of trainable variables: 22\n","Number of parameters (elements): 2079978\n","Storage space needed for all trainable variables: 7.93MB\u001b[0m\n","\u001b[32m[0717 09:13:54 @base.py:207]\u001b[0m Setup callbacks graph ...\n","\u001b[32m[0717 09:13:54 @argtools.py:138]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m \"import prctl\" failed! Install python-prctl so that processes can be cleaned with guarantee.\n","\u001b[32m[0717 09:13:55 @inference_runner.py:148]\u001b[0m [InferenceRunner] Building tower 'InferenceTower' on device /gpu:0 ...\n","\u001b[32m[0717 09:13:55 @<ipython-input-20-64ea70a806e1>:113]\u001b[0m Binarizing weight conv0/W\n","\u001b[32m[0717 09:13:55 @<ipython-input-20-64ea70a806e1>:113]\u001b[0m Binarizing weight conv1/W\n","\u001b[32m[0717 09:13:56 @<ipython-input-20-64ea70a806e1>:113]\u001b[0m Binarizing weight conv2/W\n","\u001b[32m[0717 09:13:56 @<ipython-input-20-64ea70a806e1>:113]\u001b[0m Binarizing weight conv3/W\n","\u001b[32m[0717 09:13:56 @<ipython-input-20-64ea70a806e1>:113]\u001b[0m Binarizing weight conv4/W\n","\u001b[32m[0717 09:13:56 @<ipython-input-20-64ea70a806e1>:113]\u001b[0m Binarizing weight conv5/W\n","\u001b[32m[0717 09:13:57 @<ipython-input-20-64ea70a806e1>:113]\u001b[0m Binarizing weight conv6/W\n","\u001b[32m[0717 09:13:57 @<ipython-input-20-64ea70a806e1>:113]\u001b[0m Binarizing weight fc1/W\n","\u001b[32m[0717 09:13:57 @summary.py:47]\u001b[0m [MovingAverageSummary] 5 operations in collection 'MOVING_SUMMARY_OPS' will be run with session hooks.\n","\u001b[32m[0717 09:13:57 @summary.py:94]\u001b[0m Summarizing collection 'summaries' of size 22.\n","\u001b[32m[0717 09:13:57 @graph.py:99]\u001b[0m Applying collection UPDATE_OPS of 12 ops.\n","\u001b[32m[0717 09:13:57 @base.py:228]\u001b[0m Creating the session ...\n","\u001b[32m[0717 09:13:58 @base.py:234]\u001b[0m Initializing the session ...\n","\u001b[32m[0717 09:13:58 @base.py:241]\u001b[0m Graph Finalized.\n","\u001b[32m[0717 09:13:58 @concurrency.py:37]\u001b[0m Starting EnqueueThread: enqueue dataflow to TF queue \"QueueInput/input_queue\" ...\n","\u001b[32m[0717 09:13:58 @inference_runner.py:95]\u001b[0m [InferenceRunner] Will eval 79 iterations\n","\u001b[32m[0717 09:13:58 @monitor.py:361]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m History epoch=10 from JSON is not the predecessor of the current starting_epoch=1\n","\u001b[32m[0717 09:13:58 @monitor.py:362]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m If you want to resume old training, either use `AutoResumeTrainConfig` or correctly set the new starting_epoch yourself to avoid inconsistency. \n","\u001b[32m[0717 09:13:58 @monitor.py:369]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m Now, we will train with starting_epoch=1 and backup old json to train_log/mnist-dorefa-6,6,6/stats.json.0717-091358\n","\u001b[32m[0717 09:13:58 @base.py:273]\u001b[0m Start Epoch 1 ...\n"],"name":"stdout"},{"output_type":"stream","text":["100%|##########|468/468[00:14<00:00,32.48it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0717 09:14:13 @base.py:283]\u001b[0m Epoch 1 (global_step 468) finished, time:14.4 seconds.\n","\u001b[32m[0717 09:14:13 @saver.py:82]\u001b[0m Model saved to train_log/mnist-dorefa-6,6,6/model-468.\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|79/79[00:01<00:00,76.05it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0717 09:14:14 @monitor.py:476]\u001b[0m QueueInput/queue_size: 50\n","\u001b[32m[0717 09:14:14 @monitor.py:476]\u001b[0m accuracy: 0.96493\n","\u001b[32m[0717 09:14:14 @monitor.py:476]\u001b[0m cost: 0.10435\n","\u001b[32m[0717 09:14:14 @monitor.py:476]\u001b[0m cross_entropy_loss: 0.10435\n","\u001b[32m[0717 09:14:14 @monitor.py:476]\u001b[0m param-summary/conv0/W-rms: 0.2855\n","\u001b[32m[0717 09:14:14 @monitor.py:476]\u001b[0m param-summary/conv1/W-rms: 0.067979\n","\u001b[32m[0717 09:14:14 @monitor.py:476]\u001b[0m param-summary/conv2/W-rms: 0.059744\n","\u001b[32m[0717 09:14:14 @monitor.py:476]\u001b[0m param-summary/conv3/W-rms: 0.059539\n","\u001b[32m[0717 09:14:14 @monitor.py:476]\u001b[0m param-summary/conv4/W-rms: 0.042983\n","\u001b[32m[0717 09:14:14 @monitor.py:476]\u001b[0m param-summary/conv5/W-rms: 0.043162\n","\u001b[32m[0717 09:14:14 @monitor.py:476]\u001b[0m param-summary/conv6/W-rms: 0.027592\n","\u001b[32m[0717 09:14:14 @monitor.py:476]\u001b[0m param-summary/fc1/W-rms: 0.057285\n","\u001b[32m[0717 09:14:14 @monitor.py:476]\u001b[0m regularize_cost: 8.4149e-07\n","\u001b[32m[0717 09:14:14 @monitor.py:476]\u001b[0m train_error: 0.035066\n","\u001b[32m[0717 09:14:14 @monitor.py:476]\u001b[0m val_accuracy: 0.97953\n","\u001b[32m[0717 09:14:14 @monitor.py:476]\u001b[0m val_cross_entropy_loss: 0.069036\n","\u001b[32m[0717 09:14:14 @base.py:273]\u001b[0m Start Epoch 2 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|468/468[00:13<00:00,35.53it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0717 09:14:27 @base.py:283]\u001b[0m Epoch 2 (global_step 936) finished, time:13.2 seconds.\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0717 09:14:27 @saver.py:82]\u001b[0m Model saved to train_log/mnist-dorefa-6,6,6/model-936.\n"],"name":"stdout"},{"output_type":"stream","text":["100%|##########|79/79[00:00<00:00,86.31it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0717 09:14:28 @monitor.py:476]\u001b[0m QueueInput/queue_size: 50\n","\u001b[32m[0717 09:14:28 @monitor.py:476]\u001b[0m accuracy: 0.97634\n","\u001b[32m[0717 09:14:28 @monitor.py:476]\u001b[0m cost: 0.074439\n","\u001b[32m[0717 09:14:28 @monitor.py:476]\u001b[0m cross_entropy_loss: 0.074438\n","\u001b[32m[0717 09:14:28 @monitor.py:476]\u001b[0m param-summary/conv0/W-rms: 0.28595\n","\u001b[32m[0717 09:14:28 @monitor.py:476]\u001b[0m param-summary/conv1/W-rms: 0.068308\n","\u001b[32m[0717 09:14:28 @monitor.py:476]\u001b[0m param-summary/conv2/W-rms: 0.060022\n","\u001b[32m[0717 09:14:28 @monitor.py:476]\u001b[0m param-summary/conv3/W-rms: 0.059868\n","\u001b[32m[0717 09:14:28 @monitor.py:476]\u001b[0m param-summary/conv4/W-rms: 0.043444\n","\u001b[32m[0717 09:14:28 @monitor.py:476]\u001b[0m param-summary/conv5/W-rms: 0.043803\n","\u001b[32m[0717 09:14:28 @monitor.py:476]\u001b[0m param-summary/conv6/W-rms: 0.028663\n","\u001b[32m[0717 09:14:28 @monitor.py:476]\u001b[0m param-summary/fc1/W-rms: 0.056382\n","\u001b[32m[0717 09:14:28 @monitor.py:476]\u001b[0m regularize_cost: 8.1475e-07\n","\u001b[32m[0717 09:14:28 @monitor.py:476]\u001b[0m train_error: 0.02366\n","\u001b[32m[0717 09:14:28 @monitor.py:476]\u001b[0m val_accuracy: 0.98259\n","\u001b[32m[0717 09:14:28 @monitor.py:476]\u001b[0m val_cross_entropy_loss: 0.054493\n","\u001b[32m[0717 09:14:28 @base.py:273]\u001b[0m Start Epoch 3 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|468/468[00:13<00:00,35.43it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0717 09:14:42 @base.py:283]\u001b[0m Epoch 3 (global_step 1404) finished, time:13.2 seconds.\n","\u001b[32m[0717 09:14:42 @saver.py:82]\u001b[0m Model saved to train_log/mnist-dorefa-6,6,6/model-1404.\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|79/79[00:00<00:00,84.67it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0717 09:14:43 @monitor.py:476]\u001b[0m QueueInput/queue_size: 50\n","\u001b[32m[0717 09:14:43 @monitor.py:476]\u001b[0m accuracy: 0.98456\n","\u001b[32m[0717 09:14:43 @monitor.py:476]\u001b[0m cost: 0.05296\n","\u001b[32m[0717 09:14:43 @monitor.py:476]\u001b[0m cross_entropy_loss: 0.052959\n","\u001b[32m[0717 09:14:43 @monitor.py:476]\u001b[0m param-summary/conv0/W-rms: 0.28653\n","\u001b[32m[0717 09:14:43 @monitor.py:476]\u001b[0m param-summary/conv1/W-rms: 0.068892\n","\u001b[32m[0717 09:14:43 @monitor.py:476]\u001b[0m param-summary/conv2/W-rms: 0.060289\n","\u001b[32m[0717 09:14:43 @monitor.py:476]\u001b[0m param-summary/conv3/W-rms: 0.060174\n","\u001b[32m[0717 09:14:43 @monitor.py:476]\u001b[0m param-summary/conv4/W-rms: 0.043874\n","\u001b[32m[0717 09:14:43 @monitor.py:476]\u001b[0m param-summary/conv5/W-rms: 0.044392\n","\u001b[32m[0717 09:14:43 @monitor.py:476]\u001b[0m param-summary/conv6/W-rms: 0.029587\n","\u001b[32m[0717 09:14:43 @monitor.py:476]\u001b[0m param-summary/fc1/W-rms: 0.056781\n","\u001b[32m[0717 09:14:43 @monitor.py:476]\u001b[0m regularize_cost: 8.2471e-07\n","\u001b[32m[0717 09:14:43 @monitor.py:476]\u001b[0m train_error: 0.01544\n","\u001b[32m[0717 09:14:43 @monitor.py:476]\u001b[0m val_accuracy: 0.98833\n","\u001b[32m[0717 09:14:43 @monitor.py:476]\u001b[0m val_cross_entropy_loss: 0.036704\n","\u001b[32m[0717 09:14:43 @base.py:273]\u001b[0m Start Epoch 4 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|468/468[00:13<00:00,35.78it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0717 09:14:56 @base.py:283]\u001b[0m Epoch 4 (global_step 1872) finished, time:13.1 seconds.\n","\u001b[32m[0717 09:14:56 @saver.py:82]\u001b[0m Model saved to train_log/mnist-dorefa-6,6,6/model-1872.\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|79/79[00:00<00:00,87.84it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0717 09:14:57 @monitor.py:476]\u001b[0m QueueInput/queue_size: 50\n","\u001b[32m[0717 09:14:57 @monitor.py:476]\u001b[0m accuracy: 0.98683\n","\u001b[32m[0717 09:14:57 @monitor.py:476]\u001b[0m cost: 0.035322\n","\u001b[32m[0717 09:14:57 @monitor.py:476]\u001b[0m cross_entropy_loss: 0.035321\n","\u001b[32m[0717 09:14:57 @monitor.py:476]\u001b[0m param-summary/conv0/W-rms: 0.28715\n","\u001b[32m[0717 09:14:57 @monitor.py:476]\u001b[0m param-summary/conv1/W-rms: 0.069444\n","\u001b[32m[0717 09:14:57 @monitor.py:476]\u001b[0m param-summary/conv2/W-rms: 0.060572\n","\u001b[32m[0717 09:14:57 @monitor.py:476]\u001b[0m param-summary/conv3/W-rms: 0.060521\n","\u001b[32m[0717 09:14:57 @monitor.py:476]\u001b[0m param-summary/conv4/W-rms: 0.04435\n","\u001b[32m[0717 09:14:57 @monitor.py:476]\u001b[0m param-summary/conv5/W-rms: 0.045024\n","\u001b[32m[0717 09:14:57 @monitor.py:476]\u001b[0m param-summary/conv6/W-rms: 0.030502\n","\u001b[32m[0717 09:14:57 @monitor.py:476]\u001b[0m param-summary/fc1/W-rms: 0.05771\n","\u001b[32m[0717 09:14:57 @monitor.py:476]\u001b[0m regularize_cost: 8.5069e-07\n","\u001b[32m[0717 09:14:57 @monitor.py:476]\u001b[0m train_error: 0.013172\n","\u001b[32m[0717 09:14:57 @monitor.py:476]\u001b[0m val_accuracy: 0.98853\n","\u001b[32m[0717 09:14:57 @monitor.py:476]\u001b[0m val_cross_entropy_loss: 0.033862\n","\u001b[32m[0717 09:14:57 @base.py:273]\u001b[0m Start Epoch 5 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|468/468[00:12<00:00,36.02it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0717 09:15:10 @base.py:283]\u001b[0m Epoch 5 (global_step 2340) finished, time:13 seconds.\n","\u001b[32m[0717 09:15:10 @saver.py:82]\u001b[0m Model saved to train_log/mnist-dorefa-6,6,6/model-2340.\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|79/79[00:00<00:00,88.17it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0717 09:15:11 @monitor.py:476]\u001b[0m QueueInput/queue_size: 50\n","\u001b[32m[0717 09:15:11 @monitor.py:476]\u001b[0m accuracy: 0.98633\n","\u001b[32m[0717 09:15:11 @monitor.py:476]\u001b[0m cost: 0.041962\n","\u001b[32m[0717 09:15:11 @monitor.py:476]\u001b[0m cross_entropy_loss: 0.041961\n","\u001b[32m[0717 09:15:11 @monitor.py:476]\u001b[0m param-summary/conv0/W-rms: 0.28757\n","\u001b[32m[0717 09:15:11 @monitor.py:476]\u001b[0m param-summary/conv1/W-rms: 0.070526\n","\u001b[32m[0717 09:15:11 @monitor.py:476]\u001b[0m param-summary/conv2/W-rms: 0.060967\n","\u001b[32m[0717 09:15:11 @monitor.py:476]\u001b[0m param-summary/conv3/W-rms: 0.060985\n","\u001b[32m[0717 09:15:11 @monitor.py:476]\u001b[0m param-summary/conv4/W-rms: 0.044979\n","\u001b[32m[0717 09:15:11 @monitor.py:476]\u001b[0m param-summary/conv5/W-rms: 0.045855\n","\u001b[32m[0717 09:15:11 @monitor.py:476]\u001b[0m param-summary/conv6/W-rms: 0.031643\n","\u001b[32m[0717 09:15:11 @monitor.py:476]\u001b[0m param-summary/fc1/W-rms: 0.058758\n","\u001b[32m[0717 09:15:11 @monitor.py:476]\u001b[0m regularize_cost: 8.8265e-07\n","\u001b[32m[0717 09:15:11 @monitor.py:476]\u001b[0m train_error: 0.013672\n","\u001b[32m[0717 09:15:11 @monitor.py:476]\u001b[0m val_accuracy: 0.98863\n","\u001b[32m[0717 09:15:11 @monitor.py:476]\u001b[0m val_cross_entropy_loss: 0.03427\n","\u001b[32m[0717 09:15:11 @base.py:273]\u001b[0m Start Epoch 6 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|468/468[00:12<00:00,36.55it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0717 09:15:24 @base.py:283]\u001b[0m Epoch 6 (global_step 2808) finished, time:12.8 seconds.\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0717 09:15:24 @saver.py:82]\u001b[0m Model saved to train_log/mnist-dorefa-6,6,6/model-2808.\n"],"name":"stdout"},{"output_type":"stream","text":["100%|##########|79/79[00:00<00:00,88.45it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0717 09:15:25 @monitor.py:476]\u001b[0m QueueInput/queue_size: 50\n","\u001b[32m[0717 09:15:25 @monitor.py:476]\u001b[0m accuracy: 0.98561\n","\u001b[32m[0717 09:15:25 @monitor.py:476]\u001b[0m cost: 0.0407\n","\u001b[32m[0717 09:15:25 @monitor.py:476]\u001b[0m cross_entropy_loss: 0.040699\n","\u001b[32m[0717 09:15:25 @monitor.py:476]\u001b[0m param-summary/conv0/W-rms: 0.28816\n","\u001b[32m[0717 09:15:25 @monitor.py:476]\u001b[0m param-summary/conv1/W-rms: 0.071645\n","\u001b[32m[0717 09:15:25 @monitor.py:476]\u001b[0m param-summary/conv2/W-rms: 0.061367\n","\u001b[32m[0717 09:15:25 @monitor.py:476]\u001b[0m param-summary/conv3/W-rms: 0.06147\n","\u001b[32m[0717 09:15:25 @monitor.py:476]\u001b[0m param-summary/conv4/W-rms: 0.045596\n","\u001b[32m[0717 09:15:25 @monitor.py:476]\u001b[0m param-summary/conv5/W-rms: 0.046677\n","\u001b[32m[0717 09:15:25 @monitor.py:476]\u001b[0m param-summary/conv6/W-rms: 0.032748\n","\u001b[32m[0717 09:15:25 @monitor.py:476]\u001b[0m param-summary/fc1/W-rms: 0.06014\n","\u001b[32m[0717 09:15:25 @monitor.py:476]\u001b[0m regularize_cost: 9.2464e-07\n","\u001b[32m[0717 09:15:25 @monitor.py:476]\u001b[0m train_error: 0.01439\n","\u001b[32m[0717 09:15:25 @monitor.py:476]\u001b[0m val_accuracy: 0.98863\n","\u001b[32m[0717 09:15:25 @monitor.py:476]\u001b[0m val_cross_entropy_loss: 0.03259\n","\u001b[32m[0717 09:15:25 @base.py:273]\u001b[0m Start Epoch 7 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|468/468[00:13<00:00,35.81it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0717 09:15:38 @base.py:283]\u001b[0m Epoch 7 (global_step 3276) finished, time:13.1 seconds.\n","\u001b[32m[0717 09:15:38 @saver.py:82]\u001b[0m Model saved to train_log/mnist-dorefa-6,6,6/model-3276.\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|79/79[00:00<00:00,87.00it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0717 09:15:39 @monitor.py:476]\u001b[0m QueueInput/queue_size: 50\n","\u001b[32m[0717 09:15:39 @monitor.py:476]\u001b[0m accuracy: 0.99037\n","\u001b[32m[0717 09:15:39 @monitor.py:476]\u001b[0m cost: 0.032041\n","\u001b[32m[0717 09:15:39 @monitor.py:476]\u001b[0m cross_entropy_loss: 0.03204\n","\u001b[32m[0717 09:15:39 @monitor.py:476]\u001b[0m param-summary/conv0/W-rms: 0.28893\n","\u001b[32m[0717 09:15:39 @monitor.py:476]\u001b[0m param-summary/conv1/W-rms: 0.07271\n","\u001b[32m[0717 09:15:39 @monitor.py:476]\u001b[0m param-summary/conv2/W-rms: 0.061888\n","\u001b[32m[0717 09:15:39 @monitor.py:476]\u001b[0m param-summary/conv3/W-rms: 0.062126\n","\u001b[32m[0717 09:15:39 @monitor.py:476]\u001b[0m param-summary/conv4/W-rms: 0.046393\n","\u001b[32m[0717 09:15:39 @monitor.py:476]\u001b[0m param-summary/conv5/W-rms: 0.04775\n","\u001b[32m[0717 09:15:39 @monitor.py:476]\u001b[0m param-summary/conv6/W-rms: 0.034113\n","\u001b[32m[0717 09:15:39 @monitor.py:476]\u001b[0m param-summary/fc1/W-rms: 0.06158\n","\u001b[32m[0717 09:15:39 @monitor.py:476]\u001b[0m regularize_cost: 9.6861e-07\n","\u001b[32m[0717 09:15:39 @monitor.py:476]\u001b[0m train_error: 0.0096253\n","\u001b[32m[0717 09:15:39 @monitor.py:476]\u001b[0m val_accuracy: 0.99041\n","\u001b[32m[0717 09:15:39 @monitor.py:476]\u001b[0m val_cross_entropy_loss: 0.028934\n","\u001b[32m[0717 09:15:39 @base.py:273]\u001b[0m Start Epoch 8 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|468/468[00:13<00:00,35.50it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0717 09:15:52 @base.py:283]\u001b[0m Epoch 8 (global_step 3744) finished, time:13.2 seconds.\n","\u001b[32m[0717 09:15:52 @saver.py:82]\u001b[0m Model saved to train_log/mnist-dorefa-6,6,6/model-3744.\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|79/79[00:00<00:00,83.85it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0717 09:15:53 @monitor.py:476]\u001b[0m QueueInput/queue_size: 50\n","\u001b[32m[0717 09:15:53 @monitor.py:476]\u001b[0m accuracy: 0.99189\n","\u001b[32m[0717 09:15:53 @monitor.py:476]\u001b[0m cost: 0.024643\n","\u001b[32m[0717 09:15:53 @monitor.py:476]\u001b[0m cross_entropy_loss: 0.024642\n","\u001b[32m[0717 09:15:53 @monitor.py:476]\u001b[0m param-summary/conv0/W-rms: 0.28949\n","\u001b[32m[0717 09:15:53 @monitor.py:476]\u001b[0m param-summary/conv1/W-rms: 0.073473\n","\u001b[32m[0717 09:15:53 @monitor.py:476]\u001b[0m param-summary/conv2/W-rms: 0.062437\n","\u001b[32m[0717 09:15:53 @monitor.py:476]\u001b[0m param-summary/conv3/W-rms: 0.062813\n","\u001b[32m[0717 09:15:53 @monitor.py:476]\u001b[0m param-summary/conv4/W-rms: 0.047226\n","\u001b[32m[0717 09:15:53 @monitor.py:476]\u001b[0m param-summary/conv5/W-rms: 0.048853\n","\u001b[32m[0717 09:15:53 @monitor.py:476]\u001b[0m param-summary/conv6/W-rms: 0.035483\n","\u001b[32m[0717 09:15:53 @monitor.py:476]\u001b[0m param-summary/fc1/W-rms: 0.063406\n","\u001b[32m[0717 09:15:53 @monitor.py:476]\u001b[0m regularize_cost: 1.0261e-06\n","\u001b[32m[0717 09:15:53 @monitor.py:476]\u001b[0m train_error: 0.0081088\n","\u001b[32m[0717 09:15:53 @monitor.py:476]\u001b[0m val_accuracy: 0.9907\n","\u001b[32m[0717 09:15:53 @monitor.py:476]\u001b[0m val_cross_entropy_loss: 0.029073\n","\u001b[32m[0717 09:15:53 @base.py:273]\u001b[0m Start Epoch 9 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|468/468[00:13<00:00,35.07it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0717 09:16:07 @base.py:283]\u001b[0m Epoch 9 (global_step 4212) finished, time:13.3 seconds.\n","\u001b[32m[0717 09:16:07 @saver.py:82]\u001b[0m Model saved to train_log/mnist-dorefa-6,6,6/model-4212.\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|79/79[00:00<00:00,87.97it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0717 09:16:08 @monitor.py:476]\u001b[0m QueueInput/queue_size: 50\n","\u001b[32m[0717 09:16:08 @monitor.py:476]\u001b[0m accuracy: 0.99272\n","\u001b[32m[0717 09:16:08 @monitor.py:476]\u001b[0m cost: 0.021471\n","\u001b[32m[0717 09:16:08 @monitor.py:476]\u001b[0m cross_entropy_loss: 0.02147\n","\u001b[32m[0717 09:16:08 @monitor.py:476]\u001b[0m param-summary/conv0/W-rms: 0.29026\n","\u001b[32m[0717 09:16:08 @monitor.py:476]\u001b[0m param-summary/conv1/W-rms: 0.074085\n","\u001b[32m[0717 09:16:08 @monitor.py:476]\u001b[0m param-summary/conv2/W-rms: 0.06314\n","\u001b[32m[0717 09:16:08 @monitor.py:476]\u001b[0m param-summary/conv3/W-rms: 0.063641\n","\u001b[32m[0717 09:16:08 @monitor.py:476]\u001b[0m param-summary/conv4/W-rms: 0.048217\n","\u001b[32m[0717 09:16:08 @monitor.py:476]\u001b[0m param-summary/conv5/W-rms: 0.050128\n","\u001b[32m[0717 09:16:08 @monitor.py:476]\u001b[0m param-summary/conv6/W-rms: 0.03703\n","\u001b[32m[0717 09:16:08 @monitor.py:476]\u001b[0m param-summary/fc1/W-rms: 0.065395\n","\u001b[32m[0717 09:16:08 @monitor.py:476]\u001b[0m regularize_cost: 1.0909e-06\n","\u001b[32m[0717 09:16:08 @monitor.py:476]\u001b[0m train_error: 0.0072774\n","\u001b[32m[0717 09:16:08 @monitor.py:476]\u001b[0m val_accuracy: 0.98981\n","\u001b[32m[0717 09:16:08 @monitor.py:476]\u001b[0m val_cross_entropy_loss: 0.035255\n","\u001b[32m[0717 09:16:08 @base.py:273]\u001b[0m Start Epoch 10 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|468/468[00:12<00:00,36.62it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0717 09:16:21 @base.py:283]\u001b[0m Epoch 10 (global_step 4680) finished, time:12.8 seconds.\n","\u001b[32m[0717 09:16:21 @saver.py:82]\u001b[0m Model saved to train_log/mnist-dorefa-6,6,6/model-4680.\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|79/79[00:00<00:00,88.47it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0717 09:16:22 @monitor.py:476]\u001b[0m QueueInput/queue_size: 50\n","\u001b[32m[0717 09:16:22 @monitor.py:476]\u001b[0m accuracy: 0.99035\n","\u001b[32m[0717 09:16:22 @monitor.py:476]\u001b[0m cost: 0.029972\n","\u001b[32m[0717 09:16:22 @monitor.py:476]\u001b[0m cross_entropy_loss: 0.029971\n","\u001b[32m[0717 09:16:22 @monitor.py:476]\u001b[0m param-summary/conv0/W-rms: 0.29098\n","\u001b[32m[0717 09:16:22 @monitor.py:476]\u001b[0m param-summary/conv1/W-rms: 0.074906\n","\u001b[32m[0717 09:16:22 @monitor.py:476]\u001b[0m param-summary/conv2/W-rms: 0.063842\n","\u001b[32m[0717 09:16:22 @monitor.py:476]\u001b[0m param-summary/conv3/W-rms: 0.06453\n","\u001b[32m[0717 09:16:22 @monitor.py:476]\u001b[0m param-summary/conv4/W-rms: 0.04929\n","\u001b[32m[0717 09:16:22 @monitor.py:476]\u001b[0m param-summary/conv5/W-rms: 0.051471\n","\u001b[32m[0717 09:16:22 @monitor.py:476]\u001b[0m param-summary/conv6/W-rms: 0.038591\n","\u001b[32m[0717 09:16:22 @monitor.py:476]\u001b[0m param-summary/fc1/W-rms: 0.067537\n","\u001b[32m[0717 09:16:22 @monitor.py:476]\u001b[0m regularize_cost: 1.1663e-06\n","\u001b[32m[0717 09:16:22 @monitor.py:476]\u001b[0m train_error: 0.0096529\n","\u001b[32m[0717 09:16:22 @monitor.py:476]\u001b[0m val_accuracy: 0.98912\n","\u001b[32m[0717 09:16:22 @monitor.py:476]\u001b[0m val_cross_entropy_loss: 0.035005\n","\u001b[32m[0717 09:16:22 @base.py:287]\u001b[0m Training has finished!\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"\\nif __name__ == '__main__':\\n    parser = argparse.ArgumentParser()\\n    parser.add_argument('--dorefa',\\n                        help='number of bits for W,A,G, separated by comma. Defaults to '1,2,4'',\\n                        default='1,2,4')\\n    args = parser.parse_args()\\n\\n    BITW, BITA, BITG = map(int, args.dorefa.split(','))\\n    config = get_config()\\n    launch_train_with_config(config, SimpleTrainer())\\n\""]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":315},"id":"mduuAqCeuc4B","executionInfo":{"status":"ok","timestamp":1626513489601,"user_tz":-120,"elapsed":1023,"user":{"displayName":"Lorenzo Pasco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgShaitSLZm3zyLVjMQT7ZzTrEV3kQEXha_A9lkVw=s64","userId":"01314717049817932576"}},"outputId":"3f1ba959-99b6-4b74-cb62-63285c59b643"},"source":["import json\n","import matplotlib.pyplot as plt\n","\n","f = open(\"train_log/mnist-dorefa-6,6,6/stats_def_first&last_avg_pooling_666.json\",\"r\")\n","\n","data = json.load(f)\n","accuracy = []\n","val_accuracy = []\n","for ob in data:\n","  accuracy.append(ob[\"accuracy\"])\n","  val_accuracy.append(ob[\"val_accuracy\"])\n","\n","epochs = range(len(accuracy))\n","\n","plt.plot(epochs, accuracy, 'r', label='Training acc')\n","plt.plot(epochs, val_accuracy, 'b', label='Validation acc')\n","plt.title('Training and validation accuracy')\n","plt.legend()\n","plt.figure()"],"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<Figure size 432x288 with 0 Axes>"]},"metadata":{"tags":[]},"execution_count":24},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 0 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ST3WBdVha1W-","executionInfo":{"status":"ok","timestamp":1626513494495,"user_tz":-120,"elapsed":330,"user":{"displayName":"Lorenzo Pasco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgShaitSLZm3zyLVjMQT7ZzTrEV3kQEXha_A9lkVw=s64","userId":"01314717049817932576"}},"outputId":"8959e9ea-998a-4fd2-e404-eb488d6b8c58"},"source":["from tabulate import tabulate\n","import matplotlib.pyplot as plt\n","\n","ep = [i+1 for i in epochs]\n","table_acc = {\"Epochs\" : ep, \"Accuracy\":accuracy}\n","table_val_acc = {\"Epochs\" : ep, \"Accuracy\":val_accuracy}\n","\n","print(\"ACCURACY\\n\")\n","print(tabulate(table_acc, headers='keys', tablefmt='fancy_grid'))\n","print(\"\\nVALIDATION ACCURACY\\n\")\n","print(tabulate(table_val_acc, headers='keys', tablefmt='fancy_grid'))"],"execution_count":25,"outputs":[{"output_type":"stream","text":["ACCURACY\n","\n","╒══════════╤════════════╕\n","│   Epochs │   Accuracy │\n","╞══════════╪════════════╡\n","│        1 │   0.964934 │\n","├──────────┼────────────┤\n","│        2 │   0.97634  │\n","├──────────┼────────────┤\n","│        3 │   0.98456  │\n","├──────────┼────────────┤\n","│        4 │   0.986828 │\n","├──────────┼────────────┤\n","│        5 │   0.986329 │\n","├──────────┼────────────┤\n","│        6 │   0.98561  │\n","├──────────┼────────────┤\n","│        7 │   0.990375 │\n","├──────────┼────────────┤\n","│        8 │   0.991891 │\n","├──────────┼────────────┤\n","│        9 │   0.992723 │\n","├──────────┼────────────┤\n","│       10 │   0.990347 │\n","╘══════════╧════════════╛\n","\n","VALIDATION ACCURACY\n","\n","╒══════════╤════════════╕\n","│   Epochs │   Accuracy │\n","╞══════════╪════════════╡\n","│        1 │   0.979529 │\n","├──────────┼────────────┤\n","│        2 │   0.982595 │\n","├──────────┼────────────┤\n","│        3 │   0.988331 │\n","├──────────┼────────────┤\n","│        4 │   0.988528 │\n","├──────────┼────────────┤\n","│        5 │   0.988627 │\n","├──────────┼────────────┤\n","│        6 │   0.988627 │\n","├──────────┼────────────┤\n","│        7 │   0.990407 │\n","├──────────┼────────────┤\n","│        8 │   0.990704 │\n","├──────────┼────────────┤\n","│        9 │   0.989814 │\n","├──────────┼────────────┤\n","│       10 │   0.989122 │\n","╘══════════╧════════════╛\n"],"name":"stdout"}]}]}