{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"svhn-digit-dorefa666_first&last_avg_pooling.ipynb","provenance":[],"authorship_tag":"ABX9TyMOIq2cNCzbTxQAVYWU3qOw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"5qzKFEQKqXDt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626448731574,"user_tz":-120,"elapsed":15793,"user":{"displayName":"Lorenzo Pasco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgShaitSLZm3zyLVjMQT7ZzTrEV3kQEXha_A9lkVw=s64","userId":"01314717049817932576"}},"outputId":"689fe63b-ab85-4bfd-ca0f-eb909347873e"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eDXKVoHj26H8","executionInfo":{"status":"ok","timestamp":1626448737392,"user_tz":-120,"elapsed":3648,"user":{"displayName":"Lorenzo Pasco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgShaitSLZm3zyLVjMQT7ZzTrEV3kQEXha_A9lkVw=s64","userId":"01314717049817932576"}},"outputId":"70b85551-6b84-430a-92f5-6fb8a40707fa"},"source":["!pip install tensorpack\n","\n","%cd gdrive/MyDrive/SEAI_Project"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting tensorpack\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f9/8c/63e5f5a4a04dea36b75850f9daa885ccbfad64bec1fae0ee4ca9f31b3eaa/tensorpack-0.11-py2.py3-none-any.whl (296kB)\n","\r\u001b[K     |█                               | 10kB 20.4MB/s eta 0:00:01\r\u001b[K     |██▏                             | 20kB 17.4MB/s eta 0:00:01\r\u001b[K     |███▎                            | 30kB 14.8MB/s eta 0:00:01\r\u001b[K     |████▍                           | 40kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 51kB 7.7MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 61kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 71kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 81kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████                      | 92kB 8.8MB/s eta 0:00:01\r\u001b[K     |███████████                     | 102kB 7.6MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 112kB 7.6MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 122kB 7.6MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 133kB 7.6MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 143kB 7.6MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 153kB 7.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 163kB 7.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 174kB 7.6MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 184kB 7.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 194kB 7.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 204kB 7.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 215kB 7.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 225kB 7.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 235kB 7.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 245kB 7.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 256kB 7.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 266kB 7.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 276kB 7.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 286kB 7.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 296kB 7.6MB/s \n","\u001b[?25hRequirement already satisfied: psutil>=5 in /usr/local/lib/python3.7/dist-packages (from tensorpack) (5.4.8)\n","Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.7/dist-packages (from tensorpack) (4.41.1)\n","Requirement already satisfied: msgpack>=0.5.2 in /usr/local/lib/python3.7/dist-packages (from tensorpack) (1.0.2)\n","Requirement already satisfied: numpy>=1.14 in /usr/local/lib/python3.7/dist-packages (from tensorpack) (1.19.5)\n","Collecting msgpack-numpy>=0.4.4.2\n","  Downloading https://files.pythonhosted.org/packages/19/05/05b8d7c69c6abb36a34325cc3150089bdafc359f0a81fb998d93c5d5c737/msgpack_numpy-0.4.7.1-py2.py3-none-any.whl\n","Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.7/dist-packages (from tensorpack) (1.1.0)\n","Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.7/dist-packages (from tensorpack) (0.8.9)\n","Requirement already satisfied: pyzmq>=16 in /usr/local/lib/python3.7/dist-packages (from tensorpack) (22.1.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tensorpack) (1.15.0)\n","Installing collected packages: msgpack-numpy, tensorpack\n","Successfully installed msgpack-numpy-0.4.7.1 tensorpack-0.11\n","/content/gdrive/MyDrive/SEAI_Project\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"47qPSLMU19HM","executionInfo":{"status":"ok","timestamp":1626451489032,"user_tz":-120,"elapsed":2695041,"user":{"displayName":"Lorenzo Pasco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgShaitSLZm3zyLVjMQT7ZzTrEV3kQEXha_A9lkVw=s64","userId":"01314717049817932576"}},"outputId":"35e42427-f895-40bb-86b6-c2dcbbbb3002"},"source":["#!/usr/bin/env python\n","# -*- coding: utf-8 -*-\n","# File: svhn-digit-dorefa.py\n","# Author: Yuxin Wu\n","\n","import argparse\n","import os\n","import tensorflow as tf\n","\n","from tensorpack import *\n","from tensorpack.dataflow import dataset\n","from tensorpack.tfutils.summary import add_moving_summary, add_param_summary\n","from tensorpack.tfutils.varreplace import remap_variables\n","\n","\"\"\"\n","This is a tensorpack script for the SVHN results in paper:\n","DoReFa-Net: Training Low Bitwidth Convolutional Neural Networks with Low Bitwidth Gradients\n","http://arxiv.org/abs/1606.06160\n","The original experiements are performed on a proprietary framework.\n","This is our attempt to reproduce it on tensorpack.\n","Accuracy:\n","    With (W,A,G)=(1,1,4), can reach 3.1~3.2% error after 150 epochs.\n","    With (W,A,G)=(1,2,4), error is 3.0~3.1%.\n","    With (W,A,G)=(32,32,32), error is about 2.3%.\n","Speed:\n","    With quantization, 60 batch/s on 1 1080Ti. (4721 batch / epoch)\n","To Run:\n","    ./svhn-digit-dorefa.py --dorefa 1,2,4\n","\"\"\"\n","tf.compat.v1.reset_default_graph()\n","\n","BITW = 6\n","BITA = 6\n","BITG = 6\n","\n","\"\"\"\n","imported from dorefa file\n","\"\"\"\n","def get_dorefa(bitW, bitA, bitG):\n","    \"\"\"\n","    Return the three quantization functions fw, fa, fg, for weights, activations and gradients respectively\n","    \"\"\"\n","    def quantize(x, k):\n","        n = float(2 ** k - 1)\n","\n","        @tf.custom_gradient\n","        def _quantize(x):\n","            return tf.round(x * n) / n, lambda dy: dy\n","\n","        return _quantize(x)\n","\n","    def fw(x):\n","        if bitW == 32:\n","            return x\n","\n","        if bitW == 1:   # BWN\n","            E = tf.stop_gradient(tf.reduce_mean(tf.abs(x)))\n","\n","            @tf.custom_gradient\n","            def _sign(x):\n","                return tf.where(tf.equal(x, 0), tf.ones_like(x), tf.sign(x / E)) * E, lambda dy: dy\n","\n","            return _sign(x)\n","\n","        x = tf.tanh(x)\n","        x = x / tf.reduce_max(tf.abs(x)) * 0.5 + 0.5\n","        return 2 * quantize(x, bitW) - 1\n","\n","    def fa(x):\n","        if bitA == 32:\n","            return x\n","        return quantize(x, bitA)\n","\n","    def fg(x):\n","        if bitG == 32:\n","            return x\n","\n","        @tf.custom_gradient\n","        def _identity(input):\n","            def grad_fg(x):\n","                rank = x.get_shape().ndims\n","                assert rank is not None\n","                maxx = tf.reduce_max(tf.abs(x), list(range(1, rank)), keepdims=True)\n","                x = x / maxx\n","                n = float(2**bitG - 1)\n","                x = x * 0.5 + 0.5 + tf.random.uniform(\n","                    tf.shape(x), minval=-0.5 / n, maxval=0.5 / n)\n","                x = tf.clip_by_value(x, 0.0, 1.0)\n","                x = quantize(x, bitG) - 0.5\n","                return x * maxx * 2\n","\n","            return input, grad_fg\n","\n","        return _identity(x)\n","    return fw, fa, fg\n","\n","\n","class Model(ModelDesc):\n","    def inputs(self):\n","        return [tf.TensorSpec([None, 40, 40, 3], tf.float32, 'input'),\n","                tf.TensorSpec([None], tf.int32, 'label')]\n","\n","    def build_graph(self, image, label):\n","        fw, fa, fg = get_dorefa(BITW, BITA, BITG)\n","\n","        # monkey-patch tf.get_variable to apply fw\n","        def binarize_weight(v):\n","            name = v.op.name\n","            # don't binarize first and last layer\n","            if not name.endswith('W'):\n","                return v\n","            else:\n","                logger.info(\"Binarizing weight {}\".format(v.op.name))\n","                return fw(v)\n","\n","        def nonlin(x):\n","            if BITA == 32:\n","                return tf.nn.relu(x)\n","            return tf.clip_by_value(x, 0.0, 1.0)\n","\n","        def activate(x):\n","            return fa(nonlin(x))\n","\n","        image = image / 256.0\n","\n","        with remap_variables(binarize_weight), \\\n","                argscope(BatchNorm, momentum=0.9, epsilon=1e-4), \\\n","                argscope(Conv2D, use_bias=False):\n","            logits = (LinearWrap(image)\n","                      .Conv2D('conv0', 48, 5, padding='VALID', use_bias=True)\n","                      .AvgPooling('pool0', 2, padding='SAME')\n","                      .apply(activate)\n","                      # 18\n","                      .Conv2D('conv1', 64, 3, padding='SAME')\n","                      .apply(fg)\n","                      .BatchNorm('bn1').apply(activate)\n","#AVGPooling\n","                      .Conv2D('conv2', 64, 3, padding='SAME')\n","                      .apply(fg)\n","                      .BatchNorm('bn2')\n","                      .AvgPooling('pool1', 2, padding='SAME')\n","                      .apply(activate)\n","                      # 9\n","                      .Conv2D('conv3', 128, 3, padding='VALID')\n","                      .apply(fg)\n","                      .BatchNorm('bn3').apply(activate)\n","                      # 7\n","\n","                      .Conv2D('conv4', 128, 3, padding='SAME')\n","                      .apply(fg)\n","                      .BatchNorm('bn4').apply(activate)\n","\n","                      .Conv2D('conv5', 128, 3, padding='VALID')\n","                      .apply(fg)\n","                      .BatchNorm('bn5').apply(activate)\n","                      # 5\n","                      .Dropout(rate=0.5 if self.training else 0.0)\n","                      .Conv2D('conv6', 512, 5, padding='VALID')\n","                      .apply(fg).BatchNorm('bn6')\n","                      .apply(nonlin)\n","                      .FullyConnected('fc1', 10)())\n","        tf.nn.softmax(logits, name='output')\n","\n","        correct = tf.cast(tf.nn.in_top_k(predictions=logits, targets=label, k=1), tf.float32, name='correct')\n","        accuracy = tf.reduce_mean(correct, name='accuracy')\n","        train_error = tf.reduce_mean(1 - correct, name='train_error')\n","        summary.add_moving_summary(train_error, accuracy)\n","        \n","        cost = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=label)\n","        cost = tf.reduce_mean(cost, name='cross_entropy_loss')\n","        # weight decay on all W of fc layers\n","        wd_cost = regularize_cost('fc.*/W', l2_regularizer(1e-7))\n","        add_param_summary(('.*/W', ['histogram', 'rms']))\n","        total_cost = tf.add_n([cost, wd_cost], name='cost')\n","        add_moving_summary(cost, wd_cost, total_cost)\n","        return total_cost\n","\n","    def optimizer(self):\n","        lr = tf.compat.v1.train.exponential_decay(\n","            learning_rate=1e-3,\n","            global_step=get_global_step_var(),\n","            decay_steps=4721 * 100,\n","            decay_rate=0.5, staircase=True, name='learning_rate')\n","        tf.summary.scalar('lr', lr)\n","\n","        return tf.compat.v1.train.AdamOptimizer(lr, epsilon=1e-5)\n","\n","\n","def get_config():\n","    logger.set_logger_dir(os.path.join('train_log', 'svhn-dorefa-{}'.format(args)))\n","\n","    # prepare dataset\n","    d1 = dataset.SVHNDigit('train')\n","    d2 = dataset.SVHNDigit('extra')\n","    data_train = RandomMixData([d1, d2])\n","    data_test = dataset.SVHNDigit('test')\n","\n","    augmentors = [\n","        imgaug.Resize((40, 40)),\n","        imgaug.Brightness(30),\n","        imgaug.Contrast((0.5, 1.5)),\n","    ]\n","    data_train = AugmentImageComponent(data_train, augmentors)\n","    data_train = BatchData(data_train, 128)\n","    data_train = MultiProcessRunnerZMQ(data_train, 5)\n","\n","    augmentors = [imgaug.Resize((40, 40))]\n","    data_test = AugmentImageComponent(data_test, augmentors)\n","    data_test = BatchData(data_test, 128, remainder=True)\n","\n","    return TrainConfig(\n","        data=QueueInput(data_train),\n","        callbacks=[\n","            ModelSaver(),\n","            InferenceRunner(    # run inference(for validation) after every epoch\n","                data_test,   # the DataFlow instance used for validation\n","                ScalarStats(    # produce `val_accuracy` and `val_cross_entropy_loss`\n","                    ['cross_entropy_loss', 'accuracy'], prefix='val'))\n","        ],\n","        model=Model(),\n","        max_epoch=10,\n","    )\n","\n","args = \"6,6,6\"\n","BITW, BITA, BITG = map(int, args.split(','))\n","config = get_config()\n","launch_train_with_config(config, SimpleTrainer())\n","\n","'''\n","if __name__ == '__main__':\n","    parser = argparse.ArgumentParser()\n","    parser.add_argument('--dorefa',\n","                        help='number of bits for W,A,G, separated by comma. Defaults to \\'1,2,4\\'',\n","                        default='1,2,4')\n","    args = parser.parse_args()\n","\n","    BITW, BITA, BITG = map(int, args.dorefa.split(','))\n","    config = get_config()\n","    launch_train_with_config(config, SimpleTrainer())\n","'''"],"execution_count":3,"outputs":[{"output_type":"stream","text":["\u001b[32m[0716 15:19:57 @logger.py:92]\u001b[0m Argv: /usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py -f /root/.local/share/jupyter/runtime/kernel-761cd425-71c6-4f05-b4ca-27bf46d8d2f2.json\n","\u001b[32m[0716 15:19:57 @fs.py:101]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m Env var $TENSORPACK_DATASET not set, using /root/tensorpack_data for datasets.\n","\u001b[32m[0716 15:19:57 @fs.py:104]\u001b[0m Created the directory /root/tensorpack_data.\n","\u001b[32m[0716 15:19:57 @svhn.py:42]\u001b[0m File /root/tensorpack_data/svhn_data/train_32x32.mat not found!\n","\u001b[32m[0716 15:19:57 @svhn.py:43]\u001b[0m Downloading from http://ufldl.stanford.edu/housenumbers/train_32x32.mat ...\n"],"name":"stdout"},{"output_type":"stream","text":["train_32x32.mat: 182MB [00:03, 47.0MB/s]                           "],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 15:20:00 @fs.py:73]\u001b[0m Succesfully downloaded train_32x32.mat. 182040794 bytes.\n","\u001b[32m[0716 15:20:00 @svhn.py:45]\u001b[0m Loading /root/tensorpack_data/svhn_data/train_32x32.mat ...\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 15:20:02 @svhn.py:42]\u001b[0m File /root/tensorpack_data/svhn_data/extra_32x32.mat not found!\n","\u001b[32m[0716 15:20:02 @svhn.py:43]\u001b[0m Downloading from http://ufldl.stanford.edu/housenumbers/extra_32x32.mat ...\n"],"name":"stdout"},{"output_type":"stream","text":["extra_32x32.mat: 1.33GB [00:42, 31.5MB/s]                            "],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 15:20:45 @fs.py:73]\u001b[0m Succesfully downloaded extra_32x32.mat. 1329278602 bytes.\n","\u001b[32m[0716 15:20:45 @svhn.py:45]\u001b[0m Loading /root/tensorpack_data/svhn_data/extra_32x32.mat ...\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 15:20:57 @svhn.py:42]\u001b[0m File /root/tensorpack_data/svhn_data/test_32x32.mat not found!\n","\u001b[32m[0716 15:20:57 @svhn.py:43]\u001b[0m Downloading from http://ufldl.stanford.edu/housenumbers/test_32x32.mat ...\n"],"name":"stdout"},{"output_type":"stream","text":["test_32x32.mat: 64.3MB [00:03, 20.0MB/s]                            "],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 15:21:00 @fs.py:73]\u001b[0m Succesfully downloaded test_32x32.mat. 64275384 bytes.\n","\u001b[32m[0716 15:21:00 @svhn.py:45]\u001b[0m Loading /root/tensorpack_data/svhn_data/test_32x32.mat ...\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 15:21:01 @parallel.py:340]\u001b[0m [MultiProcessRunnerZMQ] Will fork a dataflow more than one times. This assumes the datapoints are i.i.d.\n","\u001b[32m[0716 15:21:01 @input_source.py:221]\u001b[0m Setting up the queue 'QueueInput/input_queue' for CPU prefetching ...\n","\u001b[32m[0716 15:21:01 @trainers.py:48]\u001b[0m Building graph for a single training tower ...\n","\u001b[32m[0716 15:21:01 @<ipython-input-3-dae3a3b1e360>:113]\u001b[0m Binarizing weight conv0/W\n","\u001b[32m[0716 15:21:01 @registry.py:90]\u001b[0m 'conv0': [?, 40, 40, 3] --> [?, 36, 36, 48]\n","\u001b[32m[0716 15:21:01 @registry.py:90]\u001b[0m 'pool0': [?, 36, 36, 48] --> [?, 18, 18, 48]\n","\u001b[32m[0716 15:21:01 @<ipython-input-3-dae3a3b1e360>:113]\u001b[0m Binarizing weight conv1/W\n","\u001b[32m[0716 15:21:01 @registry.py:90]\u001b[0m 'conv1': [?, 18, 18, 48] --> [?, 18, 18, 64]\n","\u001b[32m[0716 15:21:01 @<ipython-input-3-dae3a3b1e360>:113]\u001b[0m Binarizing weight conv2/W\n","\u001b[32m[0716 15:21:01 @registry.py:90]\u001b[0m 'conv2': [?, 18, 18, 64] --> [?, 18, 18, 64]\n","\u001b[32m[0716 15:21:01 @registry.py:90]\u001b[0m 'pool1': [?, 18, 18, 64] --> [?, 9, 9, 64]\n","\u001b[32m[0716 15:21:01 @<ipython-input-3-dae3a3b1e360>:113]\u001b[0m Binarizing weight conv3/W\n","\u001b[32m[0716 15:21:01 @registry.py:90]\u001b[0m 'conv3': [?, 9, 9, 64] --> [?, 7, 7, 128]\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1692: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n","  warnings.warn('`layer.apply` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 15:21:01 @<ipython-input-3-dae3a3b1e360>:113]\u001b[0m Binarizing weight conv4/W\n","\u001b[32m[0716 15:21:01 @registry.py:90]\u001b[0m 'conv4': [?, 7, 7, 128] --> [?, 7, 7, 128]\n","\u001b[32m[0716 15:21:01 @<ipython-input-3-dae3a3b1e360>:113]\u001b[0m Binarizing weight conv5/W\n","\u001b[32m[0716 15:21:01 @registry.py:90]\u001b[0m 'conv5': [?, 7, 7, 128] --> [?, 5, 5, 128]\n","\u001b[32m[0716 15:21:01 @<ipython-input-3-dae3a3b1e360>:113]\u001b[0m Binarizing weight conv6/W\n","\u001b[32m[0716 15:21:01 @registry.py:90]\u001b[0m 'conv6': [?, 5, 5, 128] --> [?, 1, 1, 512]\n","\u001b[32m[0716 15:21:01 @<ipython-input-3-dae3a3b1e360>:113]\u001b[0m Binarizing weight fc1/W\n","\u001b[32m[0716 15:21:01 @registry.py:90]\u001b[0m 'fc1': [?, 1, 1, 512] --> [?, 10]\n","\u001b[32m[0716 15:21:01 @regularize.py:97]\u001b[0m regularize_cost() found 1 variables to regularize.\n","\u001b[32m[0716 15:21:01 @regularize.py:21]\u001b[0m The following tensors will be regularized: fc1/W:0\n","\u001b[32m[0716 15:21:02 @model_utils.py:67]\u001b[0m \u001b[36mList of Trainable Variables: \n","\u001b[0mname       shape               #elements\n","---------  ----------------  -----------\n","conv0/W    [5, 5, 3, 48]            3600\n","conv0/b    [48]                       48\n","conv1/W    [3, 3, 48, 64]          27648\n","bn1/gamma  [64]                       64\n","bn1/beta   [64]                       64\n","conv2/W    [3, 3, 64, 64]          36864\n","bn2/gamma  [64]                       64\n","bn2/beta   [64]                       64\n","conv3/W    [3, 3, 64, 128]         73728\n","bn3/gamma  [128]                     128\n","bn3/beta   [128]                     128\n","conv4/W    [3, 3, 128, 128]       147456\n","bn4/gamma  [128]                     128\n","bn4/beta   [128]                     128\n","conv5/W    [3, 3, 128, 128]       147456\n","bn5/gamma  [128]                     128\n","bn5/beta   [128]                     128\n","conv6/W    [5, 5, 128, 512]      1638400\n","bn6/gamma  [512]                     512\n","bn6/beta   [512]                     512\n","fc1/W      [512, 10]                5120\n","fc1/b      [10]                       10\u001b[36m\n","Number of trainable variables: 22\n","Number of parameters (elements): 2082378\n","Storage space needed for all trainable variables: 7.94MB\u001b[0m\n","\u001b[32m[0716 15:21:02 @base.py:207]\u001b[0m Setup callbacks graph ...\n","\u001b[32m[0716 15:21:02 @argtools.py:138]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m Starting a process with 'fork' method is efficient but not safe and may cause deadlock or crash.Use 'forkserver' or 'spawn' method instead if you run into such issues.See https://docs.python.org/3/library/multiprocessing.html#contexts-and-start-methods on how to set them.\n","\u001b[32m[0716 15:21:02 @argtools.py:138]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m \"import prctl\" failed! Install python-prctl so that processes can be cleaned with guarantee.\n","\u001b[32m[0716 15:21:03 @inference_runner.py:148]\u001b[0m [InferenceRunner] Building tower 'InferenceTower' on device /gpu:0 ...\n","\u001b[32m[0716 15:21:03 @<ipython-input-3-dae3a3b1e360>:113]\u001b[0m Binarizing weight conv0/W\n","\u001b[32m[0716 15:21:03 @<ipython-input-3-dae3a3b1e360>:113]\u001b[0m Binarizing weight conv1/W\n","\u001b[32m[0716 15:21:03 @<ipython-input-3-dae3a3b1e360>:113]\u001b[0m Binarizing weight conv2/W\n","\u001b[32m[0716 15:21:03 @<ipython-input-3-dae3a3b1e360>:113]\u001b[0m Binarizing weight conv3/W\n","\u001b[32m[0716 15:21:03 @<ipython-input-3-dae3a3b1e360>:113]\u001b[0m Binarizing weight conv4/W\n","\u001b[32m[0716 15:21:03 @<ipython-input-3-dae3a3b1e360>:113]\u001b[0m Binarizing weight conv5/W\n","\u001b[32m[0716 15:21:04 @<ipython-input-3-dae3a3b1e360>:113]\u001b[0m Binarizing weight conv6/W\n","\u001b[32m[0716 15:21:04 @<ipython-input-3-dae3a3b1e360>:113]\u001b[0m Binarizing weight fc1/W\n","\u001b[32m[0716 15:21:04 @summary.py:47]\u001b[0m [MovingAverageSummary] 5 operations in collection 'MOVING_SUMMARY_OPS' will be run with session hooks.\n","\u001b[32m[0716 15:21:04 @summary.py:94]\u001b[0m Summarizing collection 'summaries' of size 22.\n","\u001b[32m[0716 15:21:04 @graph.py:99]\u001b[0m Applying collection UPDATE_OPS of 12 ops.\n","\u001b[32m[0716 15:21:04 @base.py:228]\u001b[0m Creating the session ...\n","\u001b[32m[0716 15:21:11 @base.py:234]\u001b[0m Initializing the session ...\n","\u001b[32m[0716 15:21:11 @base.py:241]\u001b[0m Graph Finalized.\n","\u001b[32m[0716 15:21:11 @concurrency.py:37]\u001b[0m Starting EnqueueThread: enqueue dataflow to TF queue \"QueueInput/input_queue\" ...\n","\u001b[32m[0716 15:21:12 @inference_runner.py:95]\u001b[0m [InferenceRunner] Will eval 204 iterations\n","\u001b[32m[0716 15:21:12 @base.py:273]\u001b[0m Start Epoch 1 ...\n"],"name":"stdout"},{"output_type":"stream","text":["100%|##########|4721/4721[04:37<00:00,17.03it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 15:25:49 @base.py:283]\u001b[0m Epoch 1 (global_step 4721) finished, time:4 minutes 37 seconds.\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 15:25:50 @saver.py:82]\u001b[0m Model saved to train_log/svhn-dorefa-6,6,6/model-4721.\n"],"name":"stdout"},{"output_type":"stream","text":["100%|##########|204/204[00:11<00:00,18.20it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 15:26:01 @monitor.py:476]\u001b[0m QueueInput/queue_size: 22\n","\u001b[32m[0716 15:26:01 @monitor.py:476]\u001b[0m accuracy: 0.9563\n","\u001b[32m[0716 15:26:01 @monitor.py:476]\u001b[0m cost: 0.14509\n","\u001b[32m[0716 15:26:01 @monitor.py:476]\u001b[0m cross_entropy_loss: 0.14509\n","\u001b[32m[0716 15:26:01 @monitor.py:476]\u001b[0m param-summary/conv0/W-rms: 0.17081\n","\u001b[32m[0716 15:26:01 @monitor.py:476]\u001b[0m param-summary/conv1/W-rms: 0.075648\n","\u001b[32m[0716 15:26:01 @monitor.py:476]\u001b[0m param-summary/conv2/W-rms: 0.066465\n","\u001b[32m[0716 15:26:01 @monitor.py:476]\u001b[0m param-summary/conv3/W-rms: 0.067522\n","\u001b[32m[0716 15:26:01 @monitor.py:476]\u001b[0m param-summary/conv4/W-rms: 0.052662\n","\u001b[32m[0716 15:26:01 @monitor.py:476]\u001b[0m param-summary/conv5/W-rms: 0.054621\n","\u001b[32m[0716 15:26:01 @monitor.py:476]\u001b[0m param-summary/conv6/W-rms: 0.04073\n","\u001b[32m[0716 15:26:01 @monitor.py:476]\u001b[0m param-summary/fc1/W-rms: 0.060072\n","\u001b[32m[0716 15:26:01 @monitor.py:476]\u001b[0m regularize_cost: 9.2131e-07\n","\u001b[32m[0716 15:26:01 @monitor.py:476]\u001b[0m train_error: 0.043705\n","\u001b[32m[0716 15:26:01 @monitor.py:476]\u001b[0m val_accuracy: 0.87868\n","\u001b[32m[0716 15:26:01 @monitor.py:476]\u001b[0m val_cross_entropy_loss: 0.39242\n","\u001b[32m[0716 15:26:01 @group.py:44]\u001b[0m Callbacks took 11.854 sec in total. InferenceRunner: 11.2 seconds\n","\u001b[32m[0716 15:26:01 @base.py:273]\u001b[0m Start Epoch 2 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|4721/4721[04:06<00:00,19.17it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 15:30:07 @base.py:283]\u001b[0m Epoch 2 (global_step 9442) finished, time:4 minutes 6 seconds.\n","\u001b[32m[0716 15:30:08 @saver.py:82]\u001b[0m Model saved to train_log/svhn-dorefa-6,6,6/model-9442.\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|204/204[00:09<00:00,20.50it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 15:30:18 @monitor.py:476]\u001b[0m QueueInput/queue_size: 0.00012207\n","\u001b[32m[0716 15:30:18 @monitor.py:476]\u001b[0m accuracy: 0.96827\n","\u001b[32m[0716 15:30:18 @monitor.py:476]\u001b[0m cost: 0.1043\n","\u001b[32m[0716 15:30:18 @monitor.py:476]\u001b[0m cross_entropy_loss: 0.1043\n","\u001b[32m[0716 15:30:18 @monitor.py:476]\u001b[0m param-summary/conv0/W-rms: 0.1805\n","\u001b[32m[0716 15:30:18 @monitor.py:476]\u001b[0m param-summary/conv1/W-rms: 0.088967\n","\u001b[32m[0716 15:30:18 @monitor.py:476]\u001b[0m param-summary/conv2/W-rms: 0.083513\n","\u001b[32m[0716 15:30:18 @monitor.py:476]\u001b[0m param-summary/conv3/W-rms: 0.086235\n","\u001b[32m[0716 15:30:18 @monitor.py:476]\u001b[0m param-summary/conv4/W-rms: 0.073889\n","\u001b[32m[0716 15:30:18 @monitor.py:476]\u001b[0m param-summary/conv5/W-rms: 0.076765\n","\u001b[32m[0716 15:30:18 @monitor.py:476]\u001b[0m param-summary/conv6/W-rms: 0.062724\n","\u001b[32m[0716 15:30:18 @monitor.py:476]\u001b[0m param-summary/fc1/W-rms: 0.080825\n","\u001b[32m[0716 15:30:18 @monitor.py:476]\u001b[0m regularize_cost: 1.6688e-06\n","\u001b[32m[0716 15:30:18 @monitor.py:476]\u001b[0m train_error: 0.03173\n","\u001b[32m[0716 15:30:18 @monitor.py:476]\u001b[0m val_accuracy: 0.93502\n","\u001b[32m[0716 15:30:18 @monitor.py:476]\u001b[0m val_cross_entropy_loss: 0.23126\n","\u001b[32m[0716 15:30:18 @group.py:44]\u001b[0m Callbacks took 10.224 sec in total. InferenceRunner: 9.98 seconds\n","\u001b[32m[0716 15:30:18 @base.py:273]\u001b[0m Start Epoch 3 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|4721/4721[04:09<00:00,18.89it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 15:34:28 @base.py:283]\u001b[0m Epoch 3 (global_step 14163) finished, time:4 minutes 9 seconds.\n","\u001b[32m[0716 15:34:28 @saver.py:82]\u001b[0m Model saved to train_log/svhn-dorefa-6,6,6/model-14163.\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|204/204[00:10<00:00,19.97it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 15:34:38 @monitor.py:476]\u001b[0m QueueInput/queue_size: 2.6193e-10\n","\u001b[32m[0716 15:34:38 @monitor.py:476]\u001b[0m accuracy: 0.96998\n","\u001b[32m[0716 15:34:38 @monitor.py:476]\u001b[0m cost: 0.097789\n","\u001b[32m[0716 15:34:38 @monitor.py:476]\u001b[0m cross_entropy_loss: 0.097787\n","\u001b[32m[0716 15:34:38 @monitor.py:476]\u001b[0m param-summary/conv0/W-rms: 0.1965\n","\u001b[32m[0716 15:34:38 @monitor.py:476]\u001b[0m param-summary/conv1/W-rms: 0.10357\n","\u001b[32m[0716 15:34:38 @monitor.py:476]\u001b[0m param-summary/conv2/W-rms: 0.10324\n","\u001b[32m[0716 15:34:38 @monitor.py:476]\u001b[0m param-summary/conv3/W-rms: 0.10655\n","\u001b[32m[0716 15:34:38 @monitor.py:476]\u001b[0m param-summary/conv4/W-rms: 0.09633\n","\u001b[32m[0716 15:34:38 @monitor.py:476]\u001b[0m param-summary/conv5/W-rms: 0.098667\n","\u001b[32m[0716 15:34:38 @monitor.py:476]\u001b[0m param-summary/conv6/W-rms: 0.083287\n","\u001b[32m[0716 15:34:38 @monitor.py:476]\u001b[0m param-summary/fc1/W-rms: 0.10132\n","\u001b[32m[0716 15:34:38 @monitor.py:476]\u001b[0m regularize_cost: 2.6286e-06\n","\u001b[32m[0716 15:34:38 @monitor.py:476]\u001b[0m train_error: 0.03002\n","\u001b[32m[0716 15:34:38 @monitor.py:476]\u001b[0m val_accuracy: 0.9418\n","\u001b[32m[0716 15:34:38 @monitor.py:476]\u001b[0m val_cross_entropy_loss: 0.21014\n","\u001b[32m[0716 15:34:38 @group.py:44]\u001b[0m Callbacks took 10.511 sec in total. InferenceRunner: 10.2 seconds\n","\u001b[32m[0716 15:34:38 @base.py:273]\u001b[0m Start Epoch 4 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|4721/4721[04:08<00:00,18.97it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 15:38:47 @base.py:283]\u001b[0m Epoch 4 (global_step 18884) finished, time:4 minutes 8 seconds.\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 15:38:47 @saver.py:82]\u001b[0m Model saved to train_log/svhn-dorefa-6,6,6/model-18884.\n"],"name":"stdout"},{"output_type":"stream","text":["100%|##########|204/204[00:10<00:00,20.19it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 15:38:57 @monitor.py:476]\u001b[0m QueueInput/queue_size: 6.9931e-21\n","\u001b[32m[0716 15:38:57 @monitor.py:476]\u001b[0m accuracy: 0.98053\n","\u001b[32m[0716 15:38:57 @monitor.py:476]\u001b[0m cost: 0.070914\n","\u001b[32m[0716 15:38:57 @monitor.py:476]\u001b[0m cross_entropy_loss: 0.070911\n","\u001b[32m[0716 15:38:57 @monitor.py:476]\u001b[0m param-summary/conv0/W-rms: 0.21236\n","\u001b[32m[0716 15:38:57 @monitor.py:476]\u001b[0m param-summary/conv1/W-rms: 0.1175\n","\u001b[32m[0716 15:38:57 @monitor.py:476]\u001b[0m param-summary/conv2/W-rms: 0.12149\n","\u001b[32m[0716 15:38:57 @monitor.py:476]\u001b[0m param-summary/conv3/W-rms: 0.12473\n","\u001b[32m[0716 15:38:57 @monitor.py:476]\u001b[0m param-summary/conv4/W-rms: 0.11572\n","\u001b[32m[0716 15:38:57 @monitor.py:476]\u001b[0m param-summary/conv5/W-rms: 0.11762\n","\u001b[32m[0716 15:38:57 @monitor.py:476]\u001b[0m param-summary/conv6/W-rms: 0.10025\n","\u001b[32m[0716 15:38:57 @monitor.py:476]\u001b[0m param-summary/fc1/W-rms: 0.12067\n","\u001b[32m[0716 15:38:57 @monitor.py:476]\u001b[0m regularize_cost: 3.7221e-06\n","\u001b[32m[0716 15:38:57 @monitor.py:476]\u001b[0m train_error: 0.019473\n","\u001b[32m[0716 15:38:57 @monitor.py:476]\u001b[0m val_accuracy: 0.95837\n","\u001b[32m[0716 15:38:57 @monitor.py:476]\u001b[0m val_cross_entropy_loss: 0.15541\n","\u001b[32m[0716 15:38:57 @group.py:44]\u001b[0m Callbacks took 10.494 sec in total. InferenceRunner: 10.1 seconds\n","\u001b[32m[0716 15:38:58 @base.py:273]\u001b[0m Start Epoch 5 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|4721/4721[04:10<00:00,18.84it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 15:43:08 @base.py:283]\u001b[0m Epoch 5 (global_step 23605) finished, time:4 minutes 10 seconds.\n","\u001b[32m[0716 15:43:08 @saver.py:82]\u001b[0m Model saved to train_log/svhn-dorefa-6,6,6/model-23605.\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|204/204[00:09<00:00,21.99it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 15:43:18 @monitor.py:476]\u001b[0m QueueInput/queue_size: 5.9605e-08\n","\u001b[32m[0716 15:43:18 @monitor.py:476]\u001b[0m accuracy: 0.98558\n","\u001b[32m[0716 15:43:18 @monitor.py:476]\u001b[0m cost: 0.061081\n","\u001b[32m[0716 15:43:18 @monitor.py:476]\u001b[0m cross_entropy_loss: 0.061076\n","\u001b[32m[0716 15:43:18 @monitor.py:476]\u001b[0m param-summary/conv0/W-rms: 0.22438\n","\u001b[32m[0716 15:43:18 @monitor.py:476]\u001b[0m param-summary/conv1/W-rms: 0.12811\n","\u001b[32m[0716 15:43:18 @monitor.py:476]\u001b[0m param-summary/conv2/W-rms: 0.13743\n","\u001b[32m[0716 15:43:18 @monitor.py:476]\u001b[0m param-summary/conv3/W-rms: 0.14092\n","\u001b[32m[0716 15:43:18 @monitor.py:476]\u001b[0m param-summary/conv4/W-rms: 0.13256\n","\u001b[32m[0716 15:43:18 @monitor.py:476]\u001b[0m param-summary/conv5/W-rms: 0.13422\n","\u001b[32m[0716 15:43:18 @monitor.py:476]\u001b[0m param-summary/conv6/W-rms: 0.11449\n","\u001b[32m[0716 15:43:18 @monitor.py:476]\u001b[0m param-summary/fc1/W-rms: 0.13805\n","\u001b[32m[0716 15:43:18 @monitor.py:476]\u001b[0m regularize_cost: 4.8711e-06\n","\u001b[32m[0716 15:43:18 @monitor.py:476]\u001b[0m train_error: 0.014422\n","\u001b[32m[0716 15:43:18 @monitor.py:476]\u001b[0m val_accuracy: 0.96481\n","\u001b[32m[0716 15:43:18 @monitor.py:476]\u001b[0m val_cross_entropy_loss: 0.1375\n","\u001b[32m[0716 15:43:18 @group.py:44]\u001b[0m Callbacks took 9.505 sec in total. InferenceRunner: 9.29 seconds\n","\u001b[32m[0716 15:43:18 @base.py:273]\u001b[0m Start Epoch 6 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|4721/4721[04:15<00:00,18.48it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 15:47:33 @base.py:283]\u001b[0m Epoch 6 (global_step 28326) finished, time:4 minutes 15 seconds.\n","\u001b[32m[0716 15:47:33 @saver.py:82]\u001b[0m Model saved to train_log/svhn-dorefa-6,6,6/model-28326.\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|204/204[00:10<00:00,19.68it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 15:47:44 @monitor.py:476]\u001b[0m QueueInput/queue_size: 4.4726e-19\n","\u001b[32m[0716 15:47:44 @monitor.py:476]\u001b[0m accuracy: 0.98561\n","\u001b[32m[0716 15:47:44 @monitor.py:476]\u001b[0m cost: 0.050876\n","\u001b[32m[0716 15:47:44 @monitor.py:476]\u001b[0m cross_entropy_loss: 0.050869\n","\u001b[32m[0716 15:47:44 @monitor.py:476]\u001b[0m param-summary/conv0/W-rms: 0.22982\n","\u001b[32m[0716 15:47:44 @monitor.py:476]\u001b[0m param-summary/conv1/W-rms: 0.13798\n","\u001b[32m[0716 15:47:44 @monitor.py:476]\u001b[0m param-summary/conv2/W-rms: 0.15214\n","\u001b[32m[0716 15:47:44 @monitor.py:476]\u001b[0m param-summary/conv3/W-rms: 0.15593\n","\u001b[32m[0716 15:47:44 @monitor.py:476]\u001b[0m param-summary/conv4/W-rms: 0.14798\n","\u001b[32m[0716 15:47:44 @monitor.py:476]\u001b[0m param-summary/conv5/W-rms: 0.14941\n","\u001b[32m[0716 15:47:44 @monitor.py:476]\u001b[0m param-summary/conv6/W-rms: 0.12726\n","\u001b[32m[0716 15:47:44 @monitor.py:476]\u001b[0m param-summary/fc1/W-rms: 0.15763\n","\u001b[32m[0716 15:47:44 @monitor.py:476]\u001b[0m regularize_cost: 6.3554e-06\n","\u001b[32m[0716 15:47:44 @monitor.py:476]\u001b[0m train_error: 0.01439\n","\u001b[32m[0716 15:47:44 @monitor.py:476]\u001b[0m val_accuracy: 0.96687\n","\u001b[32m[0716 15:47:44 @monitor.py:476]\u001b[0m val_cross_entropy_loss: 0.13222\n","\u001b[32m[0716 15:47:44 @group.py:44]\u001b[0m Callbacks took 10.649 sec in total. InferenceRunner: 10.4 seconds\n","\u001b[32m[0716 15:47:44 @base.py:273]\u001b[0m Start Epoch 7 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|4721/4721[04:06<00:00,19.13it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 15:51:51 @base.py:283]\u001b[0m Epoch 7 (global_step 33047) finished, time:4 minutes 6 seconds.\n","\u001b[32m[0716 15:51:51 @saver.py:82]\u001b[0m Model saved to train_log/svhn-dorefa-6,6,6/model-33047.\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|204/204[00:10<00:00,20.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 15:52:01 @monitor.py:476]\u001b[0m QueueInput/queue_size: 9.5367e-07\n","\u001b[32m[0716 15:52:01 @monitor.py:476]\u001b[0m accuracy: 0.98357\n","\u001b[32m[0716 15:52:01 @monitor.py:476]\u001b[0m cost: 0.068815\n","\u001b[32m[0716 15:52:01 @monitor.py:476]\u001b[0m cross_entropy_loss: 0.068807\n","\u001b[32m[0716 15:52:01 @monitor.py:476]\u001b[0m param-summary/conv0/W-rms: 0.23576\n","\u001b[32m[0716 15:52:01 @monitor.py:476]\u001b[0m param-summary/conv1/W-rms: 0.14752\n","\u001b[32m[0716 15:52:01 @monitor.py:476]\u001b[0m param-summary/conv2/W-rms: 0.16617\n","\u001b[32m[0716 15:52:01 @monitor.py:476]\u001b[0m param-summary/conv3/W-rms: 0.16971\n","\u001b[32m[0716 15:52:01 @monitor.py:476]\u001b[0m param-summary/conv4/W-rms: 0.16201\n","\u001b[32m[0716 15:52:01 @monitor.py:476]\u001b[0m param-summary/conv5/W-rms: 0.16321\n","\u001b[32m[0716 15:52:01 @monitor.py:476]\u001b[0m param-summary/conv6/W-rms: 0.13866\n","\u001b[32m[0716 15:52:01 @monitor.py:476]\u001b[0m param-summary/fc1/W-rms: 0.1743\n","\u001b[32m[0716 15:52:01 @monitor.py:476]\u001b[0m regularize_cost: 7.789e-06\n","\u001b[32m[0716 15:52:01 @monitor.py:476]\u001b[0m train_error: 0.016429\n","\u001b[32m[0716 15:52:01 @monitor.py:476]\u001b[0m val_accuracy: 0.96617\n","\u001b[32m[0716 15:52:01 @monitor.py:476]\u001b[0m val_cross_entropy_loss: 0.13178\n","\u001b[32m[0716 15:52:01 @group.py:44]\u001b[0m Callbacks took 10.480 sec in total. InferenceRunner: 10.2 seconds\n","\u001b[32m[0716 15:52:01 @base.py:273]\u001b[0m Start Epoch 8 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|4721/4721[04:05<00:00,19.26it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 15:56:06 @base.py:283]\u001b[0m Epoch 8 (global_step 37768) finished, time:4 minutes 5 seconds.\n","\u001b[32m[0716 15:56:06 @saver.py:82]\u001b[0m Model saved to train_log/svhn-dorefa-6,6,6/model-37768.\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|204/204[00:09<00:00,21.81it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 15:56:16 @monitor.py:476]\u001b[0m QueueInput/queue_size: 3.8158e-06\n","\u001b[32m[0716 15:56:16 @monitor.py:476]\u001b[0m accuracy: 0.98724\n","\u001b[32m[0716 15:56:16 @monitor.py:476]\u001b[0m cost: 0.041918\n","\u001b[32m[0716 15:56:16 @monitor.py:476]\u001b[0m cross_entropy_loss: 0.041908\n","\u001b[32m[0716 15:56:16 @monitor.py:476]\u001b[0m param-summary/conv0/W-rms: 0.24043\n","\u001b[32m[0716 15:56:16 @monitor.py:476]\u001b[0m param-summary/conv1/W-rms: 0.15388\n","\u001b[32m[0716 15:56:16 @monitor.py:476]\u001b[0m param-summary/conv2/W-rms: 0.17859\n","\u001b[32m[0716 15:56:16 @monitor.py:476]\u001b[0m param-summary/conv3/W-rms: 0.18224\n","\u001b[32m[0716 15:56:16 @monitor.py:476]\u001b[0m param-summary/conv4/W-rms: 0.17474\n","\u001b[32m[0716 15:56:16 @monitor.py:476]\u001b[0m param-summary/conv5/W-rms: 0.17596\n","\u001b[32m[0716 15:56:16 @monitor.py:476]\u001b[0m param-summary/conv6/W-rms: 0.14909\n","\u001b[32m[0716 15:56:16 @monitor.py:476]\u001b[0m param-summary/fc1/W-rms: 0.19098\n","\u001b[32m[0716 15:56:16 @monitor.py:476]\u001b[0m regularize_cost: 9.3258e-06\n","\u001b[32m[0716 15:56:16 @monitor.py:476]\u001b[0m train_error: 0.012762\n","\u001b[32m[0716 15:56:16 @monitor.py:476]\u001b[0m val_accuracy: 0.96635\n","\u001b[32m[0716 15:56:16 @monitor.py:476]\u001b[0m val_cross_entropy_loss: 0.1322\n","\u001b[32m[0716 15:56:16 @group.py:44]\u001b[0m Callbacks took 9.616 sec in total. InferenceRunner: 9.38 seconds\n","\u001b[32m[0716 15:56:16 @base.py:273]\u001b[0m Start Epoch 9 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|4721/4721[04:05<00:00,19.27it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 16:00:21 @base.py:283]\u001b[0m Epoch 9 (global_step 42489) finished, time:4 minutes 5 seconds.\n","\u001b[32m[0716 16:00:21 @saver.py:82]\u001b[0m Model saved to train_log/svhn-dorefa-6,6,6/model-42489.\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|204/204[00:09<00:00,21.86it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 16:00:30 @monitor.py:476]\u001b[0m QueueInput/queue_size: 1.0147e-06\n","\u001b[32m[0716 16:00:30 @monitor.py:476]\u001b[0m accuracy: 0.98703\n","\u001b[32m[0716 16:00:30 @monitor.py:476]\u001b[0m cost: 0.044561\n","\u001b[32m[0716 16:00:30 @monitor.py:476]\u001b[0m cross_entropy_loss: 0.04455\n","\u001b[32m[0716 16:00:30 @monitor.py:476]\u001b[0m param-summary/conv0/W-rms: 0.24371\n","\u001b[32m[0716 16:00:30 @monitor.py:476]\u001b[0m param-summary/conv1/W-rms: 0.1599\n","\u001b[32m[0716 16:00:30 @monitor.py:476]\u001b[0m param-summary/conv2/W-rms: 0.19071\n","\u001b[32m[0716 16:00:30 @monitor.py:476]\u001b[0m param-summary/conv3/W-rms: 0.19429\n","\u001b[32m[0716 16:00:30 @monitor.py:476]\u001b[0m param-summary/conv4/W-rms: 0.18661\n","\u001b[32m[0716 16:00:30 @monitor.py:476]\u001b[0m param-summary/conv5/W-rms: 0.18789\n","\u001b[32m[0716 16:00:30 @monitor.py:476]\u001b[0m param-summary/conv6/W-rms: 0.15885\n","\u001b[32m[0716 16:00:30 @monitor.py:476]\u001b[0m param-summary/fc1/W-rms: 0.2071\n","\u001b[32m[0716 16:00:30 @monitor.py:476]\u001b[0m regularize_cost: 1.0969e-05\n","\u001b[32m[0716 16:00:31 @monitor.py:476]\u001b[0m train_error: 0.012967\n","\u001b[32m[0716 16:00:31 @monitor.py:476]\u001b[0m val_accuracy: 0.96903\n","\u001b[32m[0716 16:00:31 @monitor.py:476]\u001b[0m val_cross_entropy_loss: 0.1277\n","\u001b[32m[0716 16:00:31 @group.py:44]\u001b[0m Callbacks took 9.622 sec in total. InferenceRunner: 9.35 seconds\n","\u001b[32m[0716 16:00:31 @base.py:273]\u001b[0m Start Epoch 10 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|4721/4721[04:08<00:00,18.98it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 16:04:39 @base.py:283]\u001b[0m Epoch 10 (global_step 47210) finished, time:4 minutes 8 seconds.\n","\u001b[32m[0716 16:04:39 @saver.py:82]\u001b[0m Model saved to train_log/svhn-dorefa-6,6,6/model-47210.\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|204/204[00:09<00:00,22.14it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 16:04:49 @monitor.py:476]\u001b[0m QueueInput/queue_size: 5.2387e-10\n","\u001b[32m[0716 16:04:49 @monitor.py:476]\u001b[0m accuracy: 0.98971\n","\u001b[32m[0716 16:04:49 @monitor.py:476]\u001b[0m cost: 0.037176\n","\u001b[32m[0716 16:04:49 @monitor.py:476]\u001b[0m cross_entropy_loss: 0.037163\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 16:04:49 @monitor.py:476]\u001b[0m param-summary/conv0/W-rms: 0.24769\n","\u001b[32m[0716 16:04:49 @monitor.py:476]\u001b[0m param-summary/conv1/W-rms: 0.16571\n","\u001b[32m[0716 16:04:49 @monitor.py:476]\u001b[0m param-summary/conv2/W-rms: 0.20173\n","\u001b[32m[0716 16:04:49 @monitor.py:476]\u001b[0m param-summary/conv3/W-rms: 0.20539\n","\u001b[32m[0716 16:04:49 @monitor.py:476]\u001b[0m param-summary/conv4/W-rms: 0.19773\n","\u001b[32m[0716 16:04:49 @monitor.py:476]\u001b[0m param-summary/conv5/W-rms: 0.19901\n","\u001b[32m[0716 16:04:49 @monitor.py:476]\u001b[0m param-summary/conv6/W-rms: 0.16787\n","\u001b[32m[0716 16:04:49 @monitor.py:476]\u001b[0m param-summary/fc1/W-rms: 0.22288\n","\u001b[32m[0716 16:04:49 @monitor.py:476]\u001b[0m regularize_cost: 1.2704e-05\n","\u001b[32m[0716 16:04:49 @monitor.py:476]\u001b[0m train_error: 0.010288\n","\u001b[32m[0716 16:04:49 @monitor.py:476]\u001b[0m val_accuracy: 0.96998\n","\u001b[32m[0716 16:04:49 @monitor.py:476]\u001b[0m val_cross_entropy_loss: 0.12328\n","\u001b[32m[0716 16:04:49 @group.py:44]\u001b[0m Callbacks took 9.500 sec in total. InferenceRunner: 9.23 seconds\n","\u001b[32m[0716 16:04:49 @base.py:287]\u001b[0m Training has finished!\n"],"name":"stdout"},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"\\nif __name__ == '__main__':\\n    parser = argparse.ArgumentParser()\\n    parser.add_argument('--dorefa',\\n                        help='number of bits for W,A,G, separated by comma. Defaults to '1,2,4'',\\n                        default='1,2,4')\\n    args = parser.parse_args()\\n\\n    BITW, BITA, BITG = map(int, args.dorefa.split(','))\\n    config = get_config()\\n    launch_train_with_config(config, SimpleTrainer())\\n\""]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":315},"id":"mduuAqCeuc4B","executionInfo":{"status":"ok","timestamp":1626451656052,"user_tz":-120,"elapsed":727,"user":{"displayName":"Lorenzo Pasco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgShaitSLZm3zyLVjMQT7ZzTrEV3kQEXha_A9lkVw=s64","userId":"01314717049817932576"}},"outputId":"af25d68d-7186-498f-d2e2-00569da79c68"},"source":["import json\n","import matplotlib.pyplot as plt\n","\n","f = open(\"train_log/svhn-dorefa-6,6,6/stats_def_first&last_avg_pooling_666.json\",\"r\")\n","\n","data = json.load(f)\n","accuracy = []\n","val_accuracy = []\n","for ob in data:\n","  accuracy.append(ob[\"accuracy\"])\n","  val_accuracy.append(ob[\"val_accuracy\"])\n","\n","epochs = range(len(accuracy))\n","\n","plt.plot(epochs, accuracy, 'r', label='Training acc')\n","plt.plot(epochs, val_accuracy, 'b', label='Validation acc')\n","plt.title('Training and validation accuracy')\n","plt.legend()\n","plt.figure()"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<Figure size 432x288 with 0 Axes>"]},"metadata":{"tags":[]},"execution_count":4},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 0 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ST3WBdVha1W-","executionInfo":{"status":"ok","timestamp":1626451665121,"user_tz":-120,"elapsed":222,"user":{"displayName":"Lorenzo Pasco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgShaitSLZm3zyLVjMQT7ZzTrEV3kQEXha_A9lkVw=s64","userId":"01314717049817932576"}},"outputId":"5ef4489a-b5f1-4069-f3e6-b5ff8256bc5e"},"source":["from tabulate import tabulate\n","import matplotlib.pyplot as plt\n","\n","ep = [i+1 for i in epochs]\n","table_acc = {\"Epochs\" : ep, \"Accuracy\":accuracy}\n","table_val_acc = {\"Epochs\" : ep, \"Accuracy\":val_accuracy}\n","\n","print(\"ACCURACY\\n\")\n","print(tabulate(table_acc, headers='keys', tablefmt='fancy_grid'))\n","print(\"\\nVALIDATION ACCURACY\\n\")\n","print(tabulate(table_val_acc, headers='keys', tablefmt='fancy_grid'))"],"execution_count":5,"outputs":[{"output_type":"stream","text":["ACCURACY\n","\n","╒══════════╤════════════╕\n","│   Epochs │   Accuracy │\n","╞══════════╪════════════╡\n","│        1 │   0.956295 │\n","├──────────┼────────────┤\n","│        2 │   0.96827  │\n","├──────────┼────────────┤\n","│        3 │   0.96998  │\n","├──────────┼────────────┤\n","│        4 │   0.980527 │\n","├──────────┼────────────┤\n","│        5 │   0.985578 │\n","├──────────┼────────────┤\n","│        6 │   0.98561  │\n","├──────────┼────────────┤\n","│        7 │   0.983571 │\n","├──────────┼────────────┤\n","│        8 │   0.987238 │\n","├──────────┼────────────┤\n","│        9 │   0.987033 │\n","├──────────┼────────────┤\n","│       10 │   0.989712 │\n","╘══════════╧════════════╛\n","\n","VALIDATION ACCURACY\n","\n","╒══════════╤════════════╕\n","│   Epochs │   Accuracy │\n","╞══════════╪════════════╡\n","│        1 │   0.878676 │\n","├──────────┼────────────┤\n","│        2 │   0.935023 │\n","├──────────┼────────────┤\n","│        3 │   0.941802 │\n","├──────────┼────────────┤\n","│        4 │   0.958372 │\n","├──────────┼────────────┤\n","│        5 │   0.964805 │\n","├──────────┼────────────┤\n","│        6 │   0.966873 │\n","├──────────┼────────────┤\n","│        7 │   0.966171 │\n","├──────────┼────────────┤\n","│        8 │   0.96635  │\n","├──────────┼────────────┤\n","│        9 │   0.969031 │\n","├──────────┼────────────┤\n","│       10 │   0.969975 │\n","╘══════════╧════════════╛\n"],"name":"stdout"}]}]}