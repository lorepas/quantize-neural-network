{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"svhn-digit-dorefa_first&last.ipynb","provenance":[],"authorship_tag":"ABX9TyOZj1339IwbuNXxsXL0oOvU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"5qzKFEQKqXDt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626440617260,"user_tz":-120,"elapsed":18870,"user":{"displayName":"Lorenzo Pasco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgShaitSLZm3zyLVjMQT7ZzTrEV3kQEXha_A9lkVw=s64","userId":"01314717049817932576"}},"outputId":"ae7c5d20-f4fe-4c8e-a8dd-a959a6c87e69"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eDXKVoHj26H8","executionInfo":{"status":"ok","timestamp":1626440625423,"user_tz":-120,"elapsed":4607,"user":{"displayName":"Lorenzo Pasco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgShaitSLZm3zyLVjMQT7ZzTrEV3kQEXha_A9lkVw=s64","userId":"01314717049817932576"}},"outputId":"22888ace-6185-4f35-fb3a-9438058190b7"},"source":["!pip install tensorpack\n","\n","%cd gdrive/MyDrive/SEAI_Project"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting tensorpack\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f9/8c/63e5f5a4a04dea36b75850f9daa885ccbfad64bec1fae0ee4ca9f31b3eaa/tensorpack-0.11-py2.py3-none-any.whl (296kB)\n","\r\u001b[K     |█                               | 10kB 11.6MB/s eta 0:00:01\r\u001b[K     |██▏                             | 20kB 10.5MB/s eta 0:00:01\r\u001b[K     |███▎                            | 30kB 6.3MB/s eta 0:00:01\r\u001b[K     |████▍                           | 40kB 5.8MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 51kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 61kB 3.1MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 71kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 81kB 3.6MB/s eta 0:00:01\r\u001b[K     |██████████                      | 92kB 3.8MB/s eta 0:00:01\r\u001b[K     |███████████                     | 102kB 4.0MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 112kB 4.0MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 122kB 4.0MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 133kB 4.0MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 143kB 4.0MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 153kB 4.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 163kB 4.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 174kB 4.0MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 184kB 4.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 194kB 4.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 204kB 4.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 215kB 4.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 225kB 4.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 235kB 4.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 245kB 4.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 256kB 4.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 266kB 4.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 276kB 4.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 286kB 4.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 296kB 4.0MB/s \n","\u001b[?25hRequirement already satisfied: msgpack>=0.5.2 in /usr/local/lib/python3.7/dist-packages (from tensorpack) (1.0.2)\n","Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.7/dist-packages (from tensorpack) (0.8.9)\n","Requirement already satisfied: psutil>=5 in /usr/local/lib/python3.7/dist-packages (from tensorpack) (5.4.8)\n","Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.7/dist-packages (from tensorpack) (1.1.0)\n","Collecting msgpack-numpy>=0.4.4.2\n","  Downloading https://files.pythonhosted.org/packages/19/05/05b8d7c69c6abb36a34325cc3150089bdafc359f0a81fb998d93c5d5c737/msgpack_numpy-0.4.7.1-py2.py3-none-any.whl\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tensorpack) (1.15.0)\n","Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.7/dist-packages (from tensorpack) (4.41.1)\n","Requirement already satisfied: pyzmq>=16 in /usr/local/lib/python3.7/dist-packages (from tensorpack) (22.1.0)\n","Requirement already satisfied: numpy>=1.14 in /usr/local/lib/python3.7/dist-packages (from tensorpack) (1.19.5)\n","Installing collected packages: msgpack-numpy, tensorpack\n","Successfully installed msgpack-numpy-0.4.7.1 tensorpack-0.11\n","/content/gdrive/MyDrive/SEAI_Project\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"47qPSLMU19HM","executionInfo":{"status":"ok","timestamp":1626428190575,"user_tz":-120,"elapsed":2761862,"user":{"displayName":"Lorenzo Pasco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgShaitSLZm3zyLVjMQT7ZzTrEV3kQEXha_A9lkVw=s64","userId":"01314717049817932576"}},"outputId":"67d0378c-8fc8-4a73-8f02-b2197a0f5f6c"},"source":["#!/usr/bin/env python\n","# -*- coding: utf-8 -*-\n","# File: svhn-digit-dorefa.py\n","# Author: Yuxin Wu\n","\n","import argparse\n","import os\n","import tensorflow as tf\n","\n","from tensorpack import *\n","from tensorpack.dataflow import dataset\n","from tensorpack.tfutils.summary import add_moving_summary, add_param_summary\n","from tensorpack.tfutils.varreplace import remap_variables\n","\n","\"\"\"\n","This is a tensorpack script for the SVHN results in paper:\n","DoReFa-Net: Training Low Bitwidth Convolutional Neural Networks with Low Bitwidth Gradients\n","http://arxiv.org/abs/1606.06160\n","The original experiements are performed on a proprietary framework.\n","This is our attempt to reproduce it on tensorpack.\n","Accuracy:\n","    With (W,A,G)=(1,1,4), can reach 3.1~3.2% error after 150 epochs.\n","    With (W,A,G)=(1,2,4), error is 3.0~3.1%.\n","    With (W,A,G)=(32,32,32), error is about 2.3%.\n","Speed:\n","    With quantization, 60 batch/s on 1 1080Ti. (4721 batch / epoch)\n","To Run:\n","    ./svhn-digit-dorefa.py --dorefa 1,2,4\n","\"\"\"\n","tf.compat.v1.reset_default_graph()\n","\n","BITW = 1\n","BITA = 2\n","BITG = 4\n","\n","\"\"\"\n","imported from dorefa file\n","\"\"\"\n","def get_dorefa(bitW, bitA, bitG):\n","    \"\"\"\n","    Return the three quantization functions fw, fa, fg, for weights, activations and gradients respectively\n","    \"\"\"\n","    def quantize(x, k):\n","        n = float(2 ** k - 1)\n","\n","        @tf.custom_gradient\n","        def _quantize(x):\n","            return tf.round(x * n) / n, lambda dy: dy\n","\n","        return _quantize(x)\n","\n","    def fw(x):\n","        if bitW == 32:\n","            return x\n","\n","        if bitW == 1:   # BWN\n","            E = tf.stop_gradient(tf.reduce_mean(tf.abs(x)))\n","\n","            @tf.custom_gradient\n","            def _sign(x):\n","                return tf.where(tf.equal(x, 0), tf.ones_like(x), tf.sign(x / E)) * E, lambda dy: dy\n","\n","            return _sign(x)\n","\n","        x = tf.tanh(x)\n","        x = x / tf.reduce_max(tf.abs(x)) * 0.5 + 0.5\n","        return 2 * quantize(x, bitW) - 1\n","\n","    def fa(x):\n","        if bitA == 32:\n","            return x\n","        return quantize(x, bitA)\n","\n","    def fg(x):\n","        if bitG == 32:\n","            return x\n","\n","        @tf.custom_gradient\n","        def _identity(input):\n","            def grad_fg(x):\n","                rank = x.get_shape().ndims\n","                assert rank is not None\n","                maxx = tf.reduce_max(tf.abs(x), list(range(1, rank)), keepdims=True)\n","                x = x / maxx\n","                n = float(2**bitG - 1)\n","                x = x * 0.5 + 0.5 + tf.random.uniform(\n","                    tf.shape(x), minval=-0.5 / n, maxval=0.5 / n)\n","                x = tf.clip_by_value(x, 0.0, 1.0)\n","                x = quantize(x, bitG) - 0.5\n","                return x * maxx * 2\n","\n","            return input, grad_fg\n","\n","        return _identity(x)\n","    return fw, fa, fg\n","\n","\n","class Model(ModelDesc):\n","    def inputs(self):\n","        return [tf.TensorSpec([None, 40, 40, 3], tf.float32, 'input'),\n","                tf.TensorSpec([None], tf.int32, 'label')]\n","\n","    def build_graph(self, image, label):\n","        fw, fa, fg = get_dorefa(BITW, BITA, BITG)\n","\n","        # monkey-patch tf.get_variable to apply fw\n","        def binarize_weight(v):\n","            name = v.op.name\n","            # don't binarize first and last layer\n","            if not name.endswith('W'):\n","                return v\n","            else:\n","                logger.info(\"Binarizing weight {}\".format(v.op.name))\n","                return fw(v)\n","\n","        def nonlin(x):\n","            if BITA == 32:\n","                return tf.nn.relu(x)\n","            return tf.clip_by_value(x, 0.0, 1.0)\n","\n","        def activate(x):\n","            return fa(nonlin(x))\n","\n","        image = image / 256.0\n","\n","        with remap_variables(binarize_weight), \\\n","                argscope(BatchNorm, momentum=0.9, epsilon=1e-4), \\\n","                argscope(Conv2D, use_bias=False):\n","            logits = (LinearWrap(image)\n","                      .Conv2D('conv0', 48, 5, padding='VALID', use_bias=True)\n","                      .MaxPooling('pool0', 2, padding='SAME')\n","                      .apply(activate)\n","                      # 18\n","                      .Conv2D('conv1', 64, 3, padding='SAME')\n","                      .apply(fg)\n","                      .BatchNorm('bn1').apply(activate)\n","#AVGPooling\n","                      .Conv2D('conv2', 64, 3, padding='SAME')\n","                      .apply(fg)\n","                      .BatchNorm('bn2')\n","                      .MaxPooling('pool1', 2, padding='SAME')\n","                      .apply(activate)\n","                      # 9\n","                      .Conv2D('conv3', 128, 3, padding='VALID')\n","                      .apply(fg)\n","                      .BatchNorm('bn3').apply(activate)\n","                      # 7\n","\n","                      .Conv2D('conv4', 128, 3, padding='SAME')\n","                      .apply(fg)\n","                      .BatchNorm('bn4').apply(activate)\n","\n","                      .Conv2D('conv5', 128, 3, padding='VALID')\n","                      .apply(fg)\n","                      .BatchNorm('bn5').apply(activate)\n","                      # 5\n","                      .Dropout(rate=0.5 if self.training else 0.0)\n","                      .Conv2D('conv6', 512, 5, padding='VALID')\n","                      .apply(fg).BatchNorm('bn6')\n","                      .apply(nonlin)\n","                      .FullyConnected('fc1', 10)())\n","        tf.nn.softmax(logits, name='output')\n","\n","        correct = tf.cast(tf.nn.in_top_k(predictions=logits, targets=label, k=1), tf.float32, name='correct')\n","        accuracy = tf.reduce_mean(correct, name='accuracy')\n","        train_error = tf.reduce_mean(1 - correct, name='train_error')\n","        summary.add_moving_summary(train_error, accuracy)\n","        \n","        cost = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=label)\n","        cost = tf.reduce_mean(cost, name='cross_entropy_loss')\n","        # weight decay on all W of fc layers\n","        wd_cost = regularize_cost('fc.*/W', l2_regularizer(1e-7))\n","        add_param_summary(('.*/W', ['histogram', 'rms']))\n","        total_cost = tf.add_n([cost, wd_cost], name='cost')\n","        add_moving_summary(cost, wd_cost, total_cost)\n","        return total_cost\n","\n","    def optimizer(self):\n","        lr = tf.compat.v1.train.exponential_decay(\n","            learning_rate=1e-3,\n","            global_step=get_global_step_var(),\n","            decay_steps=4721 * 100,\n","            decay_rate=0.5, staircase=True, name='learning_rate')\n","        tf.summary.scalar('lr', lr)\n","\n","        return tf.compat.v1.train.AdamOptimizer(lr, epsilon=1e-5)\n","\n","\n","def get_config():\n","    logger.set_logger_dir(os.path.join('train_log', 'svhn-dorefa-{}'.format(args)))\n","\n","    # prepare dataset\n","    d1 = dataset.SVHNDigit('train')\n","    d2 = dataset.SVHNDigit('extra')\n","    data_train = RandomMixData([d1, d2])\n","    data_test = dataset.SVHNDigit('test')\n","\n","    augmentors = [\n","        imgaug.Resize((40, 40)),\n","        imgaug.Brightness(30),\n","        imgaug.Contrast((0.5, 1.5)),\n","    ]\n","    data_train = AugmentImageComponent(data_train, augmentors)\n","    data_train = BatchData(data_train, 128)\n","    data_train = MultiProcessRunnerZMQ(data_train, 5)\n","\n","    augmentors = [imgaug.Resize((40, 40))]\n","    data_test = AugmentImageComponent(data_test, augmentors)\n","    data_test = BatchData(data_test, 128, remainder=True)\n","\n","    return TrainConfig(\n","        data=QueueInput(data_train),\n","        callbacks=[\n","            ModelSaver(),\n","            InferenceRunner(    # run inference(for validation) after every epoch\n","                data_test,   # the DataFlow instance used for validation\n","                ScalarStats(    # produce `val_accuracy` and `val_cross_entropy_loss`\n","                    ['cross_entropy_loss', 'accuracy'], prefix='val'))\n","        ],\n","        model=Model(),\n","        max_epoch=10,\n","    )\n","\n","args = \"1,2,4\"\n","BITW, BITA, BITG = map(int, args.split(','))\n","config = get_config()\n","launch_train_with_config(config, SimpleTrainer())\n","\n","'''\n","if __name__ == '__main__':\n","    parser = argparse.ArgumentParser()\n","    parser.add_argument('--dorefa',\n","                        help='number of bits for W,A,G, separated by comma. Defaults to \\'1,2,4\\'',\n","                        default='1,2,4')\n","    args = parser.parse_args()\n","\n","    BITW, BITA, BITG = map(int, args.dorefa.split(','))\n","    config = get_config()\n","    launch_train_with_config(config, SimpleTrainer())\n","'''"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[32m[0716 08:50:32 @logger.py:128]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m Log directory train_log/svhn-dorefa-1,2,4 exists! Use 'd' to delete it. \n","\u001b[32m[0716 08:50:32 @logger.py:131]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m If you're resuming from a previous run, you can choose to keep it.\n","Press any other key to exit. \n","Select Action: k (keep) / d (delete) / q (quit):k\n","\u001b[32m[0716 08:50:34 @logger.py:85]\u001b[0m Existing log file 'train_log/svhn-dorefa-1,2,4/log.log' backuped to 'train_log/svhn-dorefa-1,2,4/log.log.0716-085034'\n","\u001b[32m[0716 08:50:34 @logger.py:92]\u001b[0m Argv: /usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py -f /root/.local/share/jupyter/runtime/kernel-18d539d4-1d66-43ce-a39b-d510c5d550a3.json\n","\u001b[32m[0716 08:50:34 @fs.py:101]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m Env var $TENSORPACK_DATASET not set, using /root/tensorpack_data for datasets.\n","\u001b[32m[0716 08:50:34 @fs.py:104]\u001b[0m Created the directory /root/tensorpack_data.\n","\u001b[32m[0716 08:50:34 @svhn.py:42]\u001b[0m File /root/tensorpack_data/svhn_data/train_32x32.mat not found!\n","\u001b[32m[0716 08:50:34 @svhn.py:43]\u001b[0m Downloading from http://ufldl.stanford.edu/housenumbers/train_32x32.mat ...\n"],"name":"stdout"},{"output_type":"stream","text":["train_32x32.mat: 182MB [00:12, 14.3MB/s]                           "],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 08:50:47 @fs.py:73]\u001b[0m Succesfully downloaded train_32x32.mat. 182040794 bytes.\n","\u001b[32m[0716 08:50:47 @svhn.py:45]\u001b[0m Loading /root/tensorpack_data/svhn_data/train_32x32.mat ...\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 08:50:48 @svhn.py:42]\u001b[0m File /root/tensorpack_data/svhn_data/extra_32x32.mat not found!\n","\u001b[32m[0716 08:50:48 @svhn.py:43]\u001b[0m Downloading from http://ufldl.stanford.edu/housenumbers/extra_32x32.mat ...\n"],"name":"stdout"},{"output_type":"stream","text":["extra_32x32.mat: 1.33GB [02:02, 10.8MB/s]                            "],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 08:52:51 @fs.py:73]\u001b[0m Succesfully downloaded extra_32x32.mat. 1329278602 bytes.\n","\u001b[32m[0716 08:52:51 @svhn.py:45]\u001b[0m Loading /root/tensorpack_data/svhn_data/extra_32x32.mat ...\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 08:53:03 @svhn.py:42]\u001b[0m File /root/tensorpack_data/svhn_data/test_32x32.mat not found!\n","\u001b[32m[0716 08:53:03 @svhn.py:43]\u001b[0m Downloading from http://ufldl.stanford.edu/housenumbers/test_32x32.mat ...\n"],"name":"stdout"},{"output_type":"stream","text":["test_32x32.mat: 64.3MB [00:00, 75.4MB/s]                            "],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 08:53:04 @fs.py:73]\u001b[0m Succesfully downloaded test_32x32.mat. 64275384 bytes.\n","\u001b[32m[0716 08:53:04 @svhn.py:45]\u001b[0m Loading /root/tensorpack_data/svhn_data/test_32x32.mat ...\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 08:53:05 @parallel.py:340]\u001b[0m [MultiProcessRunnerZMQ] Will fork a dataflow more than one times. This assumes the datapoints are i.i.d.\n","\u001b[32m[0716 08:53:05 @input_source.py:221]\u001b[0m Setting up the queue 'QueueInput/input_queue' for CPU prefetching ...\n","\u001b[32m[0716 08:53:05 @trainers.py:48]\u001b[0m Building graph for a single training tower ...\n","\u001b[32m[0716 08:53:05 @<ipython-input-3-ac085d8d8c77>:113]\u001b[0m Binarizing weight conv0/W\n","\u001b[32m[0716 08:53:05 @registry.py:90]\u001b[0m 'conv0': [?, 40, 40, 3] --> [?, 36, 36, 48]\n","\u001b[32m[0716 08:53:05 @registry.py:90]\u001b[0m 'pool0': [?, 36, 36, 48] --> [?, 18, 18, 48]\n","\u001b[32m[0716 08:53:05 @<ipython-input-3-ac085d8d8c77>:113]\u001b[0m Binarizing weight conv1/W\n","\u001b[32m[0716 08:53:05 @registry.py:90]\u001b[0m 'conv1': [?, 18, 18, 48] --> [?, 18, 18, 64]\n","\u001b[32m[0716 08:53:05 @<ipython-input-3-ac085d8d8c77>:113]\u001b[0m Binarizing weight conv2/W\n","\u001b[32m[0716 08:53:05 @registry.py:90]\u001b[0m 'conv2': [?, 18, 18, 64] --> [?, 18, 18, 64]\n","\u001b[32m[0716 08:53:05 @registry.py:90]\u001b[0m 'pool1': [?, 18, 18, 64] --> [?, 9, 9, 64]\n","\u001b[32m[0716 08:53:05 @<ipython-input-3-ac085d8d8c77>:113]\u001b[0m Binarizing weight conv3/W\n","\u001b[32m[0716 08:53:05 @registry.py:90]\u001b[0m 'conv3': [?, 9, 9, 64] --> [?, 7, 7, 128]\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1692: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n","  warnings.warn('`layer.apply` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 08:53:05 @<ipython-input-3-ac085d8d8c77>:113]\u001b[0m Binarizing weight conv4/W\n","\u001b[32m[0716 08:53:05 @registry.py:90]\u001b[0m 'conv4': [?, 7, 7, 128] --> [?, 7, 7, 128]\n","\u001b[32m[0716 08:53:05 @<ipython-input-3-ac085d8d8c77>:113]\u001b[0m Binarizing weight conv5/W\n","\u001b[32m[0716 08:53:05 @registry.py:90]\u001b[0m 'conv5': [?, 7, 7, 128] --> [?, 5, 5, 128]\n","\u001b[32m[0716 08:53:05 @<ipython-input-3-ac085d8d8c77>:113]\u001b[0m Binarizing weight conv6/W\n","\u001b[32m[0716 08:53:05 @registry.py:90]\u001b[0m 'conv6': [?, 5, 5, 128] --> [?, 1, 1, 512]\n","\u001b[32m[0716 08:53:05 @<ipython-input-3-ac085d8d8c77>:113]\u001b[0m Binarizing weight fc1/W\n","\u001b[32m[0716 08:53:05 @registry.py:90]\u001b[0m 'fc1': [?, 1, 1, 512] --> [?, 10]\n","\u001b[32m[0716 08:53:05 @regularize.py:97]\u001b[0m regularize_cost() found 1 variables to regularize.\n","\u001b[32m[0716 08:53:05 @regularize.py:21]\u001b[0m The following tensors will be regularized: fc1/W:0\n","\u001b[32m[0716 08:53:06 @model_utils.py:67]\u001b[0m \u001b[36mList of Trainable Variables: \n","\u001b[0mname       shape               #elements\n","---------  ----------------  -----------\n","conv0/W    [5, 5, 3, 48]            3600\n","conv0/b    [48]                       48\n","conv1/W    [3, 3, 48, 64]          27648\n","bn1/gamma  [64]                       64\n","bn1/beta   [64]                       64\n","conv2/W    [3, 3, 64, 64]          36864\n","bn2/gamma  [64]                       64\n","bn2/beta   [64]                       64\n","conv3/W    [3, 3, 64, 128]         73728\n","bn3/gamma  [128]                     128\n","bn3/beta   [128]                     128\n","conv4/W    [3, 3, 128, 128]       147456\n","bn4/gamma  [128]                     128\n","bn4/beta   [128]                     128\n","conv5/W    [3, 3, 128, 128]       147456\n","bn5/gamma  [128]                     128\n","bn5/beta   [128]                     128\n","conv6/W    [5, 5, 128, 512]      1638400\n","bn6/gamma  [512]                     512\n","bn6/beta   [512]                     512\n","fc1/W      [512, 10]                5120\n","fc1/b      [10]                       10\u001b[36m\n","Number of trainable variables: 22\n","Number of parameters (elements): 2082378\n","Storage space needed for all trainable variables: 7.94MB\u001b[0m\n","\u001b[32m[0716 08:53:06 @base.py:207]\u001b[0m Setup callbacks graph ...\n","\u001b[32m[0716 08:53:06 @argtools.py:138]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m Starting a process with 'fork' method is efficient but not safe and may cause deadlock or crash.Use 'forkserver' or 'spawn' method instead if you run into such issues.See https://docs.python.org/3/library/multiprocessing.html#contexts-and-start-methods on how to set them.\n","\u001b[32m[0716 08:53:06 @argtools.py:138]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m \"import prctl\" failed! Install python-prctl so that processes can be cleaned with guarantee.\n","\u001b[32m[0716 08:53:07 @inference_runner.py:148]\u001b[0m [InferenceRunner] Building tower 'InferenceTower' on device /gpu:0 ...\n","\u001b[32m[0716 08:53:07 @<ipython-input-3-ac085d8d8c77>:113]\u001b[0m Binarizing weight conv0/W\n","\u001b[32m[0716 08:53:07 @<ipython-input-3-ac085d8d8c77>:113]\u001b[0m Binarizing weight conv1/W\n","\u001b[32m[0716 08:53:07 @<ipython-input-3-ac085d8d8c77>:113]\u001b[0m Binarizing weight conv2/W\n","\u001b[32m[0716 08:53:07 @<ipython-input-3-ac085d8d8c77>:113]\u001b[0m Binarizing weight conv3/W\n","\u001b[32m[0716 08:53:07 @<ipython-input-3-ac085d8d8c77>:113]\u001b[0m Binarizing weight conv4/W\n","\u001b[32m[0716 08:53:08 @<ipython-input-3-ac085d8d8c77>:113]\u001b[0m Binarizing weight conv5/W\n","\u001b[32m[0716 08:53:08 @<ipython-input-3-ac085d8d8c77>:113]\u001b[0m Binarizing weight conv6/W\n","\u001b[32m[0716 08:53:08 @<ipython-input-3-ac085d8d8c77>:113]\u001b[0m Binarizing weight fc1/W\n","\u001b[32m[0716 08:53:08 @summary.py:47]\u001b[0m [MovingAverageSummary] 5 operations in collection 'MOVING_SUMMARY_OPS' will be run with session hooks.\n","\u001b[32m[0716 08:53:08 @summary.py:94]\u001b[0m Summarizing collection 'summaries' of size 22.\n","\u001b[32m[0716 08:53:08 @graph.py:99]\u001b[0m Applying collection UPDATE_OPS of 12 ops.\n","\u001b[32m[0716 08:53:08 @base.py:228]\u001b[0m Creating the session ...\n","\u001b[32m[0716 08:53:15 @base.py:234]\u001b[0m Initializing the session ...\n","\u001b[32m[0716 08:53:15 @base.py:241]\u001b[0m Graph Finalized.\n","\u001b[32m[0716 08:53:15 @concurrency.py:37]\u001b[0m Starting EnqueueThread: enqueue dataflow to TF queue \"QueueInput/input_queue\" ...\n","\u001b[32m[0716 08:53:16 @inference_runner.py:95]\u001b[0m [InferenceRunner] Will eval 204 iterations\n","\u001b[32m[0716 08:53:16 @base.py:273]\u001b[0m Start Epoch 1 ...\n"],"name":"stdout"},{"output_type":"stream","text":["100%|##########|4721/4721[04:32<00:00,17.33it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 08:57:48 @base.py:283]\u001b[0m Epoch 1 (global_step 4721) finished, time:4 minutes 32 seconds.\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 08:57:49 @saver.py:82]\u001b[0m Model saved to train_log/svhn-dorefa-1,2,4/model-4721.\n"],"name":"stdout"},{"output_type":"stream","text":["100%|##########|204/204[00:10<00:00,18.78it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 08:58:00 @monitor.py:476]\u001b[0m QueueInput/queue_size: 18.5\n","\u001b[32m[0716 08:58:00 @monitor.py:476]\u001b[0m accuracy: 0.93954\n","\u001b[32m[0716 08:58:00 @monitor.py:476]\u001b[0m cost: 0.19235\n","\u001b[32m[0716 08:58:00 @monitor.py:476]\u001b[0m cross_entropy_loss: 0.19235\n","\u001b[32m[0716 08:58:00 @monitor.py:476]\u001b[0m param-summary/conv0/W-rms: 0.17857\n","\u001b[32m[0716 08:58:00 @monitor.py:476]\u001b[0m param-summary/conv1/W-rms: 0.079199\n","\u001b[32m[0716 08:58:00 @monitor.py:476]\u001b[0m param-summary/conv2/W-rms: 0.07235\n","\u001b[32m[0716 08:58:00 @monitor.py:476]\u001b[0m param-summary/conv3/W-rms: 0.076633\n","\u001b[32m[0716 08:58:00 @monitor.py:476]\u001b[0m param-summary/conv4/W-rms: 0.064322\n","\u001b[32m[0716 08:58:00 @monitor.py:476]\u001b[0m param-summary/conv5/W-rms: 0.068795\n","\u001b[32m[0716 08:58:00 @monitor.py:476]\u001b[0m param-summary/conv6/W-rms: 0.054514\n","\u001b[32m[0716 08:58:00 @monitor.py:476]\u001b[0m param-summary/fc1/W-rms: 0.11781\n","\u001b[32m[0716 08:58:00 @monitor.py:476]\u001b[0m regularize_cost: 3.5461e-06\n","\u001b[32m[0716 08:58:00 @monitor.py:476]\u001b[0m train_error: 0.060463\n","\u001b[32m[0716 08:58:00 @monitor.py:476]\u001b[0m val_accuracy: 0.91617\n","\u001b[32m[0716 08:58:00 @monitor.py:476]\u001b[0m val_cross_entropy_loss: 0.28432\n","\u001b[32m[0716 08:58:00 @group.py:44]\u001b[0m Callbacks took 11.484 sec in total. InferenceRunner: 10.9 seconds\n","\u001b[32m[0716 08:58:00 @base.py:273]\u001b[0m Start Epoch 2 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|4721/4721[04:02<00:00,19.43it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 09:02:03 @base.py:283]\u001b[0m Epoch 2 (global_step 9442) finished, time:4 minutes 2 seconds.\n","\u001b[32m[0716 09:02:03 @saver.py:82]\u001b[0m Model saved to train_log/svhn-dorefa-1,2,4/model-9442.\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|204/204[00:09<00:00,20.71it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 09:02:13 @monitor.py:476]\u001b[0m QueueInput/queue_size: 0.12891\n","\u001b[32m[0716 09:02:13 @monitor.py:476]\u001b[0m accuracy: 0.96312\n","\u001b[32m[0716 09:02:13 @monitor.py:476]\u001b[0m cost: 0.13418\n","\u001b[32m[0716 09:02:13 @monitor.py:476]\u001b[0m cross_entropy_loss: 0.13418\n","\u001b[32m[0716 09:02:13 @monitor.py:476]\u001b[0m param-summary/conv0/W-rms: 0.20262\n","\u001b[32m[0716 09:02:13 @monitor.py:476]\u001b[0m param-summary/conv1/W-rms: 0.090748\n","\u001b[32m[0716 09:02:13 @monitor.py:476]\u001b[0m param-summary/conv2/W-rms: 0.091948\n","\u001b[32m[0716 09:02:13 @monitor.py:476]\u001b[0m param-summary/conv3/W-rms: 0.1009\n","\u001b[32m[0716 09:02:13 @monitor.py:476]\u001b[0m param-summary/conv4/W-rms: 0.090162\n","\u001b[32m[0716 09:02:13 @monitor.py:476]\u001b[0m param-summary/conv5/W-rms: 0.096091\n","\u001b[32m[0716 09:02:13 @monitor.py:476]\u001b[0m param-summary/conv6/W-rms: 0.080982\n","\u001b[32m[0716 09:02:13 @monitor.py:476]\u001b[0m param-summary/fc1/W-rms: 0.15553\n","\u001b[32m[0716 09:02:13 @monitor.py:476]\u001b[0m regularize_cost: 6.1848e-06\n","\u001b[32m[0716 09:02:13 @monitor.py:476]\u001b[0m train_error: 0.036875\n","\u001b[32m[0716 09:02:13 @monitor.py:476]\u001b[0m val_accuracy: 0.93571\n","\u001b[32m[0716 09:02:13 @monitor.py:476]\u001b[0m val_cross_entropy_loss: 0.22623\n","\u001b[32m[0716 09:02:13 @group.py:44]\u001b[0m Callbacks took 10.129 sec in total. InferenceRunner: 9.86 seconds\n","\u001b[32m[0716 09:02:13 @base.py:273]\u001b[0m Start Epoch 3 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|4721/4721[04:04<00:00,19.29it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 09:06:18 @base.py:283]\u001b[0m Epoch 3 (global_step 14163) finished, time:4 minutes 4 seconds.\n","\u001b[32m[0716 09:06:18 @saver.py:82]\u001b[0m Model saved to train_log/svhn-dorefa-1,2,4/model-14163.\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|204/204[00:09<00:00,21.05it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 09:06:28 @monitor.py:476]\u001b[0m QueueInput/queue_size: 3.4712e-18\n","\u001b[32m[0716 09:06:28 @monitor.py:476]\u001b[0m accuracy: 0.96612\n","\u001b[32m[0716 09:06:28 @monitor.py:476]\u001b[0m cost: 0.1204\n","\u001b[32m[0716 09:06:28 @monitor.py:476]\u001b[0m cross_entropy_loss: 0.1204\n","\u001b[32m[0716 09:06:28 @monitor.py:476]\u001b[0m param-summary/conv0/W-rms: 0.22794\n","\u001b[32m[0716 09:06:28 @monitor.py:476]\u001b[0m param-summary/conv1/W-rms: 0.10747\n","\u001b[32m[0716 09:06:28 @monitor.py:476]\u001b[0m param-summary/conv2/W-rms: 0.11461\n","\u001b[32m[0716 09:06:28 @monitor.py:476]\u001b[0m param-summary/conv3/W-rms: 0.12329\n","\u001b[32m[0716 09:06:28 @monitor.py:476]\u001b[0m param-summary/conv4/W-rms: 0.11415\n","\u001b[32m[0716 09:06:28 @monitor.py:476]\u001b[0m param-summary/conv5/W-rms: 0.12005\n","\u001b[32m[0716 09:06:28 @monitor.py:476]\u001b[0m param-summary/conv6/W-rms: 0.10284\n","\u001b[32m[0716 09:06:28 @monitor.py:476]\u001b[0m param-summary/fc1/W-rms: 0.18546\n","\u001b[32m[0716 09:06:28 @monitor.py:476]\u001b[0m regularize_cost: 8.7961e-06\n","\u001b[32m[0716 09:06:28 @monitor.py:476]\u001b[0m train_error: 0.033877\n","\u001b[32m[0716 09:06:28 @monitor.py:476]\u001b[0m val_accuracy: 0.9477\n","\u001b[32m[0716 09:06:28 @monitor.py:476]\u001b[0m val_cross_entropy_loss: 0.19244\n","\u001b[32m[0716 09:06:28 @group.py:44]\u001b[0m Callbacks took 9.990 sec in total. InferenceRunner: 9.71 seconds\n","\u001b[32m[0716 09:06:28 @base.py:273]\u001b[0m Start Epoch 4 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|4721/4721[04:04<00:00,19.34it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 09:10:32 @base.py:283]\u001b[0m Epoch 4 (global_step 18884) finished, time:4 minutes 4 seconds.\n","\u001b[32m[0716 09:10:32 @saver.py:82]\u001b[0m Model saved to train_log/svhn-dorefa-1,2,4/model-18884.\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|204/204[00:09<00:00,20.89it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 09:10:42 @monitor.py:476]\u001b[0m QueueInput/queue_size: 0.25202\n","\u001b[32m[0716 09:10:42 @monitor.py:476]\u001b[0m accuracy: 0.97317\n","\u001b[32m[0716 09:10:42 @monitor.py:476]\u001b[0m cost: 0.095692\n","\u001b[32m[0716 09:10:42 @monitor.py:476]\u001b[0m cross_entropy_loss: 0.095681\n","\u001b[32m[0716 09:10:42 @monitor.py:476]\u001b[0m param-summary/conv0/W-rms: 0.24616\n","\u001b[32m[0716 09:10:42 @monitor.py:476]\u001b[0m param-summary/conv1/W-rms: 0.12228\n","\u001b[32m[0716 09:10:42 @monitor.py:476]\u001b[0m param-summary/conv2/W-rms: 0.13495\n","\u001b[32m[0716 09:10:42 @monitor.py:476]\u001b[0m param-summary/conv3/W-rms: 0.14445\n","\u001b[32m[0716 09:10:42 @monitor.py:476]\u001b[0m param-summary/conv4/W-rms: 0.13493\n","\u001b[32m[0716 09:10:42 @monitor.py:476]\u001b[0m param-summary/conv5/W-rms: 0.14131\n","\u001b[32m[0716 09:10:42 @monitor.py:476]\u001b[0m param-summary/conv6/W-rms: 0.1215\n","\u001b[32m[0716 09:10:42 @monitor.py:476]\u001b[0m param-summary/fc1/W-rms: 0.21029\n","\u001b[32m[0716 09:10:42 @monitor.py:476]\u001b[0m regularize_cost: 1.1308e-05\n","\u001b[32m[0716 09:10:42 @monitor.py:476]\u001b[0m train_error: 0.026835\n","\u001b[32m[0716 09:10:42 @monitor.py:476]\u001b[0m val_accuracy: 0.94843\n","\u001b[32m[0716 09:10:42 @monitor.py:476]\u001b[0m val_cross_entropy_loss: 0.19062\n","\u001b[32m[0716 09:10:42 @group.py:44]\u001b[0m Callbacks took 10.055 sec in total. InferenceRunner: 9.79 seconds\n","\u001b[32m[0716 09:10:42 @base.py:273]\u001b[0m Start Epoch 5 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|4721/4721[04:06<00:00,19.12it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 09:14:49 @base.py:283]\u001b[0m Epoch 5 (global_step 23605) finished, time:4 minutes 6 seconds.\n","\u001b[32m[0716 09:14:49 @saver.py:82]\u001b[0m Model saved to train_log/svhn-dorefa-1,2,4/model-23605.\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|204/204[00:09<00:00,22.47it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 09:14:58 @monitor.py:476]\u001b[0m QueueInput/queue_size: 1.7764e-15\n","\u001b[32m[0716 09:14:58 @monitor.py:476]\u001b[0m accuracy: 0.97028\n","\u001b[32m[0716 09:14:58 @monitor.py:476]\u001b[0m cost: 0.10356\n","\u001b[32m[0716 09:14:58 @monitor.py:476]\u001b[0m cross_entropy_loss: 0.10354\n","\u001b[32m[0716 09:14:58 @monitor.py:476]\u001b[0m param-summary/conv0/W-rms: 0.25944\n","\u001b[32m[0716 09:14:58 @monitor.py:476]\u001b[0m param-summary/conv1/W-rms: 0.13646\n","\u001b[32m[0716 09:14:58 @monitor.py:476]\u001b[0m param-summary/conv2/W-rms: 0.15372\n","\u001b[32m[0716 09:14:58 @monitor.py:476]\u001b[0m param-summary/conv3/W-rms: 0.16298\n","\u001b[32m[0716 09:14:58 @monitor.py:476]\u001b[0m param-summary/conv4/W-rms: 0.15452\n","\u001b[32m[0716 09:14:58 @monitor.py:476]\u001b[0m param-summary/conv5/W-rms: 0.16015\n","\u001b[32m[0716 09:14:58 @monitor.py:476]\u001b[0m param-summary/conv6/W-rms: 0.13771\n","\u001b[32m[0716 09:14:58 @monitor.py:476]\u001b[0m param-summary/fc1/W-rms: 0.23453\n","\u001b[32m[0716 09:14:58 @monitor.py:476]\u001b[0m regularize_cost: 1.4078e-05\n","\u001b[32m[0716 09:14:58 @monitor.py:476]\u001b[0m train_error: 0.029715\n","\u001b[32m[0716 09:14:58 @monitor.py:476]\u001b[0m val_accuracy: 0.95577\n","\u001b[32m[0716 09:14:58 @monitor.py:476]\u001b[0m val_cross_entropy_loss: 0.16873\n","\u001b[32m[0716 09:14:58 @group.py:44]\u001b[0m Callbacks took 9.350 sec in total. InferenceRunner: 9.09 seconds\n","\u001b[32m[0716 09:14:58 @base.py:273]\u001b[0m Start Epoch 6 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|4721/4721[04:10<00:00,18.88it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 09:19:08 @base.py:283]\u001b[0m Epoch 6 (global_step 28326) finished, time:4 minutes 10 seconds.\n","\u001b[32m[0716 09:19:09 @saver.py:82]\u001b[0m Model saved to train_log/svhn-dorefa-1,2,4/model-28326.\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|204/204[00:10<00:00,19.17it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 09:19:19 @monitor.py:476]\u001b[0m QueueInput/queue_size: 4.7685e-07\n","\u001b[32m[0716 09:19:19 @monitor.py:476]\u001b[0m accuracy: 0.97282\n","\u001b[32m[0716 09:19:19 @monitor.py:476]\u001b[0m cost: 0.10243\n","\u001b[32m[0716 09:19:19 @monitor.py:476]\u001b[0m cross_entropy_loss: 0.10242\n","\u001b[32m[0716 09:19:19 @monitor.py:476]\u001b[0m param-summary/conv0/W-rms: 0.27321\n","\u001b[32m[0716 09:19:19 @monitor.py:476]\u001b[0m param-summary/conv1/W-rms: 0.15092\n","\u001b[32m[0716 09:19:19 @monitor.py:476]\u001b[0m param-summary/conv2/W-rms: 0.17099\n","\u001b[32m[0716 09:19:19 @monitor.py:476]\u001b[0m param-summary/conv3/W-rms: 0.18061\n","\u001b[32m[0716 09:19:19 @monitor.py:476]\u001b[0m param-summary/conv4/W-rms: 0.17161\n","\u001b[32m[0716 09:19:19 @monitor.py:476]\u001b[0m param-summary/conv5/W-rms: 0.17827\n","\u001b[32m[0716 09:19:19 @monitor.py:476]\u001b[0m param-summary/conv6/W-rms: 0.1523\n","\u001b[32m[0716 09:19:19 @monitor.py:476]\u001b[0m param-summary/fc1/W-rms: 0.25992\n","\u001b[32m[0716 09:19:19 @monitor.py:476]\u001b[0m regularize_cost: 1.7297e-05\n","\u001b[32m[0716 09:19:19 @monitor.py:476]\u001b[0m train_error: 0.02718\n","\u001b[32m[0716 09:19:19 @monitor.py:476]\u001b[0m val_accuracy: 0.95646\n","\u001b[32m[0716 09:19:19 @monitor.py:476]\u001b[0m val_cross_entropy_loss: 0.16595\n","\u001b[32m[0716 09:19:19 @group.py:44]\u001b[0m Callbacks took 10.940 sec in total. InferenceRunner: 10.7 seconds\n","\u001b[32m[0716 09:19:19 @base.py:273]\u001b[0m Start Epoch 7 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|4721/4721[04:10<00:00,18.88it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 09:23:29 @base.py:283]\u001b[0m Epoch 7 (global_step 33047) finished, time:4 minutes 10 seconds.\n","\u001b[32m[0716 09:23:30 @saver.py:82]\u001b[0m Model saved to train_log/svhn-dorefa-1,2,4/model-33047.\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|204/204[00:10<00:00,19.62it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 09:23:40 @monitor.py:476]\u001b[0m QueueInput/queue_size: 5.5511e-17\n","\u001b[32m[0716 09:23:40 @monitor.py:476]\u001b[0m accuracy: 0.97015\n","\u001b[32m[0716 09:23:40 @monitor.py:476]\u001b[0m cost: 0.09472\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 09:23:40 @monitor.py:476]\u001b[0m cross_entropy_loss: 0.094699\n","\u001b[32m[0716 09:23:40 @monitor.py:476]\u001b[0m param-summary/conv0/W-rms: 0.28546\n","\u001b[32m[0716 09:23:40 @monitor.py:476]\u001b[0m param-summary/conv1/W-rms: 0.15981\n","\u001b[32m[0716 09:23:40 @monitor.py:476]\u001b[0m param-summary/conv2/W-rms: 0.18487\n","\u001b[32m[0716 09:23:40 @monitor.py:476]\u001b[0m param-summary/conv3/W-rms: 0.19772\n","\u001b[32m[0716 09:23:40 @monitor.py:476]\u001b[0m param-summary/conv4/W-rms: 0.18815\n","\u001b[32m[0716 09:23:40 @monitor.py:476]\u001b[0m param-summary/conv5/W-rms: 0.19473\n","\u001b[32m[0716 09:23:40 @monitor.py:476]\u001b[0m param-summary/conv6/W-rms: 0.16554\n","\u001b[32m[0716 09:23:40 @monitor.py:476]\u001b[0m param-summary/fc1/W-rms: 0.28491\n","\u001b[32m[0716 09:23:40 @monitor.py:476]\u001b[0m regularize_cost: 2.0757e-05\n","\u001b[32m[0716 09:23:40 @monitor.py:476]\u001b[0m train_error: 0.029847\n","\u001b[32m[0716 09:23:40 @monitor.py:476]\u001b[0m val_accuracy: 0.9598\n","\u001b[32m[0716 09:23:40 @monitor.py:476]\u001b[0m val_cross_entropy_loss: 0.15976\n","\u001b[32m[0716 09:23:40 @group.py:44]\u001b[0m Callbacks took 10.724 sec in total. InferenceRunner: 10.4 seconds\n","\u001b[32m[0716 09:23:40 @base.py:273]\u001b[0m Start Epoch 8 ...\n"],"name":"stdout"},{"output_type":"stream","text":["100%|##########|4721/4721[04:07<00:00,19.05it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 09:27:48 @base.py:283]\u001b[0m Epoch 8 (global_step 37768) finished, time:4 minutes 7 seconds.\n","\u001b[32m[0716 09:27:48 @saver.py:82]\u001b[0m Model saved to train_log/svhn-dorefa-1,2,4/model-37768.\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|204/204[00:09<00:00,20.98it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 09:27:58 @monitor.py:476]\u001b[0m QueueInput/queue_size: 7.8715e-06\n","\u001b[32m[0716 09:27:58 @monitor.py:476]\u001b[0m accuracy: 0.97729\n","\u001b[32m[0716 09:27:58 @monitor.py:476]\u001b[0m cost: 0.077121\n","\u001b[32m[0716 09:27:58 @monitor.py:476]\u001b[0m cross_entropy_loss: 0.077096\n","\u001b[32m[0716 09:27:58 @monitor.py:476]\u001b[0m param-summary/conv0/W-rms: 0.29699\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 09:27:58 @monitor.py:476]\u001b[0m param-summary/conv1/W-rms: 0.17816\n","\u001b[32m[0716 09:27:58 @monitor.py:476]\u001b[0m param-summary/conv2/W-rms: 0.20251\n","\u001b[32m[0716 09:27:58 @monitor.py:476]\u001b[0m param-summary/conv3/W-rms: 0.21469\n","\u001b[32m[0716 09:27:58 @monitor.py:476]\u001b[0m param-summary/conv4/W-rms: 0.2031\n","\u001b[32m[0716 09:27:58 @monitor.py:476]\u001b[0m param-summary/conv5/W-rms: 0.21015\n","\u001b[32m[0716 09:27:58 @monitor.py:476]\u001b[0m param-summary/conv6/W-rms: 0.17784\n","\u001b[32m[0716 09:27:58 @monitor.py:476]\u001b[0m param-summary/fc1/W-rms: 0.30908\n","\u001b[32m[0716 09:27:58 @monitor.py:476]\u001b[0m regularize_cost: 2.4437e-05\n","\u001b[32m[0716 09:27:58 @monitor.py:476]\u001b[0m train_error: 0.022711\n","\u001b[32m[0716 09:27:58 @monitor.py:476]\u001b[0m val_accuracy: 0.96147\n","\u001b[32m[0716 09:27:58 @monitor.py:476]\u001b[0m val_cross_entropy_loss: 0.15256\n","\u001b[32m[0716 09:27:58 @group.py:44]\u001b[0m Callbacks took 9.995 sec in total. InferenceRunner: 9.74 seconds\n","\u001b[32m[0716 09:27:58 @base.py:273]\u001b[0m Start Epoch 9 ...\n"],"name":"stdout"},{"output_type":"stream","text":["100%|##########|4721/4721[04:04<00:00,19.30it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 09:32:03 @base.py:283]\u001b[0m Epoch 9 (global_step 42489) finished, time:4 minutes 4 seconds.\n","\u001b[32m[0716 09:32:03 @saver.py:82]\u001b[0m Model saved to train_log/svhn-dorefa-1,2,4/model-42489.\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|204/204[00:09<00:00,21.49it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 09:32:12 @monitor.py:476]\u001b[0m QueueInput/queue_size: 0.52345\n","\u001b[32m[0716 09:32:12 @monitor.py:476]\u001b[0m accuracy: 0.97825\n","\u001b[32m[0716 09:32:12 @monitor.py:476]\u001b[0m cost: 0.081203\n","\u001b[32m[0716 09:32:12 @monitor.py:476]\u001b[0m cross_entropy_loss: 0.081175\n","\u001b[32m[0716 09:32:12 @monitor.py:476]\u001b[0m param-summary/conv0/W-rms: 0.30721\n","\u001b[32m[0716 09:32:12 @monitor.py:476]\u001b[0m param-summary/conv1/W-rms: 0.18821\n","\u001b[32m[0716 09:32:12 @monitor.py:476]\u001b[0m param-summary/conv2/W-rms: 0.21794\n","\u001b[32m[0716 09:32:12 @monitor.py:476]\u001b[0m param-summary/conv3/W-rms: 0.22894\n","\u001b[32m[0716 09:32:12 @monitor.py:476]\u001b[0m param-summary/conv4/W-rms: 0.21775\n","\u001b[32m[0716 09:32:12 @monitor.py:476]\u001b[0m param-summary/conv5/W-rms: 0.22531\n","\u001b[32m[0716 09:32:12 @monitor.py:476]\u001b[0m param-summary/conv6/W-rms: 0.1895\n","\u001b[32m[0716 09:32:12 @monitor.py:476]\u001b[0m param-summary/fc1/W-rms: 0.33176\n","\u001b[32m[0716 09:32:12 @monitor.py:476]\u001b[0m regularize_cost: 2.8147e-05\n","\u001b[32m[0716 09:32:12 @monitor.py:476]\u001b[0m train_error: 0.021753\n","\u001b[32m[0716 09:32:12 @monitor.py:476]\u001b[0m val_accuracy: 0.95782\n","\u001b[32m[0716 09:32:12 @monitor.py:476]\u001b[0m val_cross_entropy_loss: 0.15981\n","\u001b[32m[0716 09:32:12 @group.py:44]\u001b[0m Callbacks took 9.787 sec in total. InferenceRunner: 9.52 seconds\n","\u001b[32m[0716 09:32:12 @base.py:273]\u001b[0m Start Epoch 10 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|4721/4721[04:07<00:00,19.04it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 09:36:20 @base.py:283]\u001b[0m Epoch 10 (global_step 47210) finished, time:4 minutes 7 seconds.\n","\u001b[32m[0716 09:36:20 @saver.py:82]\u001b[0m Model saved to train_log/svhn-dorefa-1,2,4/model-47210.\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|204/204[00:09<00:00,21.63it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 09:36:30 @monitor.py:476]\u001b[0m QueueInput/queue_size: 1.9073e-06\n","\u001b[32m[0716 09:36:30 @monitor.py:476]\u001b[0m accuracy: 0.97878\n","\u001b[32m[0716 09:36:30 @monitor.py:476]\u001b[0m cost: 0.075832\n","\u001b[32m[0716 09:36:30 @monitor.py:476]\u001b[0m cross_entropy_loss: 0.0758\n","\u001b[32m[0716 09:36:30 @monitor.py:476]\u001b[0m param-summary/conv0/W-rms: 0.3158\n","\u001b[32m[0716 09:36:30 @monitor.py:476]\u001b[0m param-summary/conv1/W-rms: 0.20117\n","\u001b[32m[0716 09:36:30 @monitor.py:476]\u001b[0m param-summary/conv2/W-rms: 0.23085\n","\u001b[32m[0716 09:36:30 @monitor.py:476]\u001b[0m param-summary/conv3/W-rms: 0.24327\n","\u001b[32m[0716 09:36:30 @monitor.py:476]\u001b[0m param-summary/conv4/W-rms: 0.23125\n","\u001b[32m[0716 09:36:30 @monitor.py:476]\u001b[0m param-summary/conv5/W-rms: 0.23966\n","\u001b[32m[0716 09:36:30 @monitor.py:476]\u001b[0m param-summary/conv6/W-rms: 0.20037\n","\u001b[32m[0716 09:36:30 @monitor.py:476]\u001b[0m param-summary/fc1/W-rms: 0.35578\n","\u001b[32m[0716 09:36:30 @monitor.py:476]\u001b[0m regularize_cost: 3.2392e-05\n","\u001b[32m[0716 09:36:30 @monitor.py:476]\u001b[0m train_error: 0.021218\n","\u001b[32m[0716 09:36:30 @monitor.py:476]\u001b[0m val_accuracy: 0.96136\n","\u001b[32m[0716 09:36:30 @monitor.py:476]\u001b[0m val_cross_entropy_loss: 0.15088\n","\u001b[32m[0716 09:36:30 @group.py:44]\u001b[0m Callbacks took 9.680 sec in total. InferenceRunner: 9.45 seconds\n","\u001b[32m[0716 09:36:30 @base.py:287]\u001b[0m Training has finished!\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"\\nif __name__ == '__main__':\\n    parser = argparse.ArgumentParser()\\n    parser.add_argument('--dorefa',\\n                        help='number of bits for W,A,G, separated by comma. Defaults to '1,2,4'',\\n                        default='1,2,4')\\n    args = parser.parse_args()\\n\\n    BITW, BITA, BITG = map(int, args.dorefa.split(','))\\n    config = get_config()\\n    launch_train_with_config(config, SimpleTrainer())\\n\""]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":315},"id":"mduuAqCeuc4B","executionInfo":{"status":"ok","timestamp":1626440639827,"user_tz":-120,"elapsed":2173,"user":{"displayName":"Lorenzo Pasco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgShaitSLZm3zyLVjMQT7ZzTrEV3kQEXha_A9lkVw=s64","userId":"01314717049817932576"}},"outputId":"50afbdb4-790d-4cda-9280-8a8b7b468c2f"},"source":["import json\n","import matplotlib.pyplot as plt\n","\n","f = open(\"train_log/svhn-dorefa-1,2,4/stats_def_first&last.json\",\"r\")\n","\n","data = json.load(f)\n","accuracy = []\n","val_accuracy = []\n","for ob in data:\n","  accuracy.append(ob[\"accuracy\"])\n","  val_accuracy.append(ob[\"val_accuracy\"])\n","\n","epochs = range(len(accuracy))\n","\n","plt.plot(epochs, accuracy, 'r', label='Training acc')\n","plt.plot(epochs, val_accuracy, 'b', label='Validation acc')\n","plt.title('Training and validation accuracy')\n","plt.legend()\n","plt.figure()"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<Figure size 432x288 with 0 Axes>"]},"metadata":{"tags":[]},"execution_count":3},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 0 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ST3WBdVha1W-","executionInfo":{"status":"ok","timestamp":1626441974594,"user_tz":-120,"elapsed":265,"user":{"displayName":"Lorenzo Pasco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgShaitSLZm3zyLVjMQT7ZzTrEV3kQEXha_A9lkVw=s64","userId":"01314717049817932576"}},"outputId":"3515e582-625c-4b4e-e6e5-c58e21a35c1b"},"source":["from tabulate import tabulate\n","import matplotlib.pyplot as plt\n","\n","ep = [i+1 for i in epochs]\n","table_acc = {\"Epochs\" : ep, \"Accuracy\":accuracy}\n","table_val_acc = {\"Epochs\" : ep, \"Accuracy\":val_accuracy}\n","\n","print(\"ACCURACY\\n\")\n","print(tabulate(table_acc, headers='keys', tablefmt='fancy_grid'))\n","print(\"\\nVALIDATION ACCURACY\\n\")\n","print(tabulate(table_val_acc, headers='keys', tablefmt='fancy_grid'))"],"execution_count":14,"outputs":[{"output_type":"stream","text":["ACCURACY\n","\n","╒══════════╤════════════╕\n","│   Epochs │   Accuracy │\n","╞══════════╪════════════╡\n","│        1 │   0.939537 │\n","├──────────┼────────────┤\n","│        2 │   0.963125 │\n","├──────────┼────────────┤\n","│        3 │   0.966123 │\n","├──────────┼────────────┤\n","│        4 │   0.973165 │\n","├──────────┼────────────┤\n","│        5 │   0.970285 │\n","├──────────┼────────────┤\n","│        6 │   0.97282  │\n","├──────────┼────────────┤\n","│        7 │   0.970153 │\n","├──────────┼────────────┤\n","│        8 │   0.977289 │\n","├──────────┼────────────┤\n","│        9 │   0.978247 │\n","├──────────┼────────────┤\n","│       10 │   0.978782 │\n","╘══════════╧════════════╛\n","\n","VALIDATION ACCURACY\n","\n","╒══════════╤════════════╕\n","│   Epochs │   Accuracy │\n","╞══════════╪════════════╡\n","│        1 │   0.916169 │\n","├──────────┼────────────┤\n","│        2 │   0.935713 │\n","├──────────┼────────────┤\n","│        3 │   0.9477   │\n","├──────────┼────────────┤\n","│        4 │   0.948427 │\n","├──────────┼────────────┤\n","│        5 │   0.955767 │\n","├──────────┼────────────┤\n","│        6 │   0.956457 │\n","├──────────┼────────────┤\n","│        7 │   0.959801 │\n","├──────────┼────────────┤\n","│        8 │   0.961474 │\n","├──────────┼────────────┤\n","│        9 │   0.957823 │\n","├──────────┼────────────┤\n","│       10 │   0.961359 │\n","╘══════════╧════════════╛\n"],"name":"stdout"}]}]}