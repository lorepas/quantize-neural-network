{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"svhn-digit-dorefa4616_first&last_avg_pooling.ipynb","provenance":[],"authorship_tag":"ABX9TyMigJpqlKqiHvyk2OEQENQn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"5qzKFEQKqXDt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626874126577,"user_tz":-120,"elapsed":20814,"user":{"displayName":"Lorenzo Pasco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgShaitSLZm3zyLVjMQT7ZzTrEV3kQEXha_A9lkVw=s64","userId":"01314717049817932576"}},"outputId":"7412e6e9-5c5e-44b2-9b22-5eeffb27cbdb"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eDXKVoHj26H8","executionInfo":{"status":"ok","timestamp":1626874133322,"user_tz":-120,"elapsed":3820,"user":{"displayName":"Lorenzo Pasco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgShaitSLZm3zyLVjMQT7ZzTrEV3kQEXha_A9lkVw=s64","userId":"01314717049817932576"}},"outputId":"2abe7289-dcc3-46dc-892f-3da58e11dd0e"},"source":["!pip install tensorpack\n","\n","%cd gdrive/MyDrive/SEAI_Project"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting tensorpack\n","  Downloading tensorpack-0.11-py2.py3-none-any.whl (296 kB)\n","\u001b[?25l\r\u001b[K     |█                               | 10 kB 39.0 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 20 kB 30.0 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 30 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 40 kB 16.4 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 51 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 61 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 71 kB 10.1 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 81 kB 10.5 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 92 kB 10.6 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 102 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 112 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 122 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 133 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 143 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 153 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 163 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 174 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 184 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 194 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 204 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 215 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 225 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 235 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 245 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 256 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 266 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 276 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 286 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 296 kB 8.8 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.14 in /usr/local/lib/python3.7/dist-packages (from tensorpack) (1.19.5)\n","Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.7/dist-packages (from tensorpack) (0.8.9)\n","Requirement already satisfied: pyzmq>=16 in /usr/local/lib/python3.7/dist-packages (from tensorpack) (22.1.0)\n","Requirement already satisfied: msgpack>=0.5.2 in /usr/local/lib/python3.7/dist-packages (from tensorpack) (1.0.2)\n","Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.7/dist-packages (from tensorpack) (4.41.1)\n","Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.7/dist-packages (from tensorpack) (1.1.0)\n","Requirement already satisfied: psutil>=5 in /usr/local/lib/python3.7/dist-packages (from tensorpack) (5.4.8)\n","Collecting msgpack-numpy>=0.4.4.2\n","  Downloading msgpack_numpy-0.4.7.1-py2.py3-none-any.whl (6.7 kB)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tensorpack) (1.15.0)\n","Installing collected packages: msgpack-numpy, tensorpack\n","Successfully installed msgpack-numpy-0.4.7.1 tensorpack-0.11\n","/content/gdrive/MyDrive/SEAI_Project\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"47qPSLMU19HM","executionInfo":{"status":"ok","timestamp":1626454524550,"user_tz":-120,"elapsed":2715314,"user":{"displayName":"Lorenzo Pasco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgShaitSLZm3zyLVjMQT7ZzTrEV3kQEXha_A9lkVw=s64","userId":"01314717049817932576"}},"outputId":"a4343248-7d6e-4943-84da-a840f083625c"},"source":["#!/usr/bin/env python\n","# -*- coding: utf-8 -*-\n","# File: svhn-digit-dorefa.py\n","# Author: Yuxin Wu\n","\n","import argparse\n","import os\n","import tensorflow as tf\n","\n","from tensorpack import *\n","from tensorpack.dataflow import dataset\n","from tensorpack.tfutils.summary import add_moving_summary, add_param_summary\n","from tensorpack.tfutils.varreplace import remap_variables\n","\n","\"\"\"\n","This is a tensorpack script for the SVHN results in paper:\n","DoReFa-Net: Training Low Bitwidth Convolutional Neural Networks with Low Bitwidth Gradients\n","http://arxiv.org/abs/1606.06160\n","The original experiements are performed on a proprietary framework.\n","This is our attempt to reproduce it on tensorpack.\n","Accuracy:\n","    With (W,A,G)=(1,1,4), can reach 3.1~3.2% error after 150 epochs.\n","    With (W,A,G)=(1,2,4), error is 3.0~3.1%.\n","    With (W,A,G)=(32,32,32), error is about 2.3%.\n","Speed:\n","    With quantization, 60 batch/s on 1 1080Ti. (4721 batch / epoch)\n","To Run:\n","    ./svhn-digit-dorefa.py --dorefa 1,2,4\n","\"\"\"\n","tf.compat.v1.reset_default_graph()\n","\n","BITW = 4\n","BITA = 6\n","BITG = 16\n","\n","\"\"\"\n","imported from dorefa file\n","\"\"\"\n","def get_dorefa(bitW, bitA, bitG):\n","    \"\"\"\n","    Return the three quantization functions fw, fa, fg, for weights, activations and gradients respectively\n","    \"\"\"\n","    def quantize(x, k):\n","        n = float(2 ** k - 1)\n","\n","        @tf.custom_gradient\n","        def _quantize(x):\n","            return tf.round(x * n) / n, lambda dy: dy\n","\n","        return _quantize(x)\n","\n","    def fw(x):\n","        if bitW == 32:\n","            return x\n","\n","        if bitW == 1:   # BWN\n","            E = tf.stop_gradient(tf.reduce_mean(tf.abs(x)))\n","\n","            @tf.custom_gradient\n","            def _sign(x):\n","                return tf.where(tf.equal(x, 0), tf.ones_like(x), tf.sign(x / E)) * E, lambda dy: dy\n","\n","            return _sign(x)\n","\n","        x = tf.tanh(x)\n","        x = x / tf.reduce_max(tf.abs(x)) * 0.5 + 0.5\n","        return 2 * quantize(x, bitW) - 1\n","\n","    def fa(x):\n","        if bitA == 32:\n","            return x\n","        return quantize(x, bitA)\n","\n","    def fg(x):\n","        if bitG == 32:\n","            return x\n","\n","        @tf.custom_gradient\n","        def _identity(input):\n","            def grad_fg(x):\n","                rank = x.get_shape().ndims\n","                assert rank is not None\n","                maxx = tf.reduce_max(tf.abs(x), list(range(1, rank)), keepdims=True)\n","                x = x / maxx\n","                n = float(2**bitG - 1)\n","                x = x * 0.5 + 0.5 + tf.random.uniform(\n","                    tf.shape(x), minval=-0.5 / n, maxval=0.5 / n)\n","                x = tf.clip_by_value(x, 0.0, 1.0)\n","                x = quantize(x, bitG) - 0.5\n","                return x * maxx * 2\n","\n","            return input, grad_fg\n","\n","        return _identity(x)\n","    return fw, fa, fg\n","\n","\n","class Model(ModelDesc):\n","    def inputs(self):\n","        return [tf.TensorSpec([None, 40, 40, 3], tf.float32, 'input'),\n","                tf.TensorSpec([None], tf.int32, 'label')]\n","\n","    def build_graph(self, image, label):\n","        fw, fa, fg = get_dorefa(BITW, BITA, BITG)\n","\n","        # monkey-patch tf.get_variable to apply fw\n","        def binarize_weight(v):\n","            name = v.op.name\n","            # don't binarize first and last layer\n","            if not name.endswith('W'):\n","                return v\n","            else:\n","                logger.info(\"Binarizing weight {}\".format(v.op.name))\n","                return fw(v)\n","\n","        def nonlin(x):\n","            if BITA == 32:\n","                return tf.nn.relu(x)\n","            return tf.clip_by_value(x, 0.0, 1.0)\n","\n","        def activate(x):\n","            return fa(nonlin(x))\n","\n","        image = image / 256.0\n","\n","        with remap_variables(binarize_weight), \\\n","                argscope(BatchNorm, momentum=0.9, epsilon=1e-4), \\\n","                argscope(Conv2D, use_bias=False):\n","            logits = (LinearWrap(image)\n","                      .Conv2D('conv0', 48, 5, padding='VALID', use_bias=True)\n","                      .AvgPooling('pool0', 2, padding='SAME')\n","                      .apply(activate)\n","                      # 18\n","                      .Conv2D('conv1', 64, 3, padding='SAME')\n","                      .apply(fg)\n","                      .BatchNorm('bn1').apply(activate)\n","#AVGPooling\n","                      .Conv2D('conv2', 64, 3, padding='SAME')\n","                      .apply(fg)\n","                      .BatchNorm('bn2')\n","                      .AvgPooling('pool1', 2, padding='SAME')\n","                      .apply(activate)\n","                      # 9\n","                      .Conv2D('conv3', 128, 3, padding='VALID')\n","                      .apply(fg)\n","                      .BatchNorm('bn3').apply(activate)\n","                      # 7\n","\n","                      .Conv2D('conv4', 128, 3, padding='SAME')\n","                      .apply(fg)\n","                      .BatchNorm('bn4').apply(activate)\n","\n","                      .Conv2D('conv5', 128, 3, padding='VALID')\n","                      .apply(fg)\n","                      .BatchNorm('bn5').apply(activate)\n","                      # 5\n","                      .Dropout(rate=0.5 if self.training else 0.0)\n","                      .Conv2D('conv6', 512, 5, padding='VALID')\n","                      .apply(fg).BatchNorm('bn6')\n","                      .apply(nonlin)\n","                      .FullyConnected('fc1', 10)())\n","        tf.nn.softmax(logits, name='output')\n","\n","        correct = tf.cast(tf.nn.in_top_k(predictions=logits, targets=label, k=1), tf.float32, name='correct')\n","        accuracy = tf.reduce_mean(correct, name='accuracy')\n","        train_error = tf.reduce_mean(1 - correct, name='train_error')\n","        summary.add_moving_summary(train_error, accuracy)\n","        \n","        cost = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=label)\n","        cost = tf.reduce_mean(cost, name='cross_entropy_loss')\n","        # weight decay on all W of fc layers\n","        wd_cost = regularize_cost('fc.*/W', l2_regularizer(1e-7))\n","        add_param_summary(('.*/W', ['histogram', 'rms']))\n","        total_cost = tf.add_n([cost, wd_cost], name='cost')\n","        add_moving_summary(cost, wd_cost, total_cost)\n","        return total_cost\n","\n","    def optimizer(self):\n","        lr = tf.compat.v1.train.exponential_decay(\n","            learning_rate=1e-3,\n","            global_step=get_global_step_var(),\n","            decay_steps=4721 * 100,\n","            decay_rate=0.5, staircase=True, name='learning_rate')\n","        tf.summary.scalar('lr', lr)\n","\n","        return tf.compat.v1.train.AdamOptimizer(lr, epsilon=1e-5)\n","\n","\n","def get_config():\n","    logger.set_logger_dir(os.path.join('train_log', 'svhn-dorefa-{}'.format(args)))\n","\n","    # prepare dataset\n","    d1 = dataset.SVHNDigit('train')\n","    d2 = dataset.SVHNDigit('extra')\n","    data_train = RandomMixData([d1, d2])\n","    data_test = dataset.SVHNDigit('test')\n","\n","    augmentors = [\n","        imgaug.Resize((40, 40)),\n","        imgaug.Brightness(30),\n","        imgaug.Contrast((0.5, 1.5)),\n","    ]\n","    data_train = AugmentImageComponent(data_train, augmentors)\n","    data_train = BatchData(data_train, 128)\n","    data_train = MultiProcessRunnerZMQ(data_train, 5)\n","\n","    augmentors = [imgaug.Resize((40, 40))]\n","    data_test = AugmentImageComponent(data_test, augmentors)\n","    data_test = BatchData(data_test, 128, remainder=True)\n","\n","    return TrainConfig(\n","        data=QueueInput(data_train),\n","        callbacks=[\n","            ModelSaver(),\n","            InferenceRunner(    # run inference(for validation) after every epoch\n","                data_test,   # the DataFlow instance used for validation\n","                ScalarStats(    # produce `val_accuracy` and `val_cross_entropy_loss`\n","                    ['cross_entropy_loss', 'accuracy'], prefix='val'))\n","        ],\n","        model=Model(),\n","        max_epoch=10,\n","    )\n","\n","args = \"4,6,16\"\n","BITW, BITA, BITG = map(int, args.split(','))\n","config = get_config()\n","launch_train_with_config(config, SimpleTrainer())\n","\n","'''\n","if __name__ == '__main__':\n","    parser = argparse.ArgumentParser()\n","    parser.add_argument('--dorefa',\n","                        help='number of bits for W,A,G, separated by comma. Defaults to \\'1,2,4\\'',\n","                        default='1,2,4')\n","    args = parser.parse_args()\n","\n","    BITW, BITA, BITG = map(int, args.dorefa.split(','))\n","    config = get_config()\n","    launch_train_with_config(config, SimpleTrainer())\n","'''"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[32m[0716 16:10:12 @logger.py:92]\u001b[0m Argv: /usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py -f /root/.local/share/jupyter/runtime/kernel-0f562677-9457-43f0-9242-37f8c5c2f7d8.json\n","\u001b[32m[0716 16:10:12 @fs.py:101]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m Env var $TENSORPACK_DATASET not set, using /root/tensorpack_data for datasets.\n","\u001b[32m[0716 16:10:12 @fs.py:104]\u001b[0m Created the directory /root/tensorpack_data.\n","\u001b[32m[0716 16:10:12 @svhn.py:42]\u001b[0m File /root/tensorpack_data/svhn_data/train_32x32.mat not found!\n","\u001b[32m[0716 16:10:12 @svhn.py:43]\u001b[0m Downloading from http://ufldl.stanford.edu/housenumbers/train_32x32.mat ...\n"],"name":"stdout"},{"output_type":"stream","text":["train_32x32.mat: 182MB [00:09, 19.8MB/s]                           "],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 16:10:21 @fs.py:73]\u001b[0m Succesfully downloaded train_32x32.mat. 182040794 bytes.\n","\u001b[32m[0716 16:10:21 @svhn.py:45]\u001b[0m Loading /root/tensorpack_data/svhn_data/train_32x32.mat ...\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 16:10:23 @svhn.py:42]\u001b[0m File /root/tensorpack_data/svhn_data/extra_32x32.mat not found!\n","\u001b[32m[0716 16:10:23 @svhn.py:43]\u001b[0m Downloading from http://ufldl.stanford.edu/housenumbers/extra_32x32.mat ...\n"],"name":"stdout"},{"output_type":"stream","text":["extra_32x32.mat: 1.33GB [01:15, 17.7MB/s]                            "],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 16:11:38 @fs.py:73]\u001b[0m Succesfully downloaded extra_32x32.mat. 1329278602 bytes.\n","\u001b[32m[0716 16:11:38 @svhn.py:45]\u001b[0m Loading /root/tensorpack_data/svhn_data/extra_32x32.mat ...\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 16:11:50 @svhn.py:42]\u001b[0m File /root/tensorpack_data/svhn_data/test_32x32.mat not found!\n","\u001b[32m[0716 16:11:50 @svhn.py:43]\u001b[0m Downloading from http://ufldl.stanford.edu/housenumbers/test_32x32.mat ...\n"],"name":"stdout"},{"output_type":"stream","text":["test_32x32.mat: 64.3MB [00:03, 19.0MB/s]                            "],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 16:11:53 @fs.py:73]\u001b[0m Succesfully downloaded test_32x32.mat. 64275384 bytes.\n","\u001b[32m[0716 16:11:53 @svhn.py:45]\u001b[0m Loading /root/tensorpack_data/svhn_data/test_32x32.mat ...\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 16:11:54 @parallel.py:340]\u001b[0m [MultiProcessRunnerZMQ] Will fork a dataflow more than one times. This assumes the datapoints are i.i.d.\n","\u001b[32m[0716 16:11:54 @input_source.py:221]\u001b[0m Setting up the queue 'QueueInput/input_queue' for CPU prefetching ...\n","\u001b[32m[0716 16:11:54 @trainers.py:48]\u001b[0m Building graph for a single training tower ...\n","\u001b[32m[0716 16:11:54 @<ipython-input-3-4fb0ff93d44f>:113]\u001b[0m Binarizing weight conv0/W\n","\u001b[32m[0716 16:11:54 @registry.py:90]\u001b[0m 'conv0': [?, 40, 40, 3] --> [?, 36, 36, 48]\n","\u001b[32m[0716 16:11:54 @registry.py:90]\u001b[0m 'pool0': [?, 36, 36, 48] --> [?, 18, 18, 48]\n","\u001b[32m[0716 16:11:54 @<ipython-input-3-4fb0ff93d44f>:113]\u001b[0m Binarizing weight conv1/W\n","\u001b[32m[0716 16:11:54 @registry.py:90]\u001b[0m 'conv1': [?, 18, 18, 48] --> [?, 18, 18, 64]\n","\u001b[32m[0716 16:11:54 @<ipython-input-3-4fb0ff93d44f>:113]\u001b[0m Binarizing weight conv2/W\n","\u001b[32m[0716 16:11:54 @registry.py:90]\u001b[0m 'conv2': [?, 18, 18, 64] --> [?, 18, 18, 64]\n","\u001b[32m[0716 16:11:54 @registry.py:90]\u001b[0m 'pool1': [?, 18, 18, 64] --> [?, 9, 9, 64]\n","\u001b[32m[0716 16:11:54 @<ipython-input-3-4fb0ff93d44f>:113]\u001b[0m Binarizing weight conv3/W\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1692: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n","  warnings.warn('`layer.apply` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 16:11:54 @registry.py:90]\u001b[0m 'conv3': [?, 9, 9, 64] --> [?, 7, 7, 128]\n","\u001b[32m[0716 16:11:54 @<ipython-input-3-4fb0ff93d44f>:113]\u001b[0m Binarizing weight conv4/W\n","\u001b[32m[0716 16:11:54 @registry.py:90]\u001b[0m 'conv4': [?, 7, 7, 128] --> [?, 7, 7, 128]\n","\u001b[32m[0716 16:11:54 @<ipython-input-3-4fb0ff93d44f>:113]\u001b[0m Binarizing weight conv5/W\n","\u001b[32m[0716 16:11:54 @registry.py:90]\u001b[0m 'conv5': [?, 7, 7, 128] --> [?, 5, 5, 128]\n","\u001b[32m[0716 16:11:54 @<ipython-input-3-4fb0ff93d44f>:113]\u001b[0m Binarizing weight conv6/W\n","\u001b[32m[0716 16:11:54 @registry.py:90]\u001b[0m 'conv6': [?, 5, 5, 128] --> [?, 1, 1, 512]\n","\u001b[32m[0716 16:11:54 @<ipython-input-3-4fb0ff93d44f>:113]\u001b[0m Binarizing weight fc1/W\n","\u001b[32m[0716 16:11:54 @registry.py:90]\u001b[0m 'fc1': [?, 1, 1, 512] --> [?, 10]\n","\u001b[32m[0716 16:11:54 @regularize.py:97]\u001b[0m regularize_cost() found 1 variables to regularize.\n","\u001b[32m[0716 16:11:54 @regularize.py:21]\u001b[0m The following tensors will be regularized: fc1/W:0\n","\u001b[32m[0716 16:11:55 @model_utils.py:67]\u001b[0m \u001b[36mList of Trainable Variables: \n","\u001b[0mname       shape               #elements\n","---------  ----------------  -----------\n","conv0/W    [5, 5, 3, 48]            3600\n","conv0/b    [48]                       48\n","conv1/W    [3, 3, 48, 64]          27648\n","bn1/gamma  [64]                       64\n","bn1/beta   [64]                       64\n","conv2/W    [3, 3, 64, 64]          36864\n","bn2/gamma  [64]                       64\n","bn2/beta   [64]                       64\n","conv3/W    [3, 3, 64, 128]         73728\n","bn3/gamma  [128]                     128\n","bn3/beta   [128]                     128\n","conv4/W    [3, 3, 128, 128]       147456\n","bn4/gamma  [128]                     128\n","bn4/beta   [128]                     128\n","conv5/W    [3, 3, 128, 128]       147456\n","bn5/gamma  [128]                     128\n","bn5/beta   [128]                     128\n","conv6/W    [5, 5, 128, 512]      1638400\n","bn6/gamma  [512]                     512\n","bn6/beta   [512]                     512\n","fc1/W      [512, 10]                5120\n","fc1/b      [10]                       10\u001b[36m\n","Number of trainable variables: 22\n","Number of parameters (elements): 2082378\n","Storage space needed for all trainable variables: 7.94MB\u001b[0m\n","\u001b[32m[0716 16:11:55 @base.py:207]\u001b[0m Setup callbacks graph ...\n","\u001b[32m[0716 16:11:56 @argtools.py:138]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m Starting a process with 'fork' method is efficient but not safe and may cause deadlock or crash.Use 'forkserver' or 'spawn' method instead if you run into such issues.See https://docs.python.org/3/library/multiprocessing.html#contexts-and-start-methods on how to set them.\n","\u001b[32m[0716 16:11:56 @argtools.py:138]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m \"import prctl\" failed! Install python-prctl so that processes can be cleaned with guarantee.\n","\u001b[32m[0716 16:11:56 @inference_runner.py:148]\u001b[0m [InferenceRunner] Building tower 'InferenceTower' on device /gpu:0 ...\n","\u001b[32m[0716 16:11:56 @<ipython-input-3-4fb0ff93d44f>:113]\u001b[0m Binarizing weight conv0/W\n","\u001b[32m[0716 16:11:56 @<ipython-input-3-4fb0ff93d44f>:113]\u001b[0m Binarizing weight conv1/W\n","\u001b[32m[0716 16:11:56 @<ipython-input-3-4fb0ff93d44f>:113]\u001b[0m Binarizing weight conv2/W\n","\u001b[32m[0716 16:11:57 @<ipython-input-3-4fb0ff93d44f>:113]\u001b[0m Binarizing weight conv3/W\n","\u001b[32m[0716 16:11:57 @<ipython-input-3-4fb0ff93d44f>:113]\u001b[0m Binarizing weight conv4/W\n","\u001b[32m[0716 16:11:57 @<ipython-input-3-4fb0ff93d44f>:113]\u001b[0m Binarizing weight conv5/W\n","\u001b[32m[0716 16:11:57 @<ipython-input-3-4fb0ff93d44f>:113]\u001b[0m Binarizing weight conv6/W\n","\u001b[32m[0716 16:11:57 @<ipython-input-3-4fb0ff93d44f>:113]\u001b[0m Binarizing weight fc1/W\n","\u001b[32m[0716 16:11:57 @summary.py:47]\u001b[0m [MovingAverageSummary] 5 operations in collection 'MOVING_SUMMARY_OPS' will be run with session hooks.\n","\u001b[32m[0716 16:11:57 @summary.py:94]\u001b[0m Summarizing collection 'summaries' of size 22.\n","\u001b[32m[0716 16:11:57 @graph.py:99]\u001b[0m Applying collection UPDATE_OPS of 12 ops.\n","\u001b[32m[0716 16:11:57 @base.py:228]\u001b[0m Creating the session ...\n","\u001b[32m[0716 16:12:05 @base.py:234]\u001b[0m Initializing the session ...\n","\u001b[32m[0716 16:12:05 @base.py:241]\u001b[0m Graph Finalized.\n","\u001b[32m[0716 16:12:05 @concurrency.py:37]\u001b[0m Starting EnqueueThread: enqueue dataflow to TF queue \"QueueInput/input_queue\" ...\n","\u001b[32m[0716 16:12:06 @inference_runner.py:95]\u001b[0m [InferenceRunner] Will eval 204 iterations\n","\u001b[32m[0716 16:12:06 @base.py:273]\u001b[0m Start Epoch 1 ...\n"],"name":"stdout"},{"output_type":"stream","text":["100%|##########|4721/4721[04:34<00:00,17.18it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 16:16:40 @base.py:283]\u001b[0m Epoch 1 (global_step 4721) finished, time:4 minutes 34 seconds.\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 16:16:41 @saver.py:82]\u001b[0m Model saved to train_log/svhn-dorefa-4,6,16/model-4721.\n"],"name":"stdout"},{"output_type":"stream","text":["100%|##########|204/204[00:10<00:00,18.79it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 16:16:52 @monitor.py:476]\u001b[0m QueueInput/queue_size: 21.031\n","\u001b[32m[0716 16:16:52 @monitor.py:476]\u001b[0m accuracy: 0.95633\n","\u001b[32m[0716 16:16:52 @monitor.py:476]\u001b[0m cost: 0.15024\n","\u001b[32m[0716 16:16:52 @monitor.py:476]\u001b[0m cross_entropy_loss: 0.15023\n","\u001b[32m[0716 16:16:52 @monitor.py:476]\u001b[0m param-summary/conv0/W-rms: 0.16644\n","\u001b[32m[0716 16:16:52 @monitor.py:476]\u001b[0m param-summary/conv1/W-rms: 0.073002\n","\u001b[32m[0716 16:16:52 @monitor.py:476]\u001b[0m param-summary/conv2/W-rms: 0.065802\n","\u001b[32m[0716 16:16:52 @monitor.py:476]\u001b[0m param-summary/conv3/W-rms: 0.067586\n","\u001b[32m[0716 16:16:52 @monitor.py:476]\u001b[0m param-summary/conv4/W-rms: 0.052364\n","\u001b[32m[0716 16:16:52 @monitor.py:476]\u001b[0m param-summary/conv5/W-rms: 0.054567\n","\u001b[32m[0716 16:16:52 @monitor.py:476]\u001b[0m param-summary/conv6/W-rms: 0.041083\n","\u001b[32m[0716 16:16:52 @monitor.py:476]\u001b[0m param-summary/fc1/W-rms: 0.05914\n","\u001b[32m[0716 16:16:52 @monitor.py:476]\u001b[0m regularize_cost: 8.9298e-07\n","\u001b[32m[0716 16:16:52 @monitor.py:476]\u001b[0m train_error: 0.043669\n","\u001b[32m[0716 16:16:52 @monitor.py:476]\u001b[0m val_accuracy: 0.90672\n","\u001b[32m[0716 16:16:52 @monitor.py:476]\u001b[0m val_cross_entropy_loss: 0.31258\n","\u001b[32m[0716 16:16:52 @group.py:44]\u001b[0m Callbacks took 11.395 sec in total. InferenceRunner: 10.9 seconds\n","\u001b[32m[0716 16:16:52 @base.py:273]\u001b[0m Start Epoch 2 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|4721/4721[04:06<00:00,19.19it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 16:20:58 @base.py:283]\u001b[0m Epoch 2 (global_step 9442) finished, time:4 minutes 6 seconds.\n","\u001b[32m[0716 16:20:58 @saver.py:82]\u001b[0m Model saved to train_log/svhn-dorefa-4,6,16/model-9442.\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|204/204[00:09<00:00,21.18it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 16:21:08 @monitor.py:476]\u001b[0m QueueInput/queue_size: 0.00050402\n","\u001b[32m[0716 16:21:08 @monitor.py:476]\u001b[0m accuracy: 0.96868\n","\u001b[32m[0716 16:21:08 @monitor.py:476]\u001b[0m cost: 0.10502\n","\u001b[32m[0716 16:21:08 @monitor.py:476]\u001b[0m cross_entropy_loss: 0.10502\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 16:21:08 @monitor.py:476]\u001b[0m param-summary/conv0/W-rms: 0.17373\n","\u001b[32m[0716 16:21:08 @monitor.py:476]\u001b[0m param-summary/conv1/W-rms: 0.082745\n","\u001b[32m[0716 16:21:08 @monitor.py:476]\u001b[0m param-summary/conv2/W-rms: 0.082559\n","\u001b[32m[0716 16:21:08 @monitor.py:476]\u001b[0m param-summary/conv3/W-rms: 0.085871\n","\u001b[32m[0716 16:21:08 @monitor.py:476]\u001b[0m param-summary/conv4/W-rms: 0.073173\n","\u001b[32m[0716 16:21:08 @monitor.py:476]\u001b[0m param-summary/conv5/W-rms: 0.076556\n","\u001b[32m[0716 16:21:08 @monitor.py:476]\u001b[0m param-summary/conv6/W-rms: 0.063074\n","\u001b[32m[0716 16:21:08 @monitor.py:476]\u001b[0m param-summary/fc1/W-rms: 0.080279\n","\u001b[32m[0716 16:21:08 @monitor.py:476]\u001b[0m regularize_cost: 1.6478e-06\n","\u001b[32m[0716 16:21:08 @monitor.py:476]\u001b[0m train_error: 0.031322\n","\u001b[32m[0716 16:21:08 @monitor.py:476]\u001b[0m val_accuracy: 0.94358\n","\u001b[32m[0716 16:21:08 @monitor.py:476]\u001b[0m val_cross_entropy_loss: 0.20089\n","\u001b[32m[0716 16:21:08 @group.py:44]\u001b[0m Callbacks took 9.910 sec in total. InferenceRunner: 9.65 seconds\n","\u001b[32m[0716 16:21:08 @base.py:273]\u001b[0m Start Epoch 3 ...\n"],"name":"stdout"},{"output_type":"stream","text":["100%|##########|4721/4721[04:08<00:00,19.03it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 16:25:16 @base.py:283]\u001b[0m Epoch 3 (global_step 14163) finished, time:4 minutes 8 seconds.\n","\u001b[32m[0716 16:25:16 @saver.py:82]\u001b[0m Model saved to train_log/svhn-dorefa-4,6,16/model-14163.\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|204/204[00:09<00:00,21.05it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 16:25:26 @monitor.py:476]\u001b[0m QueueInput/queue_size: 0.5\n","\u001b[32m[0716 16:25:26 @monitor.py:476]\u001b[0m accuracy: 0.9767\n","\u001b[32m[0716 16:25:26 @monitor.py:476]\u001b[0m cost: 0.076972\n","\u001b[32m[0716 16:25:26 @monitor.py:476]\u001b[0m cross_entropy_loss: 0.076969\n","\u001b[32m[0716 16:25:26 @monitor.py:476]\u001b[0m param-summary/conv0/W-rms: 0.18453\n","\u001b[32m[0716 16:25:26 @monitor.py:476]\u001b[0m param-summary/conv1/W-rms: 0.09284\n","\u001b[32m[0716 16:25:26 @monitor.py:476]\u001b[0m param-summary/conv2/W-rms: 0.10265\n","\u001b[32m[0716 16:25:26 @monitor.py:476]\u001b[0m param-summary/conv3/W-rms: 0.10616\n","\u001b[32m[0716 16:25:26 @monitor.py:476]\u001b[0m param-summary/conv4/W-rms: 0.095401\n","\u001b[32m[0716 16:25:26 @monitor.py:476]\u001b[0m param-summary/conv5/W-rms: 0.09838\n","\u001b[32m[0716 16:25:26 @monitor.py:476]\u001b[0m param-summary/conv6/W-rms: 0.083638\n","\u001b[32m[0716 16:25:26 @monitor.py:476]\u001b[0m param-summary/fc1/W-rms: 0.10146\n","\u001b[32m[0716 16:25:26 @monitor.py:476]\u001b[0m regularize_cost: 2.6231e-06\n","\u001b[32m[0716 16:25:26 @monitor.py:476]\u001b[0m train_error: 0.023298\n","\u001b[32m[0716 16:25:26 @monitor.py:476]\u001b[0m val_accuracy: 0.95411\n","\u001b[32m[0716 16:25:26 @monitor.py:476]\u001b[0m val_cross_entropy_loss: 0.17062\n","\u001b[32m[0716 16:25:26 @group.py:44]\u001b[0m Callbacks took 9.982 sec in total. InferenceRunner: 9.7 seconds\n","\u001b[32m[0716 16:25:26 @base.py:273]\u001b[0m Start Epoch 4 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|4721/4721[04:07<00:00,19.10it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 16:29:33 @base.py:283]\u001b[0m Epoch 4 (global_step 18884) finished, time:4 minutes 7 seconds.\n","\u001b[32m[0716 16:29:33 @saver.py:82]\u001b[0m Model saved to train_log/svhn-dorefa-4,6,16/model-18884.\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|204/204[00:09<00:00,20.49it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 16:29:43 @monitor.py:476]\u001b[0m QueueInput/queue_size: 0.18762\n","\u001b[32m[0716 16:29:43 @monitor.py:476]\u001b[0m accuracy: 0.97773\n","\u001b[32m[0716 16:29:43 @monitor.py:476]\u001b[0m cost: 0.087059\n","\u001b[32m[0716 16:29:43 @monitor.py:476]\u001b[0m cross_entropy_loss: 0.087056\n","\u001b[32m[0716 16:29:43 @monitor.py:476]\u001b[0m param-summary/conv0/W-rms: 0.19454\n","\u001b[32m[0716 16:29:43 @monitor.py:476]\u001b[0m param-summary/conv1/W-rms: 0.10181\n","\u001b[32m[0716 16:29:43 @monitor.py:476]\u001b[0m param-summary/conv2/W-rms: 0.12153\n","\u001b[32m[0716 16:29:43 @monitor.py:476]\u001b[0m param-summary/conv3/W-rms: 0.1245\n","\u001b[32m[0716 16:29:43 @monitor.py:476]\u001b[0m param-summary/conv4/W-rms: 0.11494\n","\u001b[32m[0716 16:29:43 @monitor.py:476]\u001b[0m param-summary/conv5/W-rms: 0.11756\n","\u001b[32m[0716 16:29:43 @monitor.py:476]\u001b[0m param-summary/conv6/W-rms: 0.10054\n","\u001b[32m[0716 16:29:43 @monitor.py:476]\u001b[0m param-summary/fc1/W-rms: 0.12097\n","\u001b[32m[0716 16:29:43 @monitor.py:476]\u001b[0m regularize_cost: 3.7436e-06\n","\u001b[32m[0716 16:29:43 @monitor.py:476]\u001b[0m train_error: 0.022273\n","\u001b[32m[0716 16:29:43 @monitor.py:476]\u001b[0m val_accuracy: 0.94504\n","\u001b[32m[0716 16:29:43 @monitor.py:476]\u001b[0m val_cross_entropy_loss: 0.19731\n","\u001b[32m[0716 16:29:43 @group.py:44]\u001b[0m Callbacks took 10.241 sec in total. InferenceRunner: 9.98 seconds\n","\u001b[32m[0716 16:29:43 @base.py:273]\u001b[0m Start Epoch 5 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|4721/4721[04:10<00:00,18.85it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 16:33:54 @base.py:283]\u001b[0m Epoch 5 (global_step 23605) finished, time:4 minutes 10 seconds.\n","\u001b[32m[0716 16:33:54 @saver.py:82]\u001b[0m Model saved to train_log/svhn-dorefa-4,6,16/model-23605.\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|204/204[00:09<00:00,21.84it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 16:34:03 @monitor.py:476]\u001b[0m QueueInput/queue_size: 0.00097656\n","\u001b[32m[0716 16:34:03 @monitor.py:476]\u001b[0m accuracy: 0.98043\n","\u001b[32m[0716 16:34:03 @monitor.py:476]\u001b[0m cost: 0.069614\n","\u001b[32m[0716 16:34:03 @monitor.py:476]\u001b[0m cross_entropy_loss: 0.069609\n","\u001b[32m[0716 16:34:03 @monitor.py:476]\u001b[0m param-summary/conv0/W-rms: 0.20622\n","\u001b[32m[0716 16:34:03 @monitor.py:476]\u001b[0m param-summary/conv1/W-rms: 0.10939\n","\u001b[32m[0716 16:34:03 @monitor.py:476]\u001b[0m param-summary/conv2/W-rms: 0.13828\n","\u001b[32m[0716 16:34:03 @monitor.py:476]\u001b[0m param-summary/conv3/W-rms: 0.14079\n","\u001b[32m[0716 16:34:03 @monitor.py:476]\u001b[0m param-summary/conv4/W-rms: 0.132\n","\u001b[32m[0716 16:34:03 @monitor.py:476]\u001b[0m param-summary/conv5/W-rms: 0.13452\n","\u001b[32m[0716 16:34:03 @monitor.py:476]\u001b[0m param-summary/conv6/W-rms: 0.11506\n","\u001b[32m[0716 16:34:03 @monitor.py:476]\u001b[0m param-summary/fc1/W-rms: 0.14133\n","\u001b[32m[0716 16:34:03 @monitor.py:476]\u001b[0m regularize_cost: 5.1064e-06\n","\u001b[32m[0716 16:34:03 @monitor.py:476]\u001b[0m train_error: 0.019575\n","\u001b[32m[0716 16:34:03 @monitor.py:476]\u001b[0m val_accuracy: 0.96304\n","\u001b[32m[0716 16:34:03 @monitor.py:476]\u001b[0m val_cross_entropy_loss: 0.14501\n","\u001b[32m[0716 16:34:04 @group.py:44]\u001b[0m Callbacks took 9.615 sec in total. InferenceRunner: 9.37 seconds\n","\u001b[32m[0716 16:34:04 @base.py:273]\u001b[0m Start Epoch 6 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|4721/4721[04:09<00:00,18.91it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 16:38:13 @base.py:283]\u001b[0m Epoch 6 (global_step 28326) finished, time:4 minutes 9 seconds.\n","\u001b[32m[0716 16:38:13 @saver.py:82]\u001b[0m Model saved to train_log/svhn-dorefa-4,6,16/model-28326.\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|204/204[00:10<00:00,20.36it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 16:38:23 @monitor.py:476]\u001b[0m QueueInput/queue_size: 0.5\n","\u001b[32m[0716 16:38:23 @monitor.py:476]\u001b[0m accuracy: 0.98492\n","\u001b[32m[0716 16:38:23 @monitor.py:476]\u001b[0m cost: 0.056267\n","\u001b[32m[0716 16:38:23 @monitor.py:476]\u001b[0m cross_entropy_loss: 0.05626\n","\u001b[32m[0716 16:38:23 @monitor.py:476]\u001b[0m param-summary/conv0/W-rms: 0.21586\n","\u001b[32m[0716 16:38:23 @monitor.py:476]\u001b[0m param-summary/conv1/W-rms: 0.11693\n","\u001b[32m[0716 16:38:23 @monitor.py:476]\u001b[0m param-summary/conv2/W-rms: 0.15385\n","\u001b[32m[0716 16:38:23 @monitor.py:476]\u001b[0m param-summary/conv3/W-rms: 0.1558\n","\u001b[32m[0716 16:38:23 @monitor.py:476]\u001b[0m param-summary/conv4/W-rms: 0.14749\n","\u001b[32m[0716 16:38:23 @monitor.py:476]\u001b[0m param-summary/conv5/W-rms: 0.14987\n","\u001b[32m[0716 16:38:23 @monitor.py:476]\u001b[0m param-summary/conv6/W-rms: 0.12787\n","\u001b[32m[0716 16:38:23 @monitor.py:476]\u001b[0m param-summary/fc1/W-rms: 0.16037\n","\u001b[32m[0716 16:38:23 @monitor.py:476]\u001b[0m regularize_cost: 6.5801e-06\n","\u001b[32m[0716 16:38:23 @monitor.py:476]\u001b[0m train_error: 0.015082\n","\u001b[32m[0716 16:38:23 @monitor.py:476]\u001b[0m val_accuracy: 0.96447\n","\u001b[32m[0716 16:38:23 @monitor.py:476]\u001b[0m val_cross_entropy_loss: 0.14128\n","\u001b[32m[0716 16:38:23 @group.py:44]\u001b[0m Callbacks took 10.264 sec in total. InferenceRunner: 10 seconds\n","\u001b[32m[0716 16:38:23 @base.py:273]\u001b[0m Start Epoch 7 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|4721/4721[04:04<00:00,19.35it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 16:42:27 @base.py:283]\u001b[0m Epoch 7 (global_step 33047) finished, time:4 minutes 4 seconds.\n","\u001b[32m[0716 16:42:28 @saver.py:82]\u001b[0m Model saved to train_log/svhn-dorefa-4,6,16/model-33047.\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|204/204[00:09<00:00,21.10it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 16:42:37 @monitor.py:476]\u001b[0m QueueInput/queue_size: 1.2666e-24\n","\u001b[32m[0716 16:42:37 @monitor.py:476]\u001b[0m accuracy: 0.98494\n","\u001b[32m[0716 16:42:37 @monitor.py:476]\u001b[0m cost: 0.05083\n","\u001b[32m[0716 16:42:37 @monitor.py:476]\u001b[0m cross_entropy_loss: 0.050822\n","\u001b[32m[0716 16:42:37 @monitor.py:476]\u001b[0m param-summary/conv0/W-rms: 0.22297\n","\u001b[32m[0716 16:42:37 @monitor.py:476]\u001b[0m param-summary/conv1/W-rms: 0.12363\n","\u001b[32m[0716 16:42:37 @monitor.py:476]\u001b[0m param-summary/conv2/W-rms: 0.1678\n","\u001b[32m[0716 16:42:37 @monitor.py:476]\u001b[0m param-summary/conv3/W-rms: 0.16952\n","\u001b[32m[0716 16:42:37 @monitor.py:476]\u001b[0m param-summary/conv4/W-rms: 0.16146\n","\u001b[32m[0716 16:42:37 @monitor.py:476]\u001b[0m param-summary/conv5/W-rms: 0.16361\n","\u001b[32m[0716 16:42:37 @monitor.py:476]\u001b[0m param-summary/conv6/W-rms: 0.13929\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 16:42:37 @monitor.py:476]\u001b[0m param-summary/fc1/W-rms: 0.1792\n","\u001b[32m[0716 16:42:37 @monitor.py:476]\u001b[0m regularize_cost: 8.2128e-06\n","\u001b[32m[0716 16:42:37 @monitor.py:476]\u001b[0m train_error: 0.015065\n","\u001b[32m[0716 16:42:37 @monitor.py:476]\u001b[0m val_accuracy: 0.96433\n","\u001b[32m[0716 16:42:37 @monitor.py:476]\u001b[0m val_cross_entropy_loss: 0.14302\n","\u001b[32m[0716 16:42:37 @group.py:44]\u001b[0m Callbacks took 9.907 sec in total. InferenceRunner: 9.68 seconds\n","\u001b[32m[0716 16:42:37 @base.py:273]\u001b[0m Start Epoch 8 ...\n"],"name":"stdout"},{"output_type":"stream","text":["100%|##########|4721/4721[04:05<00:00,19.25it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 16:46:43 @base.py:283]\u001b[0m Epoch 8 (global_step 37768) finished, time:4 minutes 5 seconds.\n","\u001b[32m[0716 16:46:43 @saver.py:82]\u001b[0m Model saved to train_log/svhn-dorefa-4,6,16/model-37768.\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|204/204[00:10<00:00,19.95it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 16:46:53 @monitor.py:476]\u001b[0m QueueInput/queue_size: 6.3538e-22\n","\u001b[32m[0716 16:46:53 @monitor.py:476]\u001b[0m accuracy: 0.98814\n","\u001b[32m[0716 16:46:53 @monitor.py:476]\u001b[0m cost: 0.047342\n","\u001b[32m[0716 16:46:53 @monitor.py:476]\u001b[0m cross_entropy_loss: 0.047332\n","\u001b[32m[0716 16:46:53 @monitor.py:476]\u001b[0m param-summary/conv0/W-rms: 0.22909\n","\u001b[32m[0716 16:46:53 @monitor.py:476]\u001b[0m param-summary/conv1/W-rms: 0.12988\n","\u001b[32m[0716 16:46:53 @monitor.py:476]\u001b[0m param-summary/conv2/W-rms: 0.181\n","\u001b[32m[0716 16:46:53 @monitor.py:476]\u001b[0m param-summary/conv3/W-rms: 0.18235\n","\u001b[32m[0716 16:46:53 @monitor.py:476]\u001b[0m param-summary/conv4/W-rms: 0.1745\n","\u001b[32m[0716 16:46:53 @monitor.py:476]\u001b[0m param-summary/conv5/W-rms: 0.17648\n","\u001b[32m[0716 16:46:53 @monitor.py:476]\u001b[0m param-summary/conv6/W-rms: 0.14982\n","\u001b[32m[0716 16:46:53 @monitor.py:476]\u001b[0m param-summary/fc1/W-rms: 0.19632\n","\u001b[32m[0716 16:46:53 @monitor.py:476]\u001b[0m regularize_cost: 9.8608e-06\n","\u001b[32m[0716 16:46:53 @monitor.py:476]\u001b[0m train_error: 0.01186\n","\u001b[32m[0716 16:46:53 @monitor.py:476]\u001b[0m val_accuracy: 0.96593\n","\u001b[32m[0716 16:46:53 @monitor.py:476]\u001b[0m val_cross_entropy_loss: 0.13496\n","\u001b[32m[0716 16:46:53 @group.py:44]\u001b[0m Callbacks took 10.485 sec in total. InferenceRunner: 10.2 seconds\n","\u001b[32m[0716 16:46:53 @base.py:273]\u001b[0m Start Epoch 9 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|4721/4721[04:05<00:00,19.25it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 16:50:59 @base.py:283]\u001b[0m Epoch 9 (global_step 42489) finished, time:4 minutes 5 seconds.\n","\u001b[32m[0716 16:50:59 @saver.py:82]\u001b[0m Model saved to train_log/svhn-dorefa-4,6,16/model-42489.\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|204/204[00:09<00:00,21.38it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 16:51:08 @monitor.py:476]\u001b[0m QueueInput/queue_size: 0.16029\n","\u001b[32m[0716 16:51:08 @monitor.py:476]\u001b[0m accuracy: 0.98708\n","\u001b[32m[0716 16:51:08 @monitor.py:476]\u001b[0m cost: 0.044589\n","\u001b[32m[0716 16:51:08 @monitor.py:476]\u001b[0m cross_entropy_loss: 0.044578\n","\u001b[32m[0716 16:51:08 @monitor.py:476]\u001b[0m param-summary/conv0/W-rms: 0.23402\n","\u001b[32m[0716 16:51:08 @monitor.py:476]\u001b[0m param-summary/conv1/W-rms: 0.13625\n","\u001b[32m[0716 16:51:08 @monitor.py:476]\u001b[0m param-summary/conv2/W-rms: 0.19315\n","\u001b[32m[0716 16:51:08 @monitor.py:476]\u001b[0m param-summary/conv3/W-rms: 0.19424\n","\u001b[32m[0716 16:51:08 @monitor.py:476]\u001b[0m param-summary/conv4/W-rms: 0.18656\n","\u001b[32m[0716 16:51:08 @monitor.py:476]\u001b[0m param-summary/conv5/W-rms: 0.18842\n","\u001b[32m[0716 16:51:08 @monitor.py:476]\u001b[0m param-summary/conv6/W-rms: 0.1595\n","\u001b[32m[0716 16:51:08 @monitor.py:476]\u001b[0m param-summary/fc1/W-rms: 0.21314\n","\u001b[32m[0716 16:51:08 @monitor.py:476]\u001b[0m regularize_cost: 1.162e-05\n","\u001b[32m[0716 16:51:08 @monitor.py:476]\u001b[0m train_error: 0.01292\n","\u001b[32m[0716 16:51:08 @monitor.py:476]\u001b[0m val_accuracy: 0.96456\n","\u001b[32m[0716 16:51:08 @monitor.py:476]\u001b[0m val_cross_entropy_loss: 0.14133\n","\u001b[32m[0716 16:51:08 @group.py:44]\u001b[0m Callbacks took 9.791 sec in total. InferenceRunner: 9.55 seconds\n","\u001b[32m[0716 16:51:08 @base.py:273]\u001b[0m Start Epoch 10 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|4721/4721[04:06<00:00,19.18it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 16:55:15 @base.py:283]\u001b[0m Epoch 10 (global_step 47210) finished, time:4 minutes 6 seconds.\n","\u001b[32m[0716 16:55:15 @saver.py:82]\u001b[0m Model saved to train_log/svhn-dorefa-4,6,16/model-47210.\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|204/204[00:09<00:00,21.59it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 16:55:24 @monitor.py:476]\u001b[0m QueueInput/queue_size: 1.1755e-38\n","\u001b[32m[0716 16:55:24 @monitor.py:476]\u001b[0m accuracy: 0.98489\n","\u001b[32m[0716 16:55:24 @monitor.py:476]\u001b[0m cost: 0.051025\n","\u001b[32m[0716 16:55:24 @monitor.py:476]\u001b[0m cross_entropy_loss: 0.051011\n","\u001b[32m[0716 16:55:24 @monitor.py:476]\u001b[0m param-summary/conv0/W-rms: 0.23647\n","\u001b[32m[0716 16:55:24 @monitor.py:476]\u001b[0m param-summary/conv1/W-rms: 0.14245\n","\u001b[32m[0716 16:55:24 @monitor.py:476]\u001b[0m param-summary/conv2/W-rms: 0.20483\n","\u001b[32m[0716 16:55:24 @monitor.py:476]\u001b[0m param-summary/conv3/W-rms: 0.20569\n","\u001b[32m[0716 16:55:24 @monitor.py:476]\u001b[0m param-summary/conv4/W-rms: 0.19811\n","\u001b[32m[0716 16:55:24 @monitor.py:476]\u001b[0m param-summary/conv5/W-rms: 0.19983\n","\u001b[32m[0716 16:55:24 @monitor.py:476]\u001b[0m param-summary/conv6/W-rms: 0.16875\n","\u001b[32m[0716 16:55:24 @monitor.py:476]\u001b[0m param-summary/fc1/W-rms: 0.23028\n","\u001b[32m[0716 16:55:24 @monitor.py:476]\u001b[0m regularize_cost: 1.3568e-05\n","\u001b[32m[0716 16:55:24 @monitor.py:476]\u001b[0m train_error: 0.015112\n","\u001b[32m[0716 16:55:24 @monitor.py:476]\u001b[0m val_accuracy: 0.96899\n","\u001b[32m[0716 16:55:24 @monitor.py:476]\u001b[0m val_cross_entropy_loss: 0.13\n","\u001b[32m[0716 16:55:24 @group.py:44]\u001b[0m Callbacks took 9.697 sec in total. InferenceRunner: 9.46 seconds\n","\u001b[32m[0716 16:55:24 @base.py:287]\u001b[0m Training has finished!\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"\\nif __name__ == '__main__':\\n    parser = argparse.ArgumentParser()\\n    parser.add_argument('--dorefa',\\n                        help='number of bits for W,A,G, separated by comma. Defaults to '1,2,4'',\\n                        default='1,2,4')\\n    args = parser.parse_args()\\n\\n    BITW, BITA, BITG = map(int, args.dorefa.split(','))\\n    config = get_config()\\n    launch_train_with_config(config, SimpleTrainer())\\n\""]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":315},"id":"mduuAqCeuc4B","executionInfo":{"status":"ok","timestamp":1626874143701,"user_tz":-120,"elapsed":1246,"user":{"displayName":"Lorenzo Pasco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgShaitSLZm3zyLVjMQT7ZzTrEV3kQEXha_A9lkVw=s64","userId":"01314717049817932576"}},"outputId":"838cacc3-c833-4ebc-f31b-a3ff3801c3de"},"source":["import json\n","import matplotlib.pyplot as plt\n","\n","f = open(\"train_log/svhn-dorefa-4,6,16/stats_def_first&last_avg_pooling_4616.json\",\"r\")\n","\n","data = json.load(f)\n","accuracy = []\n","val_accuracy = []\n","for ob in data:\n","  accuracy.append(ob[\"accuracy\"])\n","  val_accuracy.append(ob[\"val_accuracy\"])\n","\n","epochs = range(len(accuracy))\n","\n","plt.plot(epochs, accuracy, 'r', label='Training acc')\n","plt.plot(epochs, val_accuracy, 'b', label='Validation acc')\n","plt.title('Training and validation accuracy')\n","plt.legend()\n","plt.figure()"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<Figure size 432x288 with 0 Axes>"]},"metadata":{"tags":[]},"execution_count":3},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 0 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ST3WBdVha1W-","executionInfo":{"status":"ok","timestamp":1626874158899,"user_tz":-120,"elapsed":265,"user":{"displayName":"Lorenzo Pasco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgShaitSLZm3zyLVjMQT7ZzTrEV3kQEXha_A9lkVw=s64","userId":"01314717049817932576"}},"outputId":"960266cb-a6af-4b67-d01a-89a11742adfc"},"source":["from tabulate import tabulate\n","import matplotlib.pyplot as plt\n","\n","ep = [i+1 for i in epochs]\n","table_acc = {\"Epochs\" : ep, \"Accuracy\":accuracy}\n","table_val_acc = {\"Epochs\" : ep, \"Accuracy\":val_accuracy}\n","\n","print(\"ACCURACY\\n\")\n","print(tabulate(table_acc, headers='keys', tablefmt='fancy_grid'))\n","print(\"\\nVALIDATION ACCURACY\\n\")\n","print(tabulate(table_val_acc, headers='keys', tablefmt='fancy_grid'))"],"execution_count":4,"outputs":[{"output_type":"stream","text":["ACCURACY\n","\n","╒══════════╤════════════╕\n","│   Epochs │   Accuracy │\n","╞══════════╪════════════╡\n","│        1 │   0.956331 │\n","├──────────┼────────────┤\n","│        2 │   0.968678 │\n","├──────────┼────────────┤\n","│        3 │   0.976702 │\n","├──────────┼────────────┤\n","│        4 │   0.977727 │\n","├──────────┼────────────┤\n","│        5 │   0.980425 │\n","├──────────┼────────────┤\n","│        6 │   0.984918 │\n","├──────────┼────────────┤\n","│        7 │   0.984935 │\n","├──────────┼────────────┤\n","│        8 │   0.988141 │\n","├──────────┼────────────┤\n","│        9 │   0.98708  │\n","├──────────┼────────────┤\n","│       10 │   0.984888 │\n","╘══════════╧════════════╛\n","\n","VALIDATION ACCURACY\n","\n","╒══════════╤════════════╕\n","│   Epochs │   Accuracy │\n","╞══════════╪════════════╡\n","│        1 │   0.906722 │\n","├──────────┼────────────┤\n","│        2 │   0.943576 │\n","├──────────┼────────────┤\n","│        3 │   0.954108 │\n","├──────────┼────────────┤\n","│        4 │   0.945044 │\n","├──────────┼────────────┤\n","│        5 │   0.963044 │\n","├──────────┼────────────┤\n","│        6 │   0.964474 │\n","├──────────┼────────────┤\n","│        7 │   0.964333 │\n","├──────────┼────────────┤\n","│        8 │   0.965929 │\n","├──────────┼────────────┤\n","│        9 │   0.964563 │\n","├──────────┼────────────┤\n","│       10 │   0.968993 │\n","╘══════════╧════════════╛\n"],"name":"stdout"}]}]}