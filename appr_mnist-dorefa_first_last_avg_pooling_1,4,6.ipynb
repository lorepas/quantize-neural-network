{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"appr_mnist-dorefa_first&last_avg_pooling_1,4,6.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOMh1lwZaAlKtkfL22HY3QH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"5qzKFEQKqXDt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626899226824,"user_tz":-120,"elapsed":20919,"user":{"displayName":"Lorenzo Pasco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgShaitSLZm3zyLVjMQT7ZzTrEV3kQEXha_A9lkVw=s64","userId":"01314717049817932576"}},"outputId":"cd2fbf16-c610-4483-e4f0-563ad8eddfc2"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eDXKVoHj26H8","executionInfo":{"status":"ok","timestamp":1626899248921,"user_tz":-120,"elapsed":3825,"user":{"displayName":"Lorenzo Pasco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgShaitSLZm3zyLVjMQT7ZzTrEV3kQEXha_A9lkVw=s64","userId":"01314717049817932576"}},"outputId":"1ede5ee9-09a9-4e56-c154-6c3cc344085b"},"source":["!pip install tensorpack\n","\n","%cd gdrive/MyDrive/SEAI_Project"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting tensorpack\n","  Downloading tensorpack-0.11-py2.py3-none-any.whl (296 kB)\n","\u001b[?25l\r\u001b[K     |█                               | 10 kB 25.9 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 20 kB 31.3 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 30 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 40 kB 19.3 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 51 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 61 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 71 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 81 kB 9.6 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 92 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 102 kB 10.9 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 112 kB 10.9 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 122 kB 10.9 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 133 kB 10.9 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 143 kB 10.9 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 153 kB 10.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 163 kB 10.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 174 kB 10.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 184 kB 10.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 194 kB 10.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 204 kB 10.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 215 kB 10.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 225 kB 10.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 235 kB 10.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 245 kB 10.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 256 kB 10.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 266 kB 10.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 276 kB 10.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 286 kB 10.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 296 kB 10.9 MB/s \n","\u001b[?25hRequirement already satisfied: msgpack>=0.5.2 in /usr/local/lib/python3.7/dist-packages (from tensorpack) (1.0.2)\n","Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.7/dist-packages (from tensorpack) (0.8.9)\n","Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.7/dist-packages (from tensorpack) (1.1.0)\n","Requirement already satisfied: pyzmq>=16 in /usr/local/lib/python3.7/dist-packages (from tensorpack) (22.1.0)\n","Collecting msgpack-numpy>=0.4.4.2\n","  Downloading msgpack_numpy-0.4.7.1-py2.py3-none-any.whl (6.7 kB)\n","Requirement already satisfied: psutil>=5 in /usr/local/lib/python3.7/dist-packages (from tensorpack) (5.4.8)\n","Requirement already satisfied: numpy>=1.14 in /usr/local/lib/python3.7/dist-packages (from tensorpack) (1.19.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tensorpack) (1.15.0)\n","Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.7/dist-packages (from tensorpack) (4.41.1)\n","Installing collected packages: msgpack-numpy, tensorpack\n","Successfully installed msgpack-numpy-0.4.7.1 tensorpack-0.11\n","/content/gdrive/MyDrive/SEAI_backup\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"47qPSLMU19HM","executionInfo":{"status":"ok","timestamp":1626899801886,"user_tz":-120,"elapsed":526812,"user":{"displayName":"Lorenzo Pasco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgShaitSLZm3zyLVjMQT7ZzTrEV3kQEXha_A9lkVw=s64","userId":"01314717049817932576"}},"outputId":"9cb7f775-0fa6-4156-930d-a7500630eccc"},"source":["#!/usr/bin/env python\n","# -*- coding: utf-8 -*-\n","# File: svhn-digit-dorefa.py\n","# Author: Yuxin Wu\n","\n","import argparse\n","import os\n","import tensorflow as tf\n","\n","from tensorpack import *\n","from tensorpack.dataflow import dataset\n","from tensorpack.tfutils.summary import add_moving_summary, add_param_summary\n","from tensorpack.tfutils.varreplace import remap_variables\n","\n","\"\"\"\n","This is a tensorpack script for the SVHN results in paper:\n","DoReFa-Net: Training Low Bitwidth Convolutional Neural Networks with Low Bitwidth Gradients\n","http://arxiv.org/abs/1606.06160\n","The original experiements are performed on a proprietary framework.\n","This is our attempt to reproduce it on tensorpack.\n","Accuracy:\n","    With (W,A,G)=(1,1,4), can reach 3.1~3.2% error after 150 epochs.\n","    With (W,A,G)=(1,2,4), error is 3.0~3.1%.\n","    With (W,A,G)=(32,32,32), error is about 2.3%.\n","Speed:\n","    With quantization, 60 batch/s on 1 1080Ti. (4721 batch / epoch)\n","To Run:\n","    ./svhn-digit-dorefa.py --dorefa 1,2,4\n","\"\"\"\n","tf.compat.v1.reset_default_graph()\n","\n","BITW = 1\n","BITA = 4\n","BITG = 6\n","\n","\"\"\"\n","imported from dorefa file\n","\"\"\"\n","def get_dorefa(bitW, bitA, bitG):\n","    \"\"\"\n","    Return the three quantization functions fw, fa, fg, for weights, activations and gradients respectively\n","    \"\"\"\n","    def quantize(x, k):\n","        n = float(2 ** k - 1)\n","\n","        @tf.custom_gradient\n","        def _quantize(x):\n","            return tf.round(x * n) / n, lambda dy: dy\n","\n","        return _quantize(x)\n","\n","    def fw(x):\n","        if bitW == 32:\n","            return x\n","\n","        if bitW == 1:   # BWN\n","            E = tf.stop_gradient(tf.reduce_mean(tf.abs(x)))\n","\n","            @tf.custom_gradient\n","            def _sign(x):\n","                return tf.where(tf.equal(x, 0), tf.ones_like(x), tf.sign(x / E)) * E, lambda dy: dy\n","\n","            return _sign(x)\n","\n","        x = tf.tanh(x)\n","        x = x / tf.reduce_max(tf.abs(x)) * 0.5 + 0.5\n","        return 2 * quantize(x, bitW) - 1\n","\n","    def fa(x):\n","        if bitA == 32:\n","            return x\n","        return quantize(x, bitA)\n","\n","    def fg(x):\n","        if bitG == 32:\n","            return x\n","\n","        @tf.custom_gradient\n","        def _identity(input):\n","            def grad_fg(x):\n","                rank = x.get_shape().ndims\n","                assert rank is not None\n","                maxx = tf.reduce_max(tf.abs(x), list(range(1, rank)), keepdims=True)\n","                x = x / maxx\n","                n = float(2**bitG - 1)\n","                x = x * 0.5 + 0.5 + tf.random.uniform(\n","                    tf.shape(x), minval=-0.5 / n, maxval=0.5 / n)\n","                x = tf.clip_by_value(x, 0.0, 1.0)\n","                x = quantize(x, bitG) - 0.5\n","                return x * maxx * 2\n","\n","            return input, grad_fg\n","\n","        return _identity(x)\n","    return fw, fa, fg\n","\n","\n","class Model(ModelDesc):\n","    def inputs(self):\n","        return [tf.TensorSpec([None, 40, 40], tf.float32, 'input'),\n","                tf.TensorSpec([None], tf.int32, 'label')]\n","\n","    def build_graph(self, image, label):\n","        fw, fa, fg = get_dorefa(BITW, BITA, BITG)\n","\n","        # monkey-patch tf.get_variable to apply fw\n","        def binarize_weight(v):\n","            name = v.op.name\n","            # don't binarize first and last layer\n","            \n","            if not name.endswith('W'):\n","                return v\n","            else:\n","                logger.info(\"Binarizing weight {}\".format(v.op.name))\n","                return fw(v)\n","\n","        def nonlin(x):\n","            if BITA == 32:\n","                return tf.nn.relu(x)\n","            return tf.clip_by_value(x, 0.0, 1.0)\n","\n","        def activate(x):\n","            return fa(nonlin(x))\n","\n","        image = tf.expand_dims(image, 3)\n","        image = image / 256.0\n","\n","        with remap_variables(binarize_weight), \\\n","                argscope(BatchNorm, momentum=0.9, epsilon=1e-4), \\\n","                argscope(Conv2D, use_bias=False):\n","            logits = (LinearWrap(image)\n","                      .Conv2D('conv0', 48, 5, padding='VALID', use_bias=True)\n","                      .AvgPooling('pool0', 2, padding='SAME')\n","                      .apply(activate)\n","                      # 18\n","                      .Conv2D('conv1', 64, 3, padding='SAME')\n","                      .apply(fg)\n","                      .BatchNorm('bn1').apply(activate)\n","#AVGPooling\n","                      .Conv2D('conv2', 64, 3, padding='SAME')\n","                      .apply(fg)\n","                      .BatchNorm('bn2')\n","                      .AvgPooling('pool1', 2, padding='SAME')\n","                      .apply(activate)\n","                      # 9\n","                      .Conv2D('conv3', 128, 3, padding='VALID')\n","                      .apply(fg)\n","                      .BatchNorm('bn3').apply(activate)\n","                      # 7\n","\n","                      .Conv2D('conv4', 128, 3, padding='SAME')\n","                      .apply(fg)\n","                      .BatchNorm('bn4').apply(activate)\n","\n","                      .Conv2D('conv5', 128, 3, padding='VALID')\n","                      .apply(fg)\n","                      .BatchNorm('bn5').apply(activate)\n","                      # 5\n","                      .Dropout(rate=0.5 if self.training else 0.0)\n","                      .Conv2D('conv6', 512, 5, padding='VALID')\n","                      .apply(fg).BatchNorm('bn6')\n","                      .apply(nonlin)\n","                      .FullyConnected('fc1', 10)())\n","        tf.nn.softmax(logits, name='output')\n","\n","        correct = tf.cast(tf.nn.in_top_k(predictions=logits, targets=label, k=1), tf.float32, name='correct')\n","        accuracy = tf.reduce_mean(correct, name='accuracy')\n","        train_error = tf.reduce_mean(1 - correct, name='train_error')\n","        summary.add_moving_summary(train_error, accuracy)\n","        \n","        cost = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=label)\n","        cost = tf.reduce_mean(cost, name='cross_entropy_loss')\n","        # weight decay on all W of fc layers\n","        wd_cost = regularize_cost('fc.*/W', l2_regularizer(1e-7))\n","        add_param_summary(('.*/W', ['histogram', 'rms']))\n","        total_cost = tf.add_n([cost, wd_cost], name='cost')\n","        add_moving_summary(cost, wd_cost, total_cost)\n","        return total_cost\n","\n","    def optimizer(self):\n","        lr = tf.compat.v1.train.exponential_decay(\n","            learning_rate=1e-3,\n","            global_step=get_global_step_var(),\n","            decay_steps=4721 * 100,\n","            decay_rate=0.5, staircase=True, name='learning_rate')\n","        tf.summary.scalar('lr', lr)\n","\n","        return tf.compat.v1.train.AdamOptimizer(lr, epsilon=1e-5)\n","\n","\n","def get_config():\n","    logger.set_logger_dir(os.path.join('train_log', 'mnist-dorefa-{}'.format(args)))\n","\n","    # prepare dataset\n","    data_train = dataset.Mnist('train', shuffle=True)\n","    data_test = dataset.Mnist('test', shuffle=True)\n","\n","    augmentors = [imgaug.Resize((40, 40))]\n","    data_train = AugmentImageComponent(data_train, augmentors)\n","    data_train = BatchData(data_train, 128)\n","    data_train = MultiProcessRunnerZMQ(data_train, 5)\n","\n","    augmentors = [imgaug.Resize((40, 40))]\n","    data_test = AugmentImageComponent(data_test, augmentors)\n","    data_test = BatchData(data_test, 128, remainder=True)\n","\n","    return TrainConfig(\n","        data=QueueInput(data_train),\n","        callbacks=[\n","            ModelSaver(),\n","            InferenceRunner(    # run inference(for validation) after every epoch\n","                data_test,   # the DataFlow instance used for validation\n","                ScalarStats(    # produce `val_accuracy` and `val_cross_entropy_loss`\n","                    ['cross_entropy_loss', 'accuracy'], prefix='val'))\n","        ],\n","        model=Model(),\n","        max_epoch=10,\n","    )\n","\n","args = \"1,4,6\"\n","BITW, BITA, BITG = map(int, args.split(','))\n","config = get_config()\n","launch_train_with_config(config, SimpleTrainer())\n","\n","'''\n","if __name__ == '__main__':\n","    parser = argparse.ArgumentParser()\n","    parser.add_argument('--dorefa',\n","                        help='number of bits for W,A,G, separated by comma. Defaults to \\'1,2,4\\'',\n","                        default='1,2,4')\n","    args = parser.parse_args()\n","\n","    BITW, BITA, BITG = map(int, args.dorefa.split(','))\n","    config = get_config()\n","    launch_train_with_config(config, SimpleTrainer())\n","'''"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[32m[0721 20:27:55 @logger.py:128]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m Log directory train_log/mnist-dorefa-1,4,6 exists! Use 'd' to delete it. \n","\u001b[32m[0721 20:27:55 @logger.py:131]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m If you're resuming from a previous run, you can choose to keep it.\n","Press any other key to exit. \n","Select Action: k (keep) / d (delete) / q (quit):k\n","\u001b[32m[0721 20:27:58 @logger.py:85]\u001b[0m Existing log file 'train_log/mnist-dorefa-1,4,6/log.log' backuped to 'train_log/mnist-dorefa-1,4,6/log.log.0721-202758'\n","\u001b[32m[0721 20:27:58 @logger.py:92]\u001b[0m Argv: /usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py -f /root/.local/share/jupyter/runtime/kernel-df2f652a-6a36-4a45-bf7e-6da5e9b81f72.json\n","\u001b[32m[0721 20:27:58 @mnist.py:21]\u001b[0m Downloading to /root/tensorpack_data/mnist_data/train-images-idx3-ubyte.gz...\n"],"name":"stdout"},{"output_type":"stream","text":["train-images-idx3-ubyte.gz: 9.92MB [04:59, 33.1kB/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0721 20:32:57 @fs.py:73]\u001b[0m Succesfully downloaded train-images-idx3-ubyte.gz. 9912422 bytes.\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0721 20:32:58 @mnist.py:21]\u001b[0m Downloading to /root/tensorpack_data/mnist_data/train-labels-idx1-ubyte.gz...\n"],"name":"stdout"},{"output_type":"stream","text":["train-labels-idx1-ubyte.gz: 32.8kB [00:00, 107kB/s]                             "],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0721 20:32:58 @fs.py:73]\u001b[0m Succesfully downloaded train-labels-idx1-ubyte.gz. 28881 bytes.\n","\u001b[32m[0721 20:32:58 @mnist.py:21]\u001b[0m Downloading to /root/tensorpack_data/mnist_data/t10k-images-idx3-ubyte.gz...\n"],"name":"stdout"},{"output_type":"stream","text":["\n","t10k-images-idx3-ubyte.gz: 1.65MB [00:49, 33.4kB/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0721 20:33:48 @fs.py:73]\u001b[0m Succesfully downloaded t10k-images-idx3-ubyte.gz. 1648877 bytes.\n","\u001b[32m[0721 20:33:48 @mnist.py:21]\u001b[0m Downloading to /root/tensorpack_data/mnist_data/t10k-labels-idx1-ubyte.gz...\n"],"name":"stdout"},{"output_type":"stream","text":["\n","t10k-labels-idx1-ubyte.gz: 8.19kB [00:00, 41.2kB/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0721 20:33:48 @fs.py:73]\u001b[0m Succesfully downloaded t10k-labels-idx1-ubyte.gz. 4542 bytes.\n","\u001b[32m[0721 20:33:48 @parallel.py:340]\u001b[0m [MultiProcessRunnerZMQ] Will fork a dataflow more than one times. This assumes the datapoints are i.i.d.\n","\u001b[32m[0721 20:33:48 @input_source.py:221]\u001b[0m Setting up the queue 'QueueInput/input_queue' for CPU prefetching ...\n","\u001b[32m[0721 20:33:48 @trainers.py:48]\u001b[0m Building graph for a single training tower ...\n","\u001b[32m[0721 20:33:48 @<ipython-input-4-be49c17f8cc2>:114]\u001b[0m Binarizing weight conv0/W\n","\u001b[32m[0721 20:33:48 @registry.py:90]\u001b[0m 'conv0': [?, 40, 40, 1] --> [?, 36, 36, 48]\n","\u001b[32m[0721 20:33:48 @registry.py:90]\u001b[0m 'pool0': [?, 36, 36, 48] --> [?, 18, 18, 48]\n","\u001b[32m[0721 20:33:48 @<ipython-input-4-be49c17f8cc2>:114]\u001b[0m Binarizing weight conv1/W\n","\u001b[32m[0721 20:33:48 @registry.py:90]\u001b[0m 'conv1': [?, 18, 18, 48] --> [?, 18, 18, 64]\n","\u001b[32m[0721 20:33:48 @<ipython-input-4-be49c17f8cc2>:114]\u001b[0m Binarizing weight conv2/W\n"],"name":"stdout"},{"output_type":"stream","text":["\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1692: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n","  warnings.warn('`layer.apply` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0721 20:33:48 @registry.py:90]\u001b[0m 'conv2': [?, 18, 18, 64] --> [?, 18, 18, 64]\n","\u001b[32m[0721 20:33:48 @registry.py:90]\u001b[0m 'pool1': [?, 18, 18, 64] --> [?, 9, 9, 64]\n","\u001b[32m[0721 20:33:48 @<ipython-input-4-be49c17f8cc2>:114]\u001b[0m Binarizing weight conv3/W\n","\u001b[32m[0721 20:33:48 @registry.py:90]\u001b[0m 'conv3': [?, 9, 9, 64] --> [?, 7, 7, 128]\n","\u001b[32m[0721 20:33:48 @<ipython-input-4-be49c17f8cc2>:114]\u001b[0m Binarizing weight conv4/W\n","\u001b[32m[0721 20:33:48 @registry.py:90]\u001b[0m 'conv4': [?, 7, 7, 128] --> [?, 7, 7, 128]\n","\u001b[32m[0721 20:33:48 @<ipython-input-4-be49c17f8cc2>:114]\u001b[0m Binarizing weight conv5/W\n","\u001b[32m[0721 20:33:48 @registry.py:90]\u001b[0m 'conv5': [?, 7, 7, 128] --> [?, 5, 5, 128]\n","\u001b[32m[0721 20:33:48 @<ipython-input-4-be49c17f8cc2>:114]\u001b[0m Binarizing weight conv6/W\n","\u001b[32m[0721 20:33:48 @registry.py:90]\u001b[0m 'conv6': [?, 5, 5, 128] --> [?, 1, 1, 512]\n","\u001b[32m[0721 20:33:48 @<ipython-input-4-be49c17f8cc2>:114]\u001b[0m Binarizing weight fc1/W\n","\u001b[32m[0721 20:33:48 @registry.py:90]\u001b[0m 'fc1': [?, 1, 1, 512] --> [?, 10]\n","\u001b[32m[0721 20:33:48 @regularize.py:97]\u001b[0m regularize_cost() found 1 variables to regularize.\n","\u001b[32m[0721 20:33:48 @regularize.py:21]\u001b[0m The following tensors will be regularized: fc1/W:0\n","\u001b[32m[0721 20:33:49 @model_utils.py:67]\u001b[0m \u001b[36mList of Trainable Variables: \n","\u001b[0mname       shape               #elements\n","---------  ----------------  -----------\n","conv0/W    [5, 5, 1, 48]            1200\n","conv0/b    [48]                       48\n","conv1/W    [3, 3, 48, 64]          27648\n","bn1/gamma  [64]                       64\n","bn1/beta   [64]                       64\n","conv2/W    [3, 3, 64, 64]          36864\n","bn2/gamma  [64]                       64\n","bn2/beta   [64]                       64\n","conv3/W    [3, 3, 64, 128]         73728\n","bn3/gamma  [128]                     128\n","bn3/beta   [128]                     128\n","conv4/W    [3, 3, 128, 128]       147456\n","bn4/gamma  [128]                     128\n","bn4/beta   [128]                     128\n","conv5/W    [3, 3, 128, 128]       147456\n","bn5/gamma  [128]                     128\n","bn5/beta   [128]                     128\n","conv6/W    [5, 5, 128, 512]      1638400\n","bn6/gamma  [512]                     512\n","bn6/beta   [512]                     512\n","fc1/W      [512, 10]                5120\n","fc1/b      [10]                       10\u001b[36m\n","Number of trainable variables: 22\n","Number of parameters (elements): 2079978\n","Storage space needed for all trainable variables: 7.93MB\u001b[0m\n","\u001b[32m[0721 20:33:49 @base.py:207]\u001b[0m Setup callbacks graph ...\n","\u001b[32m[0721 20:33:49 @argtools.py:138]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m Starting a process with 'fork' method is efficient but not safe and may cause deadlock or crash.Use 'forkserver' or 'spawn' method instead if you run into such issues.See https://docs.python.org/3/library/multiprocessing.html#contexts-and-start-methods on how to set them.\n","\u001b[32m[0721 20:33:49 @argtools.py:138]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m \"import prctl\" failed! Install python-prctl so that processes can be cleaned with guarantee.\n","\u001b[32m[0721 20:33:50 @inference_runner.py:148]\u001b[0m [InferenceRunner] Building tower 'InferenceTower' on device /gpu:0 ...\n","\u001b[32m[0721 20:33:50 @<ipython-input-4-be49c17f8cc2>:114]\u001b[0m Binarizing weight conv0/W\n","\u001b[32m[0721 20:33:50 @<ipython-input-4-be49c17f8cc2>:114]\u001b[0m Binarizing weight conv1/W\n","\u001b[32m[0721 20:33:50 @<ipython-input-4-be49c17f8cc2>:114]\u001b[0m Binarizing weight conv2/W\n","\u001b[32m[0721 20:33:50 @<ipython-input-4-be49c17f8cc2>:114]\u001b[0m Binarizing weight conv3/W\n","\u001b[32m[0721 20:33:51 @<ipython-input-4-be49c17f8cc2>:114]\u001b[0m Binarizing weight conv4/W\n","\u001b[32m[0721 20:33:51 @<ipython-input-4-be49c17f8cc2>:114]\u001b[0m Binarizing weight conv5/W\n","\u001b[32m[0721 20:33:51 @<ipython-input-4-be49c17f8cc2>:114]\u001b[0m Binarizing weight conv6/W\n","\u001b[32m[0721 20:33:51 @<ipython-input-4-be49c17f8cc2>:114]\u001b[0m Binarizing weight fc1/W\n","\u001b[32m[0721 20:33:51 @summary.py:47]\u001b[0m [MovingAverageSummary] 5 operations in collection 'MOVING_SUMMARY_OPS' will be run with session hooks.\n","\u001b[32m[0721 20:33:51 @summary.py:94]\u001b[0m Summarizing collection 'summaries' of size 22.\n","\u001b[32m[0721 20:33:51 @graph.py:99]\u001b[0m Applying collection UPDATE_OPS of 12 ops.\n","\u001b[32m[0721 20:33:51 @base.py:228]\u001b[0m Creating the session ...\n","\u001b[32m[0721 20:33:58 @base.py:234]\u001b[0m Initializing the session ...\n","\u001b[32m[0721 20:33:58 @base.py:241]\u001b[0m Graph Finalized.\n","\u001b[32m[0721 20:33:58 @concurrency.py:37]\u001b[0m Starting EnqueueThread: enqueue dataflow to TF queue \"QueueInput/input_queue\" ...\n","\u001b[32m[0721 20:33:58 @inference_runner.py:95]\u001b[0m [InferenceRunner] Will eval 79 iterations\n","\u001b[32m[0721 20:33:58 @base.py:273]\u001b[0m Start Epoch 1 ...\n"],"name":"stdout"},{"output_type":"stream","text":["100%|##########|468/468[00:45<00:00,10.25it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0721 20:34:44 @base.py:283]\u001b[0m Epoch 1 (global_step 468) finished, time:45.7 seconds.\n","\u001b[32m[0721 20:34:44 @saver.py:82]\u001b[0m Model saved to train_log/mnist-dorefa-1,4,6/model-468.\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|79/79[00:01<00:00,74.10it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0721 20:34:45 @monitor.py:476]\u001b[0m QueueInput/queue_size: 50\n","\u001b[32m[0721 20:34:45 @monitor.py:476]\u001b[0m accuracy: 0.11345\n","\u001b[32m[0721 20:34:45 @monitor.py:476]\u001b[0m cost: 2.3007\n","\u001b[32m[0721 20:34:45 @monitor.py:476]\u001b[0m cross_entropy_loss: 2.3007\n","\u001b[32m[0721 20:34:45 @monitor.py:476]\u001b[0m param-summary/conv0/W-rms: 0.27889\n","\u001b[32m[0721 20:34:45 @monitor.py:476]\u001b[0m param-summary/conv1/W-rms: 0.06797\n","\u001b[32m[0721 20:34:45 @monitor.py:476]\u001b[0m param-summary/conv2/W-rms: 0.058952\n","\u001b[32m[0721 20:34:45 @monitor.py:476]\u001b[0m param-summary/conv3/W-rms: 0.058888\n","\u001b[32m[0721 20:34:45 @monitor.py:476]\u001b[0m param-summary/conv4/W-rms: 0.041671\n","\u001b[32m[0721 20:34:45 @monitor.py:476]\u001b[0m param-summary/conv5/W-rms: 0.04173\n","\u001b[32m[0721 20:34:45 @monitor.py:476]\u001b[0m param-summary/conv6/W-rms: 0.025032\n","\u001b[32m[0721 20:34:45 @monitor.py:476]\u001b[0m param-summary/fc1/W-rms: 0.064759\n","\u001b[32m[0721 20:34:45 @monitor.py:476]\u001b[0m regularize_cost: 1.0718e-06\n","\u001b[32m[0721 20:34:45 @monitor.py:476]\u001b[0m train_error: 0.88655\n","\u001b[32m[0721 20:34:45 @monitor.py:476]\u001b[0m val_accuracy: 0.10344\n","\u001b[32m[0721 20:34:45 @monitor.py:476]\u001b[0m val_cross_entropy_loss: 3.2816\n","\u001b[32m[0721 20:34:45 @base.py:273]\u001b[0m Start Epoch 2 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|468/468[00:11<00:00,40.76it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0721 20:34:56 @base.py:283]\u001b[0m Epoch 2 (global_step 936) finished, time:11.5 seconds.\n","\u001b[32m[0721 20:34:56 @saver.py:82]\u001b[0m Model saved to train_log/mnist-dorefa-1,4,6/model-936.\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|79/79[00:00<00:00,87.29it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0721 20:34:57 @monitor.py:476]\u001b[0m QueueInput/queue_size: 50\n","\u001b[32m[0721 20:34:57 @monitor.py:476]\u001b[0m accuracy: 0.10165\n","\u001b[32m[0721 20:34:57 @monitor.py:476]\u001b[0m cost: 2.351\n","\u001b[32m[0721 20:34:57 @monitor.py:476]\u001b[0m cross_entropy_loss: 2.351\n","\u001b[32m[0721 20:34:57 @monitor.py:476]\u001b[0m param-summary/conv0/W-rms: 0.28132\n","\u001b[32m[0721 20:34:57 @monitor.py:476]\u001b[0m param-summary/conv1/W-rms: 0.06797\n","\u001b[32m[0721 20:34:57 @monitor.py:476]\u001b[0m param-summary/conv2/W-rms: 0.058952\n","\u001b[32m[0721 20:34:57 @monitor.py:476]\u001b[0m param-summary/conv3/W-rms: 0.058888\n","\u001b[32m[0721 20:34:57 @monitor.py:476]\u001b[0m param-summary/conv4/W-rms: 0.041759\n","\u001b[32m[0721 20:34:57 @monitor.py:476]\u001b[0m param-summary/conv5/W-rms: 0.050283\n","\u001b[32m[0721 20:34:57 @monitor.py:476]\u001b[0m param-summary/conv6/W-rms: 0.036911\n","\u001b[32m[0721 20:34:57 @monitor.py:476]\u001b[0m param-summary/fc1/W-rms: 0.040971\n","\u001b[32m[0721 20:34:57 @monitor.py:476]\u001b[0m regularize_cost: 4.4258e-07\n","\u001b[32m[0721 20:34:57 @monitor.py:476]\u001b[0m train_error: 0.89835\n","\u001b[32m[0721 20:34:57 @monitor.py:476]\u001b[0m val_accuracy: 0.11363\n","\u001b[32m[0721 20:34:57 @monitor.py:476]\u001b[0m val_cross_entropy_loss: 2.3035\n","\u001b[32m[0721 20:34:57 @base.py:273]\u001b[0m Start Epoch 3 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|468/468[00:11<00:00,39.45it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0721 20:35:09 @base.py:283]\u001b[0m Epoch 3 (global_step 1404) finished, time:11.9 seconds.\n","\u001b[32m[0721 20:35:09 @saver.py:82]\u001b[0m Model saved to train_log/mnist-dorefa-1,4,6/model-1404.\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|79/79[00:00<00:00,86.58it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0721 20:35:10 @monitor.py:476]\u001b[0m QueueInput/queue_size: 50\n","\u001b[32m[0721 20:35:10 @monitor.py:476]\u001b[0m accuracy: 0.096461\n","\u001b[32m[0721 20:35:10 @monitor.py:476]\u001b[0m cost: 2.3235\n","\u001b[32m[0721 20:35:10 @monitor.py:476]\u001b[0m cross_entropy_loss: 2.3235\n","\u001b[32m[0721 20:35:10 @monitor.py:476]\u001b[0m param-summary/conv0/W-rms: 0.28132\n","\u001b[32m[0721 20:35:10 @monitor.py:476]\u001b[0m param-summary/conv1/W-rms: 0.06797\n","\u001b[32m[0721 20:35:10 @monitor.py:476]\u001b[0m param-summary/conv2/W-rms: 0.058952\n","\u001b[32m[0721 20:35:10 @monitor.py:476]\u001b[0m param-summary/conv3/W-rms: 0.058888\n","\u001b[32m[0721 20:35:10 @monitor.py:476]\u001b[0m param-summary/conv4/W-rms: 0.041783\n","\u001b[32m[0721 20:35:10 @monitor.py:476]\u001b[0m param-summary/conv5/W-rms: 0.051637\n","\u001b[32m[0721 20:35:10 @monitor.py:476]\u001b[0m param-summary/conv6/W-rms: 0.039544\n","\u001b[32m[0721 20:35:10 @monitor.py:476]\u001b[0m param-summary/fc1/W-rms: 0.035481\n","\u001b[32m[0721 20:35:10 @monitor.py:476]\u001b[0m regularize_cost: 3.2366e-07\n","\u001b[32m[0721 20:35:10 @monitor.py:476]\u001b[0m train_error: 0.90354\n","\u001b[32m[0721 20:35:10 @monitor.py:476]\u001b[0m val_accuracy: 0.11294\n","\u001b[32m[0721 20:35:10 @monitor.py:476]\u001b[0m val_cross_entropy_loss: 2.3014\n","\u001b[32m[0721 20:35:10 @base.py:273]\u001b[0m Start Epoch 4 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|468/468[00:11<00:00,39.73it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0721 20:35:22 @base.py:283]\u001b[0m Epoch 4 (global_step 1872) finished, time:11.8 seconds.\n","\u001b[32m[0721 20:35:22 @saver.py:82]\u001b[0m Model saved to train_log/mnist-dorefa-1,4,6/model-1872.\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|79/79[00:00<00:00,90.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0721 20:35:23 @monitor.py:476]\u001b[0m QueueInput/queue_size: 50\n","\u001b[32m[0721 20:35:23 @monitor.py:476]\u001b[0m accuracy: 0.098001\n","\u001b[32m[0721 20:35:23 @monitor.py:476]\u001b[0m cost: 2.3227\n","\u001b[32m[0721 20:35:23 @monitor.py:476]\u001b[0m cross_entropy_loss: 2.3227\n","\u001b[32m[0721 20:35:23 @monitor.py:476]\u001b[0m param-summary/conv0/W-rms: 0.28132\n","\u001b[32m[0721 20:35:23 @monitor.py:476]\u001b[0m param-summary/conv1/W-rms: 0.06797\n","\u001b[32m[0721 20:35:23 @monitor.py:476]\u001b[0m param-summary/conv2/W-rms: 0.058952\n","\u001b[32m[0721 20:35:23 @monitor.py:476]\u001b[0m param-summary/conv3/W-rms: 0.058888\n","\u001b[32m[0721 20:35:23 @monitor.py:476]\u001b[0m param-summary/conv4/W-rms: 0.041797\n","\u001b[32m[0721 20:35:23 @monitor.py:476]\u001b[0m param-summary/conv5/W-rms: 0.052644\n","\u001b[32m[0721 20:35:23 @monitor.py:476]\u001b[0m param-summary/conv6/W-rms: 0.041417\n","\u001b[32m[0721 20:35:23 @monitor.py:476]\u001b[0m param-summary/fc1/W-rms: 0.033446\n","\u001b[32m[0721 20:35:23 @monitor.py:476]\u001b[0m regularize_cost: 2.8772e-07\n","\u001b[32m[0721 20:35:23 @monitor.py:476]\u001b[0m train_error: 0.902\n","\u001b[32m[0721 20:35:23 @monitor.py:476]\u001b[0m val_accuracy: 0.11294\n","\u001b[32m[0721 20:35:23 @monitor.py:476]\u001b[0m val_cross_entropy_loss: 2.3021\n","\u001b[32m[0721 20:35:23 @base.py:273]\u001b[0m Start Epoch 5 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|468/468[00:11<00:00,39.24it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0721 20:35:35 @base.py:283]\u001b[0m Epoch 5 (global_step 2340) finished, time:11.9 seconds.\n","\u001b[32m[0721 20:35:35 @saver.py:82]\u001b[0m Model saved to train_log/mnist-dorefa-1,4,6/model-2340.\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|79/79[00:00<00:00,88.43it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0721 20:35:36 @monitor.py:476]\u001b[0m QueueInput/queue_size: 50\n","\u001b[32m[0721 20:35:36 @monitor.py:476]\u001b[0m accuracy: 0.10137\n","\u001b[32m[0721 20:35:36 @monitor.py:476]\u001b[0m cost: 2.3175\n","\u001b[32m[0721 20:35:36 @monitor.py:476]\u001b[0m cross_entropy_loss: 2.3175\n","\u001b[32m[0721 20:35:36 @monitor.py:476]\u001b[0m param-summary/conv0/W-rms: 0.28133\n","\u001b[32m[0721 20:35:36 @monitor.py:476]\u001b[0m param-summary/conv1/W-rms: 0.06797\n","\u001b[32m[0721 20:35:36 @monitor.py:476]\u001b[0m param-summary/conv2/W-rms: 0.058952\n","\u001b[32m[0721 20:35:36 @monitor.py:476]\u001b[0m param-summary/conv3/W-rms: 0.058888\n","\u001b[32m[0721 20:35:36 @monitor.py:476]\u001b[0m param-summary/conv4/W-rms: 0.041806\n","\u001b[32m[0721 20:35:36 @monitor.py:476]\u001b[0m param-summary/conv5/W-rms: 0.053379\n","\u001b[32m[0721 20:35:36 @monitor.py:476]\u001b[0m param-summary/conv6/W-rms: 0.04313\n","\u001b[32m[0721 20:35:36 @monitor.py:476]\u001b[0m param-summary/fc1/W-rms: 0.032529\n","\u001b[32m[0721 20:35:36 @monitor.py:476]\u001b[0m regularize_cost: 2.7119e-07\n","\u001b[32m[0721 20:35:36 @monitor.py:476]\u001b[0m train_error: 0.89863\n","\u001b[32m[0721 20:35:36 @monitor.py:476]\u001b[0m val_accuracy: 0.11363\n","\u001b[32m[0721 20:35:36 @monitor.py:476]\u001b[0m val_cross_entropy_loss: 2.3018\n","\u001b[32m[0721 20:35:36 @base.py:273]\u001b[0m Start Epoch 6 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|468/468[00:11<00:00,39.83it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0721 20:35:48 @base.py:283]\u001b[0m Epoch 6 (global_step 2808) finished, time:11.7 seconds.\n","\u001b[32m[0721 20:35:48 @saver.py:82]\u001b[0m Model saved to train_log/mnist-dorefa-1,4,6/model-2808.\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|79/79[00:00<00:00,91.12it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0721 20:35:49 @monitor.py:476]\u001b[0m QueueInput/queue_size: 50\n","\u001b[32m[0721 20:35:49 @monitor.py:476]\u001b[0m accuracy: 0.099836\n","\u001b[32m[0721 20:35:49 @monitor.py:476]\u001b[0m cost: 2.3155\n","\u001b[32m[0721 20:35:49 @monitor.py:476]\u001b[0m cross_entropy_loss: 2.3155\n","\u001b[32m[0721 20:35:49 @monitor.py:476]\u001b[0m param-summary/conv0/W-rms: 0.28133\n","\u001b[32m[0721 20:35:49 @monitor.py:476]\u001b[0m param-summary/conv1/W-rms: 0.06797\n","\u001b[32m[0721 20:35:49 @monitor.py:476]\u001b[0m param-summary/conv2/W-rms: 0.058952\n","\u001b[32m[0721 20:35:49 @monitor.py:476]\u001b[0m param-summary/conv3/W-rms: 0.058888\n","\u001b[32m[0721 20:35:49 @monitor.py:476]\u001b[0m param-summary/conv4/W-rms: 0.041819\n","\u001b[32m[0721 20:35:49 @monitor.py:476]\u001b[0m param-summary/conv5/W-rms: 0.054352\n","\u001b[32m[0721 20:35:49 @monitor.py:476]\u001b[0m param-summary/conv6/W-rms: 0.044719\n","\u001b[32m[0721 20:35:49 @monitor.py:476]\u001b[0m param-summary/fc1/W-rms: 0.032024\n","\u001b[32m[0721 20:35:49 @monitor.py:476]\u001b[0m regularize_cost: 2.6212e-07\n","\u001b[32m[0721 20:35:49 @monitor.py:476]\u001b[0m train_error: 0.90016\n","\u001b[32m[0721 20:35:49 @monitor.py:476]\u001b[0m val_accuracy: 0.11363\n","\u001b[32m[0721 20:35:49 @monitor.py:476]\u001b[0m val_cross_entropy_loss: 2.3017\n","\u001b[32m[0721 20:35:49 @base.py:273]\u001b[0m Start Epoch 7 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|468/468[00:12<00:00,38.82it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0721 20:36:01 @base.py:283]\u001b[0m Epoch 7 (global_step 3276) finished, time:12.1 seconds.\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0721 20:36:01 @saver.py:82]\u001b[0m Model saved to train_log/mnist-dorefa-1,4,6/model-3276.\n"],"name":"stdout"},{"output_type":"stream","text":["100%|##########|79/79[00:00<00:00,86.42it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0721 20:36:02 @monitor.py:476]\u001b[0m QueueInput/queue_size: 50\n","\u001b[32m[0721 20:36:02 @monitor.py:476]\u001b[0m accuracy: 0.10347\n","\u001b[32m[0721 20:36:02 @monitor.py:476]\u001b[0m cost: 2.315\n","\u001b[32m[0721 20:36:02 @monitor.py:476]\u001b[0m cross_entropy_loss: 2.315\n","\u001b[32m[0721 20:36:02 @monitor.py:476]\u001b[0m param-summary/conv0/W-rms: 0.28133\n","\u001b[32m[0721 20:36:02 @monitor.py:476]\u001b[0m param-summary/conv1/W-rms: 0.06797\n","\u001b[32m[0721 20:36:02 @monitor.py:476]\u001b[0m param-summary/conv2/W-rms: 0.058952\n","\u001b[32m[0721 20:36:02 @monitor.py:476]\u001b[0m param-summary/conv3/W-rms: 0.058888\n","\u001b[32m[0721 20:36:02 @monitor.py:476]\u001b[0m param-summary/conv4/W-rms: 0.041846\n","\u001b[32m[0721 20:36:02 @monitor.py:476]\u001b[0m param-summary/conv5/W-rms: 0.055531\n","\u001b[32m[0721 20:36:02 @monitor.py:476]\u001b[0m param-summary/conv6/W-rms: 0.046469\n","\u001b[32m[0721 20:36:02 @monitor.py:476]\u001b[0m param-summary/fc1/W-rms: 0.031837\n","\u001b[32m[0721 20:36:02 @monitor.py:476]\u001b[0m regularize_cost: 2.6003e-07\n","\u001b[32m[0721 20:36:02 @monitor.py:476]\u001b[0m train_error: 0.89653\n","\u001b[32m[0721 20:36:02 @monitor.py:476]\u001b[0m val_accuracy: 0.11363\n","\u001b[32m[0721 20:36:02 @monitor.py:476]\u001b[0m val_cross_entropy_loss: 2.3019\n","\u001b[32m[0721 20:36:02 @base.py:273]\u001b[0m Start Epoch 8 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|468/468[00:12<00:00,39.00it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0721 20:36:14 @base.py:283]\u001b[0m Epoch 8 (global_step 3744) finished, time:12 seconds.\n","\u001b[32m[0721 20:36:14 @saver.py:82]\u001b[0m Model saved to train_log/mnist-dorefa-1,4,6/model-3744.\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|79/79[00:00<00:00,87.10it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0721 20:36:15 @monitor.py:476]\u001b[0m QueueInput/queue_size: 50\n","\u001b[32m[0721 20:36:15 @monitor.py:476]\u001b[0m accuracy: 0.10337\n","\u001b[32m[0721 20:36:15 @monitor.py:476]\u001b[0m cost: 2.3111\n","\u001b[32m[0721 20:36:15 @monitor.py:476]\u001b[0m cross_entropy_loss: 2.3111\n","\u001b[32m[0721 20:36:15 @monitor.py:476]\u001b[0m param-summary/conv0/W-rms: 0.28133\n","\u001b[32m[0721 20:36:15 @monitor.py:476]\u001b[0m param-summary/conv1/W-rms: 0.06797\n","\u001b[32m[0721 20:36:15 @monitor.py:476]\u001b[0m param-summary/conv2/W-rms: 0.058952\n","\u001b[32m[0721 20:36:15 @monitor.py:476]\u001b[0m param-summary/conv3/W-rms: 0.058888\n","\u001b[32m[0721 20:36:15 @monitor.py:476]\u001b[0m param-summary/conv4/W-rms: 0.041875\n","\u001b[32m[0721 20:36:15 @monitor.py:476]\u001b[0m param-summary/conv5/W-rms: 0.056764\n","\u001b[32m[0721 20:36:15 @monitor.py:476]\u001b[0m param-summary/conv6/W-rms: 0.048136\n","\u001b[32m[0721 20:36:15 @monitor.py:476]\u001b[0m param-summary/fc1/W-rms: 0.03189\n","\u001b[32m[0721 20:36:15 @monitor.py:476]\u001b[0m regularize_cost: 2.6001e-07\n","\u001b[32m[0721 20:36:15 @monitor.py:476]\u001b[0m train_error: 0.89663\n","\u001b[32m[0721 20:36:15 @monitor.py:476]\u001b[0m val_accuracy: 0.11501\n","\u001b[32m[0721 20:36:15 @monitor.py:476]\u001b[0m val_cross_entropy_loss: 2.3013\n","\u001b[32m[0721 20:36:15 @base.py:273]\u001b[0m Start Epoch 9 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|468/468[00:12<00:00,38.88it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0721 20:36:27 @base.py:283]\u001b[0m Epoch 9 (global_step 4212) finished, time:12 seconds.\n","\u001b[32m[0721 20:36:27 @saver.py:82]\u001b[0m Model saved to train_log/mnist-dorefa-1,4,6/model-4212.\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|79/79[00:00<00:00,91.11it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0721 20:36:28 @monitor.py:476]\u001b[0m QueueInput/queue_size: 50\n","\u001b[32m[0721 20:36:28 @monitor.py:476]\u001b[0m accuracy: 0.10776\n","\u001b[32m[0721 20:36:28 @monitor.py:476]\u001b[0m cost: 2.311\n","\u001b[32m[0721 20:36:28 @monitor.py:476]\u001b[0m cross_entropy_loss: 2.311\n","\u001b[32m[0721 20:36:28 @monitor.py:476]\u001b[0m param-summary/conv0/W-rms: 0.28133\n","\u001b[32m[0721 20:36:28 @monitor.py:476]\u001b[0m param-summary/conv1/W-rms: 0.06797\n","\u001b[32m[0721 20:36:28 @monitor.py:476]\u001b[0m param-summary/conv2/W-rms: 0.058952\n","\u001b[32m[0721 20:36:28 @monitor.py:476]\u001b[0m param-summary/conv3/W-rms: 0.058888\n","\u001b[32m[0721 20:36:28 @monitor.py:476]\u001b[0m param-summary/conv4/W-rms: 0.041877\n","\u001b[32m[0721 20:36:28 @monitor.py:476]\u001b[0m param-summary/conv5/W-rms: 0.057685\n","\u001b[32m[0721 20:36:28 @monitor.py:476]\u001b[0m param-summary/conv6/W-rms: 0.049714\n","\u001b[32m[0721 20:36:28 @monitor.py:476]\u001b[0m param-summary/fc1/W-rms: 0.032177\n","\u001b[32m[0721 20:36:28 @monitor.py:476]\u001b[0m regularize_cost: 2.6482e-07\n","\u001b[32m[0721 20:36:28 @monitor.py:476]\u001b[0m train_error: 0.89224\n","\u001b[32m[0721 20:36:28 @monitor.py:476]\u001b[0m val_accuracy: 0.11363\n","\u001b[32m[0721 20:36:28 @monitor.py:476]\u001b[0m val_cross_entropy_loss: 2.3013\n","\u001b[32m[0721 20:36:28 @base.py:273]\u001b[0m Start Epoch 10 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|468/468[00:11<00:00,39.35it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0721 20:36:40 @base.py:283]\u001b[0m Epoch 10 (global_step 4680) finished, time:11.9 seconds.\n","\u001b[32m[0721 20:36:40 @saver.py:82]\u001b[0m Model saved to train_log/mnist-dorefa-1,4,6/model-4680.\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|79/79[00:00<00:00,87.33it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0721 20:36:41 @monitor.py:476]\u001b[0m QueueInput/queue_size: 50\n","\u001b[32m[0721 20:36:41 @monitor.py:476]\u001b[0m accuracy: 0.10364\n","\u001b[32m[0721 20:36:41 @monitor.py:476]\u001b[0m cost: 2.309\n","\u001b[32m[0721 20:36:41 @monitor.py:476]\u001b[0m cross_entropy_loss: 2.309\n","\u001b[32m[0721 20:36:41 @monitor.py:476]\u001b[0m param-summary/conv0/W-rms: 0.28133\n","\u001b[32m[0721 20:36:41 @monitor.py:476]\u001b[0m param-summary/conv1/W-rms: 0.06797\n","\u001b[32m[0721 20:36:41 @monitor.py:476]\u001b[0m param-summary/conv2/W-rms: 0.058952\n","\u001b[32m[0721 20:36:41 @monitor.py:476]\u001b[0m param-summary/conv3/W-rms: 0.058888\n","\u001b[32m[0721 20:36:41 @monitor.py:476]\u001b[0m param-summary/conv4/W-rms: 0.0419\n","\u001b[32m[0721 20:36:41 @monitor.py:476]\u001b[0m param-summary/conv5/W-rms: 0.0589\n","\u001b[32m[0721 20:36:41 @monitor.py:476]\u001b[0m param-summary/conv6/W-rms: 0.051421\n","\u001b[32m[0721 20:36:41 @monitor.py:476]\u001b[0m param-summary/fc1/W-rms: 0.032217\n","\u001b[32m[0721 20:36:41 @monitor.py:476]\u001b[0m regularize_cost: 2.657e-07\n","\u001b[32m[0721 20:36:41 @monitor.py:476]\u001b[0m train_error: 0.89636\n","\u001b[32m[0721 20:36:41 @monitor.py:476]\u001b[0m val_accuracy: 0.11363\n","\u001b[32m[0721 20:36:41 @monitor.py:476]\u001b[0m val_cross_entropy_loss: 2.3013\n","\u001b[32m[0721 20:36:41 @base.py:287]\u001b[0m Training has finished!\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"\\nif __name__ == '__main__':\\n    parser = argparse.ArgumentParser()\\n    parser.add_argument('--dorefa',\\n                        help='number of bits for W,A,G, separated by comma. Defaults to '1,2,4'',\\n                        default='1,2,4')\\n    args = parser.parse_args()\\n\\n    BITW, BITA, BITG = map(int, args.dorefa.split(','))\\n    config = get_config()\\n    launch_train_with_config(config, SimpleTrainer())\\n\""]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"mduuAqCeuc4B","colab":{"base_uri":"https://localhost:8080/","height":315},"executionInfo":{"status":"ok","timestamp":1626899874976,"user_tz":-120,"elapsed":635,"user":{"displayName":"Lorenzo Pasco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgShaitSLZm3zyLVjMQT7ZzTrEV3kQEXha_A9lkVw=s64","userId":"01314717049817932576"}},"outputId":"c39bd98d-1698-40d3-a45a-f1f07392a8a0"},"source":["import json\n","import matplotlib.pyplot as plt\n","\n","f = open(\"train_log/mnist-dorefa-1,4,6/stats.json\",\"r\")\n","\n","data = json.load(f)\n","accuracy = []\n","val_accuracy = []\n","for ob in data:\n","  accuracy.append(ob[\"accuracy\"])\n","  val_accuracy.append(ob[\"val_accuracy\"])\n","\n","epochs = range(len(accuracy))\n","\n","plt.plot(epochs, accuracy, 'r', label='Training acc')\n","plt.plot(epochs, val_accuracy, 'b', label='Validation acc')\n","plt.title('Training and validation accuracy')\n","plt.legend()\n","plt.figure()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<Figure size 432x288 with 0 Axes>"]},"metadata":{"tags":[]},"execution_count":5},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 0 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ST3WBdVha1W-","executionInfo":{"status":"ok","timestamp":1626899879206,"user_tz":-120,"elapsed":222,"user":{"displayName":"Lorenzo Pasco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgShaitSLZm3zyLVjMQT7ZzTrEV3kQEXha_A9lkVw=s64","userId":"01314717049817932576"}},"outputId":"a35a5683-39c9-4f23-ddca-2f6f976e8b65"},"source":["from tabulate import tabulate\n","import matplotlib.pyplot as plt\n","\n","ep = [i+1 for i in epochs]\n","table_acc = {\"Epochs\" : ep, \"Accuracy\":accuracy}\n","table_val_acc = {\"Epochs\" : ep, \"Accuracy\":val_accuracy}\n","\n","print(\"ACCURACY\\n\")\n","print(tabulate(table_acc, headers='keys', tablefmt='fancy_grid'))\n","print(\"\\nVALIDATION ACCURACY\\n\")\n","print(tabulate(table_val_acc, headers='keys', tablefmt='fancy_grid'))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["ACCURACY\n","\n","╒══════════╤════════════╕\n","│   Epochs │   Accuracy │\n","╞══════════╪════════════╡\n","│        1 │  0.113447  │\n","├──────────┼────────────┤\n","│        2 │  0.101646  │\n","├──────────┼────────────┤\n","│        3 │  0.0964607 │\n","├──────────┼────────────┤\n","│        4 │  0.0980009 │\n","├──────────┼────────────┤\n","│        5 │  0.101369  │\n","├──────────┼────────────┤\n","│        6 │  0.0998359 │\n","├──────────┼────────────┤\n","│        7 │  0.103465  │\n","├──────────┼────────────┤\n","│        8 │  0.103373  │\n","├──────────┼────────────┤\n","│        9 │  0.107758  │\n","├──────────┼────────────┤\n","│       10 │  0.103635  │\n","╘══════════╧════════════╛\n","\n","VALIDATION ACCURACY\n","\n","╒══════════╤════════════╕\n","│   Epochs │   Accuracy │\n","╞══════════╪════════════╡\n","│        1 │   0.103441 │\n","├──────────┼────────────┤\n","│        2 │   0.113627 │\n","├──────────┼────────────┤\n","│        3 │   0.112935 │\n","├──────────┼────────────┤\n","│        4 │   0.112935 │\n","├──────────┼────────────┤\n","│        5 │   0.113627 │\n","├──────────┼────────────┤\n","│        6 │   0.113627 │\n","├──────────┼────────────┤\n","│        7 │   0.113627 │\n","├──────────┼────────────┤\n","│        8 │   0.115012 │\n","├──────────┼────────────┤\n","│        9 │   0.113627 │\n","├──────────┼────────────┤\n","│       10 │   0.113627 │\n","╘══════════╧════════════╛\n"],"name":"stdout"}]}]}