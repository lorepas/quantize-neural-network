{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"dorefa.ipynb","provenance":[],"authorship_tag":"ABX9TyMdVP9L6YSLKuSUfgk1hCHp"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"5qzKFEQKqXDt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621518512167,"user_tz":-120,"elapsed":987,"user":{"displayName":"Lorenzo Pasco","photoUrl":"https://lh6.googleusercontent.com/-CYe3n06kEO8/AAAAAAAAAAI/AAAAAAAABA0/IYoarPKO134/s64/photo.jpg","userId":"01314717049817932576"}},"outputId":"2308b763-792e-4d35-8586-98ae156692bc"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZNfm7ovA625P","executionInfo":{"status":"ok","timestamp":1621518512168,"user_tz":-120,"elapsed":985,"user":{"displayName":"Lorenzo Pasco","photoUrl":"https://lh6.googleusercontent.com/-CYe3n06kEO8/AAAAAAAAAAI/AAAAAAAABA0/IYoarPKO134/s64/photo.jpg","userId":"01314717049817932576"}}},"source":["# -*- coding: utf-8 -*-\n","# File: dorefa.py\n","# Author: Yuxin Wu\n","\n","import tensorflow as tf\n","\n","\n","def get_dorefa(bitW, bitA, bitG):\n","    \"\"\"\n","    Return the three quantization functions fw, fa, fg, for weights, activations and gradients respectively\n","    \"\"\"\n","    def quantize(x, k):\n","        n = float(2 ** k - 1)\n","\n","        @tf.custom_gradient\n","        def _quantize(x):\n","            return tf.round(x * n) / n, lambda dy: dy\n","\n","        return _quantize(x)\n","\n","    def fw(x):\n","        if bitW == 32:\n","            return x\n","\n","        if bitW == 1:   # BWN\n","            E = tf.stop_gradient(tf.reduce_mean(tf.abs(x)))\n","\n","            @tf.custom_gradient\n","            def _sign(x):\n","                return tf.where(tf.equal(x, 0), tf.ones_like(x), tf.sign(x / E)) * E, lambda dy: dy\n","\n","            return _sign(x)\n","\n","        x = tf.tanh(x)\n","        x = x / tf.reduce_max(tf.abs(x)) * 0.5 + 0.5\n","        return 2 * quantize(x, bitW) - 1\n","\n","    def fa(x):\n","        if bitA == 32:\n","            return x\n","        return quantize(x, bitA)\n","\n","    def fg(x):\n","        if bitG == 32:\n","            return x\n","\n","        @tf.custom_gradient\n","        def _identity(input):\n","            def grad_fg(x):\n","                rank = x.get_shape().ndims\n","                assert rank is not None\n","                maxx = tf.reduce_max(tf.abs(x), list(range(1, rank)), keep_dims=True)\n","                x = x / maxx\n","                n = float(2**bitG - 1)\n","                x = x * 0.5 + 0.5 + tf.random_uniform(\n","                    tf.shape(x), minval=-0.5 / n, maxval=0.5 / n)\n","                x = tf.clip_by_value(x, 0.0, 1.0)\n","                x = quantize(x, bitG) - 0.5\n","                return x * maxx * 2\n","\n","            return input, grad_fg\n","\n","        return _identity(x)\n","    return fw, fa, fg\n","\n","\n","def ternarize(x, thresh=0.05):\n","    \"\"\"\n","    Implemented Trained Ternary Quantization:\n","    https://arxiv.org/abs/1612.01064\n","    Code modified from the authors' at:\n","    https://github.com/czhu95/ternarynet/blob/master/examples/Ternary-Net/ternary.py\n","    \"\"\"\n","    shape = x.get_shape()\n","\n","    thre_x = tf.stop_gradient(tf.reduce_max(tf.abs(x)) * thresh)\n","\n","    w_p = tf.get_variable('Wp', initializer=1.0, dtype=tf.float32)\n","    w_n = tf.get_variable('Wn', initializer=1.0, dtype=tf.float32)\n","\n","    tf.summary.scalar(w_p.op.name + '-summary', w_p)\n","    tf.summary.scalar(w_n.op.name + '-summary', w_n)\n","\n","    mask = tf.ones(shape)\n","    mask_p = tf.where(x > thre_x, tf.ones(shape) * w_p, mask)\n","    mask_np = tf.where(x < -thre_x, tf.ones(shape) * w_n, mask_p)\n","    mask_z = tf.where((x < thre_x) & (x > - thre_x), tf.zeros(shape), mask)\n","\n","    @tf.custom_gradient\n","    def _sign_mask(x):\n","        return tf.sign(x) * mask_z, lambda dy: dy\n","\n","    w = _sign_mask(x)\n","\n","    w = w * mask_np\n","\n","    tf.summary.histogram(w.name, w)\n","    return w"],"execution_count":4,"outputs":[]}]}