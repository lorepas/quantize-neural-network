{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"mnist-dorefa_first&last_avg_pooling.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNFYBdoL23r3PzfUVUjZnDT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"5qzKFEQKqXDt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626874426342,"user_tz":-120,"elapsed":19005,"user":{"displayName":"Lorenzo Pasco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgShaitSLZm3zyLVjMQT7ZzTrEV3kQEXha_A9lkVw=s64","userId":"01314717049817932576"}},"outputId":"b6040e62-7b1b-437b-aede-02ec84c02363"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eDXKVoHj26H8","executionInfo":{"status":"ok","timestamp":1626874433427,"user_tz":-120,"elapsed":5001,"user":{"displayName":"Lorenzo Pasco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgShaitSLZm3zyLVjMQT7ZzTrEV3kQEXha_A9lkVw=s64","userId":"01314717049817932576"}},"outputId":"b1f03351-dbad-4072-ef4c-d734c1429884"},"source":["!pip install tensorpack\n","\n","%cd gdrive/MyDrive/SEAI_Project"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting tensorpack\n","  Downloading tensorpack-0.11-py2.py3-none-any.whl (296 kB)\n","\u001b[?25l\r\u001b[K     |█                               | 10 kB 22.2 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 20 kB 25.1 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 30 kB 24.6 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 40 kB 19.2 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 51 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 61 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 71 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 81 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 92 kB 14.2 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 102 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 112 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 122 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 133 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 143 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 153 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 163 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 174 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 184 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 194 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 204 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 215 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 225 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 235 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 245 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 256 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 266 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 276 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 286 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 296 kB 13.2 MB/s \n","\u001b[?25hRequirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.7/dist-packages (from tensorpack) (0.8.9)\n","Collecting msgpack-numpy>=0.4.4.2\n","  Downloading msgpack_numpy-0.4.7.1-py2.py3-none-any.whl (6.7 kB)\n","Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.7/dist-packages (from tensorpack) (4.41.1)\n","Requirement already satisfied: msgpack>=0.5.2 in /usr/local/lib/python3.7/dist-packages (from tensorpack) (1.0.2)\n","Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.7/dist-packages (from tensorpack) (1.1.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tensorpack) (1.15.0)\n","Requirement already satisfied: pyzmq>=16 in /usr/local/lib/python3.7/dist-packages (from tensorpack) (22.1.0)\n","Requirement already satisfied: psutil>=5 in /usr/local/lib/python3.7/dist-packages (from tensorpack) (5.4.8)\n","Requirement already satisfied: numpy>=1.14 in /usr/local/lib/python3.7/dist-packages (from tensorpack) (1.19.5)\n","Installing collected packages: msgpack-numpy, tensorpack\n","Successfully installed msgpack-numpy-0.4.7.1 tensorpack-0.11\n","/content/gdrive/MyDrive/SEAI_Project\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"47qPSLMU19HM","executionInfo":{"status":"ok","timestamp":1626518030781,"user_tz":-120,"elapsed":139863,"user":{"displayName":"Lorenzo Pasco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgShaitSLZm3zyLVjMQT7ZzTrEV3kQEXha_A9lkVw=s64","userId":"01314717049817932576"}},"outputId":"42aae246-6577-4817-e7af-58da90fc03cd"},"source":["#!/usr/bin/env python\n","# -*- coding: utf-8 -*-\n","# File: svhn-digit-dorefa.py\n","# Author: Yuxin Wu\n","\n","import argparse\n","import os\n","import tensorflow as tf\n","\n","from tensorpack import *\n","from tensorpack.dataflow import dataset\n","from tensorpack.tfutils.summary import add_moving_summary, add_param_summary\n","from tensorpack.tfutils.varreplace import remap_variables\n","\n","\"\"\"\n","This is a tensorpack script for the SVHN results in paper:\n","DoReFa-Net: Training Low Bitwidth Convolutional Neural Networks with Low Bitwidth Gradients\n","http://arxiv.org/abs/1606.06160\n","The original experiements are performed on a proprietary framework.\n","This is our attempt to reproduce it on tensorpack.\n","Accuracy:\n","    With (W,A,G)=(1,1,4), can reach 3.1~3.2% error after 150 epochs.\n","    With (W,A,G)=(1,2,4), error is 3.0~3.1%.\n","    With (W,A,G)=(32,32,32), error is about 2.3%.\n","Speed:\n","    With quantization, 60 batch/s on 1 1080Ti. (4721 batch / epoch)\n","To Run:\n","    ./svhn-digit-dorefa.py --dorefa 1,2,4\n","\"\"\"\n","tf.compat.v1.reset_default_graph()\n","\n","BITW = 1\n","BITA = 2\n","BITG = 4\n","\n","\"\"\"\n","imported from dorefa file\n","\"\"\"\n","def get_dorefa(bitW, bitA, bitG):\n","    \"\"\"\n","    Return the three quantization functions fw, fa, fg, for weights, activations and gradients respectively\n","    \"\"\"\n","    def quantize(x, k):\n","        n = float(2 ** k - 1)\n","\n","        @tf.custom_gradient\n","        def _quantize(x):\n","            return tf.round(x * n) / n, lambda dy: dy\n","\n","        return _quantize(x)\n","\n","    def fw(x):\n","        if bitW == 32:\n","            return x\n","\n","        if bitW == 1:   # BWN\n","            E = tf.stop_gradient(tf.reduce_mean(tf.abs(x)))\n","\n","            @tf.custom_gradient\n","            def _sign(x):\n","                return tf.where(tf.equal(x, 0), tf.ones_like(x), tf.sign(x / E)) * E, lambda dy: dy\n","\n","            return _sign(x)\n","\n","        x = tf.tanh(x)\n","        x = x / tf.reduce_max(tf.abs(x)) * 0.5 + 0.5\n","        return 2 * quantize(x, bitW) - 1\n","\n","    def fa(x):\n","        if bitA == 32:\n","            return x\n","        return quantize(x, bitA)\n","\n","    def fg(x):\n","        if bitG == 32:\n","            return x\n","\n","        @tf.custom_gradient\n","        def _identity(input):\n","            def grad_fg(x):\n","                rank = x.get_shape().ndims\n","                assert rank is not None\n","                maxx = tf.reduce_max(tf.abs(x), list(range(1, rank)), keepdims=True)\n","                x = x / maxx\n","                n = float(2**bitG - 1)\n","                x = x * 0.5 + 0.5 + tf.random.uniform(\n","                    tf.shape(x), minval=-0.5 / n, maxval=0.5 / n)\n","                x = tf.clip_by_value(x, 0.0, 1.0)\n","                x = quantize(x, bitG) - 0.5\n","                return x * maxx * 2\n","\n","            return input, grad_fg\n","\n","        return _identity(x)\n","    return fw, fa, fg\n","\n","\n","class Model(ModelDesc):\n","    def inputs(self):\n","        return [tf.TensorSpec([None, 40, 40], tf.float32, 'input'),\n","                tf.TensorSpec([None], tf.int32, 'label')]\n","\n","    def build_graph(self, image, label):\n","        fw, fa, fg = get_dorefa(BITW, BITA, BITG)\n","\n","        # monkey-patch tf.get_variable to apply fw\n","        def binarize_weight(v):\n","            name = v.op.name\n","            # don't binarize first and last layer\n","            if not name.endswith('W'):\n","                return v\n","            else:\n","                logger.info(\"Binarizing weight {}\".format(v.op.name))\n","                return fw(v)\n","\n","        def nonlin(x):\n","            if BITA == 32:\n","                return tf.nn.relu(x)\n","            return tf.clip_by_value(x, 0.0, 1.0)\n","\n","        def activate(x):\n","            return fa(nonlin(x))\n","\n","        image = tf.expand_dims(image, 3)\n","        image = image / 256.0\n","\n","        with remap_variables(binarize_weight), \\\n","                argscope(BatchNorm, momentum=0.9, epsilon=1e-4), \\\n","                argscope(Conv2D, use_bias=False):\n","            logits = (LinearWrap(image)\n","                      .Conv2D('conv0', 48, 5, padding='VALID', use_bias=True)\n","                      .AvgPooling('pool0', 2, padding='SAME')\n","                      .apply(activate)\n","                      # 18\n","                      .Conv2D('conv1', 64, 3, padding='SAME')\n","                      .apply(fg)\n","                      .BatchNorm('bn1').apply(activate)\n","#AVGPooling\n","                      .Conv2D('conv2', 64, 3, padding='SAME')\n","                      .apply(fg)\n","                      .BatchNorm('bn2')\n","                      .AvgPooling('pool1', 2, padding='SAME')\n","                      .apply(activate)\n","                      # 9\n","                      .Conv2D('conv3', 128, 3, padding='VALID')\n","                      .apply(fg)\n","                      .BatchNorm('bn3').apply(activate)\n","                      # 7\n","\n","                      .Conv2D('conv4', 128, 3, padding='SAME')\n","                      .apply(fg)\n","                      .BatchNorm('bn4').apply(activate)\n","\n","                      .Conv2D('conv5', 128, 3, padding='VALID')\n","                      .apply(fg)\n","                      .BatchNorm('bn5').apply(activate)\n","                      # 5\n","                      .Dropout(rate=0.5 if self.training else 0.0)\n","                      .Conv2D('conv6', 512, 5, padding='VALID')\n","                      .apply(fg).BatchNorm('bn6')\n","                      .apply(nonlin)\n","                      .FullyConnected('fc1', 10)())\n","        tf.nn.softmax(logits, name='output')\n","\n","        correct = tf.cast(tf.nn.in_top_k(predictions=logits, targets=label, k=1), tf.float32, name='correct')\n","        accuracy = tf.reduce_mean(correct, name='accuracy')\n","        train_error = tf.reduce_mean(1 - correct, name='train_error')\n","        summary.add_moving_summary(train_error, accuracy)\n","        \n","        cost = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=label)\n","        cost = tf.reduce_mean(cost, name='cross_entropy_loss')\n","        # weight decay on all W of fc layers\n","        wd_cost = regularize_cost('fc.*/W', l2_regularizer(1e-7))\n","        add_param_summary(('.*/W', ['histogram', 'rms']))\n","        total_cost = tf.add_n([cost, wd_cost], name='cost')\n","        add_moving_summary(cost, wd_cost, total_cost)\n","        return total_cost\n","\n","    def optimizer(self):\n","        lr = tf.compat.v1.train.exponential_decay(\n","            learning_rate=1e-3,\n","            global_step=get_global_step_var(),\n","            decay_steps=4721 * 100,\n","            decay_rate=0.5, staircase=True, name='learning_rate')\n","        tf.summary.scalar('lr', lr)\n","\n","        return tf.compat.v1.train.AdamOptimizer(lr, epsilon=1e-5)\n","\n","\n","def get_config():\n","    logger.set_logger_dir(os.path.join('train_log', 'mnist-dorefa-{}'.format(args)))\n","\n","    # prepare dataset\n","    data_train = dataset.Mnist('train', shuffle=True)\n","    data_test = dataset.Mnist('test', shuffle=True)\n","\n","    augmentors = [imgaug.Resize((40, 40))]\n","    data_train = AugmentImageComponent(data_train, augmentors)\n","    data_train = BatchData(data_train, 128)\n","    data_train = MultiProcessRunnerZMQ(data_train, 5)\n","\n","    augmentors = [imgaug.Resize((40, 40))]\n","    data_test = AugmentImageComponent(data_test, augmentors)\n","    data_test = BatchData(data_test, 128, remainder=True)\n","\n","    return TrainConfig(\n","        data=QueueInput(data_train),\n","        callbacks=[\n","            ModelSaver(),\n","            InferenceRunner(    # run inference(for validation) after every epoch\n","                data_test,   # the DataFlow instance used for validation\n","                ScalarStats(    # produce `val_accuracy` and `val_cross_entropy_loss`\n","                    ['cross_entropy_loss', 'accuracy'], prefix='val'))\n","        ],\n","        model=Model(),\n","        max_epoch=10,\n","    )\n","\n","args = \"1,2,4\"\n","BITW, BITA, BITG = map(int, args.split(','))\n","config = get_config()\n","launch_train_with_config(config, SimpleTrainer())\n","\n","'''\n","if __name__ == '__main__':\n","    parser = argparse.ArgumentParser()\n","    parser.add_argument('--dorefa',\n","                        help='number of bits for W,A,G, separated by comma. Defaults to \\'1,2,4\\'',\n","                        default='1,2,4')\n","    args = parser.parse_args()\n","\n","    BITW, BITA, BITG = map(int, args.dorefa.split(','))\n","    config = get_config()\n","    launch_train_with_config(config, SimpleTrainer())\n","'''"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[32m[0717 10:31:31 @logger.py:128]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m Log directory train_log/mnist-dorefa-1,2,4 exists! Use 'd' to delete it. \n","\u001b[32m[0717 10:31:31 @logger.py:131]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m If you're resuming from a previous run, you can choose to keep it.\n","Press any other key to exit. \n","Select Action: k (keep) / d (delete) / q (quit):k\n","\u001b[32m[0717 10:31:34 @logger.py:85]\u001b[0m Existing log file 'train_log/mnist-dorefa-1,2,4/log.log' backuped to 'train_log/mnist-dorefa-1,2,4/log.log.0717-103134'\n","\u001b[32m[0717 10:31:34 @logger.py:92]\u001b[0m Argv: /usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py -f /root/.local/share/jupyter/runtime/kernel-728d80ac-4555-4ad0-a400-d2e2f90775c2.json\n","\u001b[32m[0717 10:31:34 @parallel.py:340]\u001b[0m [MultiProcessRunnerZMQ] Will fork a dataflow more than one times. This assumes the datapoints are i.i.d.\n","\u001b[32m[0717 10:31:34 @input_source.py:221]\u001b[0m Setting up the queue 'QueueInput/input_queue' for CPU prefetching ...\n","\u001b[32m[0717 10:31:34 @trainers.py:48]\u001b[0m Building graph for a single training tower ...\n","\u001b[32m[0717 10:31:34 @<ipython-input-4-7ff13444fb02>:113]\u001b[0m Binarizing weight conv0/W\n","\u001b[32m[0717 10:31:34 @<ipython-input-4-7ff13444fb02>:113]\u001b[0m Binarizing weight conv1/W\n","\u001b[32m[0717 10:31:34 @<ipython-input-4-7ff13444fb02>:113]\u001b[0m Binarizing weight conv2/W\n","\u001b[32m[0717 10:31:34 @<ipython-input-4-7ff13444fb02>:113]\u001b[0m Binarizing weight conv3/W\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1692: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n","  warnings.warn('`layer.apply` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0717 10:31:34 @<ipython-input-4-7ff13444fb02>:113]\u001b[0m Binarizing weight conv4/W\n","\u001b[32m[0717 10:31:34 @<ipython-input-4-7ff13444fb02>:113]\u001b[0m Binarizing weight conv5/W\n","\u001b[32m[0717 10:31:34 @<ipython-input-4-7ff13444fb02>:113]\u001b[0m Binarizing weight conv6/W\n","\u001b[32m[0717 10:31:35 @<ipython-input-4-7ff13444fb02>:113]\u001b[0m Binarizing weight fc1/W\n","\u001b[32m[0717 10:31:35 @regularize.py:97]\u001b[0m regularize_cost() found 1 variables to regularize.\n","\u001b[32m[0717 10:31:35 @regularize.py:21]\u001b[0m The following tensors will be regularized: fc1/W:0\n","\u001b[32m[0717 10:31:35 @model_utils.py:67]\u001b[0m \u001b[36mList of Trainable Variables: \n","\u001b[0mname       shape               #elements\n","---------  ----------------  -----------\n","conv0/W    [5, 5, 1, 48]            1200\n","conv0/b    [48]                       48\n","conv1/W    [3, 3, 48, 64]          27648\n","bn1/gamma  [64]                       64\n","bn1/beta   [64]                       64\n","conv2/W    [3, 3, 64, 64]          36864\n","bn2/gamma  [64]                       64\n","bn2/beta   [64]                       64\n","conv3/W    [3, 3, 64, 128]         73728\n","bn3/gamma  [128]                     128\n","bn3/beta   [128]                     128\n","conv4/W    [3, 3, 128, 128]       147456\n","bn4/gamma  [128]                     128\n","bn4/beta   [128]                     128\n","conv5/W    [3, 3, 128, 128]       147456\n","bn5/gamma  [128]                     128\n","bn5/beta   [128]                     128\n","conv6/W    [5, 5, 128, 512]      1638400\n","bn6/gamma  [512]                     512\n","bn6/beta   [512]                     512\n","fc1/W      [512, 10]                5120\n","fc1/b      [10]                       10\u001b[36m\n","Number of trainable variables: 22\n","Number of parameters (elements): 2079978\n","Storage space needed for all trainable variables: 7.93MB\u001b[0m\n","\u001b[32m[0717 10:31:35 @base.py:207]\u001b[0m Setup callbacks graph ...\n","\u001b[32m[0717 10:31:35 @argtools.py:138]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m \"import prctl\" failed! Install python-prctl so that processes can be cleaned with guarantee.\n","\u001b[32m[0717 10:31:36 @inference_runner.py:148]\u001b[0m [InferenceRunner] Building tower 'InferenceTower' on device /gpu:0 ...\n","\u001b[32m[0717 10:31:36 @<ipython-input-4-7ff13444fb02>:113]\u001b[0m Binarizing weight conv0/W\n","\u001b[32m[0717 10:31:37 @<ipython-input-4-7ff13444fb02>:113]\u001b[0m Binarizing weight conv1/W\n","\u001b[32m[0717 10:31:37 @<ipython-input-4-7ff13444fb02>:113]\u001b[0m Binarizing weight conv2/W\n","\u001b[32m[0717 10:31:38 @<ipython-input-4-7ff13444fb02>:113]\u001b[0m Binarizing weight conv3/W\n","\u001b[32m[0717 10:31:38 @<ipython-input-4-7ff13444fb02>:113]\u001b[0m Binarizing weight conv4/W\n","\u001b[32m[0717 10:31:38 @<ipython-input-4-7ff13444fb02>:113]\u001b[0m Binarizing weight conv5/W\n","\u001b[32m[0717 10:31:38 @<ipython-input-4-7ff13444fb02>:113]\u001b[0m Binarizing weight conv6/W\n","\u001b[32m[0717 10:31:38 @<ipython-input-4-7ff13444fb02>:113]\u001b[0m Binarizing weight fc1/W\n","\u001b[32m[0717 10:31:38 @summary.py:47]\u001b[0m [MovingAverageSummary] 5 operations in collection 'MOVING_SUMMARY_OPS' will be run with session hooks.\n","\u001b[32m[0717 10:31:38 @summary.py:94]\u001b[0m Summarizing collection 'summaries' of size 22.\n","\u001b[32m[0717 10:31:38 @graph.py:99]\u001b[0m Applying collection UPDATE_OPS of 12 ops.\n","\u001b[32m[0717 10:31:38 @base.py:228]\u001b[0m Creating the session ...\n","\u001b[32m[0717 10:31:39 @base.py:234]\u001b[0m Initializing the session ...\n","\u001b[32m[0717 10:31:39 @base.py:241]\u001b[0m Graph Finalized.\n","\u001b[32m[0717 10:31:39 @concurrency.py:37]\u001b[0m Starting EnqueueThread: enqueue dataflow to TF queue \"QueueInput/input_queue\" ...\n","\u001b[32m[0717 10:31:39 @inference_runner.py:95]\u001b[0m [InferenceRunner] Will eval 79 iterations\n","\u001b[32m[0717 10:31:39 @monitor.py:361]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m History epoch=29 from JSON is not the predecessor of the current starting_epoch=1\n","\u001b[32m[0717 10:31:39 @monitor.py:362]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m If you want to resume old training, either use `AutoResumeTrainConfig` or correctly set the new starting_epoch yourself to avoid inconsistency. \n","\u001b[32m[0717 10:31:39 @monitor.py:369]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m Now, we will train with starting_epoch=1 and backup old json to train_log/mnist-dorefa-1,2,4/stats.json.0717-103139\n","\u001b[32m[0717 10:31:39 @base.py:273]\u001b[0m Start Epoch 1 ...\n"],"name":"stdout"},{"output_type":"stream","text":["100%|##########|468/468[00:13<00:00,35.76it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0717 10:31:52 @base.py:283]\u001b[0m Epoch 1 (global_step 468) finished, time:13.1 seconds.\n","\u001b[32m[0717 10:31:52 @saver.py:82]\u001b[0m Model saved to train_log/mnist-dorefa-1,2,4/model-468.\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|79/79[00:00<00:00,84.11it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0717 10:31:53 @monitor.py:476]\u001b[0m QueueInput/queue_size: 50\n","\u001b[32m[0717 10:31:53 @monitor.py:476]\u001b[0m accuracy: 0.12174\n","\u001b[32m[0717 10:31:53 @monitor.py:476]\u001b[0m cost: 2.3008\n","\u001b[32m[0717 10:31:53 @monitor.py:476]\u001b[0m cross_entropy_loss: 2.3008\n","\u001b[32m[0717 10:31:53 @monitor.py:476]\u001b[0m param-summary/conv0/W-rms: 0.29315\n","\u001b[32m[0717 10:31:53 @monitor.py:476]\u001b[0m param-summary/conv1/W-rms: 0.068168\n","\u001b[32m[0717 10:31:53 @monitor.py:476]\u001b[0m param-summary/conv2/W-rms: 0.05887\n","\u001b[32m[0717 10:31:53 @monitor.py:476]\u001b[0m param-summary/conv3/W-rms: 0.058843\n","\u001b[32m[0717 10:31:53 @monitor.py:476]\u001b[0m param-summary/conv4/W-rms: 0.041688\n","\u001b[32m[0717 10:31:53 @monitor.py:476]\u001b[0m param-summary/conv5/W-rms: 0.04158\n","\u001b[32m[0717 10:31:53 @monitor.py:476]\u001b[0m param-summary/conv6/W-rms: 0.024997\n","\u001b[32m[0717 10:31:53 @monitor.py:476]\u001b[0m param-summary/fc1/W-rms: 0.063531\n","\u001b[32m[0717 10:31:53 @monitor.py:476]\u001b[0m regularize_cost: 1.0331e-06\n","\u001b[32m[0717 10:31:53 @monitor.py:476]\u001b[0m train_error: 0.87826\n","\u001b[32m[0717 10:31:53 @monitor.py:476]\u001b[0m val_accuracy: 0.11294\n","\u001b[32m[0717 10:31:53 @monitor.py:476]\u001b[0m val_cross_entropy_loss: 2.301\n","\u001b[32m[0717 10:31:53 @base.py:273]\u001b[0m Start Epoch 2 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|468/468[00:11<00:00,39.16it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0717 10:32:05 @base.py:283]\u001b[0m Epoch 2 (global_step 936) finished, time:12 seconds.\n","\u001b[32m[0717 10:32:05 @saver.py:82]\u001b[0m Model saved to train_log/mnist-dorefa-1,2,4/model-936.\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|79/79[00:00<00:00,89.86it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0717 10:32:06 @monitor.py:476]\u001b[0m QueueInput/queue_size: 50\n","\u001b[32m[0717 10:32:06 @monitor.py:476]\u001b[0m accuracy: 0.11469\n","\u001b[32m[0717 10:32:06 @monitor.py:476]\u001b[0m cost: 2.3005\n","\u001b[32m[0717 10:32:06 @monitor.py:476]\u001b[0m cross_entropy_loss: 2.3005\n","\u001b[32m[0717 10:32:06 @monitor.py:476]\u001b[0m param-summary/conv0/W-rms: 0.29748\n","\u001b[32m[0717 10:32:06 @monitor.py:476]\u001b[0m param-summary/conv1/W-rms: 0.068168\n","\u001b[32m[0717 10:32:06 @monitor.py:476]\u001b[0m param-summary/conv2/W-rms: 0.05887\n","\u001b[32m[0717 10:32:06 @monitor.py:476]\u001b[0m param-summary/conv3/W-rms: 0.058843\n","\u001b[32m[0717 10:32:06 @monitor.py:476]\u001b[0m param-summary/conv4/W-rms: 0.041688\n","\u001b[32m[0717 10:32:06 @monitor.py:476]\u001b[0m param-summary/conv5/W-rms: 0.04158\n","\u001b[32m[0717 10:32:06 @monitor.py:476]\u001b[0m param-summary/conv6/W-rms: 0.024997\n","\u001b[32m[0717 10:32:06 @monitor.py:476]\u001b[0m param-summary/fc1/W-rms: 0.063568\n","\u001b[32m[0717 10:32:06 @monitor.py:476]\u001b[0m regularize_cost: 1.0327e-06\n","\u001b[32m[0717 10:32:06 @monitor.py:476]\u001b[0m train_error: 0.88531\n","\u001b[32m[0717 10:32:06 @monitor.py:476]\u001b[0m val_accuracy: 0.11432\n","\u001b[32m[0717 10:32:06 @monitor.py:476]\u001b[0m val_cross_entropy_loss: 2.301\n","\u001b[32m[0717 10:32:06 @base.py:273]\u001b[0m Start Epoch 3 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|468/468[00:11<00:00,39.46it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0717 10:32:18 @base.py:283]\u001b[0m Epoch 3 (global_step 1404) finished, time:11.9 seconds.\n","\u001b[32m[0717 10:32:18 @saver.py:82]\u001b[0m Model saved to train_log/mnist-dorefa-1,2,4/model-1404.\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|79/79[00:00<00:00,91.42it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0717 10:32:19 @monitor.py:476]\u001b[0m QueueInput/queue_size: 50\n","\u001b[32m[0717 10:32:19 @monitor.py:476]\u001b[0m accuracy: 0.1182\n","\u001b[32m[0717 10:32:19 @monitor.py:476]\u001b[0m cost: 2.3002\n","\u001b[32m[0717 10:32:19 @monitor.py:476]\u001b[0m cross_entropy_loss: 2.3001\n","\u001b[32m[0717 10:32:19 @monitor.py:476]\u001b[0m param-summary/conv0/W-rms: 0.3018\n","\u001b[32m[0717 10:32:19 @monitor.py:476]\u001b[0m param-summary/conv1/W-rms: 0.068168\n","\u001b[32m[0717 10:32:19 @monitor.py:476]\u001b[0m param-summary/conv2/W-rms: 0.05887\n","\u001b[32m[0717 10:32:19 @monitor.py:476]\u001b[0m param-summary/conv3/W-rms: 0.058843\n","\u001b[32m[0717 10:32:19 @monitor.py:476]\u001b[0m param-summary/conv4/W-rms: 0.041688\n","\u001b[32m[0717 10:32:19 @monitor.py:476]\u001b[0m param-summary/conv5/W-rms: 0.04158\n","\u001b[32m[0717 10:32:19 @monitor.py:476]\u001b[0m param-summary/conv6/W-rms: 0.024997\n","\u001b[32m[0717 10:32:19 @monitor.py:476]\u001b[0m param-summary/fc1/W-rms: 0.063623\n","\u001b[32m[0717 10:32:19 @monitor.py:476]\u001b[0m regularize_cost: 1.035e-06\n","\u001b[32m[0717 10:32:19 @monitor.py:476]\u001b[0m train_error: 0.8818\n","\u001b[32m[0717 10:32:19 @monitor.py:476]\u001b[0m val_accuracy: 0.11224\n","\u001b[32m[0717 10:32:19 @monitor.py:476]\u001b[0m val_cross_entropy_loss: 2.3011\n","\u001b[32m[0717 10:32:19 @base.py:273]\u001b[0m Start Epoch 4 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|468/468[00:11<00:00,39.22it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0717 10:32:31 @base.py:283]\u001b[0m Epoch 4 (global_step 1872) finished, time:11.9 seconds.\n","\u001b[32m[0717 10:32:31 @saver.py:82]\u001b[0m Model saved to train_log/mnist-dorefa-1,2,4/model-1872.\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|79/79[00:00<00:00,92.24it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0717 10:32:32 @monitor.py:476]\u001b[0m QueueInput/queue_size: 50\n","\u001b[32m[0717 10:32:32 @monitor.py:476]\u001b[0m accuracy: 0.11786\n","\u001b[32m[0717 10:32:32 @monitor.py:476]\u001b[0m cost: 2.3003\n","\u001b[32m[0717 10:32:32 @monitor.py:476]\u001b[0m cross_entropy_loss: 2.3003\n","\u001b[32m[0717 10:32:32 @monitor.py:476]\u001b[0m param-summary/conv0/W-rms: 0.30408\n","\u001b[32m[0717 10:32:32 @monitor.py:476]\u001b[0m param-summary/conv1/W-rms: 0.068168\n","\u001b[32m[0717 10:32:32 @monitor.py:476]\u001b[0m param-summary/conv2/W-rms: 0.05887\n","\u001b[32m[0717 10:32:32 @monitor.py:476]\u001b[0m param-summary/conv3/W-rms: 0.058843\n","\u001b[32m[0717 10:32:32 @monitor.py:476]\u001b[0m param-summary/conv4/W-rms: 0.041688\n","\u001b[32m[0717 10:32:32 @monitor.py:476]\u001b[0m param-summary/conv5/W-rms: 0.04158\n","\u001b[32m[0717 10:32:32 @monitor.py:476]\u001b[0m param-summary/conv6/W-rms: 0.024997\n","\u001b[32m[0717 10:32:32 @monitor.py:476]\u001b[0m param-summary/fc1/W-rms: 0.063383\n","\u001b[32m[0717 10:32:32 @monitor.py:476]\u001b[0m regularize_cost: 1.0273e-06\n","\u001b[32m[0717 10:32:32 @monitor.py:476]\u001b[0m train_error: 0.88214\n","\u001b[32m[0717 10:32:32 @monitor.py:476]\u001b[0m val_accuracy: 0.11363\n","\u001b[32m[0717 10:32:32 @monitor.py:476]\u001b[0m val_cross_entropy_loss: 2.3012\n","\u001b[32m[0717 10:32:32 @base.py:273]\u001b[0m Start Epoch 5 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|468/468[00:12<00:00,38.51it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0717 10:32:44 @base.py:283]\u001b[0m Epoch 5 (global_step 2340) finished, time:12.2 seconds.\n","\u001b[32m[0717 10:32:44 @saver.py:82]\u001b[0m Model saved to train_log/mnist-dorefa-1,2,4/model-2340.\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|79/79[00:00<00:00,88.32it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0717 10:32:45 @monitor.py:476]\u001b[0m QueueInput/queue_size: 50\n","\u001b[32m[0717 10:32:45 @monitor.py:476]\u001b[0m accuracy: 0.109\n","\u001b[32m[0717 10:32:45 @monitor.py:476]\u001b[0m cost: 2.3019\n","\u001b[32m[0717 10:32:45 @monitor.py:476]\u001b[0m cross_entropy_loss: 2.3019\n","\u001b[32m[0717 10:32:45 @monitor.py:476]\u001b[0m param-summary/conv0/W-rms: 0.30553\n","\u001b[32m[0717 10:32:45 @monitor.py:476]\u001b[0m param-summary/conv1/W-rms: 0.068168\n","\u001b[32m[0717 10:32:45 @monitor.py:476]\u001b[0m param-summary/conv2/W-rms: 0.05887\n","\u001b[32m[0717 10:32:45 @monitor.py:476]\u001b[0m param-summary/conv3/W-rms: 0.058843\n","\u001b[32m[0717 10:32:45 @monitor.py:476]\u001b[0m param-summary/conv4/W-rms: 0.041688\n","\u001b[32m[0717 10:32:45 @monitor.py:476]\u001b[0m param-summary/conv5/W-rms: 0.04158\n","\u001b[32m[0717 10:32:45 @monitor.py:476]\u001b[0m param-summary/conv6/W-rms: 0.024997\n","\u001b[32m[0717 10:32:45 @monitor.py:476]\u001b[0m param-summary/fc1/W-rms: 0.062916\n","\u001b[32m[0717 10:32:45 @monitor.py:476]\u001b[0m regularize_cost: 1.0136e-06\n","\u001b[32m[0717 10:32:45 @monitor.py:476]\u001b[0m train_error: 0.891\n","\u001b[32m[0717 10:32:45 @monitor.py:476]\u001b[0m val_accuracy: 0.11294\n","\u001b[32m[0717 10:32:45 @monitor.py:476]\u001b[0m val_cross_entropy_loss: 2.301\n","\u001b[32m[0717 10:32:45 @base.py:273]\u001b[0m Start Epoch 6 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|468/468[00:11<00:00,39.43it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0717 10:32:57 @base.py:283]\u001b[0m Epoch 6 (global_step 2808) finished, time:11.9 seconds.\n","\u001b[32m[0717 10:32:57 @saver.py:82]\u001b[0m Model saved to train_log/mnist-dorefa-1,2,4/model-2808.\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|79/79[00:00<00:00,93.13it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0717 10:32:58 @monitor.py:476]\u001b[0m QueueInput/queue_size: 50\n","\u001b[32m[0717 10:32:58 @monitor.py:476]\u001b[0m accuracy: 0.11961\n","\u001b[32m[0717 10:32:58 @monitor.py:476]\u001b[0m cost: 2.3\n","\u001b[32m[0717 10:32:58 @monitor.py:476]\u001b[0m cross_entropy_loss: 2.3\n","\u001b[32m[0717 10:32:58 @monitor.py:476]\u001b[0m param-summary/conv0/W-rms: 0.3084\n","\u001b[32m[0717 10:32:58 @monitor.py:476]\u001b[0m param-summary/conv1/W-rms: 0.068168\n","\u001b[32m[0717 10:32:58 @monitor.py:476]\u001b[0m param-summary/conv2/W-rms: 0.05887\n","\u001b[32m[0717 10:32:58 @monitor.py:476]\u001b[0m param-summary/conv3/W-rms: 0.058843\n","\u001b[32m[0717 10:32:58 @monitor.py:476]\u001b[0m param-summary/conv4/W-rms: 0.041688\n","\u001b[32m[0717 10:32:58 @monitor.py:476]\u001b[0m param-summary/conv5/W-rms: 0.04158\n","\u001b[32m[0717 10:32:58 @monitor.py:476]\u001b[0m param-summary/conv6/W-rms: 0.024997\n","\u001b[32m[0717 10:32:58 @monitor.py:476]\u001b[0m param-summary/fc1/W-rms: 0.062802\n","\u001b[32m[0717 10:32:58 @monitor.py:476]\u001b[0m regularize_cost: 1.0096e-06\n","\u001b[32m[0717 10:32:58 @monitor.py:476]\u001b[0m train_error: 0.88039\n","\u001b[32m[0717 10:32:58 @monitor.py:476]\u001b[0m val_accuracy: 0.11224\n","\u001b[32m[0717 10:32:58 @monitor.py:476]\u001b[0m val_cross_entropy_loss: 2.3011\n","\u001b[32m[0717 10:32:58 @base.py:273]\u001b[0m Start Epoch 7 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|468/468[00:11<00:00,39.12it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0717 10:33:10 @base.py:283]\u001b[0m Epoch 7 (global_step 3276) finished, time:12 seconds.\n","\u001b[32m[0717 10:33:10 @saver.py:82]\u001b[0m Model saved to train_log/mnist-dorefa-1,2,4/model-3276.\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|79/79[00:00<00:00,87.77it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0717 10:33:11 @monitor.py:476]\u001b[0m QueueInput/queue_size: 50\n","\u001b[32m[0717 10:33:11 @monitor.py:476]\u001b[0m accuracy: 0.10927\n","\u001b[32m[0717 10:33:11 @monitor.py:476]\u001b[0m cost: 2.3019\n","\u001b[32m[0717 10:33:11 @monitor.py:476]\u001b[0m cross_entropy_loss: 2.3019\n","\u001b[32m[0717 10:33:11 @monitor.py:476]\u001b[0m param-summary/conv0/W-rms: 0.31103\n","\u001b[32m[0717 10:33:11 @monitor.py:476]\u001b[0m param-summary/conv1/W-rms: 0.068168\n","\u001b[32m[0717 10:33:11 @monitor.py:476]\u001b[0m param-summary/conv2/W-rms: 0.05887\n","\u001b[32m[0717 10:33:11 @monitor.py:476]\u001b[0m param-summary/conv3/W-rms: 0.058843\n","\u001b[32m[0717 10:33:11 @monitor.py:476]\u001b[0m param-summary/conv4/W-rms: 0.041688\n","\u001b[32m[0717 10:33:11 @monitor.py:476]\u001b[0m param-summary/conv5/W-rms: 0.04158\n","\u001b[32m[0717 10:33:11 @monitor.py:476]\u001b[0m param-summary/conv6/W-rms: 0.024997\n","\u001b[32m[0717 10:33:11 @monitor.py:476]\u001b[0m param-summary/fc1/W-rms: 0.062431\n","\u001b[32m[0717 10:33:11 @monitor.py:476]\u001b[0m regularize_cost: 9.9824e-07\n","\u001b[32m[0717 10:33:11 @monitor.py:476]\u001b[0m train_error: 0.89073\n","\u001b[32m[0717 10:33:11 @monitor.py:476]\u001b[0m val_accuracy: 0.11363\n","\u001b[32m[0717 10:33:11 @monitor.py:476]\u001b[0m val_cross_entropy_loss: 2.3014\n","\u001b[32m[0717 10:33:11 @base.py:273]\u001b[0m Start Epoch 8 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|468/468[00:12<00:00,38.33it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0717 10:33:24 @base.py:283]\u001b[0m Epoch 8 (global_step 3744) finished, time:12.2 seconds.\n","\u001b[32m[0717 10:33:24 @saver.py:82]\u001b[0m Model saved to train_log/mnist-dorefa-1,2,4/model-3744.\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|79/79[00:00<00:00,88.84it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0717 10:33:25 @monitor.py:476]\u001b[0m QueueInput/queue_size: 50\n","\u001b[32m[0717 10:33:25 @monitor.py:476]\u001b[0m accuracy: 0.11265\n","\u001b[32m[0717 10:33:25 @monitor.py:476]\u001b[0m cost: 2.3017\n","\u001b[32m[0717 10:33:25 @monitor.py:476]\u001b[0m cross_entropy_loss: 2.3017\n","\u001b[32m[0717 10:33:25 @monitor.py:476]\u001b[0m param-summary/conv0/W-rms: 0.31159\n","\u001b[32m[0717 10:33:25 @monitor.py:476]\u001b[0m param-summary/conv1/W-rms: 0.068168\n","\u001b[32m[0717 10:33:25 @monitor.py:476]\u001b[0m param-summary/conv2/W-rms: 0.05887\n","\u001b[32m[0717 10:33:25 @monitor.py:476]\u001b[0m param-summary/conv3/W-rms: 0.058843\n","\u001b[32m[0717 10:33:25 @monitor.py:476]\u001b[0m param-summary/conv4/W-rms: 0.041688\n","\u001b[32m[0717 10:33:25 @monitor.py:476]\u001b[0m param-summary/conv5/W-rms: 0.04158\n","\u001b[32m[0717 10:33:25 @monitor.py:476]\u001b[0m param-summary/conv6/W-rms: 0.024997\n","\u001b[32m[0717 10:33:25 @monitor.py:476]\u001b[0m param-summary/fc1/W-rms: 0.062294\n","\u001b[32m[0717 10:33:25 @monitor.py:476]\u001b[0m regularize_cost: 9.9374e-07\n","\u001b[32m[0717 10:33:25 @monitor.py:476]\u001b[0m train_error: 0.88735\n","\u001b[32m[0717 10:33:25 @monitor.py:476]\u001b[0m val_accuracy: 0.11294\n","\u001b[32m[0717 10:33:25 @monitor.py:476]\u001b[0m val_cross_entropy_loss: 2.3011\n","\u001b[32m[0717 10:33:25 @base.py:273]\u001b[0m Start Epoch 9 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|468/468[00:12<00:00,38.85it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0717 10:33:37 @base.py:283]\u001b[0m Epoch 9 (global_step 4212) finished, time:12 seconds.\n","\u001b[32m[0717 10:33:37 @saver.py:82]\u001b[0m Model saved to train_log/mnist-dorefa-1,2,4/model-4212.\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|79/79[00:00<00:00,92.12it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0717 10:33:38 @monitor.py:476]\u001b[0m QueueInput/queue_size: 50\n","\u001b[32m[0717 10:33:38 @monitor.py:476]\u001b[0m accuracy: 0.11004\n","\u001b[32m[0717 10:33:38 @monitor.py:476]\u001b[0m cost: 2.301\n","\u001b[32m[0717 10:33:38 @monitor.py:476]\u001b[0m cross_entropy_loss: 2.301\n","\u001b[32m[0717 10:33:38 @monitor.py:476]\u001b[0m param-summary/conv0/W-rms: 0.3123\n","\u001b[32m[0717 10:33:38 @monitor.py:476]\u001b[0m param-summary/conv1/W-rms: 0.068168\n","\u001b[32m[0717 10:33:38 @monitor.py:476]\u001b[0m param-summary/conv2/W-rms: 0.05887\n","\u001b[32m[0717 10:33:38 @monitor.py:476]\u001b[0m param-summary/conv3/W-rms: 0.058843\n","\u001b[32m[0717 10:33:38 @monitor.py:476]\u001b[0m param-summary/conv4/W-rms: 0.041688\n","\u001b[32m[0717 10:33:38 @monitor.py:476]\u001b[0m param-summary/conv5/W-rms: 0.04158\n","\u001b[32m[0717 10:33:38 @monitor.py:476]\u001b[0m param-summary/conv6/W-rms: 0.024997\n","\u001b[32m[0717 10:33:38 @monitor.py:476]\u001b[0m param-summary/fc1/W-rms: 0.062123\n","\u001b[32m[0717 10:33:38 @monitor.py:476]\u001b[0m regularize_cost: 9.881e-07\n","\u001b[32m[0717 10:33:38 @monitor.py:476]\u001b[0m train_error: 0.88996\n","\u001b[32m[0717 10:33:38 @monitor.py:476]\u001b[0m val_accuracy: 0.11294\n","\u001b[32m[0717 10:33:38 @monitor.py:476]\u001b[0m val_cross_entropy_loss: 2.3013\n","\u001b[32m[0717 10:33:38 @base.py:273]\u001b[0m Start Epoch 10 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|468/468[00:11<00:00,40.16it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0717 10:33:49 @base.py:283]\u001b[0m Epoch 10 (global_step 4680) finished, time:11.7 seconds.\n","\u001b[32m[0717 10:33:49 @saver.py:82]\u001b[0m Model saved to train_log/mnist-dorefa-1,2,4/model-4680.\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|79/79[00:00<00:00,90.92it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0717 10:33:50 @monitor.py:476]\u001b[0m QueueInput/queue_size: 50\n","\u001b[32m[0717 10:33:50 @monitor.py:476]\u001b[0m accuracy: 0.1124\n","\u001b[32m[0717 10:33:50 @monitor.py:476]\u001b[0m cost: 2.3018\n","\u001b[32m[0717 10:33:50 @monitor.py:476]\u001b[0m cross_entropy_loss: 2.3018\n","\u001b[32m[0717 10:33:50 @monitor.py:476]\u001b[0m param-summary/conv0/W-rms: 0.31204\n","\u001b[32m[0717 10:33:50 @monitor.py:476]\u001b[0m param-summary/conv1/W-rms: 0.068168\n","\u001b[32m[0717 10:33:50 @monitor.py:476]\u001b[0m param-summary/conv2/W-rms: 0.05887\n","\u001b[32m[0717 10:33:50 @monitor.py:476]\u001b[0m param-summary/conv3/W-rms: 0.058843\n","\u001b[32m[0717 10:33:50 @monitor.py:476]\u001b[0m param-summary/conv4/W-rms: 0.041688\n","\u001b[32m[0717 10:33:50 @monitor.py:476]\u001b[0m param-summary/conv5/W-rms: 0.04158\n","\u001b[32m[0717 10:33:50 @monitor.py:476]\u001b[0m param-summary/conv6/W-rms: 0.024997\n","\u001b[32m[0717 10:33:50 @monitor.py:476]\u001b[0m param-summary/fc1/W-rms: 0.061772\n","\u001b[32m[0717 10:33:50 @monitor.py:476]\u001b[0m regularize_cost: 9.7736e-07\n","\u001b[32m[0717 10:33:50 @monitor.py:476]\u001b[0m train_error: 0.8876\n","\u001b[32m[0717 10:33:50 @monitor.py:476]\u001b[0m val_accuracy: 0.11363\n","\u001b[32m[0717 10:33:50 @monitor.py:476]\u001b[0m val_cross_entropy_loss: 2.3009\n","\u001b[32m[0717 10:33:50 @base.py:287]\u001b[0m Training has finished!\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"\\nif __name__ == '__main__':\\n    parser = argparse.ArgumentParser()\\n    parser.add_argument('--dorefa',\\n                        help='number of bits for W,A,G, separated by comma. Defaults to '1,2,4'',\\n                        default='1,2,4')\\n    args = parser.parse_args()\\n\\n    BITW, BITA, BITG = map(int, args.dorefa.split(','))\\n    config = get_config()\\n    launch_train_with_config(config, SimpleTrainer())\\n\""]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"mduuAqCeuc4B","colab":{"base_uri":"https://localhost:8080/","height":315},"executionInfo":{"status":"ok","timestamp":1626874438141,"user_tz":-120,"elapsed":2426,"user":{"displayName":"Lorenzo Pasco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgShaitSLZm3zyLVjMQT7ZzTrEV3kQEXha_A9lkVw=s64","userId":"01314717049817932576"}},"outputId":"19722f06-b665-40ad-974a-8f4662909cfd"},"source":["import json\n","import matplotlib.pyplot as plt\n","\n","f = open(\"train_log/mnist-dorefa-1,2,4/stats_def_first&last_avg_pooling.json\",\"r\")\n","\n","data = json.load(f)\n","accuracy = []\n","val_accuracy = []\n","for ob in data:\n","  accuracy.append(ob[\"accuracy\"])\n","  val_accuracy.append(ob[\"val_accuracy\"])\n","\n","epochs = range(len(accuracy))\n","\n","plt.plot(epochs, accuracy, 'r', label='Training acc')\n","plt.plot(epochs, val_accuracy, 'b', label='Validation acc')\n","plt.title('Training and validation accuracy')\n","plt.legend()\n","plt.figure()"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<Figure size 432x288 with 0 Axes>"]},"metadata":{"tags":[]},"execution_count":4},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 0 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ST3WBdVha1W-","executionInfo":{"status":"ok","timestamp":1626874444590,"user_tz":-120,"elapsed":302,"user":{"displayName":"Lorenzo Pasco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgShaitSLZm3zyLVjMQT7ZzTrEV3kQEXha_A9lkVw=s64","userId":"01314717049817932576"}},"outputId":"b5e8d20e-b214-4bc8-9d37-a1fef5569a8b"},"source":["from tabulate import tabulate\n","import matplotlib.pyplot as plt\n","\n","ep = [i+1 for i in epochs]\n","table_acc = {\"Epochs\" : ep, \"Accuracy\":accuracy}\n","table_val_acc = {\"Epochs\" : ep, \"Accuracy\":val_accuracy}\n","\n","print(\"ACCURACY\\n\")\n","print(tabulate(table_acc, headers='keys', tablefmt='fancy_grid'))\n","print(\"\\nVALIDATION ACCURACY\\n\")\n","print(tabulate(table_val_acc, headers='keys', tablefmt='fancy_grid'))"],"execution_count":5,"outputs":[{"output_type":"stream","text":["ACCURACY\n","\n","╒══════════╤════════════╕\n","│   Epochs │   Accuracy │\n","╞══════════╪════════════╡\n","│        1 │   0.12174  │\n","├──────────┼────────────┤\n","│        2 │   0.114686 │\n","├──────────┼────────────┤\n","│        3 │   0.118203 │\n","├──────────┼────────────┤\n","│        4 │   0.117865 │\n","├──────────┼────────────┤\n","│        5 │   0.109003 │\n","├──────────┼────────────┤\n","│        6 │   0.119606 │\n","├──────────┼────────────┤\n","│        7 │   0.109272 │\n","├──────────┼────────────┤\n","│        8 │   0.112654 │\n","├──────────┼────────────┤\n","│        9 │   0.110044 │\n","├──────────┼────────────┤\n","│       10 │   0.112402 │\n","╘══════════╧════════════╛\n","\n","VALIDATION ACCURACY\n","\n","╒══════════╤════════════╕\n","│   Epochs │   Accuracy │\n","╞══════════╪════════════╡\n","│        1 │   0.112935 │\n","├──────────┼────────────┤\n","│        2 │   0.11432  │\n","├──────────┼────────────┤\n","│        3 │   0.112243 │\n","├──────────┼────────────┤\n","│        4 │   0.113627 │\n","├──────────┼────────────┤\n","│        5 │   0.112935 │\n","├──────────┼────────────┤\n","│        6 │   0.112243 │\n","├──────────┼────────────┤\n","│        7 │   0.113627 │\n","├──────────┼────────────┤\n","│        8 │   0.112935 │\n","├──────────┼────────────┤\n","│        9 │   0.112935 │\n","├──────────┼────────────┤\n","│       10 │   0.113627 │\n","╘══════════╧════════════╛\n"],"name":"stdout"}]}]}