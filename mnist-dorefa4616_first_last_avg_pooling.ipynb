{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"mnist-dorefa4616_first&last_avg_pooling.ipynb","provenance":[],"authorship_tag":"ABX9TyNojcACZAlXuuyLuLYCiBkw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"5qzKFEQKqXDt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626514018543,"user_tz":-120,"elapsed":17770,"user":{"displayName":"Lorenzo Pasco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgShaitSLZm3zyLVjMQT7ZzTrEV3kQEXha_A9lkVw=s64","userId":"01314717049817932576"}},"outputId":"98913277-fd4a-4a0e-b60f-087b0057e5db"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eDXKVoHj26H8","executionInfo":{"status":"ok","timestamp":1626514024661,"user_tz":-120,"elapsed":3809,"user":{"displayName":"Lorenzo Pasco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgShaitSLZm3zyLVjMQT7ZzTrEV3kQEXha_A9lkVw=s64","userId":"01314717049817932576"}},"outputId":"8220e29c-a822-40a6-a1c1-c931dbf74587"},"source":["!pip install tensorpack\n","\n","%cd gdrive/MyDrive/SEAI_Project"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting tensorpack\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f9/8c/63e5f5a4a04dea36b75850f9daa885ccbfad64bec1fae0ee4ca9f31b3eaa/tensorpack-0.11-py2.py3-none-any.whl (296kB)\n","\r\u001b[K     |█                               | 10kB 19.1MB/s eta 0:00:01\r\u001b[K     |██▏                             | 20kB 26.8MB/s eta 0:00:01\r\u001b[K     |███▎                            | 30kB 31.8MB/s eta 0:00:01\r\u001b[K     |████▍                           | 40kB 35.4MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 51kB 37.8MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 61kB 40.1MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 71kB 39.0MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 81kB 38.5MB/s eta 0:00:01\r\u001b[K     |██████████                      | 92kB 39.1MB/s eta 0:00:01\r\u001b[K     |███████████                     | 102kB 35.3MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 112kB 35.3MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 122kB 35.3MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 133kB 35.3MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 143kB 35.3MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 153kB 35.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 163kB 35.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 174kB 35.3MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 184kB 35.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 194kB 35.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 204kB 35.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 215kB 35.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 225kB 35.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 235kB 35.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 245kB 35.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 256kB 35.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 266kB 35.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 276kB 35.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 286kB 35.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 296kB 35.3MB/s \n","\u001b[?25hRequirement already satisfied: msgpack>=0.5.2 in /usr/local/lib/python3.7/dist-packages (from tensorpack) (1.0.2)\n","Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.7/dist-packages (from tensorpack) (1.1.0)\n","Collecting msgpack-numpy>=0.4.4.2\n","  Downloading https://files.pythonhosted.org/packages/19/05/05b8d7c69c6abb36a34325cc3150089bdafc359f0a81fb998d93c5d5c737/msgpack_numpy-0.4.7.1-py2.py3-none-any.whl\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tensorpack) (1.15.0)\n","Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.7/dist-packages (from tensorpack) (4.41.1)\n","Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.7/dist-packages (from tensorpack) (0.8.9)\n","Requirement already satisfied: numpy>=1.14 in /usr/local/lib/python3.7/dist-packages (from tensorpack) (1.19.5)\n","Requirement already satisfied: psutil>=5 in /usr/local/lib/python3.7/dist-packages (from tensorpack) (5.4.8)\n","Requirement already satisfied: pyzmq>=16 in /usr/local/lib/python3.7/dist-packages (from tensorpack) (22.1.0)\n","Installing collected packages: msgpack-numpy, tensorpack\n","Successfully installed msgpack-numpy-0.4.7.1 tensorpack-0.11\n","/content/gdrive/MyDrive/SEAI_Project\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"47qPSLMU19HM","executionInfo":{"status":"ok","timestamp":1626514543768,"user_tz":-120,"elapsed":485017,"user":{"displayName":"Lorenzo Pasco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgShaitSLZm3zyLVjMQT7ZzTrEV3kQEXha_A9lkVw=s64","userId":"01314717049817932576"}},"outputId":"db2f031e-1b04-4bea-c9f7-f36266564cf9"},"source":["#!/usr/bin/env python\n","# -*- coding: utf-8 -*-\n","# File: svhn-digit-dorefa.py\n","# Author: Yuxin Wu\n","\n","import argparse\n","import os\n","import tensorflow as tf\n","\n","from tensorpack import *\n","from tensorpack.dataflow import dataset\n","from tensorpack.tfutils.summary import add_moving_summary, add_param_summary\n","from tensorpack.tfutils.varreplace import remap_variables\n","\n","\"\"\"\n","This is a tensorpack script for the SVHN results in paper:\n","DoReFa-Net: Training Low Bitwidth Convolutional Neural Networks with Low Bitwidth Gradients\n","http://arxiv.org/abs/1606.06160\n","The original experiements are performed on a proprietary framework.\n","This is our attempt to reproduce it on tensorpack.\n","Accuracy:\n","    With (W,A,G)=(1,1,4), can reach 3.1~3.2% error after 150 epochs.\n","    With (W,A,G)=(1,2,4), error is 3.0~3.1%.\n","    With (W,A,G)=(32,32,32), error is about 2.3%.\n","Speed:\n","    With quantization, 60 batch/s on 1 1080Ti. (4721 batch / epoch)\n","To Run:\n","    ./svhn-digit-dorefa.py --dorefa 1,2,4\n","\"\"\"\n","tf.compat.v1.reset_default_graph()\n","\n","BITW = 4\n","BITA = 6\n","BITG = 16\n","\n","\"\"\"\n","imported from dorefa file\n","\"\"\"\n","def get_dorefa(bitW, bitA, bitG):\n","    \"\"\"\n","    Return the three quantization functions fw, fa, fg, for weights, activations and gradients respectively\n","    \"\"\"\n","    def quantize(x, k):\n","        n = float(2 ** k - 1)\n","\n","        @tf.custom_gradient\n","        def _quantize(x):\n","            return tf.round(x * n) / n, lambda dy: dy\n","\n","        return _quantize(x)\n","\n","    def fw(x):\n","        if bitW == 32:\n","            return x\n","\n","        if bitW == 1:   # BWN\n","            E = tf.stop_gradient(tf.reduce_mean(tf.abs(x)))\n","\n","            @tf.custom_gradient\n","            def _sign(x):\n","                return tf.where(tf.equal(x, 0), tf.ones_like(x), tf.sign(x / E)) * E, lambda dy: dy\n","\n","            return _sign(x)\n","\n","        x = tf.tanh(x)\n","        x = x / tf.reduce_max(tf.abs(x)) * 0.5 + 0.5\n","        return 2 * quantize(x, bitW) - 1\n","\n","    def fa(x):\n","        if bitA == 32:\n","            return x\n","        return quantize(x, bitA)\n","\n","    def fg(x):\n","        if bitG == 32:\n","            return x\n","\n","        @tf.custom_gradient\n","        def _identity(input):\n","            def grad_fg(x):\n","                rank = x.get_shape().ndims\n","                assert rank is not None\n","                maxx = tf.reduce_max(tf.abs(x), list(range(1, rank)), keepdims=True)\n","                x = x / maxx\n","                n = float(2**bitG - 1)\n","                x = x * 0.5 + 0.5 + tf.random.uniform(\n","                    tf.shape(x), minval=-0.5 / n, maxval=0.5 / n)\n","                x = tf.clip_by_value(x, 0.0, 1.0)\n","                x = quantize(x, bitG) - 0.5\n","                return x * maxx * 2\n","\n","            return input, grad_fg\n","\n","        return _identity(x)\n","    return fw, fa, fg\n","\n","\n","class Model(ModelDesc):\n","    def inputs(self):\n","        return [tf.TensorSpec([None, 40, 40], tf.float32, 'input'),\n","                tf.TensorSpec([None], tf.int32, 'label')]\n","\n","    def build_graph(self, image, label):\n","        fw, fa, fg = get_dorefa(BITW, BITA, BITG)\n","\n","        # monkey-patch tf.get_variable to apply fw\n","        def binarize_weight(v):\n","            name = v.op.name\n","            # don't binarize first and last layer\n","            if not name.endswith('W'):\n","                return v\n","            else:\n","                logger.info(\"Binarizing weight {}\".format(v.op.name))\n","                return fw(v)\n","\n","        def nonlin(x):\n","            if BITA == 32:\n","                return tf.nn.relu(x)\n","            return tf.clip_by_value(x, 0.0, 1.0)\n","\n","        def activate(x):\n","            return fa(nonlin(x))\n","\n","        image = tf.expand_dims(image, 3)\n","        image = image / 256.0\n","\n","        with remap_variables(binarize_weight), \\\n","                argscope(BatchNorm, momentum=0.9, epsilon=1e-4), \\\n","                argscope(Conv2D, use_bias=False):\n","            logits = (LinearWrap(image)\n","                      .Conv2D('conv0', 48, 5, padding='VALID', use_bias=True)\n","                      .AvgPooling('pool0', 2, padding='SAME')\n","                      .apply(activate)\n","                      # 18\n","                      .Conv2D('conv1', 64, 3, padding='SAME')\n","                      .apply(fg)\n","                      .BatchNorm('bn1').apply(activate)\n","#AVGPooling\n","                      .Conv2D('conv2', 64, 3, padding='SAME')\n","                      .apply(fg)\n","                      .BatchNorm('bn2')\n","                      .AvgPooling('pool1', 2, padding='SAME')\n","                      .apply(activate)\n","                      # 9\n","                      .Conv2D('conv3', 128, 3, padding='VALID')\n","                      .apply(fg)\n","                      .BatchNorm('bn3').apply(activate)\n","                      # 7\n","\n","                      .Conv2D('conv4', 128, 3, padding='SAME')\n","                      .apply(fg)\n","                      .BatchNorm('bn4').apply(activate)\n","\n","                      .Conv2D('conv5', 128, 3, padding='VALID')\n","                      .apply(fg)\n","                      .BatchNorm('bn5').apply(activate)\n","                      # 5\n","                      .Dropout(rate=0.5 if self.training else 0.0)\n","                      .Conv2D('conv6', 512, 5, padding='VALID')\n","                      .apply(fg).BatchNorm('bn6')\n","                      .apply(nonlin)\n","                      .FullyConnected('fc1', 10)())\n","        tf.nn.softmax(logits, name='output')\n","\n","        correct = tf.cast(tf.nn.in_top_k(predictions=logits, targets=label, k=1), tf.float32, name='correct')\n","        accuracy = tf.reduce_mean(correct, name='accuracy')\n","        train_error = tf.reduce_mean(1 - correct, name='train_error')\n","        summary.add_moving_summary(train_error, accuracy)\n","        \n","        cost = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=label)\n","        cost = tf.reduce_mean(cost, name='cross_entropy_loss')\n","        # weight decay on all W of fc layers\n","        wd_cost = regularize_cost('fc.*/W', l2_regularizer(1e-7))\n","        add_param_summary(('.*/W', ['histogram', 'rms']))\n","        total_cost = tf.add_n([cost, wd_cost], name='cost')\n","        add_moving_summary(cost, wd_cost, total_cost)\n","        return total_cost\n","\n","    def optimizer(self):\n","        lr = tf.compat.v1.train.exponential_decay(\n","            learning_rate=1e-3,\n","            global_step=get_global_step_var(),\n","            decay_steps=4721 * 100,\n","            decay_rate=0.5, staircase=True, name='learning_rate')\n","        tf.summary.scalar('lr', lr)\n","\n","        return tf.compat.v1.train.AdamOptimizer(lr, epsilon=1e-5)\n","\n","\n","def get_config():\n","    logger.set_logger_dir(os.path.join('train_log', 'mnist-dorefa-{}'.format(args)))\n","\n","    # prepare dataset\n","    data_train = dataset.Mnist('train', shuffle=True)\n","    data_test = dataset.Mnist('test', shuffle=True)\n","\n","    augmentors = [imgaug.Resize((40, 40))]\n","    data_train = AugmentImageComponent(data_train, augmentors)\n","    data_train = BatchData(data_train, 128)\n","    data_train = MultiProcessRunnerZMQ(data_train, 5)\n","\n","    augmentors = [imgaug.Resize((40, 40))]\n","    data_test = AugmentImageComponent(data_test, augmentors)\n","    data_test = BatchData(data_test, 128, remainder=True)\n","\n","    return TrainConfig(\n","        data=QueueInput(data_train),\n","        callbacks=[\n","            ModelSaver(),\n","            InferenceRunner(    # run inference(for validation) after every epoch\n","                data_test,   # the DataFlow instance used for validation\n","                ScalarStats(    # produce `val_accuracy` and `val_cross_entropy_loss`\n","                    ['cross_entropy_loss', 'accuracy'], prefix='val'))\n","        ],\n","        model=Model(),\n","        max_epoch=10,\n","    )\n","\n","args = \"4,6,16\"\n","BITW, BITA, BITG = map(int, args.split(','))\n","config = get_config()\n","launch_train_with_config(config, SimpleTrainer())\n","\n","'''\n","if __name__ == '__main__':\n","    parser = argparse.ArgumentParser()\n","    parser.add_argument('--dorefa',\n","                        help='number of bits for W,A,G, separated by comma. Defaults to \\'1,2,4\\'',\n","                        default='1,2,4')\n","    args = parser.parse_args()\n","\n","    BITW, BITA, BITG = map(int, args.dorefa.split(','))\n","    config = get_config()\n","    launch_train_with_config(config, SimpleTrainer())\n","'''"],"execution_count":3,"outputs":[{"output_type":"stream","text":["\u001b[32m[0717 09:27:42 @logger.py:92]\u001b[0m Argv: /usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py -f /root/.local/share/jupyter/runtime/kernel-0bafa74d-a1b0-4a24-a86d-448d704ed62f.json\n","\u001b[32m[0717 09:27:42 @fs.py:101]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m Env var $TENSORPACK_DATASET not set, using /root/tensorpack_data for datasets.\n","\u001b[32m[0717 09:27:42 @fs.py:104]\u001b[0m Created the directory /root/tensorpack_data.\n","\u001b[32m[0717 09:27:42 @mnist.py:21]\u001b[0m Downloading to /root/tensorpack_data/mnist_data/train-images-idx3-ubyte.gz...\n"],"name":"stdout"},{"output_type":"stream","text":["train-images-idx3-ubyte.gz: 9.92MB [04:29, 36.9kB/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0717 09:32:11 @fs.py:73]\u001b[0m Succesfully downloaded train-images-idx3-ubyte.gz. 9912422 bytes.\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0717 09:32:11 @mnist.py:21]\u001b[0m Downloading to /root/tensorpack_data/mnist_data/train-labels-idx1-ubyte.gz...\n"],"name":"stdout"},{"output_type":"stream","text":["train-labels-idx1-ubyte.gz: 32.8kB [00:00, 459kB/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0717 09:32:11 @fs.py:73]\u001b[0m Succesfully downloaded train-labels-idx1-ubyte.gz. 28881 bytes.\n","\u001b[32m[0717 09:32:11 @mnist.py:21]\u001b[0m Downloading to /root/tensorpack_data/mnist_data/t10k-images-idx3-ubyte.gz...\n"],"name":"stdout"},{"output_type":"stream","text":["\n","t10k-images-idx3-ubyte.gz: 1.65MB [00:26, 62.1kB/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0717 09:32:38 @fs.py:73]\u001b[0m Succesfully downloaded t10k-images-idx3-ubyte.gz. 1648877 bytes.\n","\u001b[32m[0717 09:32:38 @mnist.py:21]\u001b[0m Downloading to /root/tensorpack_data/mnist_data/t10k-labels-idx1-ubyte.gz...\n"],"name":"stdout"},{"output_type":"stream","text":["\n","t10k-labels-idx1-ubyte.gz: 8.19kB [00:00, 191kB/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0717 09:32:38 @fs.py:73]\u001b[0m Succesfully downloaded t10k-labels-idx1-ubyte.gz. 4542 bytes.\n","\u001b[32m[0717 09:32:38 @parallel.py:340]\u001b[0m [MultiProcessRunnerZMQ] Will fork a dataflow more than one times. This assumes the datapoints are i.i.d.\n","\u001b[32m[0717 09:32:38 @input_source.py:221]\u001b[0m Setting up the queue 'QueueInput/input_queue' for CPU prefetching ...\n","\u001b[32m[0717 09:32:38 @trainers.py:48]\u001b[0m Building graph for a single training tower ...\n","\u001b[32m[0717 09:32:38 @<ipython-input-3-d6a6cc99670d>:113]\u001b[0m Binarizing weight conv0/W\n"],"name":"stdout"},{"output_type":"stream","text":["\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1692: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n","  warnings.warn('`layer.apply` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0717 09:32:38 @registry.py:90]\u001b[0m 'conv0': [?, 40, 40, 1] --> [?, 36, 36, 48]\n","\u001b[32m[0717 09:32:38 @registry.py:90]\u001b[0m 'pool0': [?, 36, 36, 48] --> [?, 18, 18, 48]\n","\u001b[32m[0717 09:32:38 @<ipython-input-3-d6a6cc99670d>:113]\u001b[0m Binarizing weight conv1/W\n","\u001b[32m[0717 09:32:38 @registry.py:90]\u001b[0m 'conv1': [?, 18, 18, 48] --> [?, 18, 18, 64]\n","\u001b[32m[0717 09:32:38 @<ipython-input-3-d6a6cc99670d>:113]\u001b[0m Binarizing weight conv2/W\n","\u001b[32m[0717 09:32:38 @registry.py:90]\u001b[0m 'conv2': [?, 18, 18, 64] --> [?, 18, 18, 64]\n","\u001b[32m[0717 09:32:38 @registry.py:90]\u001b[0m 'pool1': [?, 18, 18, 64] --> [?, 9, 9, 64]\n","\u001b[32m[0717 09:32:38 @<ipython-input-3-d6a6cc99670d>:113]\u001b[0m Binarizing weight conv3/W\n","\u001b[32m[0717 09:32:38 @registry.py:90]\u001b[0m 'conv3': [?, 9, 9, 64] --> [?, 7, 7, 128]\n","\u001b[32m[0717 09:32:38 @<ipython-input-3-d6a6cc99670d>:113]\u001b[0m Binarizing weight conv4/W\n","\u001b[32m[0717 09:32:38 @registry.py:90]\u001b[0m 'conv4': [?, 7, 7, 128] --> [?, 7, 7, 128]\n","\u001b[32m[0717 09:32:38 @<ipython-input-3-d6a6cc99670d>:113]\u001b[0m Binarizing weight conv5/W\n","\u001b[32m[0717 09:32:38 @registry.py:90]\u001b[0m 'conv5': [?, 7, 7, 128] --> [?, 5, 5, 128]\n","\u001b[32m[0717 09:32:39 @<ipython-input-3-d6a6cc99670d>:113]\u001b[0m Binarizing weight conv6/W\n","\u001b[32m[0717 09:32:39 @registry.py:90]\u001b[0m 'conv6': [?, 5, 5, 128] --> [?, 1, 1, 512]\n","\u001b[32m[0717 09:32:39 @<ipython-input-3-d6a6cc99670d>:113]\u001b[0m Binarizing weight fc1/W\n","\u001b[32m[0717 09:32:39 @registry.py:90]\u001b[0m 'fc1': [?, 1, 1, 512] --> [?, 10]\n","\u001b[32m[0717 09:32:39 @regularize.py:97]\u001b[0m regularize_cost() found 1 variables to regularize.\n","\u001b[32m[0717 09:32:39 @regularize.py:21]\u001b[0m The following tensors will be regularized: fc1/W:0\n","\u001b[32m[0717 09:32:40 @model_utils.py:67]\u001b[0m \u001b[36mList of Trainable Variables: \n","\u001b[0mname       shape               #elements\n","---------  ----------------  -----------\n","conv0/W    [5, 5, 1, 48]            1200\n","conv0/b    [48]                       48\n","conv1/W    [3, 3, 48, 64]          27648\n","bn1/gamma  [64]                       64\n","bn1/beta   [64]                       64\n","conv2/W    [3, 3, 64, 64]          36864\n","bn2/gamma  [64]                       64\n","bn2/beta   [64]                       64\n","conv3/W    [3, 3, 64, 128]         73728\n","bn3/gamma  [128]                     128\n","bn3/beta   [128]                     128\n","conv4/W    [3, 3, 128, 128]       147456\n","bn4/gamma  [128]                     128\n","bn4/beta   [128]                     128\n","conv5/W    [3, 3, 128, 128]       147456\n","bn5/gamma  [128]                     128\n","bn5/beta   [128]                     128\n","conv6/W    [5, 5, 128, 512]      1638400\n","bn6/gamma  [512]                     512\n","bn6/beta   [512]                     512\n","fc1/W      [512, 10]                5120\n","fc1/b      [10]                       10\u001b[36m\n","Number of trainable variables: 22\n","Number of parameters (elements): 2079978\n","Storage space needed for all trainable variables: 7.93MB\u001b[0m\n","\u001b[32m[0717 09:32:40 @base.py:207]\u001b[0m Setup callbacks graph ...\n","\u001b[32m[0717 09:32:40 @argtools.py:138]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m Starting a process with 'fork' method is efficient but not safe and may cause deadlock or crash.Use 'forkserver' or 'spawn' method instead if you run into such issues.See https://docs.python.org/3/library/multiprocessing.html#contexts-and-start-methods on how to set them.\n","\u001b[32m[0717 09:32:40 @argtools.py:138]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m \"import prctl\" failed! Install python-prctl so that processes can be cleaned with guarantee.\n","\u001b[32m[0717 09:32:40 @inference_runner.py:148]\u001b[0m [InferenceRunner] Building tower 'InferenceTower' on device /gpu:0 ...\n","\u001b[32m[0717 09:32:40 @<ipython-input-3-d6a6cc99670d>:113]\u001b[0m Binarizing weight conv0/W\n","\u001b[32m[0717 09:32:40 @<ipython-input-3-d6a6cc99670d>:113]\u001b[0m Binarizing weight conv1/W\n","\u001b[32m[0717 09:32:41 @<ipython-input-3-d6a6cc99670d>:113]\u001b[0m Binarizing weight conv2/W\n","\u001b[32m[0717 09:32:41 @<ipython-input-3-d6a6cc99670d>:113]\u001b[0m Binarizing weight conv3/W\n","\u001b[32m[0717 09:32:41 @<ipython-input-3-d6a6cc99670d>:113]\u001b[0m Binarizing weight conv4/W\n","\u001b[32m[0717 09:32:41 @<ipython-input-3-d6a6cc99670d>:113]\u001b[0m Binarizing weight conv5/W\n","\u001b[32m[0717 09:32:42 @<ipython-input-3-d6a6cc99670d>:113]\u001b[0m Binarizing weight conv6/W\n","\u001b[32m[0717 09:32:42 @<ipython-input-3-d6a6cc99670d>:113]\u001b[0m Binarizing weight fc1/W\n","\u001b[32m[0717 09:32:42 @summary.py:47]\u001b[0m [MovingAverageSummary] 5 operations in collection 'MOVING_SUMMARY_OPS' will be run with session hooks.\n","\u001b[32m[0717 09:32:42 @summary.py:94]\u001b[0m Summarizing collection 'summaries' of size 22.\n","\u001b[32m[0717 09:32:42 @graph.py:99]\u001b[0m Applying collection UPDATE_OPS of 12 ops.\n","\u001b[32m[0717 09:32:42 @base.py:228]\u001b[0m Creating the session ...\n","\u001b[32m[0717 09:32:48 @base.py:234]\u001b[0m Initializing the session ...\n","\u001b[32m[0717 09:32:48 @base.py:241]\u001b[0m Graph Finalized.\n","\u001b[32m[0717 09:32:48 @concurrency.py:37]\u001b[0m Starting EnqueueThread: enqueue dataflow to TF queue \"QueueInput/input_queue\" ...\n","\u001b[32m[0717 09:32:48 @inference_runner.py:95]\u001b[0m [InferenceRunner] Will eval 79 iterations\n","\u001b[32m[0717 09:32:48 @base.py:273]\u001b[0m Start Epoch 1 ...\n"],"name":"stdout"},{"output_type":"stream","text":["100%|##########|468/468[00:47<00:00, 9.94it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0717 09:33:36 @base.py:283]\u001b[0m Epoch 1 (global_step 468) finished, time:47.1 seconds.\n","\u001b[32m[0717 09:33:36 @saver.py:82]\u001b[0m Model saved to train_log/mnist-dorefa-4,6,16/model-468.\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|79/79[00:01<00:00,75.09it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0717 09:33:37 @monitor.py:476]\u001b[0m QueueInput/queue_size: 50\n","\u001b[32m[0717 09:33:37 @monitor.py:476]\u001b[0m accuracy: 0.96716\n","\u001b[32m[0717 09:33:37 @monitor.py:476]\u001b[0m cost: 0.11812\n","\u001b[32m[0717 09:33:37 @monitor.py:476]\u001b[0m cross_entropy_loss: 0.11812\n","\u001b[32m[0717 09:33:37 @monitor.py:476]\u001b[0m param-summary/conv0/W-rms: 0.28341\n","\u001b[32m[0717 09:33:37 @monitor.py:476]\u001b[0m param-summary/conv1/W-rms: 0.069285\n","\u001b[32m[0717 09:33:37 @monitor.py:476]\u001b[0m param-summary/conv2/W-rms: 0.059712\n","\u001b[32m[0717 09:33:37 @monitor.py:476]\u001b[0m param-summary/conv3/W-rms: 0.059685\n","\u001b[32m[0717 09:33:37 @monitor.py:476]\u001b[0m param-summary/conv4/W-rms: 0.043093\n","\u001b[32m[0717 09:33:37 @monitor.py:476]\u001b[0m param-summary/conv5/W-rms: 0.04331\n","\u001b[32m[0717 09:33:37 @monitor.py:476]\u001b[0m param-summary/conv6/W-rms: 0.027674\n","\u001b[32m[0717 09:33:37 @monitor.py:476]\u001b[0m param-summary/fc1/W-rms: 0.056388\n","\u001b[32m[0717 09:33:37 @monitor.py:476]\u001b[0m regularize_cost: 8.1642e-07\n","\u001b[32m[0717 09:33:37 @monitor.py:476]\u001b[0m train_error: 0.032838\n","\u001b[32m[0717 09:33:37 @monitor.py:476]\u001b[0m val_accuracy: 0.97646\n","\u001b[32m[0717 09:33:37 @monitor.py:476]\u001b[0m val_cross_entropy_loss: 0.079293\n","\u001b[32m[0717 09:33:37 @base.py:273]\u001b[0m Start Epoch 2 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|468/468[00:12<00:00,37.90it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0717 09:33:49 @base.py:283]\u001b[0m Epoch 2 (global_step 936) finished, time:12.4 seconds.\n","\u001b[32m[0717 09:33:49 @saver.py:82]\u001b[0m Model saved to train_log/mnist-dorefa-4,6,16/model-936.\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|79/79[00:00<00:00,89.68it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0717 09:33:50 @monitor.py:476]\u001b[0m QueueInput/queue_size: 50\n","\u001b[32m[0717 09:33:50 @monitor.py:476]\u001b[0m accuracy: 0.97456\n","\u001b[32m[0717 09:33:50 @monitor.py:476]\u001b[0m cost: 0.08076\n","\u001b[32m[0717 09:33:50 @monitor.py:476]\u001b[0m cross_entropy_loss: 0.080759\n","\u001b[32m[0717 09:33:50 @monitor.py:476]\u001b[0m param-summary/conv0/W-rms: 0.28425\n","\u001b[32m[0717 09:33:50 @monitor.py:476]\u001b[0m param-summary/conv1/W-rms: 0.069911\n","\u001b[32m[0717 09:33:50 @monitor.py:476]\u001b[0m param-summary/conv2/W-rms: 0.059957\n","\u001b[32m[0717 09:33:50 @monitor.py:476]\u001b[0m param-summary/conv3/W-rms: 0.060001\n","\u001b[32m[0717 09:33:50 @monitor.py:476]\u001b[0m param-summary/conv4/W-rms: 0.043552\n","\u001b[32m[0717 09:33:50 @monitor.py:476]\u001b[0m param-summary/conv5/W-rms: 0.043928\n","\u001b[32m[0717 09:33:50 @monitor.py:476]\u001b[0m param-summary/conv6/W-rms: 0.028742\n","\u001b[32m[0717 09:33:50 @monitor.py:476]\u001b[0m param-summary/fc1/W-rms: 0.055974\n","\u001b[32m[0717 09:33:50 @monitor.py:476]\u001b[0m regularize_cost: 8.0235e-07\n","\u001b[32m[0717 09:33:50 @monitor.py:476]\u001b[0m train_error: 0.025439\n","\u001b[32m[0717 09:33:50 @monitor.py:476]\u001b[0m val_accuracy: 0.97973\n","\u001b[32m[0717 09:33:50 @monitor.py:476]\u001b[0m val_cross_entropy_loss: 0.062799\n","\u001b[32m[0717 09:33:50 @base.py:273]\u001b[0m Start Epoch 3 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|468/468[00:12<00:00,37.03it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0717 09:34:03 @base.py:283]\u001b[0m Epoch 3 (global_step 1404) finished, time:12.6 seconds.\n","\u001b[32m[0717 09:34:03 @saver.py:82]\u001b[0m Model saved to train_log/mnist-dorefa-4,6,16/model-1404.\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|79/79[00:00<00:00,89.00it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0717 09:34:04 @monitor.py:476]\u001b[0m QueueInput/queue_size: 50\n","\u001b[32m[0717 09:34:04 @monitor.py:476]\u001b[0m accuracy: 0.98254\n","\u001b[32m[0717 09:34:04 @monitor.py:476]\u001b[0m cost: 0.051683\n","\u001b[32m[0717 09:34:04 @monitor.py:476]\u001b[0m cross_entropy_loss: 0.051683\n","\u001b[32m[0717 09:34:04 @monitor.py:476]\u001b[0m param-summary/conv0/W-rms: 0.28502\n","\u001b[32m[0717 09:34:04 @monitor.py:476]\u001b[0m param-summary/conv1/W-rms: 0.070242\n","\u001b[32m[0717 09:34:04 @monitor.py:476]\u001b[0m param-summary/conv2/W-rms: 0.060211\n","\u001b[32m[0717 09:34:04 @monitor.py:476]\u001b[0m param-summary/conv3/W-rms: 0.06031\n","\u001b[32m[0717 09:34:04 @monitor.py:476]\u001b[0m param-summary/conv4/W-rms: 0.043992\n","\u001b[32m[0717 09:34:04 @monitor.py:476]\u001b[0m param-summary/conv5/W-rms: 0.044531\n","\u001b[32m[0717 09:34:04 @monitor.py:476]\u001b[0m param-summary/conv6/W-rms: 0.029684\n","\u001b[32m[0717 09:34:04 @monitor.py:476]\u001b[0m param-summary/fc1/W-rms: 0.056303\n","\u001b[32m[0717 09:34:04 @monitor.py:476]\u001b[0m regularize_cost: 8.1131e-07\n","\u001b[32m[0717 09:34:04 @monitor.py:476]\u001b[0m train_error: 0.017459\n","\u001b[32m[0717 09:34:04 @monitor.py:476]\u001b[0m val_accuracy: 0.98378\n","\u001b[32m[0717 09:34:04 @monitor.py:476]\u001b[0m val_cross_entropy_loss: 0.058975\n","\u001b[32m[0717 09:34:04 @base.py:273]\u001b[0m Start Epoch 4 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|468/468[00:12<00:00,36.49it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0717 09:34:17 @base.py:283]\u001b[0m Epoch 4 (global_step 1872) finished, time:12.8 seconds.\n","\u001b[32m[0717 09:34:17 @saver.py:82]\u001b[0m Model saved to train_log/mnist-dorefa-4,6,16/model-1872.\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|79/79[00:00<00:00,85.69it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0717 09:34:18 @monitor.py:476]\u001b[0m QueueInput/queue_size: 50\n","\u001b[32m[0717 09:34:18 @monitor.py:476]\u001b[0m accuracy: 0.9829\n","\u001b[32m[0717 09:34:18 @monitor.py:476]\u001b[0m cost: 0.058885\n","\u001b[32m[0717 09:34:18 @monitor.py:476]\u001b[0m cross_entropy_loss: 0.058884\n","\u001b[32m[0717 09:34:18 @monitor.py:476]\u001b[0m param-summary/conv0/W-rms: 0.28521\n","\u001b[32m[0717 09:34:18 @monitor.py:476]\u001b[0m param-summary/conv1/W-rms: 0.070576\n","\u001b[32m[0717 09:34:18 @monitor.py:476]\u001b[0m param-summary/conv2/W-rms: 0.060507\n","\u001b[32m[0717 09:34:18 @monitor.py:476]\u001b[0m param-summary/conv3/W-rms: 0.060654\n","\u001b[32m[0717 09:34:18 @monitor.py:476]\u001b[0m param-summary/conv4/W-rms: 0.044466\n","\u001b[32m[0717 09:34:18 @monitor.py:476]\u001b[0m param-summary/conv5/W-rms: 0.045191\n","\u001b[32m[0717 09:34:18 @monitor.py:476]\u001b[0m param-summary/conv6/W-rms: 0.030693\n","\u001b[32m[0717 09:34:18 @monitor.py:476]\u001b[0m param-summary/fc1/W-rms: 0.0569\n","\u001b[32m[0717 09:34:18 @monitor.py:476]\u001b[0m regularize_cost: 8.2745e-07\n","\u001b[32m[0717 09:34:18 @monitor.py:476]\u001b[0m train_error: 0.017099\n","\u001b[32m[0717 09:34:18 @monitor.py:476]\u001b[0m val_accuracy: 0.98744\n","\u001b[32m[0717 09:34:18 @monitor.py:476]\u001b[0m val_cross_entropy_loss: 0.039096\n","\u001b[32m[0717 09:34:18 @base.py:273]\u001b[0m Start Epoch 5 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|468/468[00:13<00:00,35.75it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0717 09:34:31 @base.py:283]\u001b[0m Epoch 5 (global_step 2340) finished, time:13.1 seconds.\n","\u001b[32m[0717 09:34:31 @saver.py:82]\u001b[0m Model saved to train_log/mnist-dorefa-4,6,16/model-2340.\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|79/79[00:00<00:00,83.19it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0717 09:34:32 @monitor.py:476]\u001b[0m QueueInput/queue_size: 50\n","\u001b[32m[0717 09:34:32 @monitor.py:476]\u001b[0m accuracy: 0.98529\n","\u001b[32m[0717 09:34:32 @monitor.py:476]\u001b[0m cost: 0.043935\n","\u001b[32m[0717 09:34:32 @monitor.py:476]\u001b[0m cross_entropy_loss: 0.043934\n","\u001b[32m[0717 09:34:32 @monitor.py:476]\u001b[0m param-summary/conv0/W-rms: 0.28592\n","\u001b[32m[0717 09:34:32 @monitor.py:476]\u001b[0m param-summary/conv1/W-rms: 0.071067\n","\u001b[32m[0717 09:34:32 @monitor.py:476]\u001b[0m param-summary/conv2/W-rms: 0.060901\n","\u001b[32m[0717 09:34:32 @monitor.py:476]\u001b[0m param-summary/conv3/W-rms: 0.061117\n","\u001b[32m[0717 09:34:32 @monitor.py:476]\u001b[0m param-summary/conv4/W-rms: 0.045081\n","\u001b[32m[0717 09:34:32 @monitor.py:476]\u001b[0m param-summary/conv5/W-rms: 0.046017\n","\u001b[32m[0717 09:34:32 @monitor.py:476]\u001b[0m param-summary/conv6/W-rms: 0.031826\n","\u001b[32m[0717 09:34:32 @monitor.py:476]\u001b[0m param-summary/fc1/W-rms: 0.058135\n","\u001b[32m[0717 09:34:32 @monitor.py:476]\u001b[0m regularize_cost: 8.64e-07\n","\u001b[32m[0717 09:34:32 @monitor.py:476]\u001b[0m train_error: 0.014707\n","\u001b[32m[0717 09:34:32 @monitor.py:476]\u001b[0m val_accuracy: 0.98418\n","\u001b[32m[0717 09:34:32 @monitor.py:476]\u001b[0m val_cross_entropy_loss: 0.051688\n","\u001b[32m[0717 09:34:32 @base.py:273]\u001b[0m Start Epoch 6 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|468/468[00:12<00:00,36.51it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0717 09:34:45 @base.py:283]\u001b[0m Epoch 6 (global_step 2808) finished, time:12.8 seconds.\n","\u001b[32m[0717 09:34:45 @saver.py:82]\u001b[0m Model saved to train_log/mnist-dorefa-4,6,16/model-2808.\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|79/79[00:00<00:00,88.45it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0717 09:34:46 @monitor.py:476]\u001b[0m QueueInput/queue_size: 50\n","\u001b[32m[0717 09:34:46 @monitor.py:476]\u001b[0m accuracy: 0.98745\n","\u001b[32m[0717 09:34:46 @monitor.py:476]\u001b[0m cost: 0.039641\n","\u001b[32m[0717 09:34:46 @monitor.py:476]\u001b[0m cross_entropy_loss: 0.03964\n","\u001b[32m[0717 09:34:46 @monitor.py:476]\u001b[0m param-summary/conv0/W-rms: 0.28644\n","\u001b[32m[0717 09:34:46 @monitor.py:476]\u001b[0m param-summary/conv1/W-rms: 0.07176\n","\u001b[32m[0717 09:34:46 @monitor.py:476]\u001b[0m param-summary/conv2/W-rms: 0.061279\n","\u001b[32m[0717 09:34:46 @monitor.py:476]\u001b[0m param-summary/conv3/W-rms: 0.061627\n","\u001b[32m[0717 09:34:46 @monitor.py:476]\u001b[0m param-summary/conv4/W-rms: 0.045745\n","\u001b[32m[0717 09:34:46 @monitor.py:476]\u001b[0m param-summary/conv5/W-rms: 0.04693\n","\u001b[32m[0717 09:34:46 @monitor.py:476]\u001b[0m param-summary/conv6/W-rms: 0.033053\n","\u001b[32m[0717 09:34:46 @monitor.py:476]\u001b[0m param-summary/fc1/W-rms: 0.059555\n","\u001b[32m[0717 09:34:46 @monitor.py:476]\u001b[0m regularize_cost: 9.0657e-07\n","\u001b[32m[0717 09:34:46 @monitor.py:476]\u001b[0m train_error: 0.012547\n","\u001b[32m[0717 09:34:46 @monitor.py:476]\u001b[0m val_accuracy: 0.9736\n","\u001b[32m[0717 09:34:46 @monitor.py:476]\u001b[0m val_cross_entropy_loss: 0.091773\n","\u001b[32m[0717 09:34:46 @base.py:273]\u001b[0m Start Epoch 7 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|468/468[00:13<00:00,35.94it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0717 09:34:59 @base.py:283]\u001b[0m Epoch 7 (global_step 3276) finished, time:13 seconds.\n","\u001b[32m[0717 09:34:59 @saver.py:82]\u001b[0m Model saved to train_log/mnist-dorefa-4,6,16/model-3276.\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|79/79[00:00<00:00,88.50it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0717 09:35:00 @monitor.py:476]\u001b[0m QueueInput/queue_size: 50\n","\u001b[32m[0717 09:35:00 @monitor.py:476]\u001b[0m accuracy: 0.99122\n","\u001b[32m[0717 09:35:00 @monitor.py:476]\u001b[0m cost: 0.027847\n","\u001b[32m[0717 09:35:00 @monitor.py:476]\u001b[0m cross_entropy_loss: 0.027846\n","\u001b[32m[0717 09:35:00 @monitor.py:476]\u001b[0m param-summary/conv0/W-rms: 0.28683\n","\u001b[32m[0717 09:35:00 @monitor.py:476]\u001b[0m param-summary/conv1/W-rms: 0.072184\n","\u001b[32m[0717 09:35:00 @monitor.py:476]\u001b[0m param-summary/conv2/W-rms: 0.061691\n","\u001b[32m[0717 09:35:00 @monitor.py:476]\u001b[0m param-summary/conv3/W-rms: 0.06215\n","\u001b[32m[0717 09:35:00 @monitor.py:476]\u001b[0m param-summary/conv4/W-rms: 0.046401\n","\u001b[32m[0717 09:35:00 @monitor.py:476]\u001b[0m param-summary/conv5/W-rms: 0.047834\n","\u001b[32m[0717 09:35:00 @monitor.py:476]\u001b[0m param-summary/conv6/W-rms: 0.034215\n","\u001b[32m[0717 09:35:00 @monitor.py:476]\u001b[0m param-summary/fc1/W-rms: 0.060994\n","\u001b[32m[0717 09:35:00 @monitor.py:476]\u001b[0m regularize_cost: 9.5044e-07\n","\u001b[32m[0717 09:35:00 @monitor.py:476]\u001b[0m train_error: 0.0087801\n","\u001b[32m[0717 09:35:00 @monitor.py:476]\u001b[0m val_accuracy: 0.9914\n","\u001b[32m[0717 09:35:00 @monitor.py:476]\u001b[0m val_cross_entropy_loss: 0.030487\n","\u001b[32m[0717 09:35:00 @base.py:273]\u001b[0m Start Epoch 8 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|468/468[00:13<00:00,35.50it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0717 09:35:13 @base.py:283]\u001b[0m Epoch 8 (global_step 3744) finished, time:13.2 seconds.\n","\u001b[32m[0717 09:35:13 @saver.py:82]\u001b[0m Model saved to train_log/mnist-dorefa-4,6,16/model-3744.\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|79/79[00:00<00:00,85.50it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0717 09:35:14 @monitor.py:476]\u001b[0m QueueInput/queue_size: 50\n","\u001b[32m[0717 09:35:14 @monitor.py:476]\u001b[0m accuracy: 0.99022\n","\u001b[32m[0717 09:35:14 @monitor.py:476]\u001b[0m cost: 0.032069\n","\u001b[32m[0717 09:35:14 @monitor.py:476]\u001b[0m cross_entropy_loss: 0.032068\n","\u001b[32m[0717 09:35:14 @monitor.py:476]\u001b[0m param-summary/conv0/W-rms: 0.28719\n","\u001b[32m[0717 09:35:14 @monitor.py:476]\u001b[0m param-summary/conv1/W-rms: 0.072752\n","\u001b[32m[0717 09:35:14 @monitor.py:476]\u001b[0m param-summary/conv2/W-rms: 0.06222\n","\u001b[32m[0717 09:35:14 @monitor.py:476]\u001b[0m param-summary/conv3/W-rms: 0.06285\n","\u001b[32m[0717 09:35:14 @monitor.py:476]\u001b[0m param-summary/conv4/W-rms: 0.047267\n","\u001b[32m[0717 09:35:14 @monitor.py:476]\u001b[0m param-summary/conv5/W-rms: 0.049003\n","\u001b[32m[0717 09:35:14 @monitor.py:476]\u001b[0m param-summary/conv6/W-rms: 0.035649\n","\u001b[32m[0717 09:35:14 @monitor.py:476]\u001b[0m param-summary/fc1/W-rms: 0.062702\n","\u001b[32m[0717 09:35:14 @monitor.py:476]\u001b[0m regularize_cost: 1.0052e-06\n","\u001b[32m[0717 09:35:14 @monitor.py:476]\u001b[0m train_error: 0.0097846\n","\u001b[32m[0717 09:35:14 @monitor.py:476]\u001b[0m val_accuracy: 0.98892\n","\u001b[32m[0717 09:35:14 @monitor.py:476]\u001b[0m val_cross_entropy_loss: 0.034267\n","\u001b[32m[0717 09:35:14 @base.py:273]\u001b[0m Start Epoch 9 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|468/468[00:13<00:00,34.92it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0717 09:35:28 @base.py:283]\u001b[0m Epoch 9 (global_step 4212) finished, time:13.4 seconds.\n","\u001b[32m[0717 09:35:28 @saver.py:82]\u001b[0m Model saved to train_log/mnist-dorefa-4,6,16/model-4212.\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|79/79[00:00<00:00,86.06it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0717 09:35:29 @monitor.py:476]\u001b[0m QueueInput/queue_size: 50\n","\u001b[32m[0717 09:35:29 @monitor.py:476]\u001b[0m accuracy: 0.99281\n","\u001b[32m[0717 09:35:29 @monitor.py:476]\u001b[0m cost: 0.026634\n","\u001b[32m[0717 09:35:29 @monitor.py:476]\u001b[0m cross_entropy_loss: 0.026633\n","\u001b[32m[0717 09:35:29 @monitor.py:476]\u001b[0m param-summary/conv0/W-rms: 0.2878\n","\u001b[32m[0717 09:35:29 @monitor.py:476]\u001b[0m param-summary/conv1/W-rms: 0.073416\n","\u001b[32m[0717 09:35:29 @monitor.py:476]\u001b[0m param-summary/conv2/W-rms: 0.062812\n","\u001b[32m[0717 09:35:29 @monitor.py:476]\u001b[0m param-summary/conv3/W-rms: 0.063652\n","\u001b[32m[0717 09:35:29 @monitor.py:476]\u001b[0m param-summary/conv4/W-rms: 0.048235\n","\u001b[32m[0717 09:35:29 @monitor.py:476]\u001b[0m param-summary/conv5/W-rms: 0.050258\n","\u001b[32m[0717 09:35:29 @monitor.py:476]\u001b[0m param-summary/conv6/W-rms: 0.037177\n","\u001b[32m[0717 09:35:29 @monitor.py:476]\u001b[0m param-summary/fc1/W-rms: 0.064549\n","\u001b[32m[0717 09:35:29 @monitor.py:476]\u001b[0m regularize_cost: 1.0646e-06\n","\u001b[32m[0717 09:35:29 @monitor.py:476]\u001b[0m train_error: 0.0071947\n","\u001b[32m[0717 09:35:29 @monitor.py:476]\u001b[0m val_accuracy: 0.98883\n","\u001b[32m[0717 09:35:29 @monitor.py:476]\u001b[0m val_cross_entropy_loss: 0.037124\n","\u001b[32m[0717 09:35:29 @base.py:273]\u001b[0m Start Epoch 10 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|468/468[00:13<00:00,35.99it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0717 09:35:42 @base.py:283]\u001b[0m Epoch 10 (global_step 4680) finished, time:13 seconds.\n","\u001b[32m[0717 09:35:42 @saver.py:82]\u001b[0m Model saved to train_log/mnist-dorefa-4,6,16/model-4680.\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|79/79[00:00<00:00,85.61it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0717 09:35:43 @monitor.py:476]\u001b[0m QueueInput/queue_size: 50\n","\u001b[32m[0717 09:35:43 @monitor.py:476]\u001b[0m accuracy: 0.99337\n","\u001b[32m[0717 09:35:43 @monitor.py:476]\u001b[0m cost: 0.018946\n","\u001b[32m[0717 09:35:43 @monitor.py:476]\u001b[0m cross_entropy_loss: 0.018945\n","\u001b[32m[0717 09:35:43 @monitor.py:476]\u001b[0m param-summary/conv0/W-rms: 0.28849\n","\u001b[32m[0717 09:35:43 @monitor.py:476]\u001b[0m param-summary/conv1/W-rms: 0.074297\n","\u001b[32m[0717 09:35:43 @monitor.py:476]\u001b[0m param-summary/conv2/W-rms: 0.063608\n","\u001b[32m[0717 09:35:43 @monitor.py:476]\u001b[0m param-summary/conv3/W-rms: 0.064658\n","\u001b[32m[0717 09:35:43 @monitor.py:476]\u001b[0m param-summary/conv4/W-rms: 0.049382\n","\u001b[32m[0717 09:35:43 @monitor.py:476]\u001b[0m param-summary/conv5/W-rms: 0.051706\n","\u001b[32m[0717 09:35:43 @monitor.py:476]\u001b[0m param-summary/conv6/W-rms: 0.038883\n","\u001b[32m[0717 09:35:43 @monitor.py:476]\u001b[0m param-summary/fc1/W-rms: 0.066926\n","\u001b[32m[0717 09:35:43 @monitor.py:476]\u001b[0m regularize_cost: 1.1413e-06\n","\u001b[32m[0717 09:35:43 @monitor.py:476]\u001b[0m train_error: 0.006633\n","\u001b[32m[0717 09:35:43 @monitor.py:476]\u001b[0m val_accuracy: 0.9911\n","\u001b[32m[0717 09:35:43 @monitor.py:476]\u001b[0m val_cross_entropy_loss: 0.029845\n","\u001b[32m[0717 09:35:43 @base.py:287]\u001b[0m Training has finished!\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"\\nif __name__ == '__main__':\\n    parser = argparse.ArgumentParser()\\n    parser.add_argument('--dorefa',\\n                        help='number of bits for W,A,G, separated by comma. Defaults to '1,2,4'',\\n                        default='1,2,4')\\n    args = parser.parse_args()\\n\\n    BITW, BITA, BITG = map(int, args.dorefa.split(','))\\n    config = get_config()\\n    launch_train_with_config(config, SimpleTrainer())\\n\""]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":315},"id":"mduuAqCeuc4B","executionInfo":{"status":"ok","timestamp":1626514632970,"user_tz":-120,"elapsed":788,"user":{"displayName":"Lorenzo Pasco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgShaitSLZm3zyLVjMQT7ZzTrEV3kQEXha_A9lkVw=s64","userId":"01314717049817932576"}},"outputId":"0ff1a76f-18d2-43de-eabd-21fa23b97b15"},"source":["import json\n","import matplotlib.pyplot as plt\n","\n","f = open(\"train_log/mnist-dorefa-4,6,16/stats_def_first&last_avg_pooling_4616.json\",\"r\")\n","\n","data = json.load(f)\n","accuracy = []\n","val_accuracy = []\n","for ob in data:\n","  accuracy.append(ob[\"accuracy\"])\n","  val_accuracy.append(ob[\"val_accuracy\"])\n","\n","epochs = range(len(accuracy))\n","\n","plt.plot(epochs, accuracy, 'r', label='Training acc')\n","plt.plot(epochs, val_accuracy, 'b', label='Validation acc')\n","plt.title('Training and validation accuracy')\n","plt.legend()\n","plt.figure()"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<Figure size 432x288 with 0 Axes>"]},"metadata":{"tags":[]},"execution_count":6},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYAAAAEICAYAAABWJCMKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZzVY/vA8c/VtC9EyVK0SChpG1lCJUvhQeFRlqfwCJU9pERP1og8/ZKlh5IQRVkTacauTSWpaNOKad9raq7fH9eZOo2Z5szMmfmeM+d6v17ndbbv+Z7rnKnvfb7Xfd/XLaqKc865xFMi6ACcc84FwxsA55xLUN4AOOdcgvIGwDnnEpQ3AM45l6C8AXDOuQTlDYDbS0QmiEjnaG8bJBFZKiLnFsJ+VUTqhm6/KCJ9I9k2H+9zjYh8lt84nTsQ8XkA8U1EtoTdLQ/sBPaE7t+sqm8UfVSxQ0SWAv9W1UlR3q8Cx6nqwmhtKyK1gCVAKVXdHY04nTuQkkEH4ApGVStm3j7QwU5ESvpBxcUK//cYGzwFVEyJSCsRWSEi94vIH8BwETlERD4SkTQRWR+6XSPsNaki8u/Q7S4i8o2IDAxtu0RE2uVz29oi8pWIbBaRSSLyvIiMyiHuSGJ8RES+De3vMxGpGvb8dSLyu4isFZE+B/h+ThWRP0QkKeyx9iLyU+h2cxH5XkQ2iMhqERkiIqVz2NcIEXk07P69odesEpEbsmx7kYjMFJFNIrJcRPqFPf1V6HqDiGwRkdMzv9uw158hItNEZGPo+oxIv5s8fs+Hisjw0GdYLyLjw567VERmhT7DIhFpG3p8v3SbiPTL/DuLSK1QKuxGEVkGTA49Pib0d9gY+jfSIOz15UTkmdDfc2Po31g5EflYRG7L8nl+EpH22X1WlzNvAIq3I4BDgZpAV+zvPTx0/xhgOzDkAK8/FVgAVAWeAl4REcnHtm8CU4EqQD/gugO8ZyQxXg1cD1QDSgM9AUSkPvBCaP9Hhd6vBtlQ1SnAVuCcLPt9M3R7D3BX6POcDrQBuh0gbkIxtA3Fcx5wHJC1/2Er8C+gMnARcKuIXBZ67uzQdWVVraiq32fZ96HAx8Dg0Gd7FvhYRKpk+Qx/+26ykdv3/DqWUmwQ2tegUAzNgZHAvaHPcDawNKfvIxstgROBC0L3J2DfUzXgRyA8ZTkQaAacgf07vg/IAF4Drs3cSEQaAdWx78blhar6pZhcsP+I54ZutwJ2AWUPsH1jYH3Y/VQshQTQBVgY9lx5QIEj8rItdnDZDZQPe34UMCrCz5RdjA+G3e8GfBq6/RAwOuy5CqHv4Nwc9v0o8GrodiXs4Fwzh23vBMaF3Vegbuj2CODR0O1XgSfDtqsXvm02+30OGBS6XSu0bcmw57sA34RuXwdMzfL674EuuX03efmegSOxA+0h2Wz3Uma8B/r3F7rfL/PvHPbZ6hwghsqhbQ7GGqjtQKNstisLrMf6VcAaiqFF/f+tOFz8DKB4S1PVHZl3RKS8iLwUOqXehKUcKoenQbL4I/OGqm4L3ayYx22PAtaFPQawPKeAI4zxj7Db28JiOip836q6FVib03thv/Y7iEgZoAPwo6r+HoqjXigt8kcojsexs4Hc7BcD8HuWz3eqiKSEUi8bgVsi3G/mvn/P8tjv2K/fTDl9N/vJ5Xs+Gvubrc/mpUcDiyKMNzt7vxsRSRKRJ0NppE3sO5OoGrqUze69Qv+m3wauFZESQCfsjMXlkTcAxVvWIV73AMcDp6rqQexLOeSU1omG1cChIlI+7LGjD7B9QWJcHb7v0HtWyWljVf0FO4C2Y//0D1gqaT72K/MgoHd+YsDOgMK9CXwAHK2qBwMvhu03tyF5q7CUTbhjgJURxJXVgb7n5djfrHI2r1sOHJvDPrdiZ3+Zjshmm/DPeDVwKZYmOxg7S8iMYQ2w4wDv9RpwDZaa26ZZ0mUuMt4AJJZK2Gn1hlA++eHCfsPQL+rpQD8RKS0ipwP/KKQYxwIXi8iZoQ7b/uT+b/xN4A7sADgmSxybgC0icgJwa4QxvAN0EZH6oQYoa/yVsF/XO0L59KvDnkvDUi91ctj3J0A9EblaREqKyFVAfeCjCGPLGke237OqrsZy80NDncWlRCSzgXgFuF5E2ohICRGpHvp+AGYBHUPbJwNXRBDDTuwsrTx2lpUZQwaWTntWRI4KnS2cHjpbI3TAzwCewX/955s3AInlOaAc9uvqB+DTInrfa7CO1LVY3v1t7D9+dvIdo6rOBbpjB/XVWJ54RS4vewvrmJysqmvCHu+JHZw3A8NCMUcSw4TQZ5gMLAxdh+sG9BeRzVifxTthr90GPAZ8Kzb66LQs+14LXIz9el+LdYpenCXuSOX2PV8HpGNnQX9hfSCo6lSsk3kQsBH4kn1nJX2xX+zrgf+w/xlVdkZiZ2ArgV9CcYTrCcwBpgHrgAHsf8waCTTE+pRcPvhEMFfkRORtYL6qFvoZiCu+RORfQFdVPTPoWOKVnwG4Qicip4jIsaGUQVss7zs+t9c5l5NQeq0b8HLQscQzbwBcUTgCG6K4BRvDfquqzgw0Ihe3ROQCrL/kT3JPM7kD8BSQc84lKD8DcM65BBVXxeCqVq2qtWrVCjoM55yLKzNmzFijqodlfTyuGoBatWoxffr0oMNwzrm4IiJZZ5ADngJyzrmE5Q2Ac84lKG8AnHMuQcVVH0B20tPTWbFiBTt27Mh9YxeIsmXLUqNGDUqVKhV0KM65MHHfAKxYsYJKlSpRq1Ytcl6rxAVFVVm7di0rVqygdu3aQYfjnAsT9ymgHTt2UKVKFT/4xygRoUqVKn6G5lwMivsGAPCDf4zzv49zsSnuU0DOOVfs7NgBy5bBkiWwdKldevWCgw+O6tt4A1BAa9eupU2bNgD88ccfJCUlcdhhNuFu6tSplC5dOsfXTp8+nZEjRzJ48OADvscZZ5zBd999F72gnXPByjzAZx7cs15Wr95/+5Il4eqroWHDqIbhDUABValShVmzZgHQr18/KlasSM+ePfc+v3v3bkqWzP5rTk5OJjk5Odf38IO/c3EmPwf4Y46BWrWgXTu7zrzUrg1HHglJOS3dnX/eABSCLl26ULZsWWbOnEmLFi3o2LEjd9xxBzt27KBcuXIMHz6c448/ntTUVAYOHMhHH31Ev379WLZsGYsXL2bZsmXceeed3H777QBUrFiRLVu2kJqaSr9+/ahatSo///wzzZo1Y9SoUYgIn3zyCXfffTcVKlSgRYsWLF68mI8+2n+lwKVLl3LdddexdetWAIYMGcIZZ5wBwIABAxg1ahQlSpSgXbt2PPnkkyxcuJBbbrmFtLQ0kpKSGDNmDMcem9MSrc4lkJ07D3yAX7Vq/+1LloSjj87+AF+rFhx1VKEc4HNTvBqAO++E0K/xqGncGJ57Ls8vW7FiBd999x1JSUls2rSJr7/+mpIlSzJp0iR69+7Nu++++7fXzJ8/n5SUFDZv3szxxx/Prbfe+rex8zNnzmTu3LkcddRRtGjRgm+//Zbk5GRuvvlmvvrqK2rXrk2nTp2yjalatWp8/vnnlC1blt9++41OnToxffp0JkyYwPvvv8+UKVMoX74869atA+Caa66hV69etG/fnh07dpCRkZHn78G5uKUK33wD8+fnfoBPStr3C/6CC7I/wOeQCQhS7EVUTFx55ZUkhVr0jRs30rlzZ3777TdEhPT09Gxfc9FFF1GmTBnKlClDtWrV+PPPP6lRo8Z+2zRv3nzvY40bN2bp0qVUrFiROnXq7B1n36lTJ15++e8LJaWnp9OjRw9mzZpFUlISv/76KwCTJk3i+uuvp3z58gAceuihbN68mZUrV9K+fXvAJnM5lzBmzoQ77oCvv7b7SUn7fsGff/7+6ZkYPsDnJv4iPpB8/FIvLBUqVNh7u2/fvrRu3Zpx48axdOlSWrVqle1rypQps/d2UlISu3fvztc2ORk0aBCHH344s2fPJiMjww/qzmX111/w4IPwv/9BlSrwwguWsqlePS4P8LkpFvMAYt3GjRupXr06ACNGjIj6/o8//ngWL17M0qVLAXj77bdzjOPII4+kRIkSvP766+zZsweA8847j+HDh7Nt2zYA1q1bR6VKlahRowbjx9vSvTt37tz7vHPFzq5d8OyzcNxxMHw43HUX/PYb3HIL1KxZLA/+4A1Akbjvvvt44IEHaNKkSZ5+sUeqXLlyDB06lLZt29KsWTMqVarEwdmMF+7WrRuvvfYajRo1Yv78+XvPUtq2bcsll1xCcnIyjRs3ZuDAgQC8/vrrDB48mJNPPpkzzjiDP/74I+qxOxcoVfj4Yxteec89cOaZ8PPP8MwzULly0NEVurhaEzg5OVmzLggzb948TjzxxIAiih1btmyhYsWKqCrdu3fnuOOO46677go6rL387+Rizrx5cPfd8OmncPzxdgZw4YVBR1UoRGSGqv5tzLmfARQTw4YNo3HjxjRo0ICNGzdy8803Bx2Sc7Fp/XpL8Zx8Mnz/vR34f/qp2B78D6R4JrYS0F133RVTv/idizl79ljn7oMPwtq10LUrPPIIHPa3pXIThp8BOOeKv9RUaNrUOnUbNIAff4QXX0zogz94A+CcK86WLIErroDWrWHjRhgzBlJSbIKn8xSQc64Y2rIFnnwSBg60SVyPPGKjfMqVCzqymOINgHNur7ffhrQ0uOkmCJtzGD8yMuDNN+H++61cwzXXWEOQZUa9M54CKqDWrVszceLE/R577rnnuPXWW3N8TatWrcgcznrhhReyYcOGv23Tr1+/vePxczJ+/Hh++eWXvfcfeughJk2alJfwndsrIwN6dNvDbbfBiScoo0fbMPm4MXUqtGgB111npRm+/RZGjfKD/wF4A1BAnTp1YvTo0fs9Nnr06BwLsmX1ySefUDmfE06yNgD9+/fn3HPPzde+nPtl0ETWrEviVoZy0O8/0akTnHrUMr567Gv488+gw8vZqlXQuTOceqoVahsxAqZMgVCl23iXlgZPP20NdLR5A1BAV1xxBR9//DG7du0CrOTyqlWrOOuss7j11ltJTk6mQYMGPPzww9m+vlatWqxZswaAxx57jHr16nHmmWeyYMGCvdsMGzaMU045hUaNGnH55Zezbds2vvvuOz744APuvfdeGjduzKJFi+jSpQtjx44F4IsvvqBJkyY0bNiQG264gZ07d+59v4cffpimTZvSsGFD5s+f/7eYli5dyllnnUXTpk1p2rTpfusRDBgwgIYNG9KoUSN69eoFwMKFCzn33HNp1KgRTZs2ZdGiRVH4Zl2RUYVHHyWlp5UPv2/w0cy4fSQj6vRn9R9CywfP4rIjvmfB0efCtdfC889bsbRCmNWeJzt2wBNPQL16MHq0rZj166/WGJSI/0Pb2rXwwANWb65XL5gxoxDeRFXj5tKsWTPN6pdfftl7+447VFu2jO7ljjv+9pZ/c9FFF+n48eNVVfWJJ57Qe+65R1VV165dq6qqu3fv1pYtW+rs2bNVVbVly5Y6bdo0VVWtWbOmpqWl6fTp0/Wkk07SrVu36saNG/XYY4/Vp59+WlVV16xZs/e9+vTpo4MHD1ZV1c6dO+uYMWP2Ppd5f/v27VqjRg1dsGCBqqped911OmjQoL3vl/n6559/Xm+88ca/fZ6tW7fq9u3bVVX1119/1czv/ZNPPtHTTz9dt27dut/na968ub733nuqqrp9+/a9z4cL/zu5GLJ9u+rVV6uCdjh6itaquWe/p7et266P37xUK5XZoUmyW28tN1z/oJoqqFaooNqqlWrv3qoffqiallY0MWdkqL73nmrt2hbHZZepLlxYNO9dBNatU33wQdWKFVVF7M8zf37B9glM12yOqfHfTMaA8DRQePrnnXfeoWnTpjRp0oS5c+ful67J6uuvv6Z9+/aUL1+egw46iEsuuWTvcz///DNnnXUWDRs25I033mDu3LkHjGfBggXUrl2bevXqAdC5c2e++uqrvc936NABgGbNmu0tIBcuPT2dm266iYYNG3LllVfujTvSstGZz7sY9+efNjzyzTfJ6P8oqVtPofU5+x8Syh1SlgderMnCZWW4pVsSw9I7U7fCah69cjbbru0KmzfDgAHwj3/YmPrjj4cuXeDll2HOHJt8FU1z5sC550KHDlC+PHz+OYwbB8VgoaING6BfP6su/eijNjH555/hjTfsay0MxWoUUFDVoC+99FLuuusufvzxR7Zt20azZs1YsmQJAwcOZNq0aRxyyCF06dKFHTt25Gv/Xbp0Yfz48TRq1IgRI0aQmppaoHgzS0rnVE7ay0YngDlz4OKLLcE8Zgw/17uCdQ9BDpXKqVYNhgyB228XevUS+o45mReOepZHH4V/Xb6VpJnTrazC999bcbXXXrMXVqoEp50Gp59uOflTT81fkbU1a+Dhh23yVuXKlobq2rVYVOnctAkGD7b6cxs2wOWX20eN8vK/2fIzgCioWLEirVu35oYbbtj763/Tpk1UqFCBgw8+mD///JMJEyYccB9nn30248ePZ/v27WzevJkPP/xw73ObN2/myCOPJD09nTfeeGPv45UqVWLz5s1/29fxxx/P0qVLWbhwIWBVPVu2bBnx5/Gy0cXcRx/ZwXj3bvjqK7jiClJS7KmcGoBM9erBe+/ZOilHHw033ABNzqzAxB0tLVH9/vtWU/+332DkSBuG+ddf9pO2bVs49FCbiXvTTfDqq7ba1oF6N9PT7eh43HHw0kvQvbvtu1u3uD/4Z05VqF0b+vaFli2ta2Xs2KI5+EOEDYCItBWRBSKyUER6ZfN8TRH5QkR+EpFUEakR9twAEfk5dLkq7PHaIjIltM+3RaR0dD5SMDp16sTs2bP3NgCNGjWiSZMmnHDCCVx99dW0aNHigK9v2rQpV111FY0aNaJdu3accsope5975JFHOPXUU2nRogUnnHDC3sc7duzI008/TZMmTfbreC1btizDhw/nyiuvpGHDhpQoUYJbbrkl4s/iZaOLKVUrfHbJJXYknzoVkq1AZGoq1KljqxpG4swz7cf+O+/A1q12bD//fJg9GxCBunVtOOYLL9gyrRs2wKRJ0L+/1dd/91248UY48USoWtXyHY8+Cl98YWklgM8+g0aNbGWu5GTb+eDB1ojEsa1bbVRP7drWyXv66TBtGowfH8AE5ew6BsIvQBKwCKgDlAZmA/WzbDMG6By6fQ7weuj2RcDnWKqpAjANOCj03DtAx9DtF4Fbc4slt05gF7v87xSwnTtV//1v6zTt0EF1y5a9T+3Zo3rIIarZjAeIyI4dqoMGqR56qHVadu6sunx5Li/as0d13jzVV16xuBo0sNhAtUQJ1Tp17Paxx6q+/751/Ma5bdtUn31WtVqoD/2CC1R/+KFo3pscOoEjaQBOByaG3X8AeCDLNnOBo0O3BdgUun0v0Ddsu1eAf4a2WQOUzO49crp4AxC//O8UoLVrbbQO2IidPfuP9Jk50556/fWCvc369ar33qtapoxq2bKqDzygunFjHnfw6aeqDz+sevHFqgMGWOsS57ZvVx08WPXII+17Pvdc1W+/LdoYcmoAIkkBVQeWh91fEXos3GygQ+h2e6CSiFQJPd5WRMqLSFWgNXA0UAXYoKq7D7BP51xBLVhgHa/ffWc5+cce+9sY+Ujz/7mpXBmeesre8vLLbYj+scdaf216eoQ7uOACGwrz4Ydw331xWo/C7NxpGbC6deH22y3r9uWXNnApVuaoRasTuCfQUkRmAi2BlcAeVf0M+AT4DngL+B7I07gwEekqItNFZHpaWlq222hczVdPPP73CcikSTYCZ8MGmDzZcvLZSE21g1S0KibUrGkVGKZNg5NOgh497HrcuDgrLZFP6ekwbJgd8Lt1s2Gdkyfb93z22UFHt79IGoCV2K/2TDVCj+2lqqtUtYOqNgH6hB7bELp+TFUbq+p5WOrnV2AtUFlESua0z7B9v6yqyaqafFg2tbvLli3L2rVr/SATo1SVtWvX+lDSovbii9YzW736vho52dizx36Vtm4d/RCSk+3A9+GHVpCzQwc7AE6ZEv33igXp6TawqV49G6F61FHWj/3114Xz/UZDJOOopgHHiUht7CDdEbg6fINQemedqmZgfQSvhh5PAiqr6loRORk4GfhMVVVEUoArgNFAZ+D9/HyAGjVqsGLFCnI6O3DBK1u2LDW8IFfR2L0bevaE//4X2rWzEgkHHZTj5rNnW5n8gqZ/ciJi0w3atrWD40MP2UnJP/8Jjz9eLOZvsXu3FSDt3x8WLbKGb+hQ+8wiQUeXi+w6BrJegAuxX+6LgD6hx/oDl4RuXwH8Ftrmf0CZ0ONlgV9Clx+AxmH7rANMBRZio4jK5BZHdp3AzrmQDRtU27WznsY771RNT8/1Jc88Y5uvXFkE8anq5s3Wx1u+vGqpUhZmWKWTuLJ7t+obb6jWq2ffYZMmqh98EJsDlsjvKKBYungD4FwOFi+2oZRJSaovvhjxyy6+2A5gRW3lShv9WaKE6sEHqz71lI2WiQd79qiOHq164ol2BD35ZNVx42LzwJ8ppwbAZwI7F+++/RaaN4eVK2HiRLj55ohetmePTQQurPTPgRx1lHWU/vSTdU/cdx+ccILVvSmMssfRkJFh89caNYKOHS29M2aMzd697LI4SPdkwxsA5+LZ66/DOefAIYfADz9AmzYRv3TmTKtDE2QHZYMGVjroiy9sgu+111pbljk0NRaoWoWLpk1teeH0dHjrLWu8rrgivitPx3cxDecSVUYGPPigDbZv3doKyOSxREJmTcE8lIkqNOecA9On2xlAnz52v2RJKF3aLqVKHfh2bs/n9Xbm9fr1Nrfhxx+tHNGoUfbrPykp6G8sOrwBcC7ebN0K//qXVWW76SabaVWqVJ53k5JiaZcjjyyEGPOhRAmbqnDFFbao1/LlsGuX/eIOv87u9s6dVkLoQNtk3s5riqlOHYvnmmvivv7c3xSzj+NcMbdypRVzmznTCrvdeWe+ks+7d9v49GuuKYQYC6hcOTjAktoFtmePNQiRNBZgKal8tK9xwRsA5+LF9Ol28N+82WZXXXRRvnf144+2m1idoFSYkpLs4nMTvRPYufgwdqxNoy1d2ur6FODgD7GV/3fB8QbAuVimagXcrrzSisVPnRqV1UJSUqB+fTj88CjE6OKWNwDOxaodO6xX9MEHLVk/ebKtzVhA6enwzTfBjP93scUbAOdi0V9/2Zj+N96wlbJefz1qSesZM2w5wkTM/7v9eSewc7Fmzhz4xz+sERgzxsZFRpHn/10mPwNwLpZ8/LGtFrJr194F26MtJcXq82dTXd0lGG8AnIsFqjBokA3zPO64/RZsjybP/7tw3gC4QHzzjdVL/+KLoCOJATNmWDWxu++266+/jt7yXFlMmwbbtnn+3xlvAFyRGzbMar18/jmcdx707h3hmrHFzTff2KItycmW7nn8ccv5V6hQaG+Zmf+PtaUJXTC8AXBFJj3d1oft2tUagOXL4cYbrZ7Z2WfDkiVBR1gEVK3la9UKzjrLfv0/8QT8/js88EChl5ZMSYGTT4aqVQv1bVyc8AbAFYk1a+CCC6xuWc+e1teZWRP+7bdh3jyb5/T220FHWkgyMuCDD2w9xPPPh99+g+eeg6VLoVevAy7bGC27dtnSAZ7/d5m8AXCFbs4cOOUUq2AwciQ8/fT+5XT/+U+YNctmpnbsaGcFW7cGF29U7dlj6/I2bgyXXgppafDSS7B4MdxxB5QvX2ShTJ0K27d7A+D28QbAFar33oPTT983qvG667LfrlYte753bxg+HJo1s0YhbqWn2wepXx86dbLymyNHwq+/Wg6sTJkiDyk11QqH+vh/l8kbAFcoMjLgP/+Byy+3MefTpllZ3QMpVcrK3kyaZCtVnXoqDB5safO4sWMHDB0KdevCDTfYL/yxY+Hnn631C7CgfGb+P4/rxrhizBsAF3Vbtljtsn79oHNn++V51FGRv/6cc2y5vfPPtyzJJZdYH0JM27IFBg6E2rWhe3eoXt06On780VrBgNcN3LnTUnA+/NOF8wbARdWSJTaRdfx4W69k+PD8lbCpWtX6TAcPhs8+s1+usbRO7F4bNsAjj0DNmnDvvbbI7eTJ1tt64YUxs1L41Kl2cuL5fxfOGwAXNSkp1tm7fDlMmAB33VWw458I3HYbTJlig2TatLHCmDExZyAtzTosjjkGHnrIWr3vv7f8VevWMXPgz5SSYiH5+H8XzhsAV2CqNrzzvPOsWvHUqZa+iZbGjW24/PXXWx9By5Y2ejIQK1day1azJjz5pE3kmjXLVug67bSAgspdaqp9j4ccEnQkLpZ4A+AKZNcuuPlmm+DVrh388IOVsom2ChXglVfgrbdg7lw7mI0ZE/33ydHixfZB69SB//s/G7v6yy82caFRoyIMJO927PD8v8ueNwAu3zJL1g8bZpNYx48v/PlMHTvaD+4TT7Rj8E03FfKcgXnz4F//gnr1YMQIG9nz2292+4QTCvGNo2fKFOsE9vy/y8obAJcvM2daCZsZM2ye0+OP7z+5qzDVrm1zBh54wM4KkpNh9uwov8nMmVaKuUEDePdduP126+F+4QULII6kpNggpLPOCjoSF2u8AXB59vbb0KKF3f7mG7jqqqKPoVQpa3Q+/xw2brQ5A0OGRGHOQOaC602b2s5797YOh2efzdtY1hiSmgpNmkDlykFH4mKNNwAuYhkZ0KePpWGaNrXJXU2bBhtTmzb2679NGxsxdNllsHZtHneianWpzznHWrYpU2wZxt9/t+s4Xjll+3YbnOT5f5ediBoAEWkrIgtEZKGI9Mrm+Zoi8oWI/CQiqSJSI+y5p0RkrojME5HBIjY+LrTdAhGZFboUfLVrV2g2bbKD6+OPW9598mQ4/PCgozKHHQYffWS11T791PpkM8seH5CqTTI44ww491yYPx+eecZ+8ffpUyx+Mv/wg3XUe/7fZUtVD3gBkoBFQB2gNDAbqJ9lmzFA59Dtc4DXQ7fPAL4N7SMJ+B5oFXouFUjO7f3DL82aNVNX9H77TbV+fdWkJNUhQ1QzMoKOKGczZqjWq6cqovrgg6rp6TlsOGWKauvWqqB6zDGqL7ygun17kcunYwEAAB7zSURBVMZaFPr2VS1RQnXjxqAjcUECpms2x9RIzgCaAwtVdbGq7gJGA5dm2aY+MDl0OyXseQXKhhqOMkAp4M8I2yYXAz7/3Gr4/Pmn3e7ePebmOO2naVPrmO7SxbI3LVtaJmevBQusc/fUU61M6XPPWYG2W27J35TlGJeaaoX1iqDatItDkTQA1YHlYfdXhB4LNxvoELrdHqgkIlVU9XusQVgdukxU1XlhrxseSv/0zUwNZSUiXUVkuohMT0tLiyBcFw2qdmxs29ZWJ5w2LX7yyBUrwquvwptv2jG+cWMY+9Jay101aAATJ8LDD+8ryRxAZc6isG2bpYDi5e/mil60OoF7Ai1FZCbQElgJ7BGRusCJQA2s0ThHRDIHo12jqg2Bs0KXbAsFq+rLqpqsqsmHxXFnXDzZudOGu991l5Ww/+67uBv5CFgV5lmpG6hXbhlX3lKFm19tzraud8KiRVaprlKloEMsVN9/b2UzPP/vchJJA7ASODrsfo3QY3up6ipV7aCqTYA+occ2YGcDP6jqFlXdAkwATg89vzJ0vRl4E0s1uYCtXm0HjBEj7Efy2LH2izrubNsGTzxBnXNq8c3qutzf4CNezriJ5NSBzPkzMcYbpKTY3Iwzzww6EherImkApgHHiUhtESkNdAQ+CN9ARKqKSOa+HgBeDd1ehp0ZlBSRUtjZwbzQ/aqh15YCLgZ+LvjHcQUxbZpNqpozxw78/foFXsU479LTbcWtunVtDP9ZZ1Fq9nSe/PliPvsM1q+3gnVDh8bZOgP5kJpqf89ifqLjCiDX/96quhvoAUwE5gHvqOpcEekvIpeENmsFLBCRX4HDgcdCj4/FRhDNwfoJZqvqh1iH8EQR+QmYhZ1RDIvap3J5NmqUzRQtXdpSPpdfHnREeZSRAe+8Yzn+W27ZN134ww+tljRWrG72bBvu3707tG+fjzkDcWLrVivK5+kfd0DZDQ2K1YsPA42+3btVe/a00ZCtWqmmpQUdUT589plqs2b2IRo0UP3ggwOOVd2zR/XZZ1VLlVKtXl01NbUIYy0in31mX8ennwYdiYsFFGAYqCumNmyAiy+2hay6d7c5UVWrBh1VHkybZhO4zj/f6vOPGGE/8f/xjwOOVS1Rwjq4f/jBVmw8/3xYtqzowi4KKSm2+mRmyQ7nsuMNQIJasMCGwk+aZCnzIUOsvk5cWLDA1pxs3twO+IMG2Vj+zp3zVJGuaVP7/Lt3W4234iQ11fo64rID3xUZbwAS0IQJduxcv95KOnTtGnREEVq50oJt0MA+xEMP2ZDOO+/M91j+Y46xoa7Dhlnd/OJgyxY7OfL8v8uNNwAJ5qWXLO1z7LEwfXqclAhevx7uv99G9owYAd262SSu//wnKlNce/SwzuDRowseaiz49ls7q/EJYC433gAkCFXo398GyLRrB19/bb9+Y9q2bbbsYp068PTTVsJh/nxbKb5a9Mbyt24N9evbQl/FYWhoSoql8844I+hIXKzzBiAB7NljP5offtjS5OPG2RKLMSs9HV5+2daWfOABO5LNnAmvv26NQZSJ2FnAjz9ax3C8S021FF9M/41dTPAGoJjbscOWTnzxRejVC4YPj+HOXlVb6Pekk2z93Zo14csv4eOPC33d3euus2zSkCGF+jaFbvNmS+15/t9FwhuAYmzDBivm9t57VtjtiSdiuJLnpEk2bOWf/7QW6v33LZl99tlF8vYVK8L111v788cfRfKWheKbb+yMz/P/LhLeABRTq1ZZKeTvvoO33rKilzFpxgybonveebbK/PDhNrTzkkuKvLXq3n1f9ilepaZa+3n66UFH4uJByaADcNG3YAFccIGNbPnkE5srFZg9e2DdOlizxiZrpaXtu/3jj9YhUaWKrbl7662B1uQ/7jg7Y3rxRet6iNlU2QGkpMBpp9kEN+dy4w1AMTN1Klx4oc2HylwMJKq2bdt3AM96nd1j69blPLTm0EOhb1/o2TNmViy57TZbE/6994JZ7L4gNm2yE6o+fYKOxMULbwCKkU8/tSJuRxxha57UrZvLCzIybIx9dgfunA7u27Zlv6+kJKsjUbWqLdJ70kl2nXk/8zrzdtWqMbkQS9u2NkdiyJD4awC+/tr+pJ7/d5HyBqCYeP11W8TlpJNskuwRR+Sw4ebNNp5+5kzLEWVkZL9dxYr7DtrVqtns2+wO6JnXBx8ch7Wj/65ECesLuPtumDXLVhOLF6mpVs31tNOCjsTFC28AioGBA+Hee63M8bhxuWRTBgywqm833ghHHpnzQb0Yro8bqS5d4MEH7Szgf/8LOprIZeb/y5ULOhIXL7wBiGMZGXDfffDMMzZ6cuTIXLIqy5fbxtdcE19HtiJ2yCFw7bX2fQ4YYH3UsW7DBjup69s36EhcPIn/c/YElZ5us3qfecZmsb71VgQp9d697frxxws9vnjXo4dNonv11dy3jQWZ+X+fAObywhuAOLRli5W8HzUKHnvMSuPkmn6fNs1ecPfdcVAEKHgNG9o8iqFDbSRrrEtNtR8Anv93eeENQJxJS7Nc/+efWxand+8I5kup2oG/WjWrB+EictttsHSpVaKIdSkpNvkrgbtuXD54AxBHli61FZ7mzLHO3htvjPCF771nNQIefdRXCM+DSy+FGjWsSmgsW7/eRiz58E+XV94AxImffrKimGvWWNmcSy6J8IU7d1pPccOGNk7URaxkSZucPGkSzJsXdDQ5++orO8nz/L/LK28A4kBqqi3ckpRknX15Wud1yBBbPOWZZ/K0XKIz//63ja1//vmgI8lZaqqlfk49NehIXLzxBiDGvfuu1fWpXt0KuzVokIcXr1kDjzxiK8Ccd16hxVicVasGHTvCa69ZqYVYlJJiZ4cxOLHaxThvAGLYCy/Y2ufNmlkK/+ij87iD/v1tyNDAgYUSX6Lo0cO+xtdeCzqSv1u3ztKDnv93+eENQAxStdW7unWzwmSTJlndtDyZP9/GMHbtausdunw75RRLrwwZknPljKB8+aXn/13+eQMQY3bvtnV7+/e3BUrGjctnad/77rM1Afv1i3aICalHD/j1V/jii6Aj2V9qqpV+aN486EhcPPIGIIZs324pn5dftnr0r7xiI1HybPJk+PBDqwscxcXTE9mVV9pXGWtDQlNSbFBA6dJBR+LikTcAMWLDBuvsff99+O9/rVpDvhbE2rMH7rkHatWC22+PdpgJq0wZy6Z99BEsWRJ0NGbNGpsT4vl/l1/eAMSAlSttmOcPP1hNnwIdt0eOtFlBTz7p00Kj7JZbrOTG0KFBR2K+/NKuPf/v8ssbgIDNn29D+H7/3er4F2gRki1bLO1z2mlWHtRFVfXq0KGDpeZyWhenKKWmWv/QKacEHYmLVxE1ACLSVkQWiMhCEflbMRkRqSkiX4jITyKSKiI1wp57SkTmisg8ERksYokNEWkmInNC+9z7eCKZMgXOPNOqTqamQps2Bdzh00/D6tUwaFCRL6ieKHr0sNILb74ZdCSW/z/zzPhcu9jFhlwbABFJAp4H2gH1gU4iknVc4UBgpKqeDPQHngi99gygBXAycBJwCtAy9JoXgJuA40KXtgX9MPFkwgQr6la5sk3watq0gDtcscIagI4dvSRkITrrLDj5ZBsSmtNSx0Xhr79g7lxP/7iCieQMoDmwUFUXq+ouYDRwaZZt6gOTQ7dTwp5XoCxQGigDlAL+FJEjgYNU9QdVVWAkcFmBPkkcGTnSyjmfcAJ8+62tQVtgffrYIPUnnojCzlxOROwsYPZsm5wXlK++smvvAHYFEUkDUB1YHnZ/ReixcLOBDqHb7YFKIlJFVb/HGoTVoctEVZ0Xev2KXPYJgIh0FZHpIjI9LS0tgnBjlyo89ZQt5NKqlaV9Dj88CjueMcNalTvvtNE/rlBdc42duQ0ZElwMKSk2zaNZs+BicPEvWp3APYGWIjITS/GsBPaISF3gRKAGdoA/R0TOysuOVfVlVU1W1eTDDjssSuEWvfR0Oz7ff7919H78cZQqM6vasM/DDrPJA67QlS9vpbjffddGcAUhs0Cg5/9dQUTSAKwEwqvQ1Ag9tpeqrlLVDqraBOgTemwDdjbwg6puUdUtwATg9NDraxxon8XJokXWWTd4sDUCb74ZxcJd779v4wH794eDD47STl1uunWzjNtLLxX9e//5J/zyi+f/XcFF0gBMA44TkdoiUhroCHwQvoGIVBWRzH09AGSupLoMOzMoKSKlsLODeaq6GtgkIqeFRv/8C3g/Cp8n5rz5JjRpYmUExo61ATq5Lt8YqV274N57rdbPv/8dpZ26SNSpY3WaXnrJllwoSpnj/z3/7woq10ORqu4GegATgXnAO6o6V0T6i0jmsiStgAUi8itwOPBY6PGxwCJgDtZPMFtVPww91w34H7AwtM2EqHyiGLFlC3TpYvnik0+2uVmXXx7lNxk6FBYutFr/+aoZ4QritttsNM7YsUX7vikplj4s8Mgxl/BEgxzLlkfJyck6ffr0oMPI1Y8/2mjMRYvgwQehb99COD6vWwd169osoIkTo7xzF4mMDDjxRDjkEJvFXVROPNHOQOJhrWIXG0RkhqomZ33cZwJHkaqleE47zWaKTp4M//lPIf04f+QR2LjRa/0HqEQJGxI6ZQpMm1Y077l6tc0e9/y/iwZvAKLkr7/g4ovh7rvhwgttnHjLlrm/Ll9+/dXGIP7737bWrwtM585QsWLRLRnp+X8XTd4ARMEXX0CjRnY9ZIjV8K9SpRDf8P77rdBb//6F+CYuEgcdZI3A6NFQFNNUUlLsPRs3Lvz3csWfNwAFkJ5uQ+/PO8/ywFOnQvfuhVyG58svYfx46N07SrPIXEF1724jgf73v8J/r9RUOPts7/N30eENQD4tWWITcZ580jIx06bZaJ9ClZFhOaZjjrEJBS4mnHginHuureG8e3fhvc+qVZb98/y/ixZvAPJh9Gg7BZ8/H955x1bwqlChCN541CgbYvTEE7YOoIsZPXrA8uXwwQe5b5tfqal27fl/Fy3eAOTB1q1www3QqROcdJJ19F55ZRG+ee/etvhrx45F9KYuUhdfDDVrFu6SkSkpVoOoUaPCew+XWLwBiNCsWVZ4a8QIG9v/5Zf2H77IPPOMFZ559tkoTiV20ZKUZOUhUlPh558L5z0y8/9JSYWzf5d4/EiSC1Wr4XPqqbB5s430eeSRIu6EW7UKBgyw040WLYrwjV1e3HijDc4qjCqhK1bYpG/P/7to8gbgANLSrG7/HXfYgu2zZweUf33wQetdfPLJAN7cRapKFbj6anj9ddiwIbr7zsz/ewPgoskbgBxMnmy51s8/tzOA99+HqlUDCGTWLMs73X67zf93Ma1HD5sFPnx4dPebkmJDjT3/76LJG4As0tNtca1zz7XqylOnWtGvQJbYzaz1f+ihFpSLeU2aWJbu+edt1G60ZOb/vfvHRZP/cwqzZIn9J3v8ccvnTp8e8C+ujz7aV1CocuUAA3F50aOHFQL89NPo7G/ZMli82Id/uujzBiDknXdsbP8vv9g4/2HDimhsf07S06FnT1s4uGvXAANxedWhAxx5ZPQ6gz3/7wpLwjcAW7fCTTfZMo3161vK/aqrgo4KePFFm/Y5cKCv+xdnSpeGm2+GCRNs5E5BpaRYFtDr/rloS+gGYPZsSE6GV16xOVZffQW1awcdFbB+vaV92rSx0qIu7tx8s7Xb0agSmppqlWU9/++iLSH/SanajM3mza2k/qRJ8NhjMfRD+7HHbMGXZ54JqPfZFdQRR8AVV9hooC1b8r+fpUvt4vl/VxgSrgFYswYuvdRGVZ53np0FnHNO0FGFWbTIxp3ecIOP+Ytzt91mPzBGjcr/Pjz/7wpTQjUAKSl2TJ04Ef77X/jwQzjssKCjyuL++y2J/MgjQUfiCui002zd3iFD7KwzP1JTbf5JgwZRDc05IEEagN27bV3eNm1sMe0pU+wMIOayK19/De++C7162TASF9dEbEjo3Ln7fsnnhar9aPH8vyssxf6flaqlfB59FK6/HmbMiNHVlDJr/VevbteuWOjY0UpE5GdI6NKlNgfA8/+usBT7BkDE0ulvvmmjfQId238gb71lM8+eeALKlw86Ghcl5crZgkHjx9vBPC9SUuza8/+usBT7BgDg8suthn/M2rbN0j7NmsE11wQdjYuyW2+16xdfzNvrUlOtj6p+/aiH5ByQIA1AzBs0yOr9eq3/YqlmTbjkEptdvmNHZK/JzP+3ahWDfVWu2PCjTdD++MPSPh06WCEiVyzddpsNQX777ci2X7zYfhN4/t8VJm8Agta3L+zaZQu+uGKrdWtL5fzf/0U2JNTz/64oeAMQpJ9+gldftbGCdesGHY0rRJlDQmfMsGHIuUlNhcMPt1qAzhUWbwCCklnrv3JlOwtwxd5118FBB+W+cLzn/11R8QYgKBMmWBGihx+2pZ5csVexos1FGTPGun5ysnChLQPt6R9X2CJqAESkrYgsEJGFItIrm+drisgXIvKTiKSKSI3Q461FZFbYZYeIXBZ6boSILAl7LhanZxWO9HT79V+v3r4xgi4hdOtmf/5hw3LeJjP/7x3ArrDl2gCISBLwPNAOqA90EpGsI5MHAiNV9WSgP/AEgKqmqGpjVW0MnANsAz4Le929mc+r6qyCf5w4MWwYzJ8PTz8dQyVIXVGoVw/atrU5Aenp2W+TmmrVROvVK9LQXAKK5AygObBQVRer6i5gNHBplm3qA5NDt1OyeR7gCmCCqm7Lb7DFwsaNlvZp1Qr+8Y+go3EB6NHDUjzjxv39ucz8f+vWnv93hS+SBqA6sDzs/orQY+FmAx1Ct9sDlUSkSpZtOgJvZXnssVDaaJCIlMnuzUWkq4hMF5HpaWlpEYQb4x5/HNau9Vr/CaxdO6hTJ/vO4F9/tf4Bz/+7ohCtTuCeQEsRmQm0BFYCezKfFJEjgYbAxLDXPACcAJwCHArcn92OVfVlVU1W1eTDYq52cx4tWQLPPQedO1udYJeQSpSA7t3hm29sCdJwnv93RSmSBmAlcHTY/Rqhx/ZS1VWq2kFVmwB9Qo9tCNvkn8A4VU0Pe81qNTuB4ViqqXi7/34oWdJKk7qEdv31VvMva5XQ1FQ46iifFuKKRiQNwDTgOBGpLSKlsVTOB+EbiEhVEcnc1wPAq1n20Yks6Z/QWQEiIsBlwM95Dz+OfPGFjf+77z4r+ewS2iGHwLXXwhtv2OqfYPn/1FTP/7uik2sDoKq7gR5Y+mYe8I6qzhWR/iJySWizVsACEfkVOBx4LPP1IlILO4P4Msuu3xCROcAcoCpQfH8W79plPX/HHmsNgHPYP4kdO6xMOdjAsD//9Py/KzolI9lIVT8BPsny2ENht8cCY3N47VL+3mmMqsbSSryF69ln7X/3J59YgXjngIYNbbWvoUNtDSDP/7ui5jOBC9uyZba+b/v2NvzDuTA9etjKXx9/bOmfGjVshJBzRSGiMwBXAHfeadfPPRdsHC4mXXaZHfT/7/9g9mybJOb5f1dU/AygMH3yic326dsXjjkm6GhcDCpZEm65xcpCpaV5/t8VLW8ACsv27bYKyAkn+CLv7oBuuglKl7bbnv93RclTQIVlwABb1umLL/b973YuG9WqQZcuNjGsVq2go3GJxBuAwrBoETz5JHTsCOckzmAnl3/PPw+7d3v+3xUtbwCiTdVSP6VLW70f5yJQsqRdnCtK/k8u2saPt8VeBg2yOf3OORejvBM4mrZuhTvugJNPtgHezjkXw/wMIJoeeQSWL4e33vLzeedczPMzgGiZN89y/l26QIsWQUfjnHO58gYgGlStwHvFijb80znn4oDnKaJh9Gir5DV0qA3qds65OOBnAAW1aRPccw8kJ0PXrkFH45xzEfMzgIJ6+GFbxPX99yEpKehonHMuYn4GUBA//WRlHG++GU45JehonHMuT7wByK+MDLj1Vlvb77HHct/eOedijKeA8uu11+C77+DVV+HQQ4OOxjnn8szPAPJj3Tpb2/eMM6Bz56Cjcc65fPEGID/69LFGYOhQKOFfoXMuPvnRK6+mTYOXXrKKn40aBR2Nc87lmzcAebFnD3TrBocfDv/5T9DROOdcgXgncF4MGwbTp8Mbb8DBBwcdjXPOFYifAUTqr7+gd29btLVTp6Cjcc65AvMGIFL33w9bttjafb5un3OuGPAGIBLffgsjRsDdd8OJJwYdjXPORYU3ALnZvds6fo8+Gvr2DToa55yLGu8Ezs2QIVbz5913oUKFoKNxzrmoiegMQETaisgCEVkoIr2yeb6miHwhIj+JSKqI1Ag93lpEZoVddojIZaHnaovIlNA+3xaR0tH9aFGwahU89BC0bQvt2wcdjXPORVWuDYCIJAHPA+2A+kAnEamfZbOBwEhVPRnoDzwBoKopqtpYVRsD5wDbgM9CrxkADFLVusB64MYofJ7o6tkTdu2yip/e8eucK2YiOQNoDixU1cWqugsYDVyaZZv6wOTQ7ZRsnge4ApigqttERLAGYWzoudeAy/IafKGaPNkWd7//fqhbN+honHMu6iJpAKoDy8Purwg9Fm420CF0uz1QSUSqZNmmI/BW6HYVYIOq7j7APoOza5et8Vu7NvT6W8bLOeeKhWiNAuoJtBSRmUBLYCWwJ/NJETkSaAhMzOuORaSriEwXkelpaWlRCjcXzz4L8+dbB3C5ckXzns45V8QiaQBWAkeH3a8RemwvVV2lqh1UtQnQJ/TYhrBN/gmMU9X00P21QGURyRyF9Ld9hu37ZVVNVtXkww47LIJwC2jZMnjkEbjsMrjwwsJ/P+ecC0gkDcA04LjQqJ3SWCrng/ANRKSqiGTu6wHg1Sz76MS+9A+qqlhfwRWhhzoD7+c9/EJw552gCs89F3QkzjlXqHJtAEJ5+h5Y+mYe8I6qzhWR/iJySWizVsACEfkVOBzYu0aiiNTCziC+zLLr+4G7RWQh1ifwSoE+STRMmADjxtmEr5o1g47GOecKldiP8fiQnJys06dPL5yd79gBJ50EJUvaxK/SsTctwTnn8kNEZqhqctbHfSZwpgEDYNEimDTJD/7OuYTgtYDADvxPPAFXXQVt2gQdjXPOFQlvAFRtecdSpeCZZ4KOxjnnioyngMaPt87fZ56B6rEzF8055wpbYp8BbN0Kd9wBDRvaWYBzziWQxD4DePRRWL4c3nzTUkDOOZdAEvcMYP58S/t07gxnnhl0NM45V+QSswFQtWJvFSrAU08FHY1zzgUiMVNAb79t5Z6ffx6qVQs6GuecC0TinQFs2mSLuzdrBjffHHQ0zjkXmMQ7A3j4YfjjDxv+mZQUdDTOOReYxDoD+OknW97xppugefOgo3HOuUAlTgOQkQHdusEhh8DjjwcdjXPOBS5xUkAjR8K338Irr0CVrKtVOudc4kmMM4D16+G+++D006FLl6Cjcc65mJAYZwB9+sDatfDZZ1AiMdo855zLTWIcDevUsTOAxo2DjsQ552JGYpwB9OwZdATOORdzEuMMwDnn3N94A+CccwnKGwDnnEtQ3gA451yC8gbAOecSlDcAzjmXoLwBcM65BOUNgHPOJShR1aBjiJiIpAG/5/PlVYE1UQwn3vn3sY9/F/vz72N/xeH7qKmqh2V9MK4agIIQkemqmhx0HLHCv499/LvYn38f+yvO34engJxzLkF5A+CccwkqkRqAl4MOIMb497GPfxf78+9jf8X2+0iYPgDnnHP7S6QzAOecc2G8AXDOuQSVEA2AiLQVkQUislBEegUdT1BE5GgRSRGRX0RkrojcEXRMsUBEkkRkpoh8FHQsQRORyiIyVkTmi8g8ETk96JiCIiJ3hf6f/Cwib4lI2aBjirZi3wCISBLwPNAOqA90EpH6wUYVmN3APapaHzgN6J7A30W4O4B5QQcRI/4LfKqqJwCNSNDvRUSqA7cDyap6EpAEdAw2qugr9g0A0BxYqKqLVXUXMBq4NOCYAqGqq1X1x9Dtzdh/7urBRhUsEakBXAT8L+hYgiYiBwNnA68AqOouVd0QbFSBKgmUE5GSQHlgVcDxRF0iNADVgeVh91eQ4Ac9ABGpBTQBpgQbSeCeA+4DMoIOJAbUBtKA4aGU2P9EpELQQQVBVVcCA4FlwGpgo6p+FmxU0ZcIDYDLQkQqAu8Cd6rqpqDjCYqIXAz8paozgo4lRpQEmgIvqGoTYCuQkH1mInIIlimoDRwFVBCRa4ONKvoSoQFYCRwddr9G6LGEJCKlsIP/G6r6XtDxBKwFcImILMVSg+eIyKhgQwrUCmCFqmaeFY7FGoREdC6wRFXTVDUdeA84I+CYoi4RGoBpwHEiUltESmMdOR8EHFMgRESw/O48VX026HiCpqoPqGoNVa2F/buYrKrF7ldepFT1D2C5iBwfeqgN8EuAIQVpGXCaiJQP/b9pQzHsEC8ZdACFTVV3i0gPYCLWk/+qqs4NOKygtACuA+aIyKzQY71V9ZMAY3Kx5TbgjdCPpcXA9QHHEwhVnSIiY4EfsdFzMymGJSG8FIRzziWoREgBOeecy4Y3AM45l6C8AXDOuQTlDYBzziUobwCccy5BeQPgnHMJyhsA55xLUP8PnOAWi2Tw0JkAAAAASUVORK5CYII=\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 0 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ST3WBdVha1W-","executionInfo":{"status":"ok","timestamp":1626514638069,"user_tz":-120,"elapsed":223,"user":{"displayName":"Lorenzo Pasco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgShaitSLZm3zyLVjMQT7ZzTrEV3kQEXha_A9lkVw=s64","userId":"01314717049817932576"}},"outputId":"96297c51-9ecd-428a-acaa-186f2d72160e"},"source":["from tabulate import tabulate\n","import matplotlib.pyplot as plt\n","\n","ep = [i+1 for i in epochs]\n","table_acc = {\"Epochs\" : ep, \"Accuracy\":accuracy}\n","table_val_acc = {\"Epochs\" : ep, \"Accuracy\":val_accuracy}\n","\n","print(\"ACCURACY\\n\")\n","print(tabulate(table_acc, headers='keys', tablefmt='fancy_grid'))\n","print(\"\\nVALIDATION ACCURACY\\n\")\n","print(tabulate(table_val_acc, headers='keys', tablefmt='fancy_grid'))"],"execution_count":7,"outputs":[{"output_type":"stream","text":["ACCURACY\n","\n","╒══════════╤════════════╕\n","│   Epochs │   Accuracy │\n","╞══════════╪════════════╡\n","│        1 │   0.967162 │\n","├──────────┼────────────┤\n","│        2 │   0.974561 │\n","├──────────┼────────────┤\n","│        3 │   0.982541 │\n","├──────────┼────────────┤\n","│        4 │   0.982901 │\n","├──────────┼────────────┤\n","│        5 │   0.985293 │\n","├──────────┼────────────┤\n","│        6 │   0.987453 │\n","├──────────┼────────────┤\n","│        7 │   0.99122  │\n","├──────────┼────────────┤\n","│        8 │   0.990215 │\n","├──────────┼────────────┤\n","│        9 │   0.992805 │\n","├──────────┼────────────┤\n","│       10 │   0.993367 │\n","╘══════════╧════════════╛\n","\n","VALIDATION ACCURACY\n","\n","╒══════════╤════════════╕\n","│   Epochs │   Accuracy │\n","╞══════════╪════════════╡\n","│        1 │   0.976464 │\n","├──────────┼────────────┤\n","│        2 │   0.979727 │\n","├──────────┼────────────┤\n","│        3 │   0.983782 │\n","├──────────┼────────────┤\n","│        4 │   0.987441 │\n","├──────────┼────────────┤\n","│        5 │   0.984177 │\n","├──────────┼────────────┤\n","│        6 │   0.973596 │\n","├──────────┼────────────┤\n","│        7 │   0.991396 │\n","├──────────┼────────────┤\n","│        8 │   0.988924 │\n","├──────────┼────────────┤\n","│        9 │   0.988825 │\n","├──────────┼────────────┤\n","│       10 │   0.9911   │\n","╘══════════╧════════════╛\n"],"name":"stdout"}]}]}