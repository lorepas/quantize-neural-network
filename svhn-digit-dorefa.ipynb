{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"svhn-digit-dorefa_32bit.ipynb","provenance":[],"authorship_tag":"ABX9TyOyutRRIDOh6ekci+f606b2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"5qzKFEQKqXDt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626441571768,"user_tz":-120,"elapsed":21746,"user":{"displayName":"Lorenzo Pasco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgShaitSLZm3zyLVjMQT7ZzTrEV3kQEXha_A9lkVw=s64","userId":"01314717049817932576"}},"outputId":"11eef2d0-92a6-43cb-8ad3-eb424c2a6a77"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eDXKVoHj26H8","executionInfo":{"status":"ok","timestamp":1626441578706,"user_tz":-120,"elapsed":4379,"user":{"displayName":"Lorenzo Pasco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgShaitSLZm3zyLVjMQT7ZzTrEV3kQEXha_A9lkVw=s64","userId":"01314717049817932576"}},"outputId":"99b28d24-e27e-4f81-f726-8aa8ddf7af82"},"source":["!pip install tensorpack\n","\n","%cd gdrive/MyDrive/SEAI_Project"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting tensorpack\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f9/8c/63e5f5a4a04dea36b75850f9daa885ccbfad64bec1fae0ee4ca9f31b3eaa/tensorpack-0.11-py2.py3-none-any.whl (296kB)\n","\r\u001b[K     |█                               | 10kB 18.4MB/s eta 0:00:01\r\u001b[K     |██▏                             | 20kB 13.1MB/s eta 0:00:01\r\u001b[K     |███▎                            | 30kB 14.9MB/s eta 0:00:01\r\u001b[K     |████▍                           | 40kB 17.1MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 51kB 19.3MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 61kB 21.7MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 71kB 22.7MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 81kB 23.6MB/s eta 0:00:01\r\u001b[K     |██████████                      | 92kB 25.0MB/s eta 0:00:01\r\u001b[K     |███████████                     | 102kB 21.9MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 112kB 21.9MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 122kB 21.9MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 133kB 21.9MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 143kB 21.9MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 153kB 21.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 163kB 21.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 174kB 21.9MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 184kB 21.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 194kB 21.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 204kB 21.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 215kB 21.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 225kB 21.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 235kB 21.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 245kB 21.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 256kB 21.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 266kB 21.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 276kB 21.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 286kB 21.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 296kB 21.9MB/s \n","\u001b[?25hRequirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.7/dist-packages (from tensorpack) (0.8.9)\n","Requirement already satisfied: pyzmq>=16 in /usr/local/lib/python3.7/dist-packages (from tensorpack) (22.1.0)\n","Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.7/dist-packages (from tensorpack) (1.1.0)\n","Collecting msgpack-numpy>=0.4.4.2\n","  Downloading https://files.pythonhosted.org/packages/19/05/05b8d7c69c6abb36a34325cc3150089bdafc359f0a81fb998d93c5d5c737/msgpack_numpy-0.4.7.1-py2.py3-none-any.whl\n","Requirement already satisfied: msgpack>=0.5.2 in /usr/local/lib/python3.7/dist-packages (from tensorpack) (1.0.2)\n","Requirement already satisfied: psutil>=5 in /usr/local/lib/python3.7/dist-packages (from tensorpack) (5.4.8)\n","Requirement already satisfied: numpy>=1.14 in /usr/local/lib/python3.7/dist-packages (from tensorpack) (1.19.5)\n","Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.7/dist-packages (from tensorpack) (4.41.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tensorpack) (1.15.0)\n","Installing collected packages: msgpack-numpy, tensorpack\n","Successfully installed msgpack-numpy-0.4.7.1 tensorpack-0.11\n","/content/gdrive/MyDrive/SEAI_Project\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"47qPSLMU19HM","executionInfo":{"status":"ok","timestamp":1626360854243,"user_tz":-120,"elapsed":350483,"user":{"displayName":"Lorenzo Pasco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgShaitSLZm3zyLVjMQT7ZzTrEV3kQEXha_A9lkVw=s64","userId":"01314717049817932576"}},"outputId":"53bab98a-63b2-48bc-c7d6-6312b6b9c97d"},"source":["#!/usr/bin/env python\n","# -*- coding: utf-8 -*-\n","# File: svhn-digit-dorefa.py\n","# Author: Yuxin Wu\n","\n","import argparse\n","import os\n","import tensorflow as tf\n","\n","from tensorpack import *\n","from tensorpack.dataflow import dataset\n","from tensorpack.tfutils.summary import add_moving_summary, add_param_summary\n","from tensorpack.tfutils.varreplace import remap_variables\n","\n","\"\"\"\n","This is a tensorpack script for the SVHN results in paper:\n","DoReFa-Net: Training Low Bitwidth Convolutional Neural Networks with Low Bitwidth Gradients\n","http://arxiv.org/abs/1606.06160\n","The original experiements are performed on a proprietary framework.\n","This is our attempt to reproduce it on tensorpack.\n","Accuracy:\n","    With (W,A,G)=(1,1,4), can reach 3.1~3.2% error after 150 epochs.\n","    With (W,A,G)=(1,2,4), error is 3.0~3.1%.\n","    With (W,A,G)=(32,32,32), error is about 2.3%.\n","Speed:\n","    With quantization, 60 batch/s on 1 1080Ti. (4721 batch / epoch)\n","To Run:\n","    ./svhn-digit-dorefa.py --dorefa 1,2,4\n","\"\"\"\n","tf.compat.v1.reset_default_graph()\n","\n","BITW = 1\n","BITA = 2\n","BITG = 4\n","\n","\"\"\"\n","imported from dorefa file\n","\"\"\"\n","def get_dorefa(bitW, bitA, bitG):\n","    \"\"\"\n","    Return the three quantization functions fw, fa, fg, for weights, activations and gradients respectively\n","    \"\"\"\n","    def quantize(x, k):\n","        n = float(2 ** k - 1)\n","\n","        @tf.custom_gradient\n","        def _quantize(x):\n","            return tf.round(x * n) / n, lambda dy: dy\n","\n","        return _quantize(x)\n","\n","    def fw(x):\n","        if bitW == 32:\n","            return x\n","\n","        if bitW == 1:   # BWN\n","            E = tf.stop_gradient(tf.reduce_mean(tf.abs(x)))\n","\n","            @tf.custom_gradient\n","            def _sign(x):\n","                return tf.where(tf.equal(x, 0), tf.ones_like(x), tf.sign(x / E)) * E, lambda dy: dy\n","\n","            return _sign(x)\n","\n","        x = tf.tanh(x)\n","        x = x / tf.reduce_max(tf.abs(x)) * 0.5 + 0.5\n","        return 2 * quantize(x, bitW) - 1\n","\n","    def fa(x):\n","        if bitA == 32:\n","            return x\n","        return quantize(x, bitA)\n","\n","    def fg(x):\n","        if bitG == 32:\n","            return x\n","\n","        @tf.custom_gradient\n","        def _identity(input):\n","            def grad_fg(x):\n","                rank = x.get_shape().ndims\n","                assert rank is not None\n","                maxx = tf.reduce_max(tf.abs(x), list(range(1, rank)), keepdims=True)\n","                x = x / maxx\n","                n = float(2**bitG - 1)\n","                x = x * 0.5 + 0.5 + tf.random.uniform(\n","                    tf.shape(x), minval=-0.5 / n, maxval=0.5 / n)\n","                x = tf.clip_by_value(x, 0.0, 1.0)\n","                x = quantize(x, bitG) - 0.5\n","                return x * maxx * 2\n","\n","            return input, grad_fg\n","\n","        return _identity(x)\n","    return fw, fa, fg\n","\n","\n","class Model(ModelDesc):\n","    def inputs(self):\n","        return [tf.TensorSpec([None, 40, 40, 3], tf.float32, 'input'),\n","                tf.TensorSpec([None], tf.int32, 'label')]\n","\n","    def build_graph(self, image, label):\n","        fw, fa, fg = get_dorefa(BITW, BITA, BITG)\n","\n","        # monkey-patch tf.get_variable to apply fw\n","        def binarize_weight(v):\n","            name = v.op.name\n","            # don't binarize first and last layer\n","            if not name.endswith('W') or 'conv0' in name or 'fc' in name:\n","                return v\n","            else:\n","                logger.info(\"Binarizing weight {}\".format(v.op.name))\n","                return fw(v)\n","\n","        def nonlin(x):\n","            if BITA == 32:\n","                return tf.nn.relu(x)\n","            return tf.clip_by_value(x, 0.0, 1.0)\n","\n","        def activate(x):\n","            return fa(nonlin(x))\n","\n","        image = image / 256.0\n","\n","        with remap_variables(binarize_weight), \\\n","                argscope(BatchNorm, momentum=0.9, epsilon=1e-4), \\\n","                argscope(Conv2D, use_bias=False):\n","            logits = (LinearWrap(image)\n","                      .Conv2D('conv0', 48, 5, padding='VALID', use_bias=True)\n","                      .MaxPooling('pool0', 2, padding='SAME')\n","                      .apply(activate)\n","                      # 18\n","                      .Conv2D('conv1', 64, 3, padding='SAME')\n","                      .apply(fg)\n","                      .BatchNorm('bn1').apply(activate)\n","#AVGPooling\n","                      .Conv2D('conv2', 64, 3, padding='SAME')\n","                      .apply(fg)\n","                      .BatchNorm('bn2')\n","                      .MaxPooling('pool1', 2, padding='SAME')\n","                      .apply(activate)\n","                      # 9\n","                      .Conv2D('conv3', 128, 3, padding='VALID')\n","                      .apply(fg)\n","                      .BatchNorm('bn3').apply(activate)\n","                      # 7\n","\n","                      .Conv2D('conv4', 128, 3, padding='SAME')\n","                      .apply(fg)\n","                      .BatchNorm('bn4').apply(activate)\n","\n","                      .Conv2D('conv5', 128, 3, padding='VALID')\n","                      .apply(fg)\n","                      .BatchNorm('bn5').apply(activate)\n","                      # 5\n","                      .Dropout(rate=0.5 if self.training else 0.0)\n","                      .Conv2D('conv6', 512, 5, padding='VALID')\n","                      .apply(fg).BatchNorm('bn6')\n","                      .apply(nonlin)\n","                      .FullyConnected('fc1', 10)())\n","        tf.nn.softmax(logits, name='output')\n","\n","        correct = tf.cast(tf.nn.in_top_k(predictions=logits, targets=label, k=1), tf.float32, name='correct')\n","        accuracy = tf.reduce_mean(correct, name='accuracy')\n","        train_error = tf.reduce_mean(1 - correct, name='train_error')\n","        summary.add_moving_summary(train_error, accuracy)\n","        \n","        cost = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=label)\n","        cost = tf.reduce_mean(cost, name='cross_entropy_loss')\n","        # weight decay on all W of fc layers\n","        wd_cost = regularize_cost('fc.*/W', l2_regularizer(1e-7))\n","        add_param_summary(('.*/W', ['histogram', 'rms']))\n","        total_cost = tf.add_n([cost, wd_cost], name='cost')\n","        add_moving_summary(cost, wd_cost, total_cost)\n","        return total_cost\n","\n","    def optimizer(self):\n","        lr = tf.compat.v1.train.exponential_decay(\n","            learning_rate=1e-3,\n","            global_step=get_global_step_var(),\n","            decay_steps=4721 * 100,\n","            decay_rate=0.5, staircase=True, name='learning_rate')\n","        tf.summary.scalar('lr', lr)\n","\n","        return tf.compat.v1.train.AdamOptimizer(lr, epsilon=1e-5)\n","\n","\n","def get_config():\n","    logger.set_logger_dir(os.path.join('train_log', 'svhn-dorefa-{}'.format(args)))\n","\n","    # prepare dataset\n","    d1 = dataset.SVHNDigit('train')\n","    d2 = dataset.SVHNDigit('extra')\n","    data_train = RandomMixData([d1, d2])\n","    data_test = dataset.SVHNDigit('test')\n","\n","    augmentors = [\n","        imgaug.Resize((40, 40)),\n","        imgaug.Brightness(30),\n","        imgaug.Contrast((0.5, 1.5)),\n","    ]\n","    data_train = AugmentImageComponent(data_train, augmentors)\n","    data_train = BatchData(data_train, 128)\n","    data_train = MultiProcessRunnerZMQ(data_train, 5)\n","\n","    augmentors = [imgaug.Resize((40, 40))]\n","    data_test = AugmentImageComponent(data_test, augmentors)\n","    data_test = BatchData(data_test, 128, remainder=True)\n","\n","    return TrainConfig(\n","        data=QueueInput(data_train),\n","        callbacks=[\n","            ModelSaver(),\n","            InferenceRunner(    # run inference(for validation) after every epoch\n","                data_test,   # the DataFlow instance used for validation\n","                ScalarStats(    # produce `val_accuracy` and `val_cross_entropy_loss`\n","                    ['cross_entropy_loss', 'accuracy'], prefix='val'))\n","        ],\n","        model=Model(),\n","        max_epoch=10,\n","    )\n","\n","args = \"1,2,4\"\n","BITW, BITA, BITG = map(int, args.split(','))\n","config = get_config()\n","launch_train_with_config(config, SimpleTrainer())\n","\n","'''\n","if __name__ == '__main__':\n","    parser = argparse.ArgumentParser()\n","    parser.add_argument('--dorefa',\n","                        help='number of bits for W,A,G, separated by comma. Defaults to \\'1,2,4\\'',\n","                        default='1,2,4')\n","    args = parser.parse_args()\n","\n","    BITW, BITA, BITG = map(int, args.dorefa.split(','))\n","    config = get_config()\n","    launch_train_with_config(config, SimpleTrainer())\n","'''"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[32m[0715 14:02:40 @logger.py:128]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m Log directory train_log/svhn-dorefa-1,2,4 exists! Use 'd' to delete it. \n","\u001b[32m[0715 14:02:40 @logger.py:131]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m If you're resuming from a previous run, you can choose to keep it.\n","Press any other key to exit. \n","\u001b[32m[0715 14:02:42 @logger.py:85]\u001b[0m Existing log file 'train_log/svhn-dorefa-1,2,4/log.log' backuped to 'train_log/svhn-dorefa-1,2,4/log.log.0715-140242'\n","\u001b[32m[0715 14:02:42 @logger.py:92]\u001b[0m Argv: /usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py -f /root/.local/share/jupyter/runtime/kernel-49d3f7f6-7d8c-4bc8-ae1e-7863be7d26fe.json\n","\u001b[32m[0715 14:02:42 @parallel.py:340]\u001b[0m [MultiProcessRunnerZMQ] Will fork a dataflow more than one times. This assumes the datapoints are i.i.d.\n","\u001b[32m[0715 14:02:42 @input_source.py:221]\u001b[0m Setting up the queue 'QueueInput/input_queue' for CPU prefetching ...\n","\u001b[32m[0715 14:02:43 @trainers.py:48]\u001b[0m Building graph for a single training tower ...\n","\u001b[32m[0715 14:02:43 @<ipython-input-17-200335a6510d>:113]\u001b[0m Binarizing weight conv1/W\n","\u001b[32m[0715 14:02:43 @<ipython-input-17-200335a6510d>:113]\u001b[0m Binarizing weight conv2/W\n","\u001b[32m[0715 14:02:43 @<ipython-input-17-200335a6510d>:113]\u001b[0m Binarizing weight conv3/W\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1692: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n","  warnings.warn('`layer.apply` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0715 14:02:43 @<ipython-input-17-200335a6510d>:113]\u001b[0m Binarizing weight conv4/W\n","\u001b[32m[0715 14:02:43 @<ipython-input-17-200335a6510d>:113]\u001b[0m Binarizing weight conv5/W\n","\u001b[32m[0715 14:02:43 @<ipython-input-17-200335a6510d>:113]\u001b[0m Binarizing weight conv6/W\n","\u001b[32m[0715 14:02:43 @regularize.py:97]\u001b[0m regularize_cost() found 1 variables to regularize.\n","\u001b[32m[0715 14:02:43 @regularize.py:21]\u001b[0m The following tensors will be regularized: fc1/W:0\n","\u001b[32m[0715 14:02:44 @model_utils.py:67]\u001b[0m \u001b[36mList of Trainable Variables: \n","\u001b[0mname       shape               #elements\n","---------  ----------------  -----------\n","conv0/W    [5, 5, 3, 48]            3600\n","conv0/b    [48]                       48\n","conv1/W    [3, 3, 48, 64]          27648\n","bn1/gamma  [64]                       64\n","bn1/beta   [64]                       64\n","conv2/W    [3, 3, 64, 64]          36864\n","bn2/gamma  [64]                       64\n","bn2/beta   [64]                       64\n","conv3/W    [3, 3, 64, 128]         73728\n","bn3/gamma  [128]                     128\n","bn3/beta   [128]                     128\n","conv4/W    [3, 3, 128, 128]       147456\n","bn4/gamma  [128]                     128\n","bn4/beta   [128]                     128\n","conv5/W    [3, 3, 128, 128]       147456\n","bn5/gamma  [128]                     128\n","bn5/beta   [128]                     128\n","conv6/W    [5, 5, 128, 512]      1638400\n","bn6/gamma  [512]                     512\n","bn6/beta   [512]                     512\n","fc1/W      [512, 10]                5120\n","fc1/b      [10]                       10\u001b[36m\n","Number of trainable variables: 22\n","Number of parameters (elements): 2082378\n","Storage space needed for all trainable variables: 7.94MB\u001b[0m\n","\u001b[32m[0715 14:02:44 @base.py:207]\u001b[0m Setup callbacks graph ...\n","\u001b[32m[0715 14:02:44 @argtools.py:138]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m \"import prctl\" failed! Install python-prctl so that processes can be cleaned with guarantee.\n","\u001b[32m[0715 14:02:45 @inference_runner.py:148]\u001b[0m [InferenceRunner] Building tower 'InferenceTower' on device /gpu:0 ...\n","\u001b[32m[0715 14:02:45 @<ipython-input-17-200335a6510d>:113]\u001b[0m Binarizing weight conv1/W\n","\u001b[32m[0715 14:02:45 @<ipython-input-17-200335a6510d>:113]\u001b[0m Binarizing weight conv2/W\n","\u001b[32m[0715 14:02:45 @<ipython-input-17-200335a6510d>:113]\u001b[0m Binarizing weight conv3/W\n","\u001b[32m[0715 14:02:46 @<ipython-input-17-200335a6510d>:113]\u001b[0m Binarizing weight conv4/W\n","\u001b[32m[0715 14:02:46 @<ipython-input-17-200335a6510d>:113]\u001b[0m Binarizing weight conv5/W\n","\u001b[32m[0715 14:02:46 @<ipython-input-17-200335a6510d>:113]\u001b[0m Binarizing weight conv6/W\n","\u001b[32m[0715 14:02:46 @summary.py:47]\u001b[0m [MovingAverageSummary] 5 operations in collection 'MOVING_SUMMARY_OPS' will be run with session hooks.\n","\u001b[32m[0715 14:02:46 @summary.py:94]\u001b[0m Summarizing collection 'summaries' of size 22.\n","\u001b[32m[0715 14:02:46 @graph.py:99]\u001b[0m Applying collection UPDATE_OPS of 12 ops.\n","\u001b[32m[0715 14:02:46 @base.py:228]\u001b[0m Creating the session ...\n","\u001b[32m[0715 14:02:48 @base.py:234]\u001b[0m Initializing the session ...\n","\u001b[32m[0715 14:02:48 @base.py:241]\u001b[0m Graph Finalized.\n","\u001b[32m[0715 14:02:48 @concurrency.py:37]\u001b[0m Starting EnqueueThread: enqueue dataflow to TF queue \"QueueInput/input_queue\" ...\n","\u001b[32m[0715 14:02:49 @inference_runner.py:95]\u001b[0m [InferenceRunner] Will eval 204 iterations\n","\u001b[32m[0715 14:02:49 @monitor.py:361]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m History epoch=2 from JSON is not the predecessor of the current starting_epoch=1\n","\u001b[32m[0715 14:02:49 @monitor.py:362]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m If you want to resume old training, either use `AutoResumeTrainConfig` or correctly set the new starting_epoch yourself to avoid inconsistency. \n","\u001b[32m[0715 14:02:49 @monitor.py:369]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m Now, we will train with starting_epoch=1 and backup old json to train_log/svhn-dorefa-1,2,4/stats.json.0715-140249\n","\u001b[32m[0715 14:02:49 @base.py:273]\u001b[0m Start Epoch 1 ...\n"],"name":"stdout"},{"output_type":"stream","text":["100%|##########|4721/4721[05:10<00:00,15.19it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0715 14:08:00 @base.py:283]\u001b[0m Epoch 1 (global_step 4721) finished, time:5 minutes 10 seconds.\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0715 14:08:00 @saver.py:82]\u001b[0m Model saved to train_log/svhn-dorefa-1,2,4/model-4721.\n"],"name":"stdout"},{"output_type":"stream","text":["100%|##########|204/204[00:12<00:00,15.93it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0715 14:08:13 @monitor.py:476]\u001b[0m QueueInput/queue_size: 19\n","\u001b[32m[0715 14:08:13 @monitor.py:476]\u001b[0m accuracy: 0.95088\n","\u001b[32m[0715 14:08:13 @monitor.py:476]\u001b[0m cost: 0.1655\n","\u001b[32m[0715 14:08:13 @monitor.py:476]\u001b[0m cross_entropy_loss: 0.1655\n","\u001b[32m[0715 14:08:13 @monitor.py:476]\u001b[0m param-summary/conv0/W-rms: 0.17576\n","\u001b[32m[0715 14:08:13 @monitor.py:476]\u001b[0m param-summary/conv1/W-rms: 0.078577\n","\u001b[32m[0715 14:08:13 @monitor.py:476]\u001b[0m param-summary/conv2/W-rms: 0.071168\n","\u001b[32m[0715 14:08:13 @monitor.py:476]\u001b[0m param-summary/conv3/W-rms: 0.074478\n","\u001b[32m[0715 14:08:13 @monitor.py:476]\u001b[0m param-summary/conv4/W-rms: 0.062045\n","\u001b[32m[0715 14:08:13 @monitor.py:476]\u001b[0m param-summary/conv5/W-rms: 0.065983\n","\u001b[32m[0715 14:08:13 @monitor.py:476]\u001b[0m param-summary/conv6/W-rms: 0.052521\n","\u001b[32m[0715 14:08:13 @monitor.py:476]\u001b[0m param-summary/fc1/W-rms: 0.10409\n","\u001b[32m[0715 14:08:13 @monitor.py:476]\u001b[0m regularize_cost: 2.7634e-06\n","\u001b[32m[0715 14:08:13 @monitor.py:476]\u001b[0m train_error: 0.049122\n","\u001b[32m[0715 14:08:13 @monitor.py:476]\u001b[0m val_accuracy: 0.92184\n","\u001b[32m[0715 14:08:13 @monitor.py:476]\u001b[0m val_cross_entropy_loss: 0.2737\n","\u001b[32m[0715 14:08:13 @group.py:44]\u001b[0m Callbacks took 13.576 sec in total. InferenceRunner: 12.8 seconds\n","\u001b[32m[0715 14:08:13 @base.py:273]\u001b[0m Start Epoch 2 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|4721/4721[04:50<00:00,16.24it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0715 14:13:04 @base.py:283]\u001b[0m Epoch 2 (global_step 9442) finished, time:4 minutes 50 seconds.\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0715 14:13:04 @saver.py:82]\u001b[0m Model saved to train_log/svhn-dorefa-1,2,4/model-9442.\n"],"name":"stdout"},{"output_type":"stream","text":["100%|##########|204/204[00:12<00:00,16.85it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0715 14:13:16 @monitor.py:476]\u001b[0m QueueInput/queue_size: 0.55469\n","\u001b[32m[0715 14:13:16 @monitor.py:476]\u001b[0m accuracy: 0.9615\n","\u001b[32m[0715 14:13:16 @monitor.py:476]\u001b[0m cost: 0.1334\n","\u001b[32m[0715 14:13:16 @monitor.py:476]\u001b[0m cross_entropy_loss: 0.13339\n","\u001b[32m[0715 14:13:16 @monitor.py:476]\u001b[0m param-summary/conv0/W-rms: 0.19275\n","\u001b[32m[0715 14:13:16 @monitor.py:476]\u001b[0m param-summary/conv1/W-rms: 0.093796\n","\u001b[32m[0715 14:13:16 @monitor.py:476]\u001b[0m param-summary/conv2/W-rms: 0.092398\n","\u001b[32m[0715 14:13:16 @monitor.py:476]\u001b[0m param-summary/conv3/W-rms: 0.097813\n","\u001b[32m[0715 14:13:16 @monitor.py:476]\u001b[0m param-summary/conv4/W-rms: 0.087621\n","\u001b[32m[0715 14:13:16 @monitor.py:476]\u001b[0m param-summary/conv5/W-rms: 0.091966\n","\u001b[32m[0715 14:13:16 @monitor.py:476]\u001b[0m param-summary/conv6/W-rms: 0.078654\n","\u001b[32m[0715 14:13:16 @monitor.py:476]\u001b[0m param-summary/fc1/W-rms: 0.12801\n","\u001b[32m[0715 14:13:16 @monitor.py:476]\u001b[0m regularize_cost: 4.1913e-06\n","\u001b[32m[0715 14:13:16 @monitor.py:476]\u001b[0m train_error: 0.038498\n","\u001b[32m[0715 14:13:16 @monitor.py:476]\u001b[0m val_accuracy: 0.93879\n","\u001b[32m[0715 14:13:16 @monitor.py:476]\u001b[0m val_cross_entropy_loss: 0.21328\n","\u001b[32m[0715 14:13:16 @group.py:44]\u001b[0m Callbacks took 12.502 sec in total. InferenceRunner: 12.1 seconds\n","\u001b[32m[0715 14:13:16 @base.py:273]\u001b[0m Start Epoch 3 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|4721/4721[04:52<00:00,16.16it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0715 14:18:09 @base.py:283]\u001b[0m Epoch 3 (global_step 14163) finished, time:4 minutes 52 seconds.\n","\u001b[32m[0715 14:18:09 @saver.py:82]\u001b[0m Model saved to train_log/svhn-dorefa-1,2,4/model-14163.\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|204/204[00:12<00:00,16.73it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0715 14:18:21 @monitor.py:476]\u001b[0m QueueInput/queue_size: 3.2588e-30\n","\u001b[32m[0715 14:18:21 @monitor.py:476]\u001b[0m accuracy: 0.97266\n","\u001b[32m[0715 14:18:21 @monitor.py:476]\u001b[0m cost: 0.097908\n","\u001b[32m[0715 14:18:21 @monitor.py:476]\u001b[0m cross_entropy_loss: 0.097902\n","\u001b[32m[0715 14:18:21 @monitor.py:476]\u001b[0m param-summary/conv0/W-rms: 0.21286\n","\u001b[32m[0715 14:18:21 @monitor.py:476]\u001b[0m param-summary/conv1/W-rms: 0.11218\n","\u001b[32m[0715 14:18:21 @monitor.py:476]\u001b[0m param-summary/conv2/W-rms: 0.1134\n","\u001b[32m[0715 14:18:21 @monitor.py:476]\u001b[0m param-summary/conv3/W-rms: 0.12164\n","\u001b[32m[0715 14:18:21 @monitor.py:476]\u001b[0m param-summary/conv4/W-rms: 0.11177\n","\u001b[32m[0715 14:18:21 @monitor.py:476]\u001b[0m param-summary/conv5/W-rms: 0.11602\n","\u001b[32m[0715 14:18:21 @monitor.py:476]\u001b[0m param-summary/conv6/W-rms: 0.10088\n","\u001b[32m[0715 14:18:21 @monitor.py:476]\u001b[0m param-summary/fc1/W-rms: 0.14532\n","\u001b[32m[0715 14:18:21 @monitor.py:476]\u001b[0m regularize_cost: 5.3996e-06\n","\u001b[32m[0715 14:18:21 @monitor.py:476]\u001b[0m train_error: 0.027341\n","\u001b[32m[0715 14:18:21 @monitor.py:476]\u001b[0m val_accuracy: 0.95144\n","\u001b[32m[0715 14:18:21 @monitor.py:476]\u001b[0m val_cross_entropy_loss: 0.18067\n","\u001b[32m[0715 14:18:21 @group.py:44]\u001b[0m Callbacks took 12.481 sec in total. InferenceRunner: 12.2 seconds\n","\u001b[32m[0715 14:18:21 @base.py:273]\u001b[0m Start Epoch 4 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|4721/4721[04:52<00:00,16.15it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0715 14:23:14 @base.py:283]\u001b[0m Epoch 4 (global_step 18884) finished, time:4 minutes 52 seconds.\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0715 14:23:14 @saver.py:82]\u001b[0m Model saved to train_log/svhn-dorefa-1,2,4/model-18884.\n"],"name":"stdout"},{"output_type":"stream","text":["100%|##########|204/204[00:11<00:00,17.00it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0715 14:23:26 @monitor.py:476]\u001b[0m QueueInput/queue_size: 3.4925e-10\n","\u001b[32m[0715 14:23:26 @monitor.py:476]\u001b[0m accuracy: 0.97083\n","\u001b[32m[0715 14:23:26 @monitor.py:476]\u001b[0m cost: 0.10469\n","\u001b[32m[0715 14:23:26 @monitor.py:476]\u001b[0m cross_entropy_loss: 0.10469\n","\u001b[32m[0715 14:23:26 @monitor.py:476]\u001b[0m param-summary/conv0/W-rms: 0.23129\n","\u001b[32m[0715 14:23:26 @monitor.py:476]\u001b[0m param-summary/conv1/W-rms: 0.1311\n","\u001b[32m[0715 14:23:26 @monitor.py:476]\u001b[0m param-summary/conv2/W-rms: 0.13496\n","\u001b[32m[0715 14:23:26 @monitor.py:476]\u001b[0m param-summary/conv3/W-rms: 0.1417\n","\u001b[32m[0715 14:23:26 @monitor.py:476]\u001b[0m param-summary/conv4/W-rms: 0.13243\n","\u001b[32m[0715 14:23:26 @monitor.py:476]\u001b[0m param-summary/conv5/W-rms: 0.13764\n","\u001b[32m[0715 14:23:26 @monitor.py:476]\u001b[0m param-summary/conv6/W-rms: 0.11945\n","\u001b[32m[0715 14:23:26 @monitor.py:476]\u001b[0m param-summary/fc1/W-rms: 0.15858\n","\u001b[32m[0715 14:23:26 @monitor.py:476]\u001b[0m regularize_cost: 6.4354e-06\n","\u001b[32m[0715 14:23:26 @monitor.py:476]\u001b[0m train_error: 0.029169\n","\u001b[32m[0715 14:23:26 @monitor.py:476]\u001b[0m val_accuracy: 0.95287\n","\u001b[32m[0715 14:23:26 @monitor.py:476]\u001b[0m val_cross_entropy_loss: 0.17245\n","\u001b[32m[0715 14:23:26 @group.py:44]\u001b[0m Callbacks took 12.327 sec in total. InferenceRunner: 12 seconds\n","\u001b[32m[0715 14:23:26 @base.py:273]\u001b[0m Start Epoch 5 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|4721/4721[04:55<00:00,15.96it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0715 14:28:22 @base.py:283]\u001b[0m Epoch 5 (global_step 23605) finished, time:4 minutes 55 seconds.\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0715 14:28:22 @saver.py:82]\u001b[0m Model saved to train_log/svhn-dorefa-1,2,4/model-23605.\n"],"name":"stdout"},{"output_type":"stream","text":["100%|##########|204/204[00:11<00:00,17.80it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0715 14:28:33 @monitor.py:476]\u001b[0m QueueInput/queue_size: 1.3531e-26\n","\u001b[32m[0715 14:28:33 @monitor.py:476]\u001b[0m accuracy: 0.97286\n","\u001b[32m[0715 14:28:33 @monitor.py:476]\u001b[0m cost: 0.09501\n","\u001b[32m[0715 14:28:33 @monitor.py:476]\u001b[0m cross_entropy_loss: 0.095002\n","\u001b[32m[0715 14:28:33 @monitor.py:476]\u001b[0m param-summary/conv0/W-rms: 0.24888\n","\u001b[32m[0715 14:28:33 @monitor.py:476]\u001b[0m param-summary/conv1/W-rms: 0.14511\n","\u001b[32m[0715 14:28:33 @monitor.py:476]\u001b[0m param-summary/conv2/W-rms: 0.15052\n","\u001b[32m[0715 14:28:33 @monitor.py:476]\u001b[0m param-summary/conv3/W-rms: 0.16046\n","\u001b[32m[0715 14:28:33 @monitor.py:476]\u001b[0m param-summary/conv4/W-rms: 0.1509\n","\u001b[32m[0715 14:28:33 @monitor.py:476]\u001b[0m param-summary/conv5/W-rms: 0.15718\n","\u001b[32m[0715 14:28:33 @monitor.py:476]\u001b[0m param-summary/conv6/W-rms: 0.13557\n","\u001b[32m[0715 14:28:33 @monitor.py:476]\u001b[0m param-summary/fc1/W-rms: 0.17182\n","\u001b[32m[0715 14:28:33 @monitor.py:476]\u001b[0m regularize_cost: 7.5527e-06\n","\u001b[32m[0715 14:28:33 @monitor.py:476]\u001b[0m train_error: 0.027136\n","\u001b[32m[0715 14:28:33 @monitor.py:476]\u001b[0m val_accuracy: 0.95412\n","\u001b[32m[0715 14:28:33 @monitor.py:476]\u001b[0m val_cross_entropy_loss: 0.16857\n","\u001b[32m[0715 14:28:33 @group.py:44]\u001b[0m Callbacks took 11.778 sec in total. InferenceRunner: 11.5 seconds\n","\u001b[32m[0715 14:28:33 @base.py:273]\u001b[0m Start Epoch 6 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|4721/4721[05:00<00:00,15.74it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0715 14:33:33 @base.py:283]\u001b[0m Epoch 6 (global_step 28326) finished, time:5 minutes.\n","\u001b[32m[0715 14:33:34 @saver.py:82]\u001b[0m Model saved to train_log/svhn-dorefa-1,2,4/model-28326.\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|204/204[00:12<00:00,16.54it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0715 14:33:46 @monitor.py:476]\u001b[0m QueueInput/queue_size: 7.1395e-17\n","\u001b[32m[0715 14:33:46 @monitor.py:476]\u001b[0m accuracy: 0.97992\n","\u001b[32m[0715 14:33:46 @monitor.py:476]\u001b[0m cost: 0.078589\n","\u001b[32m[0715 14:33:46 @monitor.py:476]\u001b[0m cross_entropy_loss: 0.07858\n","\u001b[32m[0715 14:33:46 @monitor.py:476]\u001b[0m param-summary/conv0/W-rms: 0.25885\n","\u001b[32m[0715 14:33:46 @monitor.py:476]\u001b[0m param-summary/conv1/W-rms: 0.15598\n","\u001b[32m[0715 14:33:46 @monitor.py:476]\u001b[0m param-summary/conv2/W-rms: 0.16919\n","\u001b[32m[0715 14:33:46 @monitor.py:476]\u001b[0m param-summary/conv3/W-rms: 0.17897\n","\u001b[32m[0715 14:33:46 @monitor.py:476]\u001b[0m param-summary/conv4/W-rms: 0.16855\n","\u001b[32m[0715 14:33:46 @monitor.py:476]\u001b[0m param-summary/conv5/W-rms: 0.17577\n","\u001b[32m[0715 14:33:46 @monitor.py:476]\u001b[0m param-summary/conv6/W-rms: 0.15025\n","\u001b[32m[0715 14:33:46 @monitor.py:476]\u001b[0m param-summary/fc1/W-rms: 0.18472\n","\u001b[32m[0715 14:33:46 @monitor.py:476]\u001b[0m regularize_cost: 8.7312e-06\n","\u001b[32m[0715 14:33:46 @monitor.py:476]\u001b[0m train_error: 0.020084\n","\u001b[32m[0715 14:33:46 @monitor.py:476]\u001b[0m val_accuracy: 0.96041\n","\u001b[32m[0715 14:33:46 @monitor.py:476]\u001b[0m val_cross_entropy_loss: 0.1527\n","\u001b[32m[0715 14:33:46 @group.py:44]\u001b[0m Callbacks took 12.675 sec in total. InferenceRunner: 12.4 seconds\n","\u001b[32m[0715 14:33:46 @base.py:273]\u001b[0m Start Epoch 7 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|4721/4721[04:53<00:00,16.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0715 14:38:40 @base.py:283]\u001b[0m Epoch 7 (global_step 33047) finished, time:4 minutes 53 seconds.\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0715 14:38:40 @saver.py:82]\u001b[0m Model saved to train_log/svhn-dorefa-1,2,4/model-33047.\n"],"name":"stdout"},{"output_type":"stream","text":["100%|##########|204/204[00:11<00:00,17.09it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0715 14:38:52 @monitor.py:476]\u001b[0m QueueInput/queue_size: 1.0333\n","\u001b[32m[0715 14:38:52 @monitor.py:476]\u001b[0m accuracy: 0.97614\n","\u001b[32m[0715 14:38:52 @monitor.py:476]\u001b[0m cost: 0.082807\n","\u001b[32m[0715 14:38:52 @monitor.py:476]\u001b[0m cross_entropy_loss: 0.082797\n","\u001b[32m[0715 14:38:52 @monitor.py:476]\u001b[0m param-summary/conv0/W-rms: 0.25992\n","\u001b[32m[0715 14:38:52 @monitor.py:476]\u001b[0m param-summary/conv1/W-rms: 0.17084\n","\u001b[32m[0715 14:38:52 @monitor.py:476]\u001b[0m param-summary/conv2/W-rms: 0.18559\n","\u001b[32m[0715 14:38:52 @monitor.py:476]\u001b[0m param-summary/conv3/W-rms: 0.19525\n","\u001b[32m[0715 14:38:52 @monitor.py:476]\u001b[0m param-summary/conv4/W-rms: 0.18425\n","\u001b[32m[0715 14:38:52 @monitor.py:476]\u001b[0m param-summary/conv5/W-rms: 0.19197\n","\u001b[32m[0715 14:38:52 @monitor.py:476]\u001b[0m param-summary/conv6/W-rms: 0.16357\n","\u001b[32m[0715 14:38:52 @monitor.py:476]\u001b[0m param-summary/fc1/W-rms: 0.1973\n","\u001b[32m[0715 14:38:52 @monitor.py:476]\u001b[0m regularize_cost: 9.9643e-06\n","\u001b[32m[0715 14:38:52 @monitor.py:476]\u001b[0m train_error: 0.023864\n","\u001b[32m[0715 14:38:52 @monitor.py:476]\u001b[0m val_accuracy: 0.96126\n","\u001b[32m[0715 14:38:52 @monitor.py:476]\u001b[0m val_cross_entropy_loss: 0.14981\n","\u001b[32m[0715 14:38:52 @group.py:44]\u001b[0m Callbacks took 12.320 sec in total. InferenceRunner: 12 seconds\n","\u001b[32m[0715 14:38:52 @base.py:273]\u001b[0m Start Epoch 8 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|4721/4721[04:51<00:00,16.22it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0715 14:43:43 @base.py:283]\u001b[0m Epoch 8 (global_step 37768) finished, time:4 minutes 51 seconds.\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0715 14:43:44 @saver.py:82]\u001b[0m Model saved to train_log/svhn-dorefa-1,2,4/model-37768.\n"],"name":"stdout"},{"output_type":"stream","text":["100%|##########|204/204[00:12<00:00,16.87it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0715 14:43:56 @monitor.py:476]\u001b[0m QueueInput/queue_size: 3.0734e-08\n","\u001b[32m[0715 14:43:56 @monitor.py:476]\u001b[0m accuracy: 0.97682\n","\u001b[32m[0715 14:43:56 @monitor.py:476]\u001b[0m cost: 0.076374\n","\u001b[32m[0715 14:43:56 @monitor.py:476]\u001b[0m cross_entropy_loss: 0.076363\n","\u001b[32m[0715 14:43:56 @monitor.py:476]\u001b[0m param-summary/conv0/W-rms: 0.26822\n","\u001b[32m[0715 14:43:56 @monitor.py:476]\u001b[0m param-summary/conv1/W-rms: 0.18218\n","\u001b[32m[0715 14:43:56 @monitor.py:476]\u001b[0m param-summary/conv2/W-rms: 0.19986\n","\u001b[32m[0715 14:43:56 @monitor.py:476]\u001b[0m param-summary/conv3/W-rms: 0.21233\n","\u001b[32m[0715 14:43:56 @monitor.py:476]\u001b[0m param-summary/conv4/W-rms: 0.19969\n","\u001b[32m[0715 14:43:56 @monitor.py:476]\u001b[0m param-summary/conv5/W-rms: 0.2076\n","\u001b[32m[0715 14:43:56 @monitor.py:476]\u001b[0m param-summary/conv6/W-rms: 0.17607\n","\u001b[32m[0715 14:43:56 @monitor.py:476]\u001b[0m param-summary/fc1/W-rms: 0.20764\n","\u001b[32m[0715 14:43:56 @monitor.py:476]\u001b[0m regularize_cost: 1.1025e-05\n","\u001b[32m[0715 14:43:56 @monitor.py:476]\u001b[0m train_error: 0.023177\n","\u001b[32m[0715 14:43:56 @monitor.py:476]\u001b[0m val_accuracy: 0.96292\n","\u001b[32m[0715 14:43:56 @monitor.py:476]\u001b[0m val_cross_entropy_loss: 0.14542\n","\u001b[32m[0715 14:43:56 @group.py:44]\u001b[0m Callbacks took 12.467 sec in total. InferenceRunner: 12.1 seconds\n","\u001b[32m[0715 14:43:56 @base.py:273]\u001b[0m Start Epoch 9 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|4721/4721[04:53<00:00,16.11it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0715 14:48:49 @base.py:283]\u001b[0m Epoch 9 (global_step 42489) finished, time:4 minutes 53 seconds.\n","\u001b[32m[0715 14:48:49 @saver.py:82]\u001b[0m Model saved to train_log/svhn-dorefa-1,2,4/model-42489.\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|204/204[00:11<00:00,17.05it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0715 14:49:01 @monitor.py:476]\u001b[0m QueueInput/queue_size: 1.1921e-07\n","\u001b[32m[0715 14:49:01 @monitor.py:476]\u001b[0m accuracy: 0.98016\n","\u001b[32m[0715 14:49:01 @monitor.py:476]\u001b[0m cost: 0.06972\n","\u001b[32m[0715 14:49:01 @monitor.py:476]\u001b[0m cross_entropy_loss: 0.069708\n","\u001b[32m[0715 14:49:01 @monitor.py:476]\u001b[0m param-summary/conv0/W-rms: 0.27201\n","\u001b[32m[0715 14:49:01 @monitor.py:476]\u001b[0m param-summary/conv1/W-rms: 0.19127\n","\u001b[32m[0715 14:49:01 @monitor.py:476]\u001b[0m param-summary/conv2/W-rms: 0.21264\n","\u001b[32m[0715 14:49:01 @monitor.py:476]\u001b[0m param-summary/conv3/W-rms: 0.22677\n","\u001b[32m[0715 14:49:01 @monitor.py:476]\u001b[0m param-summary/conv4/W-rms: 0.2136\n","\u001b[32m[0715 14:49:01 @monitor.py:476]\u001b[0m param-summary/conv5/W-rms: 0.22198\n","\u001b[32m[0715 14:49:01 @monitor.py:476]\u001b[0m param-summary/conv6/W-rms: 0.18778\n","\u001b[32m[0715 14:49:01 @monitor.py:476]\u001b[0m param-summary/fc1/W-rms: 0.21807\n","\u001b[32m[0715 14:49:01 @monitor.py:476]\u001b[0m regularize_cost: 1.2162e-05\n","\u001b[32m[0715 14:49:01 @monitor.py:476]\u001b[0m train_error: 0.01984\n","\u001b[32m[0715 14:49:01 @monitor.py:476]\u001b[0m val_accuracy: 0.96205\n","\u001b[32m[0715 14:49:01 @monitor.py:476]\u001b[0m val_cross_entropy_loss: 0.14428\n","\u001b[32m[0715 14:49:01 @group.py:44]\u001b[0m Callbacks took 12.264 sec in total. InferenceRunner: 12 seconds\n","\u001b[32m[0715 14:49:01 @base.py:273]\u001b[0m Start Epoch 10 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|4721/4721[04:58<00:00,15.81it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0715 14:54:00 @base.py:283]\u001b[0m Epoch 10 (global_step 47210) finished, time:4 minutes 58 seconds.\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0715 14:54:00 @saver.py:82]\u001b[0m Model saved to train_log/svhn-dorefa-1,2,4/model-47210.\n"],"name":"stdout"},{"output_type":"stream","text":["100%|##########|204/204[00:11<00:00,17.70it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0715 14:54:12 @monitor.py:476]\u001b[0m QueueInput/queue_size: 0.78424\n","\u001b[32m[0715 14:54:12 @monitor.py:476]\u001b[0m accuracy: 0.97947\n","\u001b[32m[0715 14:54:12 @monitor.py:476]\u001b[0m cost: 0.083818\n","\u001b[32m[0715 14:54:12 @monitor.py:476]\u001b[0m cross_entropy_loss: 0.083805\n","\u001b[32m[0715 14:54:12 @monitor.py:476]\u001b[0m param-summary/conv0/W-rms: 0.27628\n","\u001b[32m[0715 14:54:12 @monitor.py:476]\u001b[0m param-summary/conv1/W-rms: 0.20369\n","\u001b[32m[0715 14:54:12 @monitor.py:476]\u001b[0m param-summary/conv2/W-rms: 0.22813\n","\u001b[32m[0715 14:54:12 @monitor.py:476]\u001b[0m param-summary/conv3/W-rms: 0.24078\n","\u001b[32m[0715 14:54:12 @monitor.py:476]\u001b[0m param-summary/conv4/W-rms: 0.22698\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0715 14:54:12 @monitor.py:476]\u001b[0m param-summary/conv5/W-rms: 0.23608\n","\u001b[32m[0715 14:54:12 @monitor.py:476]\u001b[0m param-summary/conv6/W-rms: 0.19868\n","\u001b[32m[0715 14:54:12 @monitor.py:476]\u001b[0m param-summary/fc1/W-rms: 0.22823\n","\u001b[32m[0715 14:54:12 @monitor.py:476]\u001b[0m regularize_cost: 1.334e-05\n","\u001b[32m[0715 14:54:12 @monitor.py:476]\u001b[0m train_error: 0.020529\n","\u001b[32m[0715 14:54:12 @monitor.py:476]\u001b[0m val_accuracy: 0.96253\n","\u001b[32m[0715 14:54:12 @monitor.py:476]\u001b[0m val_cross_entropy_loss: 0.14382\n","\u001b[32m[0715 14:54:12 @group.py:44]\u001b[0m Callbacks took 11.880 sec in total. InferenceRunner: 11.5 seconds\n","\u001b[32m[0715 14:54:12 @base.py:287]\u001b[0m Training has finished!\n","\u001b[32m[0715 14:54:13 @input_source.py:177]\u001b[0m [EnqueueThread] Thread EnqueueThread: enqueue dataflow to TF queue \"QueueInput/input_queue\" Exited.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"\\nif __name__ == '__main__':\\n    parser = argparse.ArgumentParser()\\n    parser.add_argument('--dorefa',\\n                        help='number of bits for W,A,G, separated by comma. Defaults to '1,2,4'',\\n                        default='1,2,4')\\n    args = parser.parse_args()\\n\\n    BITW, BITA, BITG = map(int, args.dorefa.split(','))\\n    config = get_config()\\n    launch_train_with_config(config, SimpleTrainer())\\n\""]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":315},"id":"mduuAqCeuc4B","executionInfo":{"status":"ok","timestamp":1626441617879,"user_tz":-120,"elapsed":1756,"user":{"displayName":"Lorenzo Pasco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgShaitSLZm3zyLVjMQT7ZzTrEV3kQEXha_A9lkVw=s64","userId":"01314717049817932576"}},"outputId":"72f9637d-3629-4542-b82f-0fa82378dd7f"},"source":["import json\n","import matplotlib.pyplot as plt\n","\n","f = open(\"train_log/svhn-dorefa-1,2,4/stats_def_1.json\",\"r\")\n","\n","data = json.load(f)\n","accuracy = []\n","val_accuracy = []\n","for ob in data:\n","  accuracy.append(ob[\"accuracy\"])\n","  val_accuracy.append(ob[\"val_accuracy\"])\n","\n","epochs = range(len(accuracy))\n","\n","plt.plot(epochs, accuracy, 'r', label='Training acc')\n","plt.plot(epochs, val_accuracy, 'b', label='Validation acc')\n","plt.title('Training and validation accuracy')\n","plt.legend()\n","plt.figure()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<Figure size 432x288 with 0 Axes>"]},"metadata":{"tags":[]},"execution_count":4},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 0 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ST3WBdVha1W-","executionInfo":{"status":"ok","timestamp":1626441955150,"user_tz":-120,"elapsed":364,"user":{"displayName":"Lorenzo Pasco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgShaitSLZm3zyLVjMQT7ZzTrEV3kQEXha_A9lkVw=s64","userId":"01314717049817932576"}},"outputId":"27d93356-0831-4403-9c40-0800a28c9055"},"source":["from tabulate import tabulate\n","import matplotlib.pyplot as plt\n","\n","ep = [i+1 for i in epochs]\n","table_acc = {\"Epochs\" : ep, \"Accuracy\":accuracy}\n","table_val_acc = {\"Epochs\" : ep, \"Accuracy\":val_accuracy}\n","\n","print(\"ACCURACY\\n\")\n","print(tabulate(table_acc, headers='keys', tablefmt='fancy_grid'))\n","print(\"\\nVALIDATION ACCURACY\\n\")\n","print(tabulate(table_val_acc, headers='keys', tablefmt='fancy_grid'))"],"execution_count":8,"outputs":[{"output_type":"stream","text":["ACCURACY\n","\n","╒══════════╤════════════╕\n","│   Epochs │   Accuracy │\n","╞══════════╪════════════╡\n","│        1 │   0.950878 │\n","├──────────┼────────────┤\n","│        2 │   0.961502 │\n","├──────────┼────────────┤\n","│        3 │   0.972659 │\n","├──────────┼────────────┤\n","│        4 │   0.970831 │\n","├──────────┼────────────┤\n","│        5 │   0.972864 │\n","├──────────┼────────────┤\n","│        6 │   0.979916 │\n","├──────────┼────────────┤\n","│        7 │   0.976136 │\n","├──────────┼────────────┤\n","│        8 │   0.976823 │\n","├──────────┼────────────┤\n","│        9 │   0.98016  │\n","├──────────┼────────────┤\n","│       10 │   0.979471 │\n","╘══════════╧════════════╛\n","\n","VALIDATION ACCURACY\n","\n","╒══════════╤════════════╕\n","│   Epochs │   Accuracy │\n","╞══════════╪════════════╡\n","│        1 │   0.921837 │\n","├──────────┼────────────┤\n","│        2 │   0.938789 │\n","├──────────┼────────────┤\n","│        3 │   0.95144  │\n","├──────────┼────────────┤\n","│        4 │   0.95287  │\n","├──────────┼────────────┤\n","│        5 │   0.954121 │\n","├──────────┼────────────┤\n","│        6 │   0.960414 │\n","├──────────┼────────────┤\n","│        7 │   0.961257 │\n","├──────────┼────────────┤\n","│        8 │   0.962916 │\n","├──────────┼────────────┤\n","│        9 │   0.962048 │\n","├──────────┼────────────┤\n","│       10 │   0.962533 │\n","╘══════════╧════════════╛\n"],"name":"stdout"}]}]}