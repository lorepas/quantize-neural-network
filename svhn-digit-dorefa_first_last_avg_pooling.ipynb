{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"svhn-digit-dorefa_first&last_avg_pooling.ipynb","provenance":[],"authorship_tag":"ABX9TyN6aQSKkdwSBesXgGhaySWi"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"5qzKFEQKqXDt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626448366964,"user_tz":-120,"elapsed":18337,"user":{"displayName":"Lorenzo Pasco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgShaitSLZm3zyLVjMQT7ZzTrEV3kQEXha_A9lkVw=s64","userId":"01314717049817932576"}},"outputId":"adf830f3-de0c-495c-cde1-fea18c5fb288"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eDXKVoHj26H8","executionInfo":{"status":"ok","timestamp":1626448373278,"user_tz":-120,"elapsed":3663,"user":{"displayName":"Lorenzo Pasco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgShaitSLZm3zyLVjMQT7ZzTrEV3kQEXha_A9lkVw=s64","userId":"01314717049817932576"}},"outputId":"92daf5ef-dcee-4517-d74c-f6aa18f86958"},"source":["!pip install tensorpack\n","\n","%cd gdrive/MyDrive/SEAI_Project"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting tensorpack\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f9/8c/63e5f5a4a04dea36b75850f9daa885ccbfad64bec1fae0ee4ca9f31b3eaa/tensorpack-0.11-py2.py3-none-any.whl (296kB)\n","\r\u001b[K     |█                               | 10kB 26.1MB/s eta 0:00:01\r\u001b[K     |██▏                             | 20kB 23.2MB/s eta 0:00:01\r\u001b[K     |███▎                            | 30kB 16.7MB/s eta 0:00:01\r\u001b[K     |████▍                           | 40kB 14.4MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 51kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 61kB 8.4MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 71kB 7.7MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 81kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████                      | 92kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████                     | 102kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 112kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 122kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 133kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 143kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 153kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 163kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 174kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 184kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 194kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 204kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 215kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 225kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 235kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 245kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 256kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 266kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 276kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 286kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 296kB 8.3MB/s \n","\u001b[?25hRequirement already satisfied: pyzmq>=16 in /usr/local/lib/python3.7/dist-packages (from tensorpack) (22.1.0)\n","Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.7/dist-packages (from tensorpack) (4.41.1)\n","Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.7/dist-packages (from tensorpack) (1.1.0)\n","Requirement already satisfied: msgpack>=0.5.2 in /usr/local/lib/python3.7/dist-packages (from tensorpack) (1.0.2)\n","Requirement already satisfied: psutil>=5 in /usr/local/lib/python3.7/dist-packages (from tensorpack) (5.4.8)\n","Collecting msgpack-numpy>=0.4.4.2\n","  Downloading https://files.pythonhosted.org/packages/19/05/05b8d7c69c6abb36a34325cc3150089bdafc359f0a81fb998d93c5d5c737/msgpack_numpy-0.4.7.1-py2.py3-none-any.whl\n","Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.7/dist-packages (from tensorpack) (0.8.9)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tensorpack) (1.15.0)\n","Requirement already satisfied: numpy>=1.14 in /usr/local/lib/python3.7/dist-packages (from tensorpack) (1.19.5)\n","Installing collected packages: msgpack-numpy, tensorpack\n","Successfully installed msgpack-numpy-0.4.7.1 tensorpack-0.11\n","/content/gdrive/MyDrive/SEAI_Project\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"47qPSLMU19HM","executionInfo":{"status":"ok","timestamp":1626445415114,"user_tz":-120,"elapsed":2682824,"user":{"displayName":"Lorenzo Pasco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgShaitSLZm3zyLVjMQT7ZzTrEV3kQEXha_A9lkVw=s64","userId":"01314717049817932576"}},"outputId":"e35d732b-7f0b-4f92-f3f8-4a473f9080cc"},"source":["#!/usr/bin/env python\n","# -*- coding: utf-8 -*-\n","# File: svhn-digit-dorefa.py\n","# Author: Yuxin Wu\n","\n","import argparse\n","import os\n","import tensorflow as tf\n","\n","from tensorpack import *\n","from tensorpack.dataflow import dataset\n","from tensorpack.tfutils.summary import add_moving_summary, add_param_summary\n","from tensorpack.tfutils.varreplace import remap_variables\n","\n","\"\"\"\n","This is a tensorpack script for the SVHN results in paper:\n","DoReFa-Net: Training Low Bitwidth Convolutional Neural Networks with Low Bitwidth Gradients\n","http://arxiv.org/abs/1606.06160\n","The original experiements are performed on a proprietary framework.\n","This is our attempt to reproduce it on tensorpack.\n","Accuracy:\n","    With (W,A,G)=(1,1,4), can reach 3.1~3.2% error after 150 epochs.\n","    With (W,A,G)=(1,2,4), error is 3.0~3.1%.\n","    With (W,A,G)=(32,32,32), error is about 2.3%.\n","Speed:\n","    With quantization, 60 batch/s on 1 1080Ti. (4721 batch / epoch)\n","To Run:\n","    ./svhn-digit-dorefa.py --dorefa 1,2,4\n","\"\"\"\n","tf.compat.v1.reset_default_graph()\n","\n","BITW = 1\n","BITA = 2\n","BITG = 4\n","\n","\"\"\"\n","imported from dorefa file\n","\"\"\"\n","def get_dorefa(bitW, bitA, bitG):\n","    \"\"\"\n","    Return the three quantization functions fw, fa, fg, for weights, activations and gradients respectively\n","    \"\"\"\n","    def quantize(x, k):\n","        n = float(2 ** k - 1)\n","\n","        @tf.custom_gradient\n","        def _quantize(x):\n","            return tf.round(x * n) / n, lambda dy: dy\n","\n","        return _quantize(x)\n","\n","    def fw(x):\n","        if bitW == 32:\n","            return x\n","\n","        if bitW == 1:   # BWN\n","            E = tf.stop_gradient(tf.reduce_mean(tf.abs(x)))\n","\n","            @tf.custom_gradient\n","            def _sign(x):\n","                return tf.where(tf.equal(x, 0), tf.ones_like(x), tf.sign(x / E)) * E, lambda dy: dy\n","\n","            return _sign(x)\n","\n","        x = tf.tanh(x)\n","        x = x / tf.reduce_max(tf.abs(x)) * 0.5 + 0.5\n","        return 2 * quantize(x, bitW) - 1\n","\n","    def fa(x):\n","        if bitA == 32:\n","            return x\n","        return quantize(x, bitA)\n","\n","    def fg(x):\n","        if bitG == 32:\n","            return x\n","\n","        @tf.custom_gradient\n","        def _identity(input):\n","            def grad_fg(x):\n","                rank = x.get_shape().ndims\n","                assert rank is not None\n","                maxx = tf.reduce_max(tf.abs(x), list(range(1, rank)), keepdims=True)\n","                x = x / maxx\n","                n = float(2**bitG - 1)\n","                x = x * 0.5 + 0.5 + tf.random.uniform(\n","                    tf.shape(x), minval=-0.5 / n, maxval=0.5 / n)\n","                x = tf.clip_by_value(x, 0.0, 1.0)\n","                x = quantize(x, bitG) - 0.5\n","                return x * maxx * 2\n","\n","            return input, grad_fg\n","\n","        return _identity(x)\n","    return fw, fa, fg\n","\n","\n","class Model(ModelDesc):\n","    def inputs(self):\n","        return [tf.TensorSpec([None, 40, 40, 3], tf.float32, 'input'),\n","                tf.TensorSpec([None], tf.int32, 'label')]\n","\n","    def build_graph(self, image, label):\n","        fw, fa, fg = get_dorefa(BITW, BITA, BITG)\n","\n","        # monkey-patch tf.get_variable to apply fw\n","        def binarize_weight(v):\n","            name = v.op.name\n","            # don't binarize first and last layer\n","            if not name.endswith('W'):\n","                return v\n","            else:\n","                logger.info(\"Binarizing weight {}\".format(v.op.name))\n","                return fw(v)\n","\n","        def nonlin(x):\n","            if BITA == 32:\n","                return tf.nn.relu(x)\n","            return tf.clip_by_value(x, 0.0, 1.0)\n","\n","        def activate(x):\n","            return fa(nonlin(x))\n","\n","        image = image / 256.0\n","\n","        with remap_variables(binarize_weight), \\\n","                argscope(BatchNorm, momentum=0.9, epsilon=1e-4), \\\n","                argscope(Conv2D, use_bias=False):\n","            logits = (LinearWrap(image)\n","                      .Conv2D('conv0', 48, 5, padding='VALID', use_bias=True)\n","                      .AvgPooling('pool0', 2, padding='SAME')\n","                      .apply(activate)\n","                      # 18\n","                      .Conv2D('conv1', 64, 3, padding='SAME')\n","                      .apply(fg)\n","                      .BatchNorm('bn1').apply(activate)\n","#AVGPooling\n","                      .Conv2D('conv2', 64, 3, padding='SAME')\n","                      .apply(fg)\n","                      .BatchNorm('bn2')\n","                      .AvgPooling('pool1', 2, padding='SAME')\n","                      .apply(activate)\n","                      # 9\n","                      .Conv2D('conv3', 128, 3, padding='VALID')\n","                      .apply(fg)\n","                      .BatchNorm('bn3').apply(activate)\n","                      # 7\n","\n","                      .Conv2D('conv4', 128, 3, padding='SAME')\n","                      .apply(fg)\n","                      .BatchNorm('bn4').apply(activate)\n","\n","                      .Conv2D('conv5', 128, 3, padding='VALID')\n","                      .apply(fg)\n","                      .BatchNorm('bn5').apply(activate)\n","                      # 5\n","                      .Dropout(rate=0.5 if self.training else 0.0)\n","                      .Conv2D('conv6', 512, 5, padding='VALID')\n","                      .apply(fg).BatchNorm('bn6')\n","                      .apply(nonlin)\n","                      .FullyConnected('fc1', 10)())\n","        tf.nn.softmax(logits, name='output')\n","\n","        correct = tf.cast(tf.nn.in_top_k(predictions=logits, targets=label, k=1), tf.float32, name='correct')\n","        accuracy = tf.reduce_mean(correct, name='accuracy')\n","        train_error = tf.reduce_mean(1 - correct, name='train_error')\n","        summary.add_moving_summary(train_error, accuracy)\n","        \n","        cost = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=label)\n","        cost = tf.reduce_mean(cost, name='cross_entropy_loss')\n","        # weight decay on all W of fc layers\n","        wd_cost = regularize_cost('fc.*/W', l2_regularizer(1e-7))\n","        add_param_summary(('.*/W', ['histogram', 'rms']))\n","        total_cost = tf.add_n([cost, wd_cost], name='cost')\n","        add_moving_summary(cost, wd_cost, total_cost)\n","        return total_cost\n","\n","    def optimizer(self):\n","        lr = tf.compat.v1.train.exponential_decay(\n","            learning_rate=1e-3,\n","            global_step=get_global_step_var(),\n","            decay_steps=4721 * 100,\n","            decay_rate=0.5, staircase=True, name='learning_rate')\n","        tf.summary.scalar('lr', lr)\n","\n","        return tf.compat.v1.train.AdamOptimizer(lr, epsilon=1e-5)\n","\n","\n","def get_config():\n","    logger.set_logger_dir(os.path.join('train_log', 'svhn-dorefa-{}'.format(args)))\n","\n","    # prepare dataset\n","    d1 = dataset.SVHNDigit('train')\n","    d2 = dataset.SVHNDigit('extra')\n","    data_train = RandomMixData([d1, d2])\n","    data_test = dataset.SVHNDigit('test')\n","\n","    augmentors = [\n","        imgaug.Resize((40, 40)),\n","        imgaug.Brightness(30),\n","        imgaug.Contrast((0.5, 1.5)),\n","    ]\n","    data_train = AugmentImageComponent(data_train, augmentors)\n","    data_train = BatchData(data_train, 128)\n","    data_train = MultiProcessRunnerZMQ(data_train, 5)\n","\n","    augmentors = [imgaug.Resize((40, 40))]\n","    data_test = AugmentImageComponent(data_test, augmentors)\n","    data_test = BatchData(data_test, 128, remainder=True)\n","\n","    return TrainConfig(\n","        data=QueueInput(data_train),\n","        callbacks=[\n","            ModelSaver(),\n","            InferenceRunner(    # run inference(for validation) after every epoch\n","                data_test,   # the DataFlow instance used for validation\n","                ScalarStats(    # produce `val_accuracy` and `val_cross_entropy_loss`\n","                    ['cross_entropy_loss', 'accuracy'], prefix='val'))\n","        ],\n","        model=Model(),\n","        max_epoch=10,\n","    )\n","\n","args = \"1,2,4\"\n","BITW, BITA, BITG = map(int, args.split(','))\n","config = get_config()\n","launch_train_with_config(config, SimpleTrainer())\n","\n","'''\n","if __name__ == '__main__':\n","    parser = argparse.ArgumentParser()\n","    parser.add_argument('--dorefa',\n","                        help='number of bits for W,A,G, separated by comma. Defaults to \\'1,2,4\\'',\n","                        default='1,2,4')\n","    args = parser.parse_args()\n","\n","    BITW, BITA, BITG = map(int, args.dorefa.split(','))\n","    config = get_config()\n","    launch_train_with_config(config, SimpleTrainer())\n","'''"],"execution_count":3,"outputs":[{"output_type":"stream","text":["\u001b[32m[0716 13:38:56 @logger.py:128]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m Log directory train_log/svhn-dorefa-1,2,4 exists! Use 'd' to delete it. \n","\u001b[32m[0716 13:38:56 @logger.py:131]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m If you're resuming from a previous run, you can choose to keep it.\n","Press any other key to exit. \n","Select Action: k (keep) / d (delete) / q (quit):k\n","\u001b[32m[0716 13:39:00 @logger.py:85]\u001b[0m Existing log file 'train_log/svhn-dorefa-1,2,4/log.log' backuped to 'train_log/svhn-dorefa-1,2,4/log.log.0716-133900'\n","\u001b[32m[0716 13:39:00 @logger.py:92]\u001b[0m Argv: /usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py -f /root/.local/share/jupyter/runtime/kernel-58044733-aaf5-4691-8bda-2d09249537d3.json\n","\u001b[32m[0716 13:39:00 @fs.py:101]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m Env var $TENSORPACK_DATASET not set, using /root/tensorpack_data for datasets.\n","\u001b[32m[0716 13:39:00 @fs.py:104]\u001b[0m Created the directory /root/tensorpack_data.\n","\u001b[32m[0716 13:39:00 @svhn.py:42]\u001b[0m File /root/tensorpack_data/svhn_data/train_32x32.mat not found!\n","\u001b[32m[0716 13:39:00 @svhn.py:43]\u001b[0m Downloading from http://ufldl.stanford.edu/housenumbers/train_32x32.mat ...\n"],"name":"stdout"},{"output_type":"stream","text":["train_32x32.mat: 182MB [00:03, 53.3MB/s]                           "],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 13:39:03 @fs.py:73]\u001b[0m Succesfully downloaded train_32x32.mat. 182040794 bytes.\n","\u001b[32m[0716 13:39:03 @svhn.py:45]\u001b[0m Loading /root/tensorpack_data/svhn_data/train_32x32.mat ...\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 13:39:05 @svhn.py:42]\u001b[0m File /root/tensorpack_data/svhn_data/extra_32x32.mat not found!\n","\u001b[32m[0716 13:39:05 @svhn.py:43]\u001b[0m Downloading from http://ufldl.stanford.edu/housenumbers/extra_32x32.mat ...\n"],"name":"stdout"},{"output_type":"stream","text":["extra_32x32.mat: 1.33GB [01:04, 20.5MB/s]                            "],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 13:40:10 @fs.py:73]\u001b[0m Succesfully downloaded extra_32x32.mat. 1329278602 bytes.\n","\u001b[32m[0716 13:40:10 @svhn.py:45]\u001b[0m Loading /root/tensorpack_data/svhn_data/extra_32x32.mat ...\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 13:40:22 @svhn.py:42]\u001b[0m File /root/tensorpack_data/svhn_data/test_32x32.mat not found!\n","\u001b[32m[0716 13:40:22 @svhn.py:43]\u001b[0m Downloading from http://ufldl.stanford.edu/housenumbers/test_32x32.mat ...\n"],"name":"stdout"},{"output_type":"stream","text":["test_32x32.mat: 64.3MB [00:03, 20.9MB/s]                            "],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 13:40:25 @fs.py:73]\u001b[0m Succesfully downloaded test_32x32.mat. 64275384 bytes.\n","\u001b[32m[0716 13:40:25 @svhn.py:45]\u001b[0m Loading /root/tensorpack_data/svhn_data/test_32x32.mat ...\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 13:40:25 @parallel.py:340]\u001b[0m [MultiProcessRunnerZMQ] Will fork a dataflow more than one times. This assumes the datapoints are i.i.d.\n","\u001b[32m[0716 13:40:25 @input_source.py:221]\u001b[0m Setting up the queue 'QueueInput/input_queue' for CPU prefetching ...\n","\u001b[32m[0716 13:40:25 @trainers.py:48]\u001b[0m Building graph for a single training tower ...\n","\u001b[32m[0716 13:40:25 @<ipython-input-3-92482375c899>:113]\u001b[0m Binarizing weight conv0/W\n","\u001b[32m[0716 13:40:25 @registry.py:90]\u001b[0m 'conv0': [?, 40, 40, 3] --> [?, 36, 36, 48]\n","\u001b[32m[0716 13:40:25 @registry.py:90]\u001b[0m 'pool0': [?, 36, 36, 48] --> [?, 18, 18, 48]\n","\u001b[32m[0716 13:40:25 @<ipython-input-3-92482375c899>:113]\u001b[0m Binarizing weight conv1/W\n","\u001b[32m[0716 13:40:25 @registry.py:90]\u001b[0m 'conv1': [?, 18, 18, 48] --> [?, 18, 18, 64]\n","\u001b[32m[0716 13:40:26 @<ipython-input-3-92482375c899>:113]\u001b[0m Binarizing weight conv2/W\n","\u001b[32m[0716 13:40:26 @registry.py:90]\u001b[0m 'conv2': [?, 18, 18, 64] --> [?, 18, 18, 64]\n","\u001b[32m[0716 13:40:26 @registry.py:90]\u001b[0m 'pool1': [?, 18, 18, 64] --> [?, 9, 9, 64]\n","\u001b[32m[0716 13:40:26 @<ipython-input-3-92482375c899>:113]\u001b[0m Binarizing weight conv3/W\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1692: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n","  warnings.warn('`layer.apply` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 13:40:26 @registry.py:90]\u001b[0m 'conv3': [?, 9, 9, 64] --> [?, 7, 7, 128]\n","\u001b[32m[0716 13:40:26 @<ipython-input-3-92482375c899>:113]\u001b[0m Binarizing weight conv4/W\n","\u001b[32m[0716 13:40:26 @registry.py:90]\u001b[0m 'conv4': [?, 7, 7, 128] --> [?, 7, 7, 128]\n","\u001b[32m[0716 13:40:26 @<ipython-input-3-92482375c899>:113]\u001b[0m Binarizing weight conv5/W\n","\u001b[32m[0716 13:40:26 @registry.py:90]\u001b[0m 'conv5': [?, 7, 7, 128] --> [?, 5, 5, 128]\n","\u001b[32m[0716 13:40:26 @<ipython-input-3-92482375c899>:113]\u001b[0m Binarizing weight conv6/W\n","\u001b[32m[0716 13:40:26 @registry.py:90]\u001b[0m 'conv6': [?, 5, 5, 128] --> [?, 1, 1, 512]\n","\u001b[32m[0716 13:40:26 @<ipython-input-3-92482375c899>:113]\u001b[0m Binarizing weight fc1/W\n","\u001b[32m[0716 13:40:26 @registry.py:90]\u001b[0m 'fc1': [?, 1, 1, 512] --> [?, 10]\n","\u001b[32m[0716 13:40:26 @regularize.py:97]\u001b[0m regularize_cost() found 1 variables to regularize.\n","\u001b[32m[0716 13:40:26 @regularize.py:21]\u001b[0m The following tensors will be regularized: fc1/W:0\n","\u001b[32m[0716 13:40:27 @model_utils.py:67]\u001b[0m \u001b[36mList of Trainable Variables: \n","\u001b[0mname       shape               #elements\n","---------  ----------------  -----------\n","conv0/W    [5, 5, 3, 48]            3600\n","conv0/b    [48]                       48\n","conv1/W    [3, 3, 48, 64]          27648\n","bn1/gamma  [64]                       64\n","bn1/beta   [64]                       64\n","conv2/W    [3, 3, 64, 64]          36864\n","bn2/gamma  [64]                       64\n","bn2/beta   [64]                       64\n","conv3/W    [3, 3, 64, 128]         73728\n","bn3/gamma  [128]                     128\n","bn3/beta   [128]                     128\n","conv4/W    [3, 3, 128, 128]       147456\n","bn4/gamma  [128]                     128\n","bn4/beta   [128]                     128\n","conv5/W    [3, 3, 128, 128]       147456\n","bn5/gamma  [128]                     128\n","bn5/beta   [128]                     128\n","conv6/W    [5, 5, 128, 512]      1638400\n","bn6/gamma  [512]                     512\n","bn6/beta   [512]                     512\n","fc1/W      [512, 10]                5120\n","fc1/b      [10]                       10\u001b[36m\n","Number of trainable variables: 22\n","Number of parameters (elements): 2082378\n","Storage space needed for all trainable variables: 7.94MB\u001b[0m\n","\u001b[32m[0716 13:40:27 @base.py:207]\u001b[0m Setup callbacks graph ...\n","\u001b[32m[0716 13:40:27 @argtools.py:138]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m Starting a process with 'fork' method is efficient but not safe and may cause deadlock or crash.Use 'forkserver' or 'spawn' method instead if you run into such issues.See https://docs.python.org/3/library/multiprocessing.html#contexts-and-start-methods on how to set them.\n","\u001b[32m[0716 13:40:27 @argtools.py:138]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m \"import prctl\" failed! Install python-prctl so that processes can be cleaned with guarantee.\n","\u001b[32m[0716 13:40:27 @inference_runner.py:148]\u001b[0m [InferenceRunner] Building tower 'InferenceTower' on device /gpu:0 ...\n","\u001b[32m[0716 13:40:27 @<ipython-input-3-92482375c899>:113]\u001b[0m Binarizing weight conv0/W\n","\u001b[32m[0716 13:40:27 @<ipython-input-3-92482375c899>:113]\u001b[0m Binarizing weight conv1/W\n","\u001b[32m[0716 13:40:28 @<ipython-input-3-92482375c899>:113]\u001b[0m Binarizing weight conv2/W\n","\u001b[32m[0716 13:40:28 @<ipython-input-3-92482375c899>:113]\u001b[0m Binarizing weight conv3/W\n","\u001b[32m[0716 13:40:28 @<ipython-input-3-92482375c899>:113]\u001b[0m Binarizing weight conv4/W\n","\u001b[32m[0716 13:40:28 @<ipython-input-3-92482375c899>:113]\u001b[0m Binarizing weight conv5/W\n","\u001b[32m[0716 13:40:28 @<ipython-input-3-92482375c899>:113]\u001b[0m Binarizing weight conv6/W\n","\u001b[32m[0716 13:40:28 @<ipython-input-3-92482375c899>:113]\u001b[0m Binarizing weight fc1/W\n","\u001b[32m[0716 13:40:29 @summary.py:47]\u001b[0m [MovingAverageSummary] 5 operations in collection 'MOVING_SUMMARY_OPS' will be run with session hooks.\n","\u001b[32m[0716 13:40:29 @summary.py:94]\u001b[0m Summarizing collection 'summaries' of size 22.\n","\u001b[32m[0716 13:40:29 @graph.py:99]\u001b[0m Applying collection UPDATE_OPS of 12 ops.\n","\u001b[32m[0716 13:40:29 @base.py:228]\u001b[0m Creating the session ...\n","\u001b[32m[0716 13:40:36 @base.py:234]\u001b[0m Initializing the session ...\n","\u001b[32m[0716 13:40:36 @base.py:241]\u001b[0m Graph Finalized.\n","\u001b[32m[0716 13:40:36 @concurrency.py:37]\u001b[0m Starting EnqueueThread: enqueue dataflow to TF queue \"QueueInput/input_queue\" ...\n","\u001b[32m[0716 13:40:37 @inference_runner.py:95]\u001b[0m [InferenceRunner] Will eval 204 iterations\n","\u001b[32m[0716 13:40:37 @monitor.py:361]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m History epoch=10 from JSON is not the predecessor of the current starting_epoch=1\n","\u001b[32m[0716 13:40:37 @monitor.py:362]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m If you want to resume old training, either use `AutoResumeTrainConfig` or correctly set the new starting_epoch yourself to avoid inconsistency. \n","\u001b[32m[0716 13:40:37 @monitor.py:369]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m Now, we will train with starting_epoch=1 and backup old json to train_log/svhn-dorefa-1,2,4/stats.json.0716-134037\n","\u001b[32m[0716 13:40:37 @base.py:273]\u001b[0m Start Epoch 1 ...\n"],"name":"stdout"},{"output_type":"stream","text":["100%|##########|4721/4721[04:30<00:00,17.45it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 13:45:08 @base.py:283]\u001b[0m Epoch 1 (global_step 4721) finished, time:4 minutes 30 seconds.\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 13:45:08 @saver.py:82]\u001b[0m Model saved to train_log/svhn-dorefa-1,2,4/model-4721.\n"],"name":"stdout"},{"output_type":"stream","text":["100%|##########|204/204[00:10<00:00,18.89it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 13:45:19 @monitor.py:476]\u001b[0m QueueInput/queue_size: 17.5\n","\u001b[32m[0716 13:45:19 @monitor.py:476]\u001b[0m accuracy: 0.9514\n","\u001b[32m[0716 13:45:19 @monitor.py:476]\u001b[0m cost: 0.17174\n","\u001b[32m[0716 13:45:19 @monitor.py:476]\u001b[0m cross_entropy_loss: 0.17174\n","\u001b[32m[0716 13:45:19 @monitor.py:476]\u001b[0m param-summary/conv0/W-rms: 0.18579\n","\u001b[32m[0716 13:45:19 @monitor.py:476]\u001b[0m param-summary/conv1/W-rms: 0.079097\n","\u001b[32m[0716 13:45:19 @monitor.py:476]\u001b[0m param-summary/conv2/W-rms: 0.073921\n","\u001b[32m[0716 13:45:19 @monitor.py:476]\u001b[0m param-summary/conv3/W-rms: 0.078041\n","\u001b[32m[0716 13:45:19 @monitor.py:476]\u001b[0m param-summary/conv4/W-rms: 0.065342\n","\u001b[32m[0716 13:45:19 @monitor.py:476]\u001b[0m param-summary/conv5/W-rms: 0.069217\n","\u001b[32m[0716 13:45:19 @monitor.py:476]\u001b[0m param-summary/conv6/W-rms: 0.054508\n","\u001b[32m[0716 13:45:19 @monitor.py:476]\u001b[0m param-summary/fc1/W-rms: 0.11674\n","\u001b[32m[0716 13:45:19 @monitor.py:476]\u001b[0m regularize_cost: 3.4822e-06\n","\u001b[32m[0716 13:45:19 @monitor.py:476]\u001b[0m train_error: 0.048603\n","\u001b[32m[0716 13:45:19 @monitor.py:476]\u001b[0m val_accuracy: 0.91836\n","\u001b[32m[0716 13:45:19 @monitor.py:476]\u001b[0m val_cross_entropy_loss: 0.28042\n","\u001b[32m[0716 13:45:19 @group.py:44]\u001b[0m Callbacks took 11.442 sec in total. InferenceRunner: 10.8 seconds\n","\u001b[32m[0716 13:45:19 @base.py:273]\u001b[0m Start Epoch 2 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|4721/4721[04:03<00:00,19.42it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 13:49:22 @base.py:283]\u001b[0m Epoch 2 (global_step 9442) finished, time:4 minutes 3 seconds.\n","\u001b[32m[0716 13:49:22 @saver.py:82]\u001b[0m Model saved to train_log/svhn-dorefa-1,2,4/model-9442.\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|204/204[00:09<00:00,21.23it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 13:49:32 @monitor.py:476]\u001b[0m QueueInput/queue_size: 0.125\n","\u001b[32m[0716 13:49:32 @monitor.py:476]\u001b[0m accuracy: 0.95954\n","\u001b[32m[0716 13:49:32 @monitor.py:476]\u001b[0m cost: 0.12696\n","\u001b[32m[0716 13:49:32 @monitor.py:476]\u001b[0m cross_entropy_loss: 0.12695\n","\u001b[32m[0716 13:49:32 @monitor.py:476]\u001b[0m param-summary/conv0/W-rms: 0.21594\n","\u001b[32m[0716 13:49:32 @monitor.py:476]\u001b[0m param-summary/conv1/W-rms: 0.095424\n","\u001b[32m[0716 13:49:32 @monitor.py:476]\u001b[0m param-summary/conv2/W-rms: 0.096639\n","\u001b[32m[0716 13:49:32 @monitor.py:476]\u001b[0m param-summary/conv3/W-rms: 0.10256\n","\u001b[32m[0716 13:49:32 @monitor.py:476]\u001b[0m param-summary/conv4/W-rms: 0.090783\n","\u001b[32m[0716 13:49:32 @monitor.py:476]\u001b[0m param-summary/conv5/W-rms: 0.095921\n","\u001b[32m[0716 13:49:32 @monitor.py:476]\u001b[0m param-summary/conv6/W-rms: 0.080853\n","\u001b[32m[0716 13:49:32 @monitor.py:476]\u001b[0m param-summary/fc1/W-rms: 0.15417\n","\u001b[32m[0716 13:49:32 @monitor.py:476]\u001b[0m regularize_cost: 6.0714e-06\n","\u001b[32m[0716 13:49:32 @monitor.py:476]\u001b[0m train_error: 0.040459\n","\u001b[32m[0716 13:49:32 @monitor.py:476]\u001b[0m val_accuracy: 0.9346\n","\u001b[32m[0716 13:49:32 @monitor.py:476]\u001b[0m val_cross_entropy_loss: 0.2344\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 13:49:32 @group.py:44]\u001b[0m Callbacks took 9.864 sec in total. InferenceRunner: 9.63 seconds\n","\u001b[32m[0716 13:49:32 @base.py:273]\u001b[0m Start Epoch 3 ...\n"],"name":"stdout"},{"output_type":"stream","text":["100%|##########|4721/4721[04:05<00:00,19.25it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 13:53:37 @base.py:283]\u001b[0m Epoch 3 (global_step 14163) finished, time:4 minutes 5 seconds.\n","\u001b[32m[0716 13:53:37 @saver.py:82]\u001b[0m Model saved to train_log/svhn-dorefa-1,2,4/model-14163.\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|204/204[00:09<00:00,21.46it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 13:53:47 @monitor.py:476]\u001b[0m QueueInput/queue_size: 1.4927e-08\n","\u001b[32m[0716 13:53:47 @monitor.py:476]\u001b[0m accuracy: 0.96718\n","\u001b[32m[0716 13:53:47 @monitor.py:476]\u001b[0m cost: 0.11572\n","\u001b[32m[0716 13:53:47 @monitor.py:476]\u001b[0m cross_entropy_loss: 0.11571\n","\u001b[32m[0716 13:53:47 @monitor.py:476]\u001b[0m param-summary/conv0/W-rms: 0.24038\n","\u001b[32m[0716 13:53:47 @monitor.py:476]\u001b[0m param-summary/conv1/W-rms: 0.11408\n","\u001b[32m[0716 13:53:47 @monitor.py:476]\u001b[0m param-summary/conv2/W-rms: 0.11999\n","\u001b[32m[0716 13:53:47 @monitor.py:476]\u001b[0m param-summary/conv3/W-rms: 0.1263\n","\u001b[32m[0716 13:53:47 @monitor.py:476]\u001b[0m param-summary/conv4/W-rms: 0.11397\n","\u001b[32m[0716 13:53:47 @monitor.py:476]\u001b[0m param-summary/conv5/W-rms: 0.1194\n","\u001b[32m[0716 13:53:47 @monitor.py:476]\u001b[0m param-summary/conv6/W-rms: 0.1028\n","\u001b[32m[0716 13:53:47 @monitor.py:476]\u001b[0m param-summary/fc1/W-rms: 0.18507\n","\u001b[32m[0716 13:53:47 @monitor.py:476]\u001b[0m regularize_cost: 8.7553e-06\n","\u001b[32m[0716 13:53:47 @monitor.py:476]\u001b[0m train_error: 0.032823\n","\u001b[32m[0716 13:53:47 @monitor.py:476]\u001b[0m val_accuracy: 0.9481\n","\u001b[32m[0716 13:53:47 @monitor.py:476]\u001b[0m val_cross_entropy_loss: 0.19385\n","\u001b[32m[0716 13:53:47 @group.py:44]\u001b[0m Callbacks took 9.808 sec in total. InferenceRunner: 9.53 seconds\n","\u001b[32m[0716 13:53:47 @base.py:273]\u001b[0m Start Epoch 4 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|4721/4721[04:05<00:00,19.23it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 13:57:53 @base.py:283]\u001b[0m Epoch 4 (global_step 18884) finished, time:4 minutes 5 seconds.\n","\u001b[32m[0716 13:57:53 @saver.py:82]\u001b[0m Model saved to train_log/svhn-dorefa-1,2,4/model-18884.\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|204/204[00:09<00:00,20.71it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 13:58:03 @monitor.py:476]\u001b[0m QueueInput/queue_size: 1.3885e-17\n","\u001b[32m[0716 13:58:03 @monitor.py:476]\u001b[0m accuracy: 0.97246\n","\u001b[32m[0716 13:58:03 @monitor.py:476]\u001b[0m cost: 0.10792\n","\u001b[32m[0716 13:58:03 @monitor.py:476]\u001b[0m cross_entropy_loss: 0.10791\n","\u001b[32m[0716 13:58:03 @monitor.py:476]\u001b[0m param-summary/conv0/W-rms: 0.25949\n","\u001b[32m[0716 13:58:03 @monitor.py:476]\u001b[0m param-summary/conv1/W-rms: 0.13054\n","\u001b[32m[0716 13:58:03 @monitor.py:476]\u001b[0m param-summary/conv2/W-rms: 0.14091\n","\u001b[32m[0716 13:58:03 @monitor.py:476]\u001b[0m param-summary/conv3/W-rms: 0.14817\n","\u001b[32m[0716 13:58:03 @monitor.py:476]\u001b[0m param-summary/conv4/W-rms: 0.13491\n","\u001b[32m[0716 13:58:03 @monitor.py:476]\u001b[0m param-summary/conv5/W-rms: 0.1409\n","\u001b[32m[0716 13:58:03 @monitor.py:476]\u001b[0m param-summary/conv6/W-rms: 0.12108\n","\u001b[32m[0716 13:58:03 @monitor.py:476]\u001b[0m param-summary/fc1/W-rms: 0.21065\n","\u001b[32m[0716 13:58:03 @monitor.py:476]\u001b[0m regularize_cost: 1.1334e-05\n","\u001b[32m[0716 13:58:03 @monitor.py:476]\u001b[0m train_error: 0.027544\n","\u001b[32m[0716 13:58:03 @monitor.py:476]\u001b[0m val_accuracy: 0.95005\n","\u001b[32m[0716 13:58:03 @monitor.py:476]\u001b[0m val_cross_entropy_loss: 0.19149\n","\u001b[32m[0716 13:58:03 @group.py:44]\u001b[0m Callbacks took 10.121 sec in total. InferenceRunner: 9.88 seconds\n","\u001b[32m[0716 13:58:03 @base.py:273]\u001b[0m Start Epoch 5 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|4721/4721[04:06<00:00,19.11it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 14:02:10 @base.py:283]\u001b[0m Epoch 5 (global_step 23605) finished, time:4 minutes 7 seconds.\n","\u001b[32m[0716 14:02:10 @saver.py:82]\u001b[0m Model saved to train_log/svhn-dorefa-1,2,4/model-23605.\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|204/204[00:09<00:00,21.94it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 14:02:19 @monitor.py:476]\u001b[0m QueueInput/queue_size: 7.6611e-06\n","\u001b[32m[0716 14:02:19 @monitor.py:476]\u001b[0m accuracy: 0.97374\n","\u001b[32m[0716 14:02:19 @monitor.py:476]\u001b[0m cost: 0.093331\n","\u001b[32m[0716 14:02:19 @monitor.py:476]\u001b[0m cross_entropy_loss: 0.093316\n","\u001b[32m[0716 14:02:19 @monitor.py:476]\u001b[0m param-summary/conv0/W-rms: 0.2764\n","\u001b[32m[0716 14:02:19 @monitor.py:476]\u001b[0m param-summary/conv1/W-rms: 0.14687\n","\u001b[32m[0716 14:02:19 @monitor.py:476]\u001b[0m param-summary/conv2/W-rms: 0.16057\n","\u001b[32m[0716 14:02:19 @monitor.py:476]\u001b[0m param-summary/conv3/W-rms: 0.16751\n","\u001b[32m[0716 14:02:19 @monitor.py:476]\u001b[0m param-summary/conv4/W-rms: 0.1537\n","\u001b[32m[0716 14:02:19 @monitor.py:476]\u001b[0m param-summary/conv5/W-rms: 0.1608\n","\u001b[32m[0716 14:02:19 @monitor.py:476]\u001b[0m param-summary/conv6/W-rms: 0.13727\n","\u001b[32m[0716 14:02:19 @monitor.py:476]\u001b[0m param-summary/fc1/W-rms: 0.23683\n","\u001b[32m[0716 14:02:19 @monitor.py:476]\u001b[0m regularize_cost: 1.4342e-05\n","\u001b[32m[0716 14:02:19 @monitor.py:476]\u001b[0m train_error: 0.026265\n","\u001b[32m[0716 14:02:19 @monitor.py:476]\u001b[0m val_accuracy: 0.9559\n","\u001b[32m[0716 14:02:19 @monitor.py:476]\u001b[0m val_cross_entropy_loss: 0.16807\n","\u001b[32m[0716 14:02:19 @group.py:44]\u001b[0m Callbacks took 9.563 sec in total. InferenceRunner: 9.32 seconds\n","\u001b[32m[0716 14:02:19 @base.py:273]\u001b[0m Start Epoch 6 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|4721/4721[04:08<00:00,18.98it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 14:06:28 @base.py:283]\u001b[0m Epoch 6 (global_step 28326) finished, time:4 minutes 8 seconds.\n","\u001b[32m[0716 14:06:28 @saver.py:82]\u001b[0m Model saved to train_log/svhn-dorefa-1,2,4/model-28326.\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|204/204[00:09<00:00,21.76it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 14:06:38 @monitor.py:476]\u001b[0m QueueInput/queue_size: 0.0019531\n","\u001b[32m[0716 14:06:38 @monitor.py:476]\u001b[0m accuracy: 0.97299\n","\u001b[32m[0716 14:06:38 @monitor.py:476]\u001b[0m cost: 0.087401\n","\u001b[32m[0716 14:06:38 @monitor.py:476]\u001b[0m cross_entropy_loss: 0.087383\n","\u001b[32m[0716 14:06:38 @monitor.py:476]\u001b[0m param-summary/conv0/W-rms: 0.28857\n","\u001b[32m[0716 14:06:38 @monitor.py:476]\u001b[0m param-summary/conv1/W-rms: 0.16188\n","\u001b[32m[0716 14:06:38 @monitor.py:476]\u001b[0m param-summary/conv2/W-rms: 0.17928\n","\u001b[32m[0716 14:06:38 @monitor.py:476]\u001b[0m param-summary/conv3/W-rms: 0.18623\n","\u001b[32m[0716 14:06:38 @monitor.py:476]\u001b[0m param-summary/conv4/W-rms: 0.17088\n","\u001b[32m[0716 14:06:38 @monitor.py:476]\u001b[0m param-summary/conv5/W-rms: 0.1789\n","\u001b[32m[0716 14:06:38 @monitor.py:476]\u001b[0m param-summary/conv6/W-rms: 0.15179\n","\u001b[32m[0716 14:06:38 @monitor.py:476]\u001b[0m param-summary/fc1/W-rms: 0.26283\n","\u001b[32m[0716 14:06:38 @monitor.py:476]\u001b[0m regularize_cost: 1.7671e-05\n","\u001b[32m[0716 14:06:38 @monitor.py:476]\u001b[0m train_error: 0.02701\n","\u001b[32m[0716 14:06:38 @monitor.py:476]\u001b[0m val_accuracy: 0.9574\n","\u001b[32m[0716 14:06:38 @monitor.py:476]\u001b[0m val_cross_entropy_loss: 0.16052\n","\u001b[32m[0716 14:06:38 @group.py:44]\u001b[0m Callbacks took 9.640 sec in total. InferenceRunner: 9.38 seconds\n","\u001b[32m[0716 14:06:38 @base.py:273]\u001b[0m Start Epoch 7 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|4721/4721[04:03<00:00,19.39it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 14:10:41 @base.py:283]\u001b[0m Epoch 7 (global_step 33047) finished, time:4 minutes 3 seconds.\n","\u001b[32m[0716 14:10:41 @saver.py:82]\u001b[0m Model saved to train_log/svhn-dorefa-1,2,4/model-33047.\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|204/204[00:09<00:00,21.74it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 14:10:51 @monitor.py:476]\u001b[0m QueueInput/queue_size: 0.064484\n","\u001b[32m[0716 14:10:51 @monitor.py:476]\u001b[0m accuracy: 0.97438\n","\u001b[32m[0716 14:10:51 @monitor.py:476]\u001b[0m cost: 0.090261\n","\u001b[32m[0716 14:10:51 @monitor.py:476]\u001b[0m cross_entropy_loss: 0.09024\n","\u001b[32m[0716 14:10:51 @monitor.py:476]\u001b[0m param-summary/conv0/W-rms: 0.3014\n","\u001b[32m[0716 14:10:51 @monitor.py:476]\u001b[0m param-summary/conv1/W-rms: 0.17805\n","\u001b[32m[0716 14:10:51 @monitor.py:476]\u001b[0m param-summary/conv2/W-rms: 0.19681\n","\u001b[32m[0716 14:10:51 @monitor.py:476]\u001b[0m param-summary/conv3/W-rms: 0.20279\n","\u001b[32m[0716 14:10:51 @monitor.py:476]\u001b[0m param-summary/conv4/W-rms: 0.18721\n","\u001b[32m[0716 14:10:51 @monitor.py:476]\u001b[0m param-summary/conv5/W-rms: 0.19505\n","\u001b[32m[0716 14:10:51 @monitor.py:476]\u001b[0m param-summary/conv6/W-rms: 0.16499\n","\u001b[32m[0716 14:10:51 @monitor.py:476]\u001b[0m param-summary/fc1/W-rms: 0.28735\n","\u001b[32m[0716 14:10:51 @monitor.py:476]\u001b[0m regularize_cost: 2.1124e-05\n","\u001b[32m[0716 14:10:51 @monitor.py:476]\u001b[0m train_error: 0.02562\n","\u001b[32m[0716 14:10:51 @monitor.py:476]\u001b[0m val_accuracy: 0.95861\n","\u001b[32m[0716 14:10:51 @monitor.py:476]\u001b[0m val_cross_entropy_loss: 0.15994\n","\u001b[32m[0716 14:10:51 @group.py:44]\u001b[0m Callbacks took 9.638 sec in total. InferenceRunner: 9.4 seconds\n","\u001b[32m[0716 14:10:51 @base.py:273]\u001b[0m Start Epoch 8 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|4721/4721[04:04<00:00,19.35it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 14:14:55 @base.py:283]\u001b[0m Epoch 8 (global_step 37768) finished, time:4 minutes 4 seconds.\n","\u001b[32m[0716 14:14:55 @saver.py:82]\u001b[0m Model saved to train_log/svhn-dorefa-1,2,4/model-37768.\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|204/204[00:09<00:00,20.86it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 14:15:05 @monitor.py:476]\u001b[0m QueueInput/queue_size: 0.015672\n","\u001b[32m[0716 14:15:05 @monitor.py:476]\u001b[0m accuracy: 0.97368\n","\u001b[32m[0716 14:15:05 @monitor.py:476]\u001b[0m cost: 0.096085\n","\u001b[32m[0716 14:15:05 @monitor.py:476]\u001b[0m cross_entropy_loss: 0.09606\n","\u001b[32m[0716 14:15:05 @monitor.py:476]\u001b[0m param-summary/conv0/W-rms: 0.31298\n","\u001b[32m[0716 14:15:05 @monitor.py:476]\u001b[0m param-summary/conv1/W-rms: 0.19409\n","\u001b[32m[0716 14:15:05 @monitor.py:476]\u001b[0m param-summary/conv2/W-rms: 0.21388\n","\u001b[32m[0716 14:15:05 @monitor.py:476]\u001b[0m param-summary/conv3/W-rms: 0.21813\n","\u001b[32m[0716 14:15:05 @monitor.py:476]\u001b[0m param-summary/conv4/W-rms: 0.20263\n","\u001b[32m[0716 14:15:05 @monitor.py:476]\u001b[0m param-summary/conv5/W-rms: 0.21149\n","\u001b[32m[0716 14:15:05 @monitor.py:476]\u001b[0m param-summary/conv6/W-rms: 0.17743\n","\u001b[32m[0716 14:15:05 @monitor.py:476]\u001b[0m param-summary/fc1/W-rms: 0.31147\n","\u001b[32m[0716 14:15:05 @monitor.py:476]\u001b[0m regularize_cost: 2.4829e-05\n","\u001b[32m[0716 14:15:05 @monitor.py:476]\u001b[0m train_error: 0.026321\n","\u001b[32m[0716 14:15:05 @monitor.py:476]\u001b[0m val_accuracy: 0.95447\n","\u001b[32m[0716 14:15:05 @monitor.py:476]\u001b[0m val_cross_entropy_loss: 0.17118\n","\u001b[32m[0716 14:15:05 @group.py:44]\u001b[0m Callbacks took 10.043 sec in total. InferenceRunner: 9.79 seconds\n","\u001b[32m[0716 14:15:05 @base.py:273]\u001b[0m Start Epoch 9 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|4721/4721[04:03<00:00,19.39it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 14:19:08 @base.py:283]\u001b[0m Epoch 9 (global_step 42489) finished, time:4 minutes 3 seconds.\n","\u001b[32m[0716 14:19:09 @saver.py:82]\u001b[0m Model saved to train_log/svhn-dorefa-1,2,4/model-42489.\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|204/204[00:09<00:00,21.66it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 14:19:18 @monitor.py:476]\u001b[0m QueueInput/queue_size: 0.25\n","\u001b[32m[0716 14:19:18 @monitor.py:476]\u001b[0m accuracy: 0.97917\n","\u001b[32m[0716 14:19:18 @monitor.py:476]\u001b[0m cost: 0.069874\n","\u001b[32m[0716 14:19:18 @monitor.py:476]\u001b[0m cross_entropy_loss: 0.069845\n","\u001b[32m[0716 14:19:18 @monitor.py:476]\u001b[0m param-summary/conv0/W-rms: 0.32198\n","\u001b[32m[0716 14:19:18 @monitor.py:476]\u001b[0m param-summary/conv1/W-rms: 0.20752\n","\u001b[32m[0716 14:19:18 @monitor.py:476]\u001b[0m param-summary/conv2/W-rms: 0.2301\n","\u001b[32m[0716 14:19:18 @monitor.py:476]\u001b[0m param-summary/conv3/W-rms: 0.23279\n","\u001b[32m[0716 14:19:18 @monitor.py:476]\u001b[0m param-summary/conv4/W-rms: 0.21691\n","\u001b[32m[0716 14:19:18 @monitor.py:476]\u001b[0m param-summary/conv5/W-rms: 0.22623\n","\u001b[32m[0716 14:19:18 @monitor.py:476]\u001b[0m param-summary/conv6/W-rms: 0.18883\n","\u001b[32m[0716 14:19:18 @monitor.py:476]\u001b[0m param-summary/fc1/W-rms: 0.3351\n","\u001b[32m[0716 14:19:18 @monitor.py:476]\u001b[0m regularize_cost: 2.8717e-05\n","\u001b[32m[0716 14:19:18 @monitor.py:476]\u001b[0m train_error: 0.020835\n","\u001b[32m[0716 14:19:18 @monitor.py:476]\u001b[0m val_accuracy: 0.96072\n","\u001b[32m[0716 14:19:18 @monitor.py:476]\u001b[0m val_cross_entropy_loss: 0.15237\n","\u001b[32m[0716 14:19:18 @group.py:44]\u001b[0m Callbacks took 9.711 sec in total. InferenceRunner: 9.43 seconds\n","\u001b[32m[0716 14:19:18 @base.py:273]\u001b[0m Start Epoch 10 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|4721/4721[04:06<00:00,19.12it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 14:23:25 @base.py:283]\u001b[0m Epoch 10 (global_step 47210) finished, time:4 minutes 6 seconds.\n","\u001b[32m[0716 14:23:25 @saver.py:82]\u001b[0m Model saved to train_log/svhn-dorefa-1,2,4/model-47210.\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|##########|204/204[00:09<00:00,21.64it/s]"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[0716 14:23:35 @monitor.py:476]\u001b[0m QueueInput/queue_size: 1.5613e-17\n","\u001b[32m[0716 14:23:35 @monitor.py:476]\u001b[0m accuracy: 0.98196\n","\u001b[32m[0716 14:23:35 @monitor.py:476]\u001b[0m cost: 0.072017\n","\u001b[32m[0716 14:23:35 @monitor.py:476]\u001b[0m cross_entropy_loss: 0.071984\n","\u001b[32m[0716 14:23:35 @monitor.py:476]\u001b[0m param-summary/conv0/W-rms: 0.3309\n","\u001b[32m[0716 14:23:35 @monitor.py:476]\u001b[0m param-summary/conv1/W-rms: 0.21778\n","\u001b[32m[0716 14:23:35 @monitor.py:476]\u001b[0m param-summary/conv2/W-rms: 0.24496\n","\u001b[32m[0716 14:23:35 @monitor.py:476]\u001b[0m param-summary/conv3/W-rms: 0.2477\n","\u001b[32m[0716 14:23:35 @monitor.py:476]\u001b[0m param-summary/conv4/W-rms: 0.23059\n","\u001b[32m[0716 14:23:35 @monitor.py:476]\u001b[0m param-summary/conv5/W-rms: 0.24064\n","\u001b[32m[0716 14:23:35 @monitor.py:476]\u001b[0m param-summary/conv6/W-rms: 0.19956\n","\u001b[32m[0716 14:23:35 @monitor.py:476]\u001b[0m param-summary/fc1/W-rms: 0.35869\n","\u001b[32m[0716 14:23:35 @monitor.py:476]\u001b[0m regularize_cost: 3.292e-05\n","\u001b[32m[0716 14:23:35 @monitor.py:476]\u001b[0m train_error: 0.018036\n","\u001b[32m[0716 14:23:35 @monitor.py:476]\u001b[0m val_accuracy: 0.96133\n","\u001b[32m[0716 14:23:35 @monitor.py:476]\u001b[0m val_cross_entropy_loss: 0.14913\n","\u001b[32m[0716 14:23:35 @group.py:44]\u001b[0m Callbacks took 9.711 sec in total. InferenceRunner: 9.44 seconds\n","\u001b[32m[0716 14:23:35 @base.py:287]\u001b[0m Training has finished!\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"\\nif __name__ == '__main__':\\n    parser = argparse.ArgumentParser()\\n    parser.add_argument('--dorefa',\\n                        help='number of bits for W,A,G, separated by comma. Defaults to '1,2,4'',\\n                        default='1,2,4')\\n    args = parser.parse_args()\\n\\n    BITW, BITA, BITG = map(int, args.dorefa.split(','))\\n    config = get_config()\\n    launch_train_with_config(config, SimpleTrainer())\\n\""]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":315},"id":"mduuAqCeuc4B","executionInfo":{"status":"ok","timestamp":1626448382754,"user_tz":-120,"elapsed":1840,"user":{"displayName":"Lorenzo Pasco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgShaitSLZm3zyLVjMQT7ZzTrEV3kQEXha_A9lkVw=s64","userId":"01314717049817932576"}},"outputId":"2d273034-a04c-469b-f4bc-d4205ebf041f"},"source":["import json\n","import matplotlib.pyplot as plt\n","\n","f = open(\"train_log/svhn-dorefa-1,2,4/stats_def_first&last_avg_pooling.json\",\"r\")\n","\n","data = json.load(f)\n","accuracy = []\n","val_accuracy = []\n","for ob in data:\n","  accuracy.append(ob[\"accuracy\"])\n","  val_accuracy.append(ob[\"val_accuracy\"])\n","\n","epochs = range(len(accuracy))\n","\n","plt.plot(epochs, accuracy, 'r', label='Training acc')\n","plt.plot(epochs, val_accuracy, 'b', label='Validation acc')\n","plt.title('Training and validation accuracy')\n","plt.legend()\n","plt.figure()"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<Figure size 432x288 with 0 Axes>"]},"metadata":{"tags":[]},"execution_count":4},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3xUVdrA8d9DkyodVIIQBERcesRFRIr4iuWFBURBRJF3RcGKqy4WBFHEgoIFC7qgomtkWUVUEJEiKqsSqkZAIwRJEBeB0EvK8/5xbmASUgaY5M5Mnu/nM5+5c9s8907yzJlzzz1HVBVjjDHRq5TfARhjjClaluiNMSbKWaI3xpgoZ4neGGOinCV6Y4yJcpbojTEmylmiL4FEZK6I3BDqdf0kIski0r0I9qsi0tibfkVERgWz7gm8z0AR+exE4zSmIGLt6CODiOwNeFkROARkeq9vVtV3ij+q8CEiycBfVfXzEO9XgSaqmhSqdUWkIbARKKuqGaGI05iClPE7ABMcVa2cPV1QUhORMpY8TLiwv8fwYFU3EU5EuohIioj8XUS2AtNEpLqIfCwi20RkpzcdE7DNYhH5qzc9WES+EpEJ3robReSyE1w3VkSWiMgeEflcRCaLyNv5xB1MjI+KyNfe/j4TkVoByweJyCYR2S4iDxZwfs4Xka0iUjpgXm8RWeNNtxeR/4hImoj8JiIviki5fPb1hog8FvD6Xm+bLSIyJNe6V4jIShHZLSKbRWRMwOIl3nOaiOwVkQ7Z5zZg+wtEZJmI7PKeLwj23Bznea4hItO8Y9gpIrMClvUSkVXeMfwiIj28+TmqyURkTPbnLCINvSqs/xORX4GF3vx/eZ/DLu9v5NyA7SuIyDPe57nL+xurICKfiMjtuY5njYj0zutYTf4s0UeH04AaQANgKO5znea9PhM4ALxYwPbnA+uBWsBTwD9ERE5g3X8C3wE1gTHAoALeM5gYrwVuBOoA5YB7AESkOfCyt/8zvPeLIQ+q+i2wD+iWa7//9KYzgRHe8XQALgaGFxA3Xgw9vHguAZoAua8P7AOuB6oBVwDDROQv3rKLvOdqqlpZVf+Ta981gE+A571jexb4RERq5jqGY85NHgo7z9NxVYHnevua6MXQHngLuNc7houA5PzORx46A+cAl3qv5+LOUx1gBRBY1TgBaAdcgPs7vg/IAt4ErsteSURaAfVw58YcD1W1R4Q9cP9w3b3pLsBhoHwB67cGdga8Xoyr+gEYDCQFLKsIKHDa8ayLSyIZQMWA5W8Dbwd5THnF+FDA6+HAp970w0B8wLJK3jnons++HwOmetNVcEm4QT7r3gV8EPBagcbe9BvAY970VOCJgPWaBq6bx34nARO96YbeumUClg8GvvKmBwHf5dr+P8Dgws7N8Zxn4HRcQq2ex3qvZsdb0N+f93pM9ucccGyNCoihmrdOVdwX0QGgVR7rlQd24q57gPtCeKm4/9+i4WEl+uiwTVUPZr8QkYoi8qr3U3g3rqqgWmD1RS5bsydUdb83Wfk41z0D2BEwD2BzfgEHGePWgOn9ATGdEbhvVd0HbM/vvXCl9z4icgrQB1ihqpu8OJp61RlbvTgex5XuC5MjBmBTruM7X0QWeVUmu4Bbgtxv9r435Zq3CVeazZbfucmhkPNcH/eZ7cxj0/rAL0HGm5cj50ZESovIE171z26O/jKo5T3K5/Ve3t/0e8B1IlIKGID7BWKOkyX66JC76dTfgLOB81X1VI5WFeRXHRMKvwE1RKRiwLz6Bax/MjH+Frhv7z1r5reyqv6IS5SXkbPaBlwV0DpcqfFU4IETiQH3iybQP4HZQH1VrQq8ErDfwpq6bcFVtQQ6E0gNIq7cCjrPm3GfWbU8ttsMnJXPPvfhfs1lOy2PdQKP8VqgF656qyqu1J8dwx/AwQLe601gIK5Kbb/mquYywbFEH52q4H4Op3n1vaOL+g29EnICMEZEyolIB+B/iyjGmcCVInKhd+F0LIX/Lf8TuBOX6P6VK47dwF4RaQYMCzKGGcBgEWnufdHkjr8KrrR80KvvvjZg2TZclUmjfPY9B2gqIteKSBkRuQZoDnwcZGy548jzPKvqb7i685e8i7ZlRST7i+AfwI0icrGIlBKRet75AVgF9PfWjwOuCiKGQ7hfXRVxv5qyY8jCVYM9KyJneKX/Dt6vL7zEngU8g5XmT5gl+ug0CaiAKy19A3xaTO87EHdBczuuXvw93D94Xk44RlVNBG7FJe/fcPW4KYVs9i7uAuFCVf0jYP49uCS8B3jNizmYGOZ6x7AQSPKeAw0HxorIHtw1hRkB2+4HxgFfi2vt8+dc+94OXIkrjW/HXZy8MlfcwSrsPA8C0nG/av6Lu0aBqn6Hu9g7EdgFfMHRXxmjcCXwncAj5PyFlJe3cL+oUoEfvTgC3QN8DywDdgBPkjM3vQW0wF3zMSfAbpgyRUZE3gPWqWqR/6Iw0UtErgeGquqFfscSqaxEb0JGRM4TkbO8n/o9cPWyswrbzpj8eNViw4EpfscSySzRm1A6Ddf0by+uDfgwVV3pa0QmYonIpbjrGb9TePWQKYBV3RhjTJSzEr0xxkS5sOvUrFatWtqwYUO/wzDGmIiyfPnyP1S1dl7Lwi7RN2zYkISEBL/DMMaYiCIiue+mPsKqbowxJspZojfGmChnid4YY6Jc2NXR5yU9PZ2UlBQOHjxY+MrGF+XLlycmJoayZcv6HYoxJpeISPQpKSlUqVKFhg0bkv94GMYvqsr27dtJSUkhNjbW73CMMblERNXNwYMHqVmzpiX5MCUi1KxZ035xGROmIiLRA5bkw5x9PsaEr4ioujHGmKilChs2wMKFbnro0JC/RcSU6P20fft2WrduTevWrTnttNOoV6/ekdeHDx8ucNuEhATuuOOOQt/jggsuCFW4xphwl5ICb70FgwdDw4bQuLFL8G+8USRvZyX6INSsWZNVq1YBMGbMGCpXrsw999xzZHlGRgZlyuR9KuPi4oiLiyv0PZYuXRqaYI0x4ee//4VFi1ypfdEi+PlnN79WLejaFUaOhG7doGnTInl7K9GfoMGDB3PLLbdw/vnnc9999/Hdd9/RoUMH2rRpwwUXXMD69esBWLx4MVdeeSXgviSGDBlCly5daNSoEc8///yR/VWuXPnI+l26dOGqq66iWbNmDBw4kOweRufMmUOzZs1o164dd9xxx5H9BkpOTqZTp060bduWtm3b5vgCefLJJ2nRogWtWrVi5MiRACQlJdG9e3datWpF27Zt+eWXkxkP2hgDQFoafPgh3HkntGgBdetC//4QHw/NmsHEibB6Nfz+O8yYAcOGwdlnQxFd6wqqRO8NIvEcUBp4XVWfyLW8AW7cx9q4ocCuU9UUb9lTwBW4L5X5wJ16Mn0j33UXeKXrkGndGiZNOu7NUlJSWLp0KaVLl2b37t18+eWXlClThs8//5wHHniAf//738dss27dOhYtWsSePXs4++yzGTZs2DFtz1euXEliYiJnnHEGHTt25OuvvyYuLo6bb76ZJUuWEBsby4ABA/KMqU6dOsyfP5/y5cvz888/M2DAABISEpg7dy4ffvgh3377LRUrVmTHjh0ADBw4kJEjR9K7d28OHjxIVlbWcZ8HY0q8vXvhq69ciX3hQli5ErKyoEIF6NQJrrvOldzbtoV8fv0XpULfUURKA5OBS3Djci4Tkdmq+mPAahOAt1T1TRHpBowHBonIBUBHoKW33le4cTsXh+4Q/NOvXz9Kly4NwK5du7jhhhv4+eefERHS09Pz3OaKK67glFNO4ZRTTqFOnTr8/vvvxMTE5Finffv2R+a1bt2a5ORkKleuTKNGjY60Ux8wYABTphw76E56ejq33XYbq1atonTp0vz0008AfP7559x4441UrFgRgBo1arBnzx5SU1Pp3bs34G56MsYE4eBB+M9/jlbHfPstZGRA2bLQoQM8/LCrimnfHk45xe9ogyrRtweSVHUDgIjE44aIC0z0zYG7velFHB0+ToHyQDlAgLK40WJO3AmUvItKpUqVjkyPGjWKrl278sEHH5CcnEyXLl3y3OaUgA+9dOnSZGRknNA6+Zk4cSJ169Zl9erVZGVlWfI2JhTS0yEh4WiJ/euv4dAhKFUKzjsP7r3Xldg7dgSvMBVOgqmjrwdsDnid4s0LtBro4033BqqISE1V/Q8u8f/mPeap6trcbyAiQ0UkQUQStm3bdrzHEBZ27dpFvXrutLxRBFfOzz77bDZs2EBycjIA7733Xr5xnH766ZQqVYrp06eTmZkJwCWXXMK0adPYv38/ADt27KBKlSrExMQwa5b7Xj506NCR5caUaJmZsGIFTJgAl18ONWrABRfAQw/B9u0wfDh89BHs2AHffAOPPw6XXBKWSR5CdzH2HqCziKzEVc2kApki0hg4B4jBfTl0E5FOuTdW1SmqGqeqcbVr59lvfti77777uP/++2nTps1xlcCDVaFCBV566SV69OhBu3btqFKlClWrVj1mveHDh/Pmm2/SqlUr1q1bd+RXR48ePejZsydxcXG0bt2aCRMmADB9+nSef/55WrZsyQUXXMDWrVtDHrsxYU8VEhPhhRegTx+oXRvatXMl9Y0b4frrYeZM2LbNXSN89lm48krI438wHBU6ZqyIdADGqOql3uv7AVR1fD7rVwbWqWqMiNwLlFfVR71lDwMHVfWp/N4vLi5Ocw88snbtWs4555zgjypK7d27l8qVK6Oq3HrrrTRp0oQRI0b4HdYR9jmZiLNtGzz9tGvT/rtXq9ywoatf79bNVceccYavIQZLRJarap5tuYOpo18GNBGRWFxJvT9wba43qAXsUNUs4H5cCxyAX4GbRGQ8ro6+MxA+lewR5rXXXuPNN9/k8OHDtGnThptvvtnvkIyJTH/84RL8iy+6C6u9e7sqmq5dIQo75is00atqhojcBszDNa+cqqqJIjIWSFDV2UAXYLyIKLAEuNXbfCbQDfged2H2U1X9KPSHUTKMGDEirErwxkSc7dtdvfsLL8D+/TBgAIwa5dq2R7GgGnSq6hxgTq55DwdMz8Ql9dzbZQJW7DTG+GvHDnjmGXj+edi3D66+2jWBbN7c78iKhXWBYIyJXjt3ugunzz0He/ZAv34wejSce67fkRUrS/TGmOiTlubuuZk4EXbvhr59XYJv0cLvyHxhid4YEz127XKl92efddO9e7sE36qV35H5yjo1C0LXrl2ZN29ejnmTJk1i2LBh+W7TpUsXspuJXn755aSlpR2zzpgxY460Z8/PrFmz+PHHozchP/zww3z++efHE74x0W/3bnjsMddiZvRo6NLF9Tfz/vslPsmDJfqgDBgwgPj4+Bzz4uPj8+1YLLc5c+ZQrVq1E3rv3Il+7NixdO/e/YT2ZUzU2bPH3ZUaG+taz1x4ISxfDrNmuc4KDWCJPihXXXUVn3zyyZFBRpKTk9myZQudOnVi2LBhxMXFce655zJ69Og8t2/YsCF//PEHAOPGjaNp06ZceOGFR7oyBtdG/rzzzqNVq1b07duX/fv3s3TpUmbPns29995L69at+eWXXxg8eDAzZ7oGTgsWLKBNmza0aNGCIUOGcOjQoSPvN3r0aNq2bUuLFi1Yt27dMTFZd8Ymou3dC0884RL8gw+6jsSWLYPZs10PkSaHiKuj96OX4ho1atC+fXvmzp1Lr169iI+P5+qrr0ZEGDduHDVq1CAzM5OLL76YNWvW0LJlyzz3s3z5cuLj41m1ahUZGRm0bduWdu3aAdCnTx9uuukmAB566CH+8Y9/cPvtt9OzZ0+uvPJKrrrqqhz7OnjwIIMHD2bBggU0bdqU66+/npdffpm77roLgFq1arFixQpeeuklJkyYwOuvv55je+vO2ESkfftg8mR3s9Mff0CPHvDII66XSJMvK9EHKbD6JrDaZsaMGbRt25Y2bdqQmJiYo5olty+//JLevXtTsWJFTj31VHr27Hlk2Q8//ECnTp1o0aIF77zzDomJiQXGs379emJjY2nqjUhzww03sGTJkiPL+/Rxfcy1a9fuSEdogdLT07npppto0aIF/fr1OxJ3sN0ZVwzTzptMlNq/37WDj42Fv//dldqXLoW5cy3JByHiSvR+9VLcq1cvRowYwYoVK9i/fz/t2rVj48aNTJgwgWXLllG9enUGDx7MwYMHT2j/gwcPZtasWbRq1Yo33niDxYsXn1S82V0d59fNsXVnbCLCgQPwyivw5JOuL5ru3V0J3sZYPi5Wog9S5cqV6dq1K0OGDDlSmt+9ezeVKlWiatWq/P7778ydO7fAfVx00UXMmjWLAwcOsGfPHj766GhvEHv27OH0008nPT2dd95558j8KlWqsGfPnmP2dfbZZ5OcnExSUhLgeqHs3Llz0Mdj3RmbsHbggGsm2agR3H23u8Hpyy9h/nxL8ifAEv1xGDBgAKtXrz6S6Fu1akWbNm1o1qwZ1157LR07dixw+7Zt23LNNdfQqlUrLrvsMs4777wjyx599FHOP/98OnbsSLOAfjf69+/P008/TZs2bXJcAC1fvjzTpk2jX79+tGjRglKlSnHLLbcEfSzWnbEJSwcPun5ozjrLXZBr1gy++AIWLHAtaswJKbSb4uJm3RRHLvucwsy+fZCc7PpT37gx53RqqhvPtFo1qF49uOfs6YoVQz+I9aFD8PrrMH68i61TJ1dF07VraN8nip1sN8XGmHB06BBs2pR/Ms89Wlv58u5iZsOG7gLmwYOuq4C0NNiwwT3v3OmaLhakbNmcif94vywCB8c+dAimTnVt4VNS3FB8b77p+oIP9ZdJCWaJ3kQHVXfL+6+/usemTUensx+ZmW5IuOrV837Oa161auANAF/sMjJc8sudwLOnt2xxx52tTBlo0MAl81693HN2Yo+Nhbp1g0ueGRlHvwB27gzueePGo68LG2GtcuWjiX/7dnccHTq4hN+9uyX4IhAxiV5VEfsDCFtFXgWYnu4SQl4JPPuR+6J12bJQv75Lft26udc7drhklJzsbpHfscNVcRSkatXgvhRyP1eqVHDSysqCrVuPTeTZr7O/nLKVKgUxMS5xd++eM4nHxrqRkELxpVSmDNSq5R7HS9U1hcz+AijsS6JRIxg2DP7nfyzBF6GISPTly5dn+/bt1KxZ05J9GFJVtm/ffuJNNFXdP35+CfzXX12Sz32TVq1acOaZ0KQJXHyxmw581K3rkmNhDh92SWfnzqNfBAU9p6YefZ2env9+y5Q59suhWjV3o8/Gje5Ly7ub+YjTTnNJ+89/doNiBCbz+vWhXLnjPr3FSsR9wVWq5L6UTFiIiIux6enppKSknHAbdVP0ypcvT0xMDGXLlj12YXq6S44FJfLcpfFy5Vxiy528sx/167tk4idV92sg+wsgmC+JtDSX+HNXq8TGul8eFSr4e0wmYkX8xdiyZcsSG4XjOEY1VVi8GMaNg0WLgi+NN2jgnuvUCa407icRV99cubL74jEmTEVEojcRRBXmzXNdxn79tauKuPdeaNz4aBKvX9810TPGFAtL9CY0srJcz4GPPea6ia1f33U+NWSIa9ZnjPFNmP82NmEvMxPi493gDr17uzro11+HpCQYPtySvDFhwBK9OTHp6e7GlubNXeuQzEx4+21Ytw7+7//Cv3WIMSVIUIleRHqIyHoRSRKRkXksbyAiC0RkjYgsFpEYb35XEVkV8DgoIn8J9UGYYnToELz6KjRtCoMHu7r2mTPhhx9g4MCcdz0aY8JCoYleREoDk4HLgObAABFpnmu1CcBbqtoSGAuMB1DVRaraWlVbA92A/cBnIYzfFJf9+11vgmedBbfc4lrFfPQRrFgBffuGfwsZY0qwYP472wNJqrpBVQ8D8UCvXOs0BxZ604vyWA5wFTBXVa1/20iyZw889ZRr533XXS7Rz58P33wDV15pdzMaEwGCSfT1gM0Br1O8eYFWA3286d5AFRGpmWud/sC7eb2BiAwVkQQRSdiWuyMm44+dO2HsWNck8u9/d+MtfvGFe1h/JMZElFD93r4H6CwiK4HOQCpwpJMOETkdaAHMy2tjVZ2iqnGqGle7du0QhWROyLZtbrDlhg1h9GjXXey337q28Rdd5Hd0xpgTEMyVs1Qg8La/GG/eEaq6Ba9ELyKVgb6qmhawytXAB6paQMcgxle//QYTJrhh2w4cgKuuggcecCV5Y0xEC6ZEvwxoIiKxIlIOVwUzO3AFEaklItn7uh+YmmsfA8in2sb47Ndf4dZbXR38c8+5C6uJiTBjhiV5Y6JEoYleVTOA23DVLmuBGaqaKCJjRaSnt1oXYL2I/ATUBcZlby8iDXG/CL4IaeTm5CQlwV//6i6uvvYaDBoE69fDW2+BjRJlTFSJiN4rTQj9+KMbzefdd13/7Dfd5PqiOfNMvyMzxpyEiO+90oTAqlWuH5r333c3Od19t3ucfrrfkRljipgl+mj37bcuwX/8MZx6qrvAetddJzZ6kDEmIlmij1Zr1sDf/gaff+5GNnr0UbjtNjfCkTGmRLFEH22ysmDiRFdyr1rV3dU6bJgbHMMYUyJZoo8mmzfDDTe4EZ3+8heYMgXsBjRjSjzriSpaxMdDy5bw3XeuP/j337ckb4wBLNFHvrQ0uO461yd8s2awerXrD976ojHGeCzRR7LFi10pPj7edUD25ZfuBihjjAlgiT4SHTrkepTs1g1OOQWWLoVRo2zQD2NMniwzRJrERDeS0+rVMHQoPPOMtagxxhTISvSRIisLnn8e2rWDLVtg9mw3pJ8leWNMIaxEHwm2bHHjs86f70Z1ev11qFvX76iMMRHCSvThbuZMaNECvvrK9RU/e7YleWPMcbFEH65274Ybb4R+/aBRI1i5Em6+2ZpNGmOOmyX6cPTVV9CqlesbftQo16rm7LP9jsoYE6Es0YeTw4fdeK2dO0OpUq5d/Nixrt94Y4w5QXYxNlysW+fucF2+HIYMgUmToEoVv6MyxkQBK9H7TRVefhnatoXkZPj3v+Ef/7Akb4wJGSvR+2nrVtcvzZw5cOmlMG2ajfhkjAk5K9H75cMPXbPJhQvhhRdg7lxL8saYImEl+uK2dy+MGOFuemrTBt55B845x++ojDHFJD0ddu1yLaizn7Onq1SBXr1C/56W6IvTN9+4C64bNsDIkfDII1CunN9RGWOCkJkJe/bkTNC5E3Uwyw4ezP89zjvPx0QvIj2A54DSwOuq+kSu5Q2AqUBtYAdwnaqmeMvOBF4H6gMKXK6qyaE6gIiQkeEG6H7sMYiJcd0LX3SR31EZY3D3In70kRvaoaCEvXdv4fsqVQpOPdU9qlZ1z7VrQ+PGOeflN129etEcY6GJXkRKA5OBS4AUYJmIzFbVHwNWmwC8papvikg3YDwwyFv2FjBOVeeLSGUgK6RHEO5+/hkGDYJvv3XPL7zgPlVjjK+2bnW3rUyb5hq/VamSM/FWrQpnnnlsMs4rQWc/V6oUnjevB1Oibw8kqeoGABGJB3oBgYm+OXC3N70ImOWt2xwoo6rzAVQ1iO/EKKHq6uHvusv1Gf/ee3D11X5HZUyJd+iQu01l3DhXjfK3v8FDD0V3+SuYVjf1gM0Br1O8eYFWA3286d5AFRGpCTQF0kTkfRFZKSJPe78Qotu2bW5w7qFDoUMHWLPGkrwxPlOFWbOgeXN3iaxrVze8w9NPR3eSh9A1r7wH6CwiK4HOQCqQifvF0Mlbfh7QCBice2MRGSoiCSKSsG3bthCF5JPPPnPNJufNg2efda9jYvyOypgS7fvvoXt36N0bKlRw/5YffghNmvgdWfEIJtGn4i6kZovx5h2hqltUtY+qtgEe9Oal4Ur/q1R1g6pm4Kp02uZ+A1WdoqpxqhpXu3btEzwUn2VkuN9/PXpArVqwbJlrRlnKblUwxi/btsGwYdC6NaxaBS++6J4vucTvyIpXMFloGdBERGJFpBzQH5gduIKI1BKR7H3dj2uBk71tNRHJzt7dyFm3Hx22bIGLL3aVfjfeCN9950r1xhhfpKe7evgmTeC11+C221y7iFtvLZlDKxd6yKqaISK3AfNwzSunqmqiiIwFElR1NtAFGC8iCiwBbvW2zRSRe4AFIiLAcuC1ojkUn8yb51rT7N8P06e7dvLG+GzfPkhJgc2b837+4w9XlXHjjUc7S40Wc+bA3XfD+vWuZ5Fnn3X18iWZqKrfMeQQFxenCQkJfodRuIwMGD0aHn8c/vQn+Ne/oFkzv6MyJcD+/QUn8c2bYefOY7erXRvq13eXjCpVcglx1y6IjXUjVd5wAzRoUOyHEzJr17oE/+mn0LSpS/CXXx6ezR2LgogsV9W4vJaVwB8xIZCaCgMGuP7i//pXeO45qFjR76hMFDhwoPAkvmPHsdvVquWSeIMGcOGFLpnXr380sderB+XLH/teH3wAU6e6MsuYMa4GcsgQ12isQoViOeSTtnOni33yZKhc2SX4W2+1m84DWYn+eH36qauqOXAAXn0VBg70OyITITIy4NdfYdOm/JP49u3Hblez5tGEHZi8s59jYo5N4scrORnefNPdPLRpk2tueO21Lum3axeepeKMDPcv+PDD7q7Wm26CRx91v1xKooJK9Jbog5WR4Yb1e+IJd6H1X/+y4f3MMQ4ccF0Z/fILJCXlfE5Odv2lBKpRI+/kHZjEi7NknZXleuiYOtUNjXDwoKuZHDLEXX4KlyT6+efuXsTERNceftIkaNnS76j8ZYn+ZG3e7Kpqvv7a3QQ1aVLk/K41IZeWljOBB06npuZct1o118/JWWcdfTRseDSJh3ONX1qau6F76lTXkKxMGfjf/3VJv0cPf1qvJCW5O1lnz4ZGjWDCBFfNFI6/OIqbJfqTMWcOXH+9u296yhSX8E1UU4Xff88/meeuXjnttJzJPHu6cWNXYo8GiYmuWmf6dPjvf90xX3+9a7VTHG0Qdu1yfQI+95zrUeTBB12J/mSrrKKJJfoTkZ7uboB66ilo1QpmzHCX8k1UyMx0P9TyqmL55RfXPDFbqVKuc6u8knmjRu4CYEmRnu7KPlOnwiefuPPYoYMr5V99tevYK5QyM90XzIMPupufBg92t6vYGD3HskR/vDZvhv79YelSuPlmmEjPKR0AABT6SURBVDjRqmoiWFYWvP8+LFlyNJlv3OiSVrZy5VzSziuZN2xoLTjysnUrvP22S/pr17pqqKuucqX8iy46+bb5S5bAnXe6O1k7dnSl+XbtQhN7NLJEfzw+/tg1KD582N1S17+/f7GYk6IK8+e7DqxWrnTd0AYm8MDpevWgdPR3t1ckVF0d/tSp8O67bnCORo1cwr/hBndh+XgkJ8O998LMmW7bp592vxasHr5gBSV6VDWsHu3atVNfHD6seu+9qqDaqpXqTz/5E4cJie++U+3WzX2csbGqb7+tmpnpd1TRb98+1enTVbt2dedeRPV//kf13XdVDxwoeNs9e1QfeED1lFNUK1RQfeQRtz8THFxPBXnmVd8Te+6HL4l+0ybVDh3c6Rg2rPC/SBO2fvpJtV8/91HWqqX6/POqhw75HVXJtGGD6sMPq555pvs8qlVTHT5cNSFBNSvr6HqZmapvvql6+uluvYEDVTdv9i/uSGWJviCzZ6tWr65apYrqe+8V73ubkNmyRfWWW1TLlFGtVMklmF27/I7KqLpEPn++6oABrrQOqi1bqk6cqPrZZ6rt27t5552nunSp39FGroISfcntAiE9He6/H555Btq0ca1qGjf2OypznHbvdnW4zz7rLqvcfLO7r61uXb8jM9lKlXIdqHXv7roriI939fkjRrjlp5/u7sq97rro6lwtnJTMi7GbNrmLrN98A8OHu2RvDXIjyqFD8PLLrm319u3u43z0UfuujiTff+8ukvfpU7KaqBYV69Qs0IcfuuYAGRmuFN+vn98RmeOQmQn//KcrtW/a5AaQGD/emt1FohYtbNiG4lJyfigdPuz6MP3LX1y/rCtWWJKPIKruRp02bdwdmbVquaaTn31mSd6YwpSMRJ+cDJ06uRufbrvN3Qhlv/EjxjffQJcucMUVri/2+HjXbrt7d78jMyYyRH+inzXLFQPXrXM9Tr7wgussw4S9detc/W2HDm60oMmT4ccf4Zpr7KKdMccjev9dDh92vR717u1ufVyxwt2fbcJeaqrrJPTcc131zNixruuC4cOtKwJjTkR0XozduNEV+5Ytg9tvd+3vrBQf9nbuhCefdH2aZGa6j+7BB8OnD3RjIlX0JfoPPnCtasCNnNCnj7/xmEIdPAgvvuiG301Lc4N2jR3rrpkbY05e9FTdHDrkurrr08d1J5zdQNeErewuaJs0cZ1YnX++q2GbPt2SvDGhFD2JPjUV3njD1ct/9ZVlijCm6kYIatnS9WN+xhmwcCHMnQutW/sdnTHRJ6hELyI9RGS9iCSJyMg8ljcQkQUiskZEFotITMCyTBFZ5T1mhzL4HBo1cs00Jk60K3Zh7KuvXEvXXr3cPWszZ7rmk127+h2ZMdGr0EQvIqWBycBlQHNggIg0z7XaBOAtVW0JjAXGByw7oKqtvUfPEMWdNxt2JmwlJkLPni7Jb9gAr74KP/wAfftaP+PGFLVgSvTtgSRV3aCqh4F4oFeudZoDC73pRXksNyXQvn2utD5kiKum+eILNwzczz+75pNly/odoTElQzCtbuoBmwNepwDn51pnNdAHeA7oDVQRkZqquh0oLyIJQAbwhKrOOvmwTTjJynItWtesyfn45RdXH1+unLt08sADULOm39EaU/KEqnnlPcCLIjIYWAKkApnesgaqmioijYCFIvK9qv4SuLGIDAWGApx55pkhCskUhbQ01+tgYEL//vujg2mLuN4lWrWCQYNcSf7Pf4bTTvM3bmNKsmASfSoQOOpjjDfvCFXdgivRIyKVgb6qmuYtS/WeN4jIYqAN8Euu7acAU8B1U3wiB2JCKyPDVbHkLqX/+uvRdapXP9pypmVL9zj3XKhUyb+4jTHHCibRLwOaiEgsLsH3B64NXEFEagE7VDULuB+Y6s2vDuxX1UPeOh2Bp0IYvwmBbduOTeiJie7WBIAyZaBZM7jwwqMJvUULN6C2XUg1JvwVmuhVNUNEbgPmAaWBqaqaKCJjcUNXzQa6AONFRHFVN7d6m58DvCoiWbgLv0+o6o9FcBwmCIcOwdq1R6tbspP61q1H1zntNJfIb7/9aFJv1sx6kDAmkpXMEaZKgIwM+PxzWLXqaEJfv97NB5e4zz33aDLPLqXXqeNv3MaYE2MjTJUwqu5CaHy8e92ggUvkf/nL0aTeuLGrkjHGRD/7V49CEya4JP/ww24A5mrV/I7IGOMnS/RRZt48GDkSrr4axoyxi6XGmGjq1MyQlAT9+7u69qlTLckbYxxL9FFizx7XUVjp0m70RGvLbozJZlU3USArC66/3rWq+ewzaNjQ74iMMeHEEn0UGDfOleInTYJu3fyOxhgTbqzqJsLNnu1a11x/Pdxxh9/RGGPCkSX6CLZ2LVx3HcTFwSuv2MVXY0zeLNFHqLQ0d/G1QgU3HnqFCn5HZIwJV1ZHH4EyM+HaayE52Y21GhNT6CbGmBLMEn0EGjXKDaT9yiuuR0ljjCmIVd1EmBkzYPx4NxTfzTf7HY0xJhJYoo8gq1fDjTfCBRfACy/4HY0xJlJYoo8Q27e73ierVYN//9uNw2qMMcGwOvoIkJEB11wDv/0GS5bY+KvGmONjiT4C3HcfLFgA06ZB+/Z+R2OMiTRWdRPmpk+HiRPdXa+DB/sdjTEmElmiD2MJCXDTTdC1qxtMxBhjToQl+jD1++/Qu7erj3/vPShb1u+IjDGRyurow9Dhw3DVVa6lzdKlULu23xEZYyKZJfowdNdd8NVX8O670Lq139EYYyKdVd2Emddeg5dfdi1t+vf3OxpjTDQIKtGLSA8RWS8iSSIyMo/lDURkgYisEZHFIhKTa/mpIpIiIi+GKvBotHQp3HorXHopPP6439EYY6JFoYleREoDk4HLgObAABFpnmu1CcBbqtoSGAuMz7X8UWDJyYcbvVJToW9faNDAVdmULu13RMaYaBFMib49kKSqG1T1MBAP9Mq1TnNgoTe9KHC5iLQD6gKfnXy40engQejTB/budUMCVq/ud0TGmGgSTKKvB2wOeJ3izQu0GujjTfcGqohITREpBTwD3FPQG4jIUBFJEJGEbdu2BRd5lFCFYcPgu+/grbfg3HP9jsgYE21CdTH2HqCziKwEOgOpQCYwHJijqikFbayqU1Q1TlXjapewtoQvvghvvOHGfe3d2+9ojDHRKJjmlalA/YDXMd68I1R1C16JXkQqA31VNU1EOgCdRGQ4UBkoJyJ7VfWYC7ol0eLFMGIE9OwJo0f7HY0xJloFk+iXAU1EJBaX4PsD1wauICK1gB2qmgXcD0wFUNWBAesMBuIsyTubNkG/ftC0qevPppQ1dDXGFJFC04uqZgC3AfOAtcAMVU0UkbEi0tNbrQuwXkR+wl14HVdE8UaF/ftdNU16urv4euqpfkdkjIlmoqp+x5BDXFycJiQk+B1GkVGFgQMhPh4+/hguv9zviIwx0UBElqtqXF7LrAuEYjZhgmsnP368JXljTPGwmuFiNG8ejBzp6ub//ne/ozHGlBSW6ItJUpLru+ZPf3IjRYn4HZExpqSwRF8M9uxxA3uXKuUuvlaq5HdExpiSxOroi1hWFtxwA6xb56puYmP9jsgYU9JYoi9i48bBBx+4cV8vvtjvaIwxJZFV3RSh2bNd1waDBsGdd/odjTGmpLJEX0TWroXrroO4OHj1Vbv4aozxjyX6IpCWBr16QYUK8P777tkYY/xidfQhlpnp7nzduBEWLoT69QvfxhhjipIl+hCbOBHmzIGXXoJOnfyOxhhjrOompNatg4cecm3mb7nF72iMMcaxRB8imZkweDBUrgyvvGIXX40x4cOqbkLkmWfg229dh2V16/odjTHGHGUl+hD48UcYNQr69oVrrvE7GmOMyckS/UnKyHBdHJx6qrsAa1U2xphwY1U3J+nppyEhAWbMgDp1/I7GGGOOZSX6k/DDD25Q73793MMYY8KRJfoTlJ7uWtlUqwaTJ/sdjTHG5M+qbk7Qk0/C8uUwcybUru13NMYYkz8r0Z+ANWtg7Fg3YlTfvn5HY4wxBbNEf5yyq2yqV4cXXvA7GmOMKVxQiV5EeojIehFJEpGReSxvICILRGSNiCwWkZiA+StEZJWIJIpIxHcMMH48rFzp7n6tVcvvaIwxpnCFJnoRKQ1MBi4DmgMDRKR5rtUmAG+paktgLDDem/8b0EFVWwPnAyNF5IxQBV/cVq2CRx91vVP27u13NMYYE5xgSvTtgSRV3aCqh4F4oFeudZoDC73pRdnLVfWwqh7y5p8S5PuFpcOHXZVNrVrw/PN+R2OMMcELJvHWAzYHvE7x5gVaDfTxpnsDVUSkJoCI1BeRNd4+nlTVLbnfQESGikiCiCRs27bteI+hWIwbB6tXu9GiatTwOxpjjAleqErY9wCdRWQl0BlIBTIBVHWzV6XTGLhBRI7p8ktVp6hqnKrG1Q7DtoorVrhEP2gQ9OzpdzTGGHN8gkn0qUDgOEkx3rwjVHWLqvZR1TbAg968tNzrAD8AETUcx6FDrsqmTh147jm/ozHGmOMXTKJfBjQRkVgRKQf0B2YHriAitUQke1/3A1O9+TEiUsGbrg5cCKwPVfDF4dFH4fvv4bXXXJNKY4yJNIUmelXNAG4D5gFrgRmqmigiY0UkuyKjC7BeRH4C6gLjvPnnAN+KyGrgC2CCqn4f4mMoMgkJ8MQTrkR/xRV+R2OMMSdGVNXvGHKIi4vThIQEv8Pg0CFo1w7S0lznZdWq+R2RMcbkT0SWq2pcXsusr5t8PPIIJCa6gb4tyRtjIlnEtmsvSt995zotGzIELrvM72iMMebkWKLP5eBBVyd/xhnw7LN+R2OMMSfPqm5yGT0a1q6FTz+FqlX9jsYYY06elegDfPMNTJgAN90El17qdzTGGBMalug9Bw64KpuYGJfsjTEmWljVjWfUKFi/HubPh1NP9TsaY4wJHSvRA0uXuguvt9wC3bv7HY0xxoRWiU/0+/e7Kpszz4SnnvI7GmOMCb0SX3Xz0EPw88+wYAFUqeJ3NMYYE3olukT/5ZcwaRIMHw7duvkdjTHGFI0Sm+j37XN3vjZs6O6CNcaYaFViq24eeACSkmDRIqhc2e9ojDGm6JTIEv0XX7hxX2+/Hbp08TsaY4wpWiUu0e/d66pszjoLxo/3OxpjjCl6Ja7qZuRI2LjRleorVfI7GmOMKXolqkS/aBFMngx33AGdImrkWmOMOXElJtFnV9k0bgyPP+53NMYYU3xKTNXNfffBpk2u7XzFin5HY4wxxadElOgXLICXX4YRI6BjR7+jMcaY4hX1iX73bldl07QpPPaY39EYY0zxi/qqm3vvhZQU+OorqFDB72iMMab4BVWiF5EeIrJeRJJEZGQeyxuIyAIRWSMii0UkxpvfWkT+IyKJ3rJrQn0ABfnsM5gyBf72N+jQoTjf2RhjwoeoasEriJQGfgIuAVKAZcAAVf0xYJ1/AR+r6psi0g24UVUHiUhTQFX1ZxE5A1gOnKOqafm9X1xcnCYkJJz0ge3aBS1auLbyK1dC+fInvUtjjAlbIrJcVePyWhZM1U17IElVN3g7iwd6AT8GrNMcuNubXgTMAlDVn7JXUNUtIvJfoDaQb6IPlXvugdRUN6iIJXljTEkWTNVNPWBzwOsUb16g1UAfb7o3UEVEagauICLtgXLAL7nfQESGikiCiCRs27Yt2Njz9emn8Prrrn7+/PNPenfGGBPRQtXq5h6gs4isBDoDqUBm9kIROR2YjqvSycq9sapOUdU4VY2rXbv2SQWSlgZ//Ss0bw5jxpzUrowxJioEU3WTCtQPeB3jzTtCVbfglehFpDLQN7seXkROBT4BHlTVb0IRdEHuvhu2boUPPrAqG2OMgeBK9MuAJiISKyLlgP7A7MAVRKSWiGTv635gqje/HPAB8Jaqzgxd2Hn75BOYNg3+/nc477yifjdjjIkMhSZ6Vc0AbgPmAWuBGaqaKCJjRaSnt1oXYL2I/ATUBcZ5868GLgIGi8gq79E61AcBsHMnDB0Kf/oTPPxwUbyDMcZEpqBumFLVOcCcXPMeDpieCRxTYlfVt4G3TzLGoKSnu1L8qFFwyinF8Y7GGBMZoubO2Dp1YNYsv6MwxpjwE/V93RhjTElnid4YY6KcJXpjjIlyluiNMSbKWaI3xpgoZ4neGGOinCV6Y4yJcpbojTEmyhU68EhxE5FtwKaT2EUt4I8QhRPp7FzkZOcjJzsfR0XDuWigqnl2/xt2if5kiUhCfqOslDR2LnKy85GTnY+jov1cWNWNMcZEOUv0xhgT5aIx0U/xO4AwYuciJzsfOdn5OCqqz0XU1dEbY4zJKRpL9MYYYwJYojfGmCgXNYleRHqIyHoRSRKRkX7H4ycRqS8ii0TkRxFJFJE7/Y7JbyJSWkRWisjHfsfiNxGpJiIzRWSdiKwVkQ5+x+QnERnh/Z/8ICLvikh5v2MKtahI9CJSGpgMXAY0BwaISHN/o/JVBvA3VW0O/Bm4tYSfD4A7cWMeG3gO+FRVmwGtKMHnRUTqAXcAcar6J6A00N/fqEIvKhI90B5IUtUNqnoYiAd6+RyTb1T1N1Vd4U3vwf0j1/M3Kv+ISAxwBfC637H4TUSqAhcB/wBQ1cOqmuZvVL4rA1QQkTJARWCLz/GEXLQk+nrA5oDXKZTgxBZIRBoCbYBv/Y3EV5OA+4AsvwMJA7HANmCaV5X1uohU8jsov6hqKjAB+BX4Ddilqp/5G1XoRUuiN3kQkcrAv4G7VHW33/H4QUSuBP6rqsv9jiVMlAHaAi+rahtgH1Bir2mJSHXcr/9Y4Aygkohc529UoRctiT4VqB/wOsabV2KJSFlckn9HVd/3Ox4fdQR6ikgyrkqvm4i87W9IvkoBUlQ1+xfeTFziL6m6AxtVdZuqpgPvAxf4HFPIRUuiXwY0EZFYESmHu5gy2+eYfCMigquDXauqz/odj59U9X5VjVHVhri/i4WqGnUltmCp6lZgs4ic7c26GPjRx5D89ivwZxGp6P3fXEwUXpwu43cAoaCqGSJyGzAPd9V8qqom+hyWnzoCg4DvRWSVN+8BVZ3jY0wmfNwOvOMVijYAN/ocj29U9VsRmQmswLVWW0kUdodgXSAYY0yUi5aqG2OMMfmwRG+MMVHOEr0xxkQ5S/TGGBPlLNEbY0yUs0RvjDFRzhK9McZEuf8H/ogyYT8t54EAAAAASUVORK5CYII=\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 0 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ST3WBdVha1W-","executionInfo":{"status":"ok","timestamp":1626448394011,"user_tz":-120,"elapsed":220,"user":{"displayName":"Lorenzo Pasco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgShaitSLZm3zyLVjMQT7ZzTrEV3kQEXha_A9lkVw=s64","userId":"01314717049817932576"}},"outputId":"e3719473-da9b-4742-9469-7c464e910a01"},"source":["from tabulate import tabulate\n","import matplotlib.pyplot as plt\n","\n","ep = [i+1 for i in epochs]\n","table_acc = {\"Epochs\" : ep, \"Accuracy\":accuracy}\n","table_val_acc = {\"Epochs\" : ep, \"Accuracy\":val_accuracy}\n","\n","print(\"ACCURACY\\n\")\n","print(tabulate(table_acc, headers='keys', tablefmt='fancy_grid'))\n","print(\"\\nVALIDATION ACCURACY\\n\")\n","print(tabulate(table_val_acc, headers='keys', tablefmt='fancy_grid'))"],"execution_count":5,"outputs":[{"output_type":"stream","text":["ACCURACY\n","\n","╒══════════╤════════════╕\n","│   Epochs │   Accuracy │\n","╞══════════╪════════════╡\n","│        1 │   0.951397 │\n","├──────────┼────────────┤\n","│        2 │   0.959541 │\n","├──────────┼────────────┤\n","│        3 │   0.967177 │\n","├──────────┼────────────┤\n","│        4 │   0.972456 │\n","├──────────┼────────────┤\n","│        5 │   0.973735 │\n","├──────────┼────────────┤\n","│        6 │   0.97299  │\n","├──────────┼────────────┤\n","│        7 │   0.97438  │\n","├──────────┼────────────┤\n","│        8 │   0.973679 │\n","├──────────┼────────────┤\n","│        9 │   0.979165 │\n","├──────────┼────────────┤\n","│       10 │   0.981964 │\n","╘══════════╧════════════╛\n","\n","VALIDATION ACCURACY\n","\n","╒══════════╤════════════╕\n","│   Epochs │   Accuracy │\n","╞══════════╪════════════╡\n","│        1 │   0.918365 │\n","├──────────┼────────────┤\n","│        2 │   0.934602 │\n","├──────────┼────────────┤\n","│        3 │   0.948095 │\n","├──────────┼────────────┤\n","│        4 │   0.950049 │\n","├──────────┼────────────┤\n","│        5 │   0.955895 │\n","├──────────┼────────────┤\n","│        6 │   0.957401 │\n","├──────────┼────────────┤\n","│        7 │   0.958614 │\n","├──────────┼────────────┤\n","│        8 │   0.954465 │\n","├──────────┼────────────┤\n","│        9 │   0.960721 │\n","├──────────┼────────────┤\n","│       10 │   0.961333 │\n","╘══════════╧════════════╛\n"],"name":"stdout"}]}]}